{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900c4d38-4f3a-48ce-826b-98bcd5a44744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d75825-c192-419a-a7f1-6819aac18aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dev/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.3.0+cu118 available.\n",
      "PyTorch version 2.3.0+cu118 available.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext, Settings\n",
    "from llama_index.core.indices import load_index_from_storage\n",
    "from llama_index.core import VectorStoreIndex, DocumentSummaryIndex\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "import chromadb\n",
    "import torch\n",
    "import model_utils\n",
    "import prompt_utils\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d1d2e1-ccdf-415e-ae2b-aee2b508bc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: models/bge-small-en-v1.5\n",
      "Load pretrained SentenceTransformer: models/bge-small-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# loads BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"models/bge-small-en-v1.5\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2205677e-2bfa-479e-962f-59ba71a5e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model with quantization config from: models/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786a9e07bebb434796a7be7aa855ae84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load local llm llama\n",
    "model_name = \"models/Llama-2-7b-chat-hf\"\n",
    "model, tokenizer = model_utils.load_quantized_model(\n",
    "    model_name_or_path=model_name,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# config llm and embed_model to llamaindex\n",
    "llm_hf = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=512,\n",
    "    query_wrapper_prompt=PromptTemplate(\"<s> [INST] {query_str} [/INST] \"),\n",
    "    generate_kwargs={\n",
    "        \"temperature\": 0.7,\n",
    "        \"do_sample\": True\n",
    "    },\n",
    "    device_map=\"cuda\",\n",
    "    model_name=\"models/Llama-2-7b-chat-hf\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576f25f1-000c-40e5-9769-ed8cdce0ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings.embed_model = embed_model\n",
    "# Settings.llm = llm_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbd071-6987-44ea-a43c-853c4d1878e2",
   "metadata": {},
   "source": [
    "## Load vector index and document summary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9a2bad-01a8-4ed0-aa4d-fb9f103db78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# Creates a persistent instance of Chroma that saves to disk\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0174fe7b-6ac2-412d-a2bf-4022824784a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(id=3186f0ec-26e5-46fa-b687-281a3a26066f, name=llama_index_blogs),\n",
       " Collection(id=46aee9cc-50b0-4474-90d9-61e1e160c15d, name=blogs_vector_index),\n",
       " Collection(id=cf744ea1-c23d-41c8-8204-363adcd4b3fe, name=llma_blogs_summary),\n",
       " Collection(id=e2bc79ee-49dd-45e4-85f3-6acb87185f7a, name=blogs_summary)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ae16af-4694-462c-9264-84f64ea9d500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x7fb93167fee0>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x7fb933a79a20>, vector_stores={'default': ChromaVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=True, collection_name=None, host=None, port=None, ssl=False, headers=None, persist_dir=None, collection_kwargs={}), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x7fb93169d480>, property_graph_store=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create a collection with the given name and metadata.\n",
    "vector_collection = chroma_client.get_or_create_collection(\"blogs_vector_index\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=vector_collection)\n",
    "vector_storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "vector_storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b88d17f-4832-4fa8-aeee-139afb439670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7fb93169da50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your index from stored vectors\n",
    "vector_index = VectorStoreIndex.from_vector_store(\n",
    "    llm=llm_hf,\n",
    "    embed_model=embed_model,\n",
    "    vector_store=vector_store, \n",
    "    storage_context=vector_storage_context\n",
    ")\n",
    "vector_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d00da3-837e-4718-9fe9-565b97e4d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x7fb93169d150>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x7fb90e11b910>, vector_stores={'default': ChromaVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=True, collection_name=None, host=None, port=None, ssl=False, headers=None, persist_dir=None, collection_kwargs={})}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x7fb90e11b6a0>, property_graph_store=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create a collection with the given name and metadata.\n",
    "doc_sum_collection = chroma_client.get_or_create_collection(\"blogs_summary\")\n",
    "doc_sum_vector_store = ChromaVectorStore(\n",
    "    chroma_collection=doc_sum_collection\n",
    ")\n",
    "\n",
    "doc_sum_storage_context = StorageContext.from_defaults(\n",
    "    vector_store=doc_sum_vector_store,\n",
    "    persist_dir=\"./database/blogs_summary_index/\"\n",
    ")\n",
    "doc_sum_storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48cd9948-aed2-43d5-bc9f-fef2e475a224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.document_summary.base.DocumentSummaryIndex at 0x7fb93169cf70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_summary_index = load_index_from_storage(\n",
    "    llm=llm_hf,\n",
    "    embed_model=embed_model,\n",
    "    storage_context=doc_sum_storage_context\n",
    ")\n",
    "doc_summary_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2ec04-be0d-43da-8c94-451f6d97d21a",
   "metadata": {},
   "source": [
    "## Advanced Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2b3add-bc1b-45b9-8853-f70d064d8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What are key features of llama-agents?\"\n",
    "question2 = '''\n",
    "What are the two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook?\n",
    "'''\n",
    "question3 = '''\n",
    "What are the two main metrics used to evaluate the performance of the different rerankers in the RAG system?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9878ad79-6471-4ca0-88e3-9bae6b6e9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ref_docs(resp_metadata):\n",
    "    print(\"References:\")\n",
    "    base_url = \"https://www.llamaindex.ai/blog/\"\n",
    "    for idx, (_, doc_metatada) in enumerate(resp_metadata.items()):\n",
    "        ref_url = base_url + doc_metatada['file_name'].split(\".\")[0]\n",
    "        print(f\"{idx+1}.\", ref_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d3e20a2-9f26-4b0b-aabe-77412cb7b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm_hf\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "454cd317-734e-4e83-b40f-dc2fcb6a8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracing log\n",
    "import llama_index.core\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "llama_index.core.set_global_handler(\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0798e7b-0335-48dd-b1e0-7f0d0ce73021",
   "metadata": {},
   "source": [
    "### VectorIndex as query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df6e2f68-c30f-4e93-8907-b6a4a3a6a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine = vector_index.as_query_engine(\n",
    "    response_mode=\"compact\", \n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2705ecb5-9c2e-4ab9-9783-ddd88815e78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are key features of llama-agents?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3b3b4110944caf887f1f7de8e1d4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the provided context information, the key features of llama-agents are:\n",
       "\n",
       "1. Distributed Service Oriented Architecture: LlamaIndex allows each agent to be its own independently running microservice, with a fully customizable LLM-powered control plane that routes and distributes tasks.\n",
       "2. Communication via standardized API interfaces: Agents can communicate with each other using a central control plane orchestrator, and pass messages between agents using a message queue.\n",
       "3. Define agentic and explicit orchestration flows: Developers have the flexibility to directly define the sequence of interactions between agents or leave it up to an \"agentic orchestrator\" that decides which agents are relevant to the task.\n",
       "4. Ease of deployment: LlamaIndex allows developers to launch, scale, and monitor each agent and the control plane independently.\n",
       "5. Scalability and resource management: LlamaIndex provides built-in observability tools to monitor the quality and performance of the system and each individual agent service.\n",
       "\n",
       "These are the main features of llama-agents, based on the context information provided."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References:\n",
      "1. https://www.llamaindex.ai/blog/introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\", question1)\n",
    "response1 = vector_query_engine.query(question1)\n",
    "display_response(response1)\n",
    "print_ref_docs(response1.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3bb3b-edf3-415d-ad13-b240e1110a09",
   "metadata": {},
   "source": [
    "### DocumentSummaryIndex as query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f8a6d6c-d8d1-4a62-a018-295db831d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = doc_summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", \n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25a1edea-2b81-4c01-b8cd-44b03d345a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are key features of llama-agents?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33697f5f34b1488884e902bb5c1bb832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\", question1)\n",
    "response = summary_query_engine.query(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c406b85-5e5f-4eaf-8ffa-03e433f62daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the information provided in the article, the key features of LlmaAgents are:\n",
       "\n",
       "1. Vector database: LlmaAgents use a vector database created from DiffusionDB, which is a large-scale knowledge graph that contains billions of vectors. This database is used to suggest better prompts when generating images.\n",
       "2. Text-to-image prompts: LlmaAgents can generate text-to-image prompts using the transformers model. This allows for the generation of images from text descriptions.\n",
       "3. Temperature variable: The temperature variable allows for controlling the variation in the generated prompts. With a temperature above zero, each prompt generated by LlmaIndex with the same agent prompt will be brand new.\n",
       "4. Custom tools: LlmaAgents can be used to distribute and share custom tools in Transformers Agents using Hugging Face Spaces.\n",
       "5. Easy to use: The article mentions that the tool is easy to use, and the author provides an example of how to use the tool in the article.\n",
       "6. Improved image generation: The article claims that the tool can generate more stylized and varied images compared to the existing image-generator tool.\n",
       "\n",
       "Overall, LlmaAgents are a powerful tool for generating text-to-image prompts using transformers models, and they offer a range of features that make them easy to use and customize."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References:\n",
      "1. https://www.llamaindex.ai/blog/llamaindex-and-transformers-agents-67042ee1d8d6\n"
     ]
    }
   ],
   "source": [
    "display_response(response)\n",
    "print_ref_docs(response.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80060b08-2593-4ab0-98c9-8705aa91c504",
   "metadata": {},
   "source": [
    "### Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33419a7-905b-432f-a229-239141005973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cdf40ce-8618-40c8-8339-af673f5f8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tool = QueryEngineTool(\n",
    "    vector_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for retrieving specific context\"\n",
    "    )\n",
    ")\n",
    "\n",
    "summary_tool = QueryEngineTool(\n",
    "    summary_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarization questions related to document content\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467dd416-3d56-4e3a-90b4-5603bdacbfbe",
   "metadata": {},
   "source": [
    "#### Single selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdd69932-6246-4a34-80fe-204cf685ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_query_engine = RouterQueryEngine.from_defaults(\n",
    "    [vector_tool, summary_tool],\n",
    "    selector=LLMSingleSelector.from_defaults()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3241687-4f71-4f9c-b1e1-9b28d02860da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 0: Useful for retrieving specific context.\n",
      "Selecting query engine 0: Useful for retrieving specific context.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d403f6b018d430c8586232003fc392b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = router_query_engine.query(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8826a0c-0f62-409b-b7b1-67b01e517529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The key features of llama-agents are:\n",
       "\n",
       "1. Distributed Service Oriented Architecture: Every agent in LlamaIndex can be its own independently running microservice, orchestrated by a fully customizable LLM-powered control plane that routes and distributes tasks.\n",
       "2. Communication via standardized API interfaces: Interface between agents using a central control plane orchestrator. Pass messages between agents using a message queue.\n",
       "3. Define agentic and explicit orchestration flows: Developers have the flexibility to directly define the sequence of interactions between agents, or leave it up to an “agentic orchestrator” that decides which agents are relevant to the task.\n",
       "4. Ease of deployment: Launch, scale, and monitor each agent and your control plane independently.\n",
       "5. Scalability and resource management: Use built-in observability tools to monitor the quality and performance of the system and each individual agent service."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "180594fd-888b-412a-a1fe-9316a623a96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'05e03730-b3db-464d-831f-b87fd9c5e3b7': {'file_path': '/workspace/projects/LlamindexHelper/data/introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems.html',\n",
       "  'file_name': 'introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems.html',\n",
       "  'file_type': 'text/html',\n",
       "  'file_size': 18790,\n",
       "  'creation_date': '2024-07-21',\n",
       "  'last_modified_date': '2024-07-21'},\n",
       " 'selector_result': MultiSelection(selections=[SingleSelection(index=0, reason='Useful for retrieving specific context')])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a46bc278-3fa3-485a-8e5b-f0478204268b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Got invalid JSON object. Error: Expecting property name enclosed in double quotes: line 2 column 5 (char 6) expected '<document start>', but found '<block mapping start>'\n  in \"<unicode string>\", line 6, column 1:\n    Here is the JSON output:\n    ^. Got JSON string: {\n    choice: 1,\n    reason: \"The question is asking for specific context, so choice 1 is the most relevant. The RAG system is used to evaluate and monitor the performance of a system, and choice 1 is the most relevant because it is the most useful for retrieving specific context related to the system's performance.\"\n}\n\nHere is the JSON output:\n[\n    {\n        choice: 1,\n        reason: \"The question is asking for specific context\"\n    }",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/output_parsers/selection.py:75\u001b[0m, in \u001b[0;36mSelectionOutputParser.parse\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e_json:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 2 column 5 (char 6)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/output_parsers/selection.py:84\u001b[0m, in \u001b[0;36mSelectionOutputParser.parse\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# NOTE: parsing again with pyyaml\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m#       pyyaml is less strict, and allows for trailing commas\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m#       right now we rely on this since guidance program generates\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m#       trailing commas\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mYAMLError \u001b[38;5;28;01mas\u001b[39;00m e_yaml:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/yaml/__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mParse the first YAML document in a stream\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mand produce the corresponding Python object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mto be safe for untrusted input.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/yaml/constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/yaml/composer.py:39\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStreamEndEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     40\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/yaml/parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/yaml/parser.py:171\u001b[0m, in \u001b[0;36mParser.parse_document_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(DocumentStartToken):\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<document start>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, but found \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeek_token()\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    174\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeek_token()\u001b[38;5;241m.\u001b[39mstart_mark)\n\u001b[1;32m    175\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n",
      "\u001b[0;31mParserError\u001b[0m: expected '<document start>', but found '<block mapping start>'\n  in \"<unicode string>\", line 6, column 1:\n    Here is the JSON output:\n    ^",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrouter_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/query_engine/router_query_engine.py:170\u001b[0m, in \u001b[0;36mRouterQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RESPONSE_TYPE:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    168\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    169\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[0;32m--> 170\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result\u001b[38;5;241m.\u001b[39minds) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    173\u001b[0m             responses \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/base/base_selector.py:88\u001b[0m, in \u001b[0;36mBaseSelector.select\u001b[0;34m(self, choices, query)\u001b[0m\n\u001b[1;32m     86\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [_wrap_choice(choice) \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices]\n\u001b[1;32m     87\u001b[0m query_bundle \u001b[38;5;241m=\u001b[39m _wrap_query(query)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchoices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/selectors/llm_selectors.py:118\u001b[0m, in \u001b[0;36mLLMSingleSelector._select\u001b[0;34m(self, choices, query)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# parse output\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt\u001b[38;5;241m.\u001b[39moutput_parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m parse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _structured_output_to_selector_result(parse)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/output_parsers/selection.py:86\u001b[0m, in \u001b[0;36mSelectionOutputParser.parse\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     84\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(json_string)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mYAMLError \u001b[38;5;28;01mas\u001b[39;00m e_yaml:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot invalid JSON object. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me_yaml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot JSON string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pip install PyYAML.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting property name enclosed in double quotes: line 2 column 5 (char 6) expected '<document start>', but found '<block mapping start>'\n  in \"<unicode string>\", line 6, column 1:\n    Here is the JSON output:\n    ^. Got JSON string: {\n    choice: 1,\n    reason: \"The question is asking for specific context, so choice 1 is the most relevant. The RAG system is used to evaluate and monitor the performance of a system, and choice 1 is the most relevant because it is the most useful for retrieving specific context related to the system's performance.\"\n}\n\nHere is the JSON output:\n[\n    {\n        choice: 1,\n        reason: \"The question is asking for specific context\"\n    }"
     ]
    }
   ],
   "source": [
    "response = router_query_engine.query(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54ffb6-a666-460c-acb7-39a70f3d5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434921b-ee41-4681-83d2-8f9c1ef5fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = router_query_engine.query(question3)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d87ac-c836-4886-8133-e48e23eb05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary_question = \"What is the summmarization of bridging-the-gap-in-crisis-counseling-introducing-counselor-copilot document?\"\n",
    "response = router_query_engine.query(test_summary_question)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61953756-3702-48d4-a831-087dea86b9f3",
   "metadata": {},
   "source": [
    "### MultiSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db9dde-4d4f-45cb-b68f-f48374c0f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_selector_query_engine = RouterQueryEngine(\n",
    "    selector=LLMMultiSelector.from_defaults(),\n",
    "    query_engine_tools=[vector_tool, summary_tool],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32db4d0-e601-4d51-a9f1-877f92262f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(question1)\n",
    "response = multi_selector_query_engine.query(question1)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f4496-9004-47c6-a9ed-dde0ad77f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(question2)\n",
    "response = multi_selector_query_engine.query(question2)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7d5d1-c111-4875-9333-42f53721f7f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(question3)\n",
    "response = multi_selector_query_engine.query(question3)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effa0b8-7372-4258-a2c4-f009e22b0441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(question3)\n",
    "response = multi_selector_query_engine.query(question3)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8616286-409f-4771-80e3-ad9cc3c6ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = multi_selector_query_engine.query(\"What are diffusion models?\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f046b42-6c6a-48f7-9f60-ff89416c62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ce9c6-8d9f-4291-b460-71cdef443159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_torch230_py310",
   "language": "python",
   "name": "llm_torch230_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
