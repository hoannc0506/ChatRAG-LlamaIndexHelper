{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c24241f-c73f-464f-ae20-39b73d75dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11e43fb-a685-4c1b-8be3-b5f9b1dc56d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.3.0+cu118 available.\n",
      "PyTorch version 2.3.0+cu118 available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.callbacks import CallbackManager, TokenCountingHandler\n",
    "from IPython.display import display, Markdown\n",
    "import tiktoken\n",
    "import random\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e24e7857-f238-4dd8-8c92-9d69f32592e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator with openai models\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad2ec5d-5565-4dd9-bdff-ab9439952dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-4o-mini\").encode,\n",
    "    verbose=True\n",
    ")\n",
    "Settings.callback_manager = CallbackManager([token_counter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e619f8c-bf89-418c-be67-15f2a0a15b5d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51087d4-1b24-4963-b81f-5ce429d485df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num documents: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents: 100%|██████████| 166/166 [00:00<00:00, 10998.24it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = data_utils.load_md_documents(\n",
    "    docs_dir='./data/llama-blogs-md',\n",
    "    docs_metadata='./data/llama_blogs_metadata.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e342e478-17e7-412f-8684-2e815858ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random doc only\n",
    "test_docs = random.sample(documents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7a7f2de-b56b-4a5e-a825-c90aae6a8d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Dynamic Retrieval with LlamaCloud"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Building a robust question-answering assistant requires dynamically retrieving\n",
       "the most relevant information for each query. Sometimes a short snippet\n",
       "provides a complete answer, while other questions need the full context of an\n",
       "entire document (e.g. “Give me a summary of this book”).\n",
       "\n",
       "For questions that fall into the latter category, top-k vector search falls\n",
       "short; rather than just retrieving the top-k chunks that match, you need to\n",
       "intentionally retrieve the entire document text and feed that into the context\n",
       "window of the LLM.\n",
       "\n",
       "To address this, we’re excited to release **file-level retrieval** for\n",
       "LlamaCloud, which is a separate retrieval API from our existing **chunk-level\n",
       "retrieval** capabilities. This retrieval interface then paves the way for us\n",
       "to build an agent that can dynamically route the question to the right\n",
       "retrieval interface depending on the properties of the question, which allows\n",
       "it to more robustly handle different user questions.\n",
       "\n",
       "##  File-Level Retrieval\n",
       "\n",
       "This me"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"# {test_docs[0].metadata['title']}\"))\n",
    "display(Markdown(test_docs[0].text[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a658294-3266-4de6-a74b-5f79ab65aaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.llamaindex.ai/blog/dynamic-retrieval-with-llamacloud'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs[0].metadata['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54121424-2839-4bf2-8d6f-55feb7653a27",
   "metadata": {},
   "source": [
    "## Generate questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dba85f1-62d0-491f-983a-cdb19042fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_llama_index(\n",
    "    generator_llm=Settings.llm,\n",
    "    critic_llm=Settings.llm,\n",
    "    embeddings=Settings.embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77401aca-607a-4a1f-8753-8b740641aa7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:   0%|          | 0/56 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:   2%|▏         | 1/56 [00:00<00:33,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 905\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 828\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 797\n",
      "Embedding Token Usage: 868\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  11%|█         | 6/56 [00:00<00:04, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 183\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 712\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  16%|█▌        | 9/56 [00:01<00:04,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1169\n",
      "LLM Completion Token Usage: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Interactive chat bots', 'Multi-agent system', 'Concierge agent', 'Task agents', 'Global state']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 876\n",
      "LLM Prompt Token Usage: 1068\n",
      "LLM Completion Token Usage: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['RAG Pipelines', 'LlamaIndex', 'Retrieval Augmented Generation', 'Multimodal RAG Systems', 'No-Code RAG Pipeline']}\n",
      "embedding nodes:  20%|█▉        | 11/56 [00:01<00:04, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 295\n",
      "LLM Completion Token Usage: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Training code', 'Llama Index', 'Fine-tuning', 'Embeddings', 'Adapter utilities']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1085\n",
      "LLM Completion Token Usage: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaCloud', 'Production-quality data processing', 'Chat interface', 'Developer collaboration', 'Data and metadata access']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1197\n",
      "LLM Completion Token Usage: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaIndex', 'Generative AI', 'LLMs as reasoning engines', 'Data architecture for LLM apps', 'Seed funding']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1002\n",
      "LLM Completion Token Usage: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaExtract', 'Resume metadata', 'Schema creation', 'Multimodal extraction', 'Extraction capabilities']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Prompt Token Usage: 1139\n",
      "LLM Completion Token Usage: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaIndex updates', '$2,000 bounty program', 'Ollama Multimodal Integration', 'Enhanced RAG', 'Nomic Embedding']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  29%|██▊       | 16/56 [00:01<00:02, 17.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Prompt Token Usage: 1194\n",
      "LLM Completion Token Usage: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaIndex', 'Data management', 'Data querying', 'Open-source data framework', 'LLM applications']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 671\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  38%|███▊      | 21/56 [00:01<00:01, 19.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1125\n",
      "LLM Completion Token Usage: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Question-answering assistant', 'File-level retrieval', 'Dynamic retrieval', 'Chunk-level retrieval', 'LlamaCloud']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 834\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 538\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  43%|████▎     | 24/56 [00:01<00:01, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 244\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 19\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1075\n",
      "LLM Completion Token Usage: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Transfer money', 'Authentication agent', 'Account balance agent', 'Orchestration agent', 'Continuation agent']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 863\n",
      "LLM Completion Token Usage: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LLM apps', 'Production-ready data ingestion', 'Domain-specific LLM solutions', 'Foundation Model Development', 'MLOps']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Prompt Token Usage: 416\n",
      "LLM Completion Token Usage: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaCloud', 'Enhanced retrieval capabilities', 'Chunk-level and file-level retrieval', 'Nuanced and accurate systems', 'Enterprise plans']}\n",
      "embedding nodes:  50%|█████     | 28/56 [00:01<00:01, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 485\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1015\n",
      "LLM Completion Token Usage: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Money transfer', 'Continuation agent', 'Orchestration agent', 'Account balance', 'Transfer completion']}\n",
      "embedding nodes:  55%|█████▌    | 31/56 [00:01<00:01, 21.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 855\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1087\n",
      "LLM Completion Token Usage: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['RAG applications', 'Jamba-Instruct', '256K context window', 'LlamaIndex', 'AI21 Labs']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1079\n",
      "LLM Completion Token Usage: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaIndex newsletter', 'LlamaIndex Workflows', 'Dynamic retrieval feature', 'LlamaCloud', 'LongRAG LlamaPack']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  62%|██████▎   | 35/56 [00:02<00:00, 21.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 212\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1088\n",
      "LLM Completion Token Usage: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['ReAct agent', 'LlamaIndex workflows', 'Event-Driven RAG Pipeline', 'MLflow', 'Hybrid Search']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1063\n",
      "LLM Completion Token Usage: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['RAG system', 'Query engine', \"Company's revenue\", 'Jamba-Instruct', 'Context window']}\n",
      "embedding nodes:  68%|██████▊   | 38/56 [00:02<00:00, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 119\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 234\n",
      "LLM Completion Token Usage: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['ze AI', 'August 13th']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 926\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 808\n",
      "LLM Completion Token Usage: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Current state of the user', 'Current speaker', 'Chat history', 'Sub-agent', 'Authentication process']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  75%|███████▌  | 42/56 [00:02<00:00, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 861\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 770\n",
      "LLM Completion Token Usage: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['current speaker', 'transfer money agent', 'concierge agent', 'chat history', 'continuation agent']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 769\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  82%|████████▏ | 46/56 [00:02<00:00, 25.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 438\n",
      "LLM Completion Token Usage: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Task orchestration', 'Continuation agent', 'Multi-agent coordination', 'Natural language instructions', 'Global state management']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 687\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding nodes:  88%|████████▊ | 49/56 [00:02<00:00, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 997\n",
      "LLM Completion Token Usage: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Synthetic question-context dataset', 'Fine-tuning logic', 'Embedding model', 'Linear adapter', 'Sentence-transformers']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1223\n",
      "LLM Completion Token Usage: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Lyzr', 'Autonomous AI agents', 'Organizational General Intelligence (OGI)', 'LlamaIndex', 'Retrieval-Augmented Generation (RAG)']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1190\n",
      "LLM Completion Token Usage: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Structured extraction', 'LlamaExtract', 'Unstructured data', 'Schema inference', 'Metadata extraction']}\n",
      "embedding nodes:  93%|█████████▎| 52/56 [00:02<00:00, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1098\n",
      "LLM Completion Token Usage: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Fine-tuning job', 'LinearAdapterEmbeddingModel', 'Hit-rate metric', 'Mean Reciprocal Rank', 'LlamaIndex module']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1140\n",
      "LLM Completion Token Usage: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaIndex', 'Fine-tune linear adapter', 'Embedding representations', 'Retrieval performance', 'Document embeddings']}\n",
      "embedding nodes:  96%|█████████▋| 54/56 [00:03<00:00, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 340\n",
      "LLM Completion Token Usage: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['LlamaCloud', 'Autonomous AI agent technology', 'Enterprise solutions', 'Expand offerings', 'Leader in technology']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 504\n",
      "LLM Completion Token Usage: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.extractor.DEBUG] topics: {'keyphrases': ['Stock split', 'Amazon.com, Inc.', 'Long context model', 'RAG system', 'Enterprise contexts']}\n",
      "Generating:   0%|          | 0/10 [00:00<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['RAG Pipelines', 'LlamaIndex', 'Retrieval Augmented Generation', 'Multimodal RAG Systems', 'No-Code RAG Pipeline']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['RAG Pipelines', 'LlamaIndex', 'Retrieval Augmented Generation', 'Multimodal RAG Systems', 'No-Code RAG Pipeline']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Stock split', 'Amazon.com, Inc.', 'Long context model', 'RAG system', 'Enterprise contexts']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Stock split', 'Amazon.com, Inc.', 'Long context model', 'RAG system', 'Enterprise contexts']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Structured extraction', 'LlamaExtract', 'Unstructured data', 'Schema inference', 'Metadata extraction']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Structured extraction', 'LlamaExtract', 'Unstructured data', 'Schema inference', 'Metadata extraction']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Stock split', 'Amazon.com, Inc.', 'Long context model', 'RAG system', 'Enterprise contexts']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Stock split', 'Amazon.com, Inc.', 'Long context model', 'RAG system', 'Enterprise contexts']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaIndex newsletter', 'LlamaIndex Workflows', 'Dynamic retrieval feature', 'LlamaCloud', 'LongRAG LlamaPack']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaIndex newsletter', 'LlamaIndex Workflows', 'Dynamic retrieval feature', 'LlamaCloud', 'LongRAG LlamaPack']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Transfer money', 'Authentication agent', 'Account balance agent', 'Orchestration agent', 'Continuation agent']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Transfer money', 'Authentication agent', 'Account balance agent', 'Orchestration agent', 'Continuation agent']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Structured extraction', 'LlamaExtract', 'Unstructured data', 'Schema inference', 'Metadata extraction']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Structured extraction', 'LlamaExtract', 'Unstructured data', 'Schema inference', 'Metadata extraction']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['ReAct agent', 'LlamaIndex workflows', 'Event-Driven RAG Pipeline', 'MLflow', 'Hybrid Search']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['ReAct agent', 'LlamaIndex workflows', 'Event-Driven RAG Pipeline', 'MLflow', 'Hybrid Search']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['RAG Pipelines', 'LlamaIndex', 'Retrieval Augmented Generation', 'Multimodal RAG Systems', 'No-Code RAG Pipeline']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['RAG Pipelines', 'LlamaIndex', 'Retrieval Augmented Generation', 'Multimodal RAG Systems', 'No-Code RAG Pipeline']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Transfer money', 'Authentication agent', 'Account balance agent', 'Orchestration agent', 'Continuation agent']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Transfer money', 'Authentication agent', 'Account balance agent', 'Orchestration agent', 'Continuation agent']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What significant event involving Amazon.com, Inc. occurred in the last five years?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What significant event involving Amazon.com, Inc. occurred in the last five years?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What new feature has been introduced in LlamaCloud to enhance QA assistants?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What new feature has been introduced in LlamaCloud to enhance QA assistants?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of structured extraction in the context of LlamaExtract?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of structured extraction in the context of LlamaExtract?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of long context models in enterprise contexts?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of long context models in enterprise contexts?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of Retrieval Augmented Generation in the context of the provided tutorials and workshops?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of Retrieval Augmented Generation in the context of the provided tutorials and workshops?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does unstructured data play in the context of LlamaExtract and its functionalities?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does unstructured data play in the context of LlamaExtract and its functionalities?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does the orchestration agent play in the process of transferring money?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does the orchestration agent play in the process of transferring money?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of hybrid search in building smarter agents using LlamaIndex?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of hybrid search in building smarter agents using LlamaIndex?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the role of the account balance agent in the process of transferring money?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the role of the account balance agent in the process of transferring money?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question clearly asks about the role of the account balance agent in the money transfer process. It is specific and independent, as it does not rely on external references or additional context to be understood. The intent is clear, seeking information about a particular function within a defined process. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question clearly asks about the role of the account balance agent in the money transfer process. It is specific and independent, as it does not rely on external references or additional context to be understood. The intent is clear, seeking information about a particular function within a defined process. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What is the role of the account balance agent in the process of transferring money?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What is the role of the account balance agent in the process of transferring money?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a significant event involving Amazon.com, Inc. within the last five years. It is relatively clear in its intent, seeking information about a notable occurrence related to the company. However, the term 'significant event' is somewhat vague and could encompass a wide range of topics, such as financial milestones, product launches, legal issues, or corporate changes. To improve clarity and answerability, the question could specify the type of event of interest (e.g., financial, operational, legal) or provide a particular context (e.g., impact on the market, consumer response).\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a significant event involving Amazon.com, Inc. within the last five years. It is relatively clear in its intent, seeking information about a notable occurrence related to the company. However, the term 'significant event' is somewhat vague and could encompass a wide range of topics, such as financial milestones, product launches, legal issues, or corporate changes. To improve clarity and answerability, the question could specify the type of event of interest (e.g., financial, operational, legal) or provide a particular context (e.g., impact on the market, consumer response).\", 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about a specific new feature introduced in LlamaCloud aimed at enhancing QA assistants. It is clear in its intent and specifies the subject matter (LlamaCloud and QA assistants), making it understandable. However, it assumes that the reader is familiar with LlamaCloud and its previous features, which may not be the case for everyone. To improve clarity and answerability, the question could provide a brief context about LlamaCloud or mention the type of features typically associated with QA assistants, which would help those unfamiliar with the topic to better understand the question.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about a specific new feature introduced in LlamaCloud aimed at enhancing QA assistants. It is clear in its intent and specifies the subject matter (LlamaCloud and QA assistants), making it understandable. However, it assumes that the reader is familiar with LlamaCloud and its previous features, which may not be the case for everyone. To improve clarity and answerability, the question could provide a brief context about LlamaCloud or mention the type of features typically associated with QA assistants, which would help those unfamiliar with the topic to better understand the question.', 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Retrieval Augmented Generation (RAG) in relation to 'the provided tutorials and workshops', but it does not specify what those tutorials and workshops entail or how they relate to RAG. This lack of context makes it difficult to provide a focused answer. To improve clarity and answerability, the question could specify the content or objectives of the tutorials and workshops, or explain how RAG is expected to be applied within that context. This would help clarify the intent and allow for a more precise response.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Retrieval Augmented Generation (RAG) in relation to 'the provided tutorials and workshops', but it does not specify what those tutorials and workshops entail or how they relate to RAG. This lack of context makes it difficult to provide a focused answer. To improve clarity and answerability, the question could specify the content or objectives of the tutorials and workshops, or explain how RAG is expected to be applied within that context. This would help clarify the intent and allow for a more precise response.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of long context models specifically in enterprise contexts. It is clear in its intent, focusing on the importance of long context models and their application in a particular setting (enterprise). However, the term 'long context models' may require some prior knowledge to fully understand, as it is not defined within the question. To improve clarity and answerability, the question could briefly define what is meant by 'long context models' or provide examples of such models. Additionally, specifying what aspects of significance are of interest (e.g., efficiency, effectiveness, cost savings) could further enhance the clarity of the question.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of long context models specifically in enterprise contexts. It is clear in its intent, focusing on the importance of long context models and their application in a particular setting (enterprise). However, the term 'long context models' may require some prior knowledge to fully understand, as it is not defined within the question. To improve clarity and answerability, the question could briefly define what is meant by 'long context models' or provide examples of such models. Additionally, specifying what aspects of significance are of interest (e.g., efficiency, effectiveness, cost savings) could further enhance the clarity of the question.\", 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of hybrid search in the context of building smarter agents with LlamaIndex. It is specific in its focus on hybrid search and its application to LlamaIndex, which helps clarify the intent. However, the term 'hybrid search' may require additional context for those unfamiliar with the concept or its relevance to LlamaIndex. To improve clarity and answerability, the question could briefly define what hybrid search entails or specify the aspects of 'smarter agents' being referred to (e.g., efficiency, accuracy, adaptability).\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of hybrid search in the context of building smarter agents with LlamaIndex. It is specific in its focus on hybrid search and its application to LlamaIndex, which helps clarify the intent. However, the term 'hybrid search' may require additional context for those unfamiliar with the concept or its relevance to LlamaIndex. To improve clarity and answerability, the question could briefly define what hybrid search entails or specify the aspects of 'smarter agents' being referred to (e.g., efficiency, accuracy, adaptability).\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the significance of hybrid search in building smarter agents using LlamaIndex?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the significance of hybrid search in building smarter agents using LlamaIndex?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the purpose of structured extraction specifically in the context of LlamaExtract. It is clear in its intent, specifying both the concept (structured extraction) and the framework (LlamaExtract) it pertains to. However, the term 'structured extraction' may require some prior knowledge of the field to fully understand its implications. To enhance clarity and answerability, the question could briefly define what structured extraction entails or provide a bit of context about LlamaExtract, especially for those who may not be familiar with it.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the purpose of structured extraction specifically in the context of LlamaExtract. It is clear in its intent, specifying both the concept (structured extraction) and the framework (LlamaExtract) it pertains to. However, the term 'structured extraction' may require some prior knowledge of the field to fully understand its implications. To enhance clarity and answerability, the question could briefly define what structured extraction entails or provide a bit of context about LlamaExtract, especially for those who may not be familiar with it.\", 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of unstructured data in relation to LlamaExtract and its functionalities. It is specific in its focus on unstructured data and LlamaExtract, which helps clarify the intent. However, the term 'LlamaExtract' may not be universally understood without additional context, as it could refer to a specific tool, framework, or concept that is not defined within the question. To improve clarity and answerability, the question could provide a brief description of what LlamaExtract is or its purpose, ensuring that readers unfamiliar with it can still understand the question's context.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of unstructured data in relation to LlamaExtract and its functionalities. It is specific in its focus on unstructured data and LlamaExtract, which helps clarify the intent. However, the term 'LlamaExtract' may not be universally understood without additional context, as it could refer to a specific tool, framework, or concept that is not defined within the question. To improve clarity and answerability, the question could provide a brief description of what LlamaExtract is or its purpose, ensuring that readers unfamiliar with it can still understand the question's context.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What role does unstructured data play in the context of LlamaExtract and its functionalities?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What role does unstructured data play in the context of LlamaExtract and its functionalities?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of the orchestration agent in the process of transferring money. It is specific and has a clear intent, focusing on a particular aspect of money transfer processes. However, the term 'orchestration agent' may not be universally understood without additional context, as it could refer to different systems or technologies in various domains (e.g., finance, IT, etc.). To improve clarity and answerability, the question could specify the context in which the orchestration agent operates (e.g., in a banking system, a payment processing platform, etc.) or provide a brief definition of what is meant by 'orchestration agent' in this scenario.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of the orchestration agent in the process of transferring money. It is specific and has a clear intent, focusing on a particular aspect of money transfer processes. However, the term 'orchestration agent' may not be universally understood without additional context, as it could refer to different systems or technologies in various domains (e.g., finance, IT, etc.). To improve clarity and answerability, the question could specify the context in which the orchestration agent operates (e.g., in a banking system, a payment processing platform, etc.) or provide a brief definition of what is meant by 'orchestration agent' in this scenario.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What role does the orchestration agent play in the process of transferring money?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What role does the orchestration agent play in the process of transferring money?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] rewritten question: \"What financial milestone involving Amazon.com, Inc. occurred in the last five years?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What financial milestone involving Amazon.com, Inc. occurred in the last five years?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of Retrieval Augmented Generation (RAG) as discussed in the tutorials and workshops mentioned in the LlamaIndex updates?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of Retrieval Augmented Generation (RAG) as discussed in the tutorials and workshops mentioned in the LlamaIndex updates?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What role does hybrid search play in enhancing the capabilities of agents developed with LlamaIndex, particularly in relation to retrieval-augmented generation (RAG) methodologies?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What role does hybrid search play in enhancing the capabilities of agents developed with LlamaIndex, particularly in relation to retrieval-augmented generation (RAG) methodologies?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What functions does the orchestration agent serve in ensuring the successful completion of a money transfer, particularly in relation to user authentication and account balance verification?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What functions does the orchestration agent serve in ensuring the successful completion of a money transfer, particularly in relation to user authentication and account balance verification?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of Retrieval Augmented Generation in the context of the provided tutorials and workshops?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of Retrieval Augmented Generation in the context of the provided tutorials and workshops?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'A new feature in LlamaCloud has been introduced to enhance QA assistants, which supports dynamic retrieval for both chunk-level and file-level document retrieval based on query similarity, allowing for intelligent routing of queries.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'A new feature in LlamaCloud has been introduced to enhance QA assistants, which supports dynamic retrieval for both chunk-level and file-level document retrieval based on query similarity, allowing for intelligent routing of queries.', 'verdict': 1}\n",
      "Generating:  10%|█         | 1/10 [00:04<00:43,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the steps that must occur after authentication before transferring money. It is specific and clear in its intent, focusing on the sequence of actions required in a financial transaction context. However, it could benefit from additional context regarding the type of system or platform being referred to (e.g., banking app, online payment system) to ensure a more precise answer. Including this detail would enhance clarity and answerability for a broader audience.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the steps that must occur after authentication before transferring money. It is specific and clear in its intent, focusing on the sequence of actions required in a financial transaction context. However, it could benefit from additional context regarding the type of system or platform being referred to (e.g., banking app, online payment system) to ensure a more precise answer. Including this detail would enhance clarity and answerability for a broader audience.', 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a financial milestone related to Amazon.com, Inc. that occurred within the last five years. It is specific in its focus on Amazon and the timeframe, making it relatively clear in intent. However, the term 'financial milestone' could be interpreted in various ways, such as revenue targets, stock price achievements, or significant acquisitions. To improve clarity and answerability, the question could specify what type of financial milestone is of interest (e.g., revenue growth, stock performance, major investments) to guide the response more effectively.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a financial milestone related to Amazon.com, Inc. that occurred within the last five years. It is specific in its focus on Amazon and the timeframe, making it relatively clear in intent. However, the term 'financial milestone' could be interpreted in various ways, such as revenue targets, stock price achievements, or significant acquisitions. To improve clarity and answerability, the question could specify what type of financial milestone is of interest (e.g., revenue growth, stock performance, major investments) to guide the response more effectively.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What financial milestone involving Amazon.com, Inc. occurred in the last five years?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What financial milestone involving Amazon.com, Inc. occurred in the last five years?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The purpose of structured extraction in the context of LlamaExtract is to perform structured extraction from unstructured documents, which is a core use case for LLMs. It involves inferring a schema from existing documents and extracting values according to a specified schema, thereby facilitating data processing for retrieval and RAG use cases.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The purpose of structured extraction in the context of LlamaExtract is to perform structured extraction from unstructured documents, which is a core use case for LLMs. It involves inferring a schema from existing documents and extracting values according to a specified schema, thereby facilitating data processing for retrieval and RAG use cases.', 'verdict': 1}\n",
      "Generating:  20%|██        | 2/10 [00:05<00:18,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of unstructured data in relation to LlamaExtract and its functionalities. It is specific in its focus on unstructured data and LlamaExtract, which helps clarify the intent. However, the term 'LlamaExtract' may not be universally understood without additional context, as it could refer to a specific tool, framework, or concept that is not defined within the question. To improve clarity and answerability, the question could provide a brief description of what LlamaExtract is or its purpose, ensuring that readers unfamiliar with it can still understand the question's intent.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of unstructured data in relation to LlamaExtract and its functionalities. It is specific in its focus on unstructured data and LlamaExtract, which helps clarify the intent. However, the term 'LlamaExtract' may not be universally understood without additional context, as it could refer to a specific tool, framework, or concept that is not defined within the question. To improve clarity and answerability, the question could provide a brief description of what LlamaExtract is or its purpose, ensuring that readers unfamiliar with it can still understand the question's intent.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What must occur after authentication before transferring money?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What must occur after authentication before transferring money?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The significance of long context models in enterprise contexts lies in their ability to enhance the quality and accuracy of retrieval-augmented generation (RAG) systems, especially when dealing with lengthy documents or vast databases of information. Long context models can effectively handle large amounts of text, which is crucial as RAG systems scale and the number of documents and lengths of chunks increase.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The significance of long context models in enterprise contexts lies in their ability to enhance the quality and accuracy of retrieval-augmented generation (RAG) systems, especially when dealing with lengthy documents or vast databases of information. Long context models can effectively handle large amounts of text, which is crucial as RAG systems scale and the number of documents and lengths of chunks increase.', 'verdict': 1}\n",
      "Generating:  30%|███       | 3/10 [00:05<00:09,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question clearly specifies the topic of interest, which is the role of the orchestration agent in the context of money transfers, focusing on user authentication and account balance verification. It is self-contained and does not rely on external references, making it understandable and answerable based on the details provided. The intent is clear, as it seeks to understand the specific functions of the orchestration agent in this process. Therefore, the question meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question clearly specifies the topic of interest, which is the role of the orchestration agent in the context of money transfers, focusing on user authentication and account balance verification. It is self-contained and does not rely on external references, making it understandable and answerable based on the details provided. The intent is clear, as it seeks to understand the specific functions of the orchestration agent in this process. Therefore, the question meets the criteria for clarity and answerability.', 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What significant financial event related to stock structure took place for Amazon.com, Inc. within the past five years?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What significant financial event related to stock structure took place for Amazon.com, Inc. within the past five years?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of Retrieval Augmented Generation (RAG) as discussed in tutorials and workshops mentioned in the LlamaIndex updates. While it specifies the topic of interest (RAG) and the context (tutorials and workshops from LlamaIndex), it assumes familiarity with these updates without providing any details about them. This reliance on unspecified external references makes the question less clear and answerable for those who may not have access to the LlamaIndex updates. To improve clarity and answerability, the question could include a brief description of what the LlamaIndex updates entail or summarize the key points from the tutorials and workshops that relate to RAG.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of Retrieval Augmented Generation (RAG) as discussed in tutorials and workshops mentioned in the LlamaIndex updates. While it specifies the topic of interest (RAG) and the context (tutorials and workshops from LlamaIndex), it assumes familiarity with these updates without providing any details about them. This reliance on unspecified external references makes the question less clear and answerable for those who may not have access to the LlamaIndex updates. To improve clarity and answerability, the question could include a brief description of what the LlamaIndex updates entail or summarize the key points from the tutorials and workshops that relate to RAG.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Retrieval Augmented Generation (RAG) in relation to 'the provided tutorials and workshops', but it does not specify what those tutorials and workshops entail or how they relate to RAG. This reliance on unspecified external context makes the question unclear and difficult to answer for someone who does not have access to that information. To improve clarity and answerability, the question could specify the content or focus of the tutorials and workshops, or alternatively, ask about the significance of RAG in a more general context without relying on external references.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Retrieval Augmented Generation (RAG) in relation to 'the provided tutorials and workshops', but it does not specify what those tutorials and workshops entail or how they relate to RAG. This reliance on unspecified external context makes the question unclear and difficult to answer for someone who does not have access to that information. To improve clarity and answerability, the question could specify the content or focus of the tutorials and workshops, or alternatively, ask about the significance of RAG in a more general context without relying on external references.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of Retrieval Augmented Generation in the context of the provided tutorials and workshops?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of Retrieval Augmented Generation in the context of the provided tutorials and workshops?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 1, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 1, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaCloud', 'Autonomous AI agent technology', 'Enterprise solutions', 'Expand offerings', 'Leader in technology']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaCloud', 'Autonomous AI agent technology', 'Enterprise solutions', 'Expand offerings', 'Leader in technology']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What role does the orchestration agent play in money transfers, especially for user auth and balance checks?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What role does the orchestration agent play in money transfers, especially for user auth and balance checks?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses specifically on the role of the account balance agent in money transfer, while the second question addresses the steps that occur after authentication, which may not directly involve the account balance agent. This indicates different constraints and depths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses specifically on the role of the account balance agent in money transfer, while the second question addresses the steps that occur after authentication, which may not directly involve the account balance agent. This indicates different constraints and depths of inquiry.', 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Fine-tuning job', 'LinearAdapterEmbeddingModel', 'Hit-rate metric', 'Mean Reciprocal Rank', 'LlamaIndex module']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Fine-tuning job', 'LinearAdapterEmbeddingModel', 'Hit-rate metric', 'Mean Reciprocal Rank', 'LlamaIndex module']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What position does LlamaCloud aim to achieve in the field of autonomous AI agent technology for enterprises?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What position does LlamaCloud aim to achieve in the field of autonomous AI agent technology for enterprises?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the process for initiating a fine-tuning job in the context of embedding models?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the process for initiating a fine-tuning job in the context of embedding models?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of hybrid search in improving the capabilities of agents developed with LlamaIndex, specifically in the context of retrieval-augmented generation (RAG) methodologies. It is clear in its intent and specifies the topics of interest (hybrid search, LlamaIndex, RAG). However, the question may be challenging for those unfamiliar with the specific terms or the context of LlamaIndex and RAG methodologies. To enhance clarity and answerability, it could be beneficial to provide a brief definition or explanation of hybrid search and RAG methodologies, or to specify what aspects of agent capabilities are being referred to (e.g., efficiency, accuracy, response quality).', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of hybrid search in improving the capabilities of agents developed with LlamaIndex, specifically in the context of retrieval-augmented generation (RAG) methodologies. It is clear in its intent and specifies the topics of interest (hybrid search, LlamaIndex, RAG). However, the question may be challenging for those unfamiliar with the specific terms or the context of LlamaIndex and RAG methodologies. To enhance clarity and answerability, it could be beneficial to provide a brief definition or explanation of hybrid search and RAG methodologies, or to specify what aspects of agent capabilities are being referred to (e.g., efficiency, accuracy, response quality).', 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks about the role of the orchestration agent in transferring money, while the second question specifies additional aspects such as user authentication and balance checks. This leads to a difference in depth and breadth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks about the role of the orchestration agent in transferring money, while the second question specifies additional aspects such as user authentication and balance checks. This leads to a difference in depth and breadth of inquiry.', 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does hybrid search boost LlamaIndex agents in RAG?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does hybrid search boost LlamaIndex agents in RAG?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Retrieval Augmented Generation (RAG) in relation to 'the provided tutorials and workshops', but it does not specify what those tutorials and workshops entail or how they relate to RAG. This lack of context makes it difficult to provide a focused answer. To improve clarity and answerability, the question could specify the content or objectives of the tutorials and workshops, or explain how RAG is expected to be applied within that context. This would help clarify the intent and allow for a more precise response.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Retrieval Augmented Generation (RAG) in relation to 'the provided tutorials and workshops', but it does not specify what those tutorials and workshops entail or how they relate to RAG. This lack of context makes it difficult to provide a focused answer. To improve clarity and answerability, the question could specify the content or objectives of the tutorials and workshops, or explain how RAG is expected to be applied within that context. This would help clarify the intent and allow for a more precise response.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a significant financial event related to the stock structure of Amazon.com, Inc. within the past five years. It is specific in its focus on Amazon.com, Inc. and the timeframe, making it clear what information is being sought. However, the term 'financial event related to stock structure' could be interpreted in various ways (e.g., stock splits, dividends, changes in share structure), which may introduce some ambiguity. To improve clarity, the question could specify the type of financial event of interest or provide examples of what is meant by 'stock structure'.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a significant financial event related to the stock structure of Amazon.com, Inc. within the past five years. It is specific in its focus on Amazon.com, Inc. and the timeframe, making it clear what information is being sought. However, the term 'financial event related to stock structure' could be interpreted in various ways (e.g., stock splits, dividends, changes in share structure), which may introduce some ambiguity. To improve clarity, the question could specify the type of financial event of interest or provide examples of what is meant by 'stock structure'.\", 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the position that LlamaCloud aims to achieve in the field of autonomous AI agent technology for enterprises. It is specific and clear in its intent, focusing on a particular company (LlamaCloud) and a defined area of technology (autonomous AI agents for enterprises). However, the question could be improved by specifying what aspects of 'position' are of interest (e.g., market share, technological leadership, innovation, etc.). This would provide a clearer direction for the answer and enhance its answerability.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the position that LlamaCloud aims to achieve in the field of autonomous AI agent technology for enterprises. It is specific and clear in its intent, focusing on a particular company (LlamaCloud) and a defined area of technology (autonomous AI agents for enterprises). However, the question could be improved by specifying what aspects of 'position' are of interest (e.g., market share, technological leadership, innovation, etc.). This would provide a clearer direction for the answer and enhance its answerability.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What position does LlamaCloud aim to achieve in the field of autonomous AI agent technology for enterprises?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What position does LlamaCloud aim to achieve in the field of autonomous AI agent technology for enterprises?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What major stock event happened with Amazon in the last 5 years?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What major stock event happened with Amazon in the last 5 years?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Task orchestration', 'Continuation agent', 'Multi-agent coordination', 'Natural language instructions', 'Global state management']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Task orchestration', 'Continuation agent', 'Multi-agent coordination', 'Natural language instructions', 'Global state management']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the process for initiating a fine-tuning job specifically in the context of embedding models. It is clear in its intent and specifies the topic of interest (fine-tuning jobs and embedding models), making it understandable and answerable without needing additional context. However, it could be improved by specifying the type of embedding models (e.g., word embeddings, sentence embeddings, etc.) or the framework being used (e.g., TensorFlow, PyTorch) to provide a more focused response. Overall, the question is specific and independent, with a clear intent.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the process for initiating a fine-tuning job specifically in the context of embedding models. It is clear in its intent and specifies the topic of interest (fine-tuning jobs and embedding models), making it understandable and answerable without needing additional context. However, it could be improved by specifying the type of embedding models (e.g., word embeddings, sentence embeddings, etc.) or the framework being used (e.g., TensorFlow, PyTorch) to provide a more focused response. Overall, the question is specific and independent, with a clear intent.', 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the role of hybrid search in enhancing LlamaIndex agents, focusing on its significance and impact in a similar context. They share the same depth and breadth of inquiry regarding the functionality of hybrid search.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the role of hybrid search in enhancing LlamaIndex agents, focusing on its significance and impact in a similar context. They share the same depth and breadth of inquiry regarding the functionality of hybrid search.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the role of the continuation agent in the system described?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the role of the continuation agent in the system described?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Post-authentication, the continuation agent checks the chat history and sees that the user was trying to transfer money. It generates a prompt indicating that the user has been successfully authenticated and that another agent will assist with transferring money. However, before the transfer can occur, the orchestration agent routes the user to the account balance agent to check the account balance, which is necessary for transferring money.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Post-authentication, the continuation agent checks the chat history and sees that the user was trying to transfer money. It generates a prompt indicating that the user has been successfully authenticated and that another agent will assist with transferring money. However, before the transfer can occur, the orchestration agent routes the user to the account balance agent to check the account balance, which is necessary for transferring money.', 'verdict': 1}\n",
      "Generating:  40%|████      | 4/10 [00:09<00:15,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Money transfer', 'Continuation agent', 'Orchestration agent', 'Account balance', 'Transfer completion']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Money transfer', 'Continuation agent', 'Orchestration agent', 'Account balance', 'Transfer completion']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The orchestration agent plays a crucial role in money transfers by checking if the user is authenticated and whether they have sufficient balance. It first verifies the user's authentication status and routes them to the authentication agent if they are not authenticated. Once authenticated, the orchestration agent checks if the user has an account balance before allowing the transfer of money. It manages the flow of tasks between different agents to ensure that the user completes the necessary steps for transferring money.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The orchestration agent plays a crucial role in money transfers by checking if the user is authenticated and whether they have sufficient balance. It first verifies the user's authentication status and routes them to the authentication agent if they are not authenticated. Once authenticated, the orchestration agent checks if the user has an account balance before allowing the transfer of money. It manages the flow of tasks between different agents to ensure that the user completes the necessary steps for transferring money.\", 'verdict': 1}\n",
      "Generating:  50%|█████     | 5/10 [00:10<00:08,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about significant financial events related to Amazon.com, Inc. within the same timeframe, focusing on similar aspects of financial milestones and stock events.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about significant financial events related to Amazon.com, Inc. within the same timeframe, focusing on similar aspects of financial milestones and stock events.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of checking the account balance before proceeding with a money transfer?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of checking the account balance before proceeding with a money transfer?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The process for initiating a fine-tuning job in the context of embedding models involves calling the `finetune` method on the `finetune_engine` after setting up the necessary parameters such as the dataset, base embedding model, model output path, and number of epochs. This can be done easily on a Macbook.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The process for initiating a fine-tuning job in the context of embedding models involves calling the `finetune` method on the `finetune_engine` after setting up the necessary parameters such as the dataset, base embedding model, model output path, and number of epochs. This can be done easily on a Macbook.', 'verdict': 1}\n",
      "Generating:  60%|██████    | 6/10 [00:11<00:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role that LlamaCloud aims to fulfill in the context of enterprise autonomous AI technology. It is specific in its focus on LlamaCloud and its aspirations, making the intent clear. However, the term 'enterprise autonomous AI tech' could be interpreted in various ways, which may lead to ambiguity in the response. To enhance clarity and answerability, the question could specify what aspects of enterprise autonomous AI technology are of interest (e.g., applications, benefits, challenges) or provide a brief context about LlamaCloud's current initiatives or goals in this area.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role that LlamaCloud aims to fulfill in the context of enterprise autonomous AI technology. It is specific in its focus on LlamaCloud and its aspirations, making the intent clear. However, the term 'enterprise autonomous AI tech' could be interpreted in various ways, which may lead to ambiguity in the response. To enhance clarity and answerability, the question could specify what aspects of enterprise autonomous AI technology are of interest (e.g., applications, benefits, challenges) or provide a brief context about LlamaCloud's current initiatives or goals in this area.\", 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LLM apps', 'Production-ready data ingestion', 'Domain-specific LLM solutions', 'Foundation Model Development', 'MLOps']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LLM apps', 'Production-ready data ingestion', 'Domain-specific LLM solutions', 'Foundation Model Development', 'MLOps']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What role does LlamaCloud aspire to play in enterprise autonomous AI tech?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What role does LlamaCloud aspire to play in enterprise autonomous AI tech?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of a 'continuation agent' in a system, but it lacks clarity because it does not specify what system is being referred to. Without context about the system, it is difficult to provide a precise answer regarding the role of the continuation agent. To improve clarity and answerability, the question could specify the type of system (e.g., software, organizational, educational) and provide a brief description of its function or purpose. This would help in understanding the context in which the continuation agent operates.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of a 'continuation agent' in a system, but it lacks clarity because it does not specify what system is being referred to. Without context about the system, it is difficult to provide a precise answer regarding the role of the continuation agent. To improve clarity and answerability, the question could specify the type of system (e.g., software, organizational, educational) and provide a brief description of its function or purpose. This would help in understanding the context in which the continuation agent operates.\", 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key features and goals of LLM apps in the enterprise setting?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key features and goals of LLM apps in the enterprise setting?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the role of the continuation agent in the multi-agent system described in the provided context?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the role of the continuation agent in the multi-agent system described in the provided context?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions inquire about LlamaCloud's objectives in the realm of AI technology for enterprises, but the first question is more specific about 'autonomous AI agent technology', indicating a different depth of inquiry compared to the broader term 'enterprise AI' in the second question.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions inquire about LlamaCloud's objectives in the realm of AI technology for enterprises, but the first question is more specific about 'autonomous AI agent technology', indicating a different depth of inquiry compared to the broader term 'enterprise AI' in the second question.\", 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of checking the account balance prior to a money transfer, which is clear and specific. It conveys a direct intent to understand the importance of this action in the context of financial transactions. The question is independent and does not rely on external references or additional context, making it understandable and answerable based on general knowledge of banking practices. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of checking the account balance prior to a money transfer, which is clear and specific. It conveys a direct intent to understand the importance of this action in the context of financial transactions. The question is independent and does not rely on external references or additional context, making it understandable and answerable based on general knowledge of banking practices. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the significance of checking the account balance before proceeding with a money transfer?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the significance of checking the account balance before proceeding with a money transfer?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What role does verifying account balance play in ensuring the successful execution of a money transfer process?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What role does verifying account balance play in ensuring the successful execution of a money transfer process?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  70%|███████   | 7/10 [00:14<00:06,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of the continuation agent in a multi-agent system, referencing 'the provided context' without including or describing this context within the question itself. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to that context. To improve clarity and answerability, the question should either include a brief description of the multi-agent system and the continuation agent's function or be framed in a way that does not depend on external references. Additionally, specifying what aspects of the role are of interest (e.g., functionality, interactions with other agents) could enhance the question's clarity.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of the continuation agent in a multi-agent system, referencing 'the provided context' without including or describing this context within the question itself. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to that context. To improve clarity and answerability, the question should either include a brief description of the multi-agent system and the continuation agent's function or be framed in a way that does not depend on external references. Additionally, specifying what aspects of the role are of interest (e.g., functionality, interactions with other agents) could enhance the question's clarity.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key features and goals of LLM (Large Language Model) applications in an enterprise setting. It is clear in its intent, specifying the subject matter (LLM apps) and the context (enterprise setting). However, the term 'key features and goals' could be interpreted in various ways, such as technical features, business objectives, or user experience aspects. To enhance clarity and answerability, the question could specify whether it is interested in technical features, business impacts, or user engagement goals, or provide examples of what is meant by 'key features and goals'.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key features and goals of LLM (Large Language Model) applications in an enterprise setting. It is clear in its intent, specifying the subject matter (LLM apps) and the context (enterprise setting). However, the term 'key features and goals' could be interpreted in various ways, such as technical features, business objectives, or user experience aspects. To enhance clarity and answerability, the question could specify whether it is interested in technical features, business impacts, or user engagement goals, or provide examples of what is meant by 'key features and goals'.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What are the key features and goals of LLM apps in the enterprise setting?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What are the key features and goals of LLM apps in the enterprise setting?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of verifying account balance in the context of a money transfer process, which is specific and clear in its intent. It does not rely on external references and can be understood independently. However, it could be improved by specifying the type of money transfer process (e.g., bank transfers, digital wallets) or the context in which this verification is being discussed (e.g., security, efficiency). This would provide a more focused framework for the answer.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of verifying account balance in the context of a money transfer process, which is specific and clear in its intent. It does not rely on external references and can be understood independently. However, it could be improved by specifying the type of money transfer process (e.g., bank transfers, digital wallets) or the context in which this verification is being discussed (e.g., security, efficiency). This would provide a more focused framework for the answer.', 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaExtract', 'Resume metadata', 'Schema creation', 'Multimodal extraction', 'Extraction capabilities']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaExtract', 'Resume metadata', 'Schema creation', 'Multimodal extraction', 'Extraction capabilities']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does checking account balance affect money transfers?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does checking account balance affect money transfers?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What improvements are being made to the extraction capabilities of LlamaExtract?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What improvements are being made to the extraction capabilities of LlamaExtract?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What essential attributes and objectives characterize LLM applications tailored for enterprise environments, particularly in relation to data management and developer collaboration?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What essential attributes and objectives characterize LLM applications tailored for enterprise environments, particularly in relation to data management and developer collaboration?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the importance and impact of checking account balances in relation to money transfers, sharing similar constraints and depth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the importance and impact of checking account balances in relation to money transfers, sharing similar constraints and depth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Current state of the user', 'Current speaker', 'Chat history', 'Sub-agent', 'Authentication process']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Current state of the user', 'Current speaker', 'Chat history', 'Sub-agent', 'Authentication process']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about improvements to the extraction capabilities of LlamaExtract, which is a specific topic. However, it lacks clarity regarding what specific aspects of extraction capabilities are being referred to (e.g., speed, accuracy, types of data extracted). Additionally, the term 'improvements' is vague without context on what the current capabilities are or what benchmarks are being used for comparison. To enhance clarity and answerability, the question could specify the particular improvements of interest or provide context on the current state of LlamaExtract's extraction capabilities.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about improvements to the extraction capabilities of LlamaExtract, which is a specific topic. However, it lacks clarity regarding what specific aspects of extraction capabilities are being referred to (e.g., speed, accuracy, types of data extracted). Additionally, the term 'improvements' is vague without context on what the current capabilities are or what benchmarks are being used for comparison. To enhance clarity and answerability, the question could specify the particular improvements of interest or provide context on the current state of LlamaExtract's extraction capabilities.\", 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does the sub-agent play in the orchestration process?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does the sub-agent play in the orchestration process?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question seeks to identify the essential attributes and objectives of LLM (Large Language Model) applications specifically designed for enterprise environments, with a focus on data management and developer collaboration. It is clear in its intent and specifies the context (enterprise environments) and the areas of interest (data management and developer collaboration). However, the question could be improved by providing examples of what is meant by 'essential attributes' and 'objectives', as these terms can be interpreted in various ways. Additionally, clarifying whether the question seeks a general overview or specific case studies could enhance its clarity. Overall, the question is specific and independent, making it understandable and answerable based on the details provided.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question seeks to identify the essential attributes and objectives of LLM (Large Language Model) applications specifically designed for enterprise environments, with a focus on data management and developer collaboration. It is clear in its intent and specifies the context (enterprise environments) and the areas of interest (data management and developer collaboration). However, the question could be improved by providing examples of what is meant by 'essential attributes' and 'objectives', as these terms can be interpreted in various ways. Additionally, clarifying whether the question seeks a general overview or specific case studies could enhance its clarity. Overall, the question is specific and independent, making it understandable and answerable based on the details provided.\", 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] rewritten question: \"What specific improvements are being made to the speed, accuracy, and types of data extracted by LlamaExtract's extraction capabilities?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What specific improvements are being made to the speed, accuracy, and types of data extracted by LlamaExtract's extraction capabilities?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What key traits and goals define LLMs for enterprises, especially for data mgmt and dev collaboration?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What key traits and goals define LLMs for enterprises, especially for data mgmt and dev collaboration?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of a sub-agent in the orchestration process, which is relatively clear in intent. However, it lacks specificity regarding what type of orchestration process is being referred to (e.g., software orchestration, orchestration in a business context, etc.). This ambiguity could lead to different interpretations and answers. To improve clarity and answerability, the question could specify the context of the orchestration process, such as 'in cloud computing' or 'in project management', to provide a clearer framework for the response.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of a sub-agent in the orchestration process, which is relatively clear in intent. However, it lacks specificity regarding what type of orchestration process is being referred to (e.g., software orchestration, orchestration in a business context, etc.). This ambiguity could lead to different interpretations and answers. To improve clarity and answerability, the question could specify the context of the orchestration process, such as 'in cloud computing' or 'in project management', to provide a clearer framework for the response.\", 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the characteristics and objectives of LLM applications in an enterprise context, focusing on similar themes of features and goals, though the second question adds a specific emphasis on data management and development collaboration.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the characteristics and objectives of LLM applications in an enterprise context, focusing on similar themes of features and goals, though the second question adds a specific emphasis on data management and development collaboration.', 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] rewritten question: \"What role does the sub-agent play in the orchestration process of the money transfer system described in the context?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What role does the sub-agent play in the orchestration process of the money transfer system described in the context?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about specific improvements to the speed, accuracy, and types of data extracted by LlamaExtract's extraction capabilities. It is clear in its intent, specifying the aspects of LlamaExtract that are of interest. However, the question could benefit from additional context regarding what LlamaExtract is, as not all readers may be familiar with it. To enhance clarity and answerability, the question could include a brief description of LlamaExtract or specify the timeframe for the improvements being referenced (e.g., recent updates, version changes).\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about specific improvements to the speed, accuracy, and types of data extracted by LlamaExtract's extraction capabilities. It is clear in its intent, specifying the aspects of LlamaExtract that are of interest. However, the question could benefit from additional context regarding what LlamaExtract is, as not all readers may be familiar with it. To enhance clarity and answerability, the question could include a brief description of LlamaExtract or specify the timeframe for the improvements being referenced (e.g., recent updates, version changes).\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What specific improvements are being made to the speed, accuracy, and types of data extracted by LlamaExtract's extraction capabilities?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What specific improvements are being made to the speed, accuracy, and types of data extracted by LlamaExtract's extraction capabilities?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Key traits and goals that define LLMs for enterprises include production-ready data ingestion and management, scalability to large data volumes, and domain-specific LLM solutions. These traits aim to handle data updates, ensure data consistency, and support multi-modal data storage. Additionally, LLMs focus on increasing developer collaboration through organizational features that allow users to create organizations, share projects, and maintain a single-source of truth for data pipelines, thereby enhancing transparency and development velocity.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Key traits and goals that define LLMs for enterprises include production-ready data ingestion and management, scalability to large data volumes, and domain-specific LLM solutions. These traits aim to handle data updates, ensure data consistency, and support multi-modal data storage. Additionally, LLMs focus on increasing developer collaboration through organizational features that allow users to create organizations, share projects, and maintain a single-source of truth for data pipelines, thereby enhancing transparency and development velocity.', 'verdict': 1}\n",
      "Generating:  80%|████████  | 8/10 [00:22<00:08,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question inquires about the role of a sub-agent in the orchestration process of a money transfer system, referencing 'the context' without providing any details about this context. This reliance on unspecified external information makes the question unclear and potentially unanswerable for those who do not have access to the relevant context. To improve clarity and answerability, the question should either include a brief description of the money transfer system and the orchestration process or be framed in a way that does not depend on external references. Additionally, specifying what aspects of the sub-agent's role are of interest (e.g., responsibilities, interactions, decision-making) could enhance the question's clarity.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question inquires about the role of a sub-agent in the orchestration process of a money transfer system, referencing 'the context' without providing any details about this context. This reliance on unspecified external information makes the question unclear and potentially unanswerable for those who do not have access to the relevant context. To improve clarity and answerability, the question should either include a brief description of the money transfer system and the orchestration process or be framed in a way that does not depend on external references. Additionally, specifying what aspects of the sub-agent's role are of interest (e.g., responsibilities, interactions, decision-making) could enhance the question's clarity.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about enhancements being made to LlamaExtract in terms of speed, accuracy, and data types for extraction. It is specific and conveys a clear intent, focusing on particular aspects of LlamaExtract. However, it could benefit from additional context regarding what LlamaExtract is, as not all readers may be familiar with it. To improve clarity and answerability, the question could include a brief description of LlamaExtract or specify the context in which these enhancements are being made (e.g., a particular project, version update, or research study).', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about enhancements being made to LlamaExtract in terms of speed, accuracy, and data types for extraction. It is specific and conveys a clear intent, focusing on particular aspects of LlamaExtract. However, it could benefit from additional context regarding what LlamaExtract is, as not all readers may be familiar with it. To improve clarity and answerability, the question could include a brief description of LlamaExtract or specify the context in which these enhancements are being made (e.g., a particular project, version update, or research study).', 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Stock split', 'Amazon.com, Inc.', 'Long context model', 'RAG system', 'Enterprise contexts']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Stock split', 'Amazon.com, Inc.', 'Long context model', 'RAG system', 'Enterprise contexts']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What enhancements are being made to LlamaExtract's speed, accuracy, and data types for extraction?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What enhancements are being made to LlamaExtract's speed, accuracy, and data types for extraction?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What was the outcome of the stock split for Amazon.com, Inc. in the last five years?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What was the outcome of the stock split for Amazon.com, Inc. in the last five years?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions inquire about enhancements related to LlamaExtract's performance, specifically focusing on speed, accuracy, and data types. They share the same constraints and requirements, as well as similar depth and breadth of inquiry.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions inquire about enhancements related to LlamaExtract's performance, specifically focusing on speed, accuracy, and data types. They share the same constraints and requirements, as well as similar depth and breadth of inquiry.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the outcome of the stock split for Amazon.com, Inc. within the last five years. It is specific in terms of the company and the time frame, making it relatively clear. However, the term 'outcome' could be interpreted in various ways, such as changes in stock price, market capitalization, or investor sentiment. To improve clarity and ensure a more direct answer, the question could specify what aspect of the outcome is of interest (e.g., 'What was the impact on stock price following the stock split for Amazon.com, Inc. in the last five years?').\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the outcome of the stock split for Amazon.com, Inc. within the last five years. It is specific in terms of the company and the time frame, making it relatively clear. However, the term 'outcome' could be interpreted in various ways, such as changes in stock price, market capitalization, or investor sentiment. To improve clarity and ensure a more direct answer, the question could specify what aspect of the outcome is of interest (e.g., 'What was the impact on stock price following the stock split for Amazon.com, Inc. in the last five years?').\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What was the outcome of the stock split for Amazon.com, Inc. in the last five years?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What was the outcome of the stock split for Amazon.com, Inc. in the last five years?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaCloud', 'Enhanced retrieval capabilities', 'Chunk-level and file-level retrieval', 'Nuanced and accurate systems', 'Enterprise plans']\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LlamaCloud', 'Enhanced retrieval capabilities', 'Chunk-level and file-level retrieval', 'Nuanced and accurate systems', 'Enterprise plans']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What significant corporate action did Amazon.com, Inc. undertake in the past five years, and how does this relate to the company's financial reporting practices?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What significant corporate action did Amazon.com, Inc. undertake in the past five years, and how does this relate to the company's financial reporting practices?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] seed question generated: \"What advantages do chunk-level and file-level retrieval offer in developing nuanced and accurate systems?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What advantages do chunk-level and file-level retrieval offer in developing nuanced and accurate systems?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the advantages of chunk-level and file-level retrieval in the context of developing nuanced and accurate systems. It is specific in its focus on two types of retrieval methods and seeks to understand their benefits. However, the question could be clearer by specifying what is meant by 'nuanced and accurate systems'—for example, is it referring to systems in a particular domain (e.g., information retrieval, machine learning, etc.)? Additionally, providing a brief context or examples of where these retrieval methods are applied could enhance understanding. Overall, while the question is relatively clear, it could benefit from additional detail to ensure it is fully self-contained and understandable.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the advantages of chunk-level and file-level retrieval in the context of developing nuanced and accurate systems. It is specific in its focus on two types of retrieval methods and seeks to understand their benefits. However, the question could be clearer by specifying what is meant by 'nuanced and accurate systems'—for example, is it referring to systems in a particular domain (e.g., information retrieval, machine learning, etc.)? Additionally, providing a brief context or examples of where these retrieval methods are applied could enhance understanding. Overall, while the question is relatively clear, it could benefit from additional detail to ensure it is fully self-contained and understandable.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What advantages do chunk-level and file-level retrieval offer in developing nuanced and accurate systems?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What advantages do chunk-level and file-level retrieval offer in developing nuanced and accurate systems?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a significant corporate action taken by Amazon.com, Inc. in the past five years and its relation to the company's financial reporting practices. It is specific in its request for a corporate action and seeks to understand its implications on financial reporting. However, the term 'significant corporate action' could be interpreted in various ways (e.g., mergers, acquisitions, stock buybacks), which may lead to ambiguity. To improve clarity, the question could specify the type of corporate action of interest or provide examples of what is considered significant. Additionally, it could clarify what aspects of financial reporting practices are being referred to (e.g., changes in reporting standards, impacts on revenue recognition).\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a significant corporate action taken by Amazon.com, Inc. in the past five years and its relation to the company's financial reporting practices. It is specific in its request for a corporate action and seeks to understand its implications on financial reporting. However, the term 'significant corporate action' could be interpreted in various ways (e.g., mergers, acquisitions, stock buybacks), which may lead to ambiguity. To improve clarity, the question could specify the type of corporate action of interest or provide examples of what is considered significant. Additionally, it could clarify what aspects of financial reporting practices are being referred to (e.g., changes in reporting standards, impacts on revenue recognition).\", 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.INFO] rewritten question: \"What specific significant corporate action, such as a stock split or acquisition, did Amazon.com, Inc. undertake in the past five years, and how did this action impact the company's financial reporting practices, such as revenue recognition or reporting standards?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What specific significant corporate action, such as a stock split or acquisition, did Amazon.com, Inc. undertake in the past five years, and how did this action impact the company's financial reporting practices, such as revenue recognition or reporting standards?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the benefits of chunk-level and file-level retrieval in the context of query-specific system development. It is clear in its intent, specifying the two types of retrieval methods and the focus on their benefits for system development. However, the question could be improved by providing a bit more context about what is meant by 'query-specific system development' or examples of such systems. This would help ensure that the question is fully self-contained and understandable to a broader audience. Overall, it is specific and independent, but slight elaboration could enhance clarity.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the benefits of chunk-level and file-level retrieval in the context of query-specific system development. It is clear in its intent, specifying the two types of retrieval methods and the focus on their benefits for system development. However, the question could be improved by providing a bit more context about what is meant by 'query-specific system development' or examples of such systems. This would help ensure that the question is fully self-contained and understandable to a broader audience. Overall, it is specific and independent, but slight elaboration could enhance clarity.\", 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What benefits do chunk-level and file-level retrieval provide for query-specific system development?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What benefits do chunk-level and file-level retrieval provide for query-specific system development?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks detailed information about a significant corporate action taken by Amazon.com, Inc. in the past five years, along with its impact on financial reporting practices. It clearly identifies the type of corporate actions of interest (stock split or acquisition) and specifies the aspects of financial reporting practices to be addressed (revenue recognition or reporting standards). However, the question could be improved by clarifying what is meant by 'impact'—whether it refers to changes in accounting policies, financial results, or compliance with regulations. Additionally, it could specify if the answer should focus on a particular action or if any significant action within the timeframe is acceptable. Overall, the question is clear and answerable based on the details provided.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks detailed information about a significant corporate action taken by Amazon.com, Inc. in the past five years, along with its impact on financial reporting practices. It clearly identifies the type of corporate actions of interest (stock split or acquisition) and specifies the aspects of financial reporting practices to be addressed (revenue recognition or reporting standards). However, the question could be improved by clarifying what is meant by 'impact'—whether it refers to changes in accounting policies, financial results, or compliance with regulations. Additionally, it could specify if the answer should focus on a particular action or if any significant action within the timeframe is acceptable. Overall, the question is clear and answerable based on the details provided.\", 'verdict': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question specifically asks about the advantages of chunk-level and file-level retrieval in developing nuanced and accurate systems, indicating a deeper inquiry into the implications of these methods. The second question is more general and does not specify the context of development or accuracy, leading to a difference in depth and breadth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question specifically asks about the advantages of chunk-level and file-level retrieval in developing nuanced and accurate systems, indicating a deeper inquiry into the implications of these methods. The second question is more general and does not specify the context of development or accuracy, leading to a difference in depth and breadth of inquiry.', 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What major corporate move has Amazon made in the last 5 years, and how did it affect their financial reporting?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What major corporate move has Amazon made in the last 5 years, and how did it affect their financial reporting?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Chunk-level and file-level retrieval offer developers the ability to create more nuanced and accurate systems that adapt to the specific needs of each query.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Chunk-level and file-level retrieval offer developers the ability to create more nuanced and accurate systems that adapt to the specific needs of each query.', 'verdict': 1}\n",
      "Generating:  90%|█████████ | 9/10 [00:34<00:06,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question specifically asks about the outcome of a stock split, while the second question inquires about a broader corporate move and its impact on financial reporting. This indicates different constraints and depths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question specifically asks about the outcome of a stock split, while the second question inquires about a broader corporate move and its impact on financial reporting. This indicates different constraints and depths of inquiry.', 'verdict': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating: 100%|██████████| 10/10 [00:39<00:00,  3.93s/it]\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_llamaindex_docs(\n",
    "    test_docs,\n",
    "    test_size=10,\n",
    "    distributions={simple: 0.4, reasoning: 0.3, multi_context: 0.3},\n",
    "    with_debugging_logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a50ba26-5a4c-4071-bf61-6b5d12b5578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29ce1eaa-1ca5-4dee-b390-e52f07c1a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the significance of long context model...</td>\n",
       "      <td>[de4c96e25.pdf' -O 'data/amazon_2022.pdf'\\n   ...</td>\n",
       "      <td>The significance of long context models in ent...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'filename': 'jamba-instruct-s-256k-context-w...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of structured extraction i...</td>\n",
       "      <td>[Structured extraction from unstructured data ...</td>\n",
       "      <td>The purpose of structured extraction in the co...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'filename': 'introducing-llamaextract-beta-s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What new feature has been introduced in LlamaC...</td>\n",
       "      <td>[Greetings, Llama Lovers!\\n\\nWelcome to this w...</td>\n",
       "      <td>A new feature in LlamaCloud has been introduce...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'filename': 'llamaindex-newsletter-2024-08-0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the process for initiating a fine-tuni...</td>\n",
       "      <td>[_dataset,\\n        base_embed_model,\\n       ...</td>\n",
       "      <td>The process for initiating a fine-tuning job i...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'filename': 'fine-tuning-a-linear-adapter-fo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do chunk and file retrieval offer for que...</td>\n",
       "      <td>[ chunk-level and file-level\\nretrieval, devel...</td>\n",
       "      <td>Chunk-level and file-level retrieval offer dev...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'filename': 'dynamic-retrieval-with-llamaclo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the significance of long context model...   \n",
       "1  What is the purpose of structured extraction i...   \n",
       "2  What new feature has been introduced in LlamaC...   \n",
       "3  What is the process for initiating a fine-tuni...   \n",
       "4  What do chunk and file retrieval offer for que...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [de4c96e25.pdf' -O 'data/amazon_2022.pdf'\\n   ...   \n",
       "1  [Structured extraction from unstructured data ...   \n",
       "2  [Greetings, Llama Lovers!\\n\\nWelcome to this w...   \n",
       "3  [_dataset,\\n        base_embed_model,\\n       ...   \n",
       "4  [ chunk-level and file-level\\nretrieval, devel...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The significance of long context models in ent...         simple   \n",
       "1  The purpose of structured extraction in the co...         simple   \n",
       "2  A new feature in LlamaCloud has been introduce...         simple   \n",
       "3  The process for initiating a fine-tuning job i...         simple   \n",
       "4  Chunk-level and file-level retrieval offer dev...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'filename': 'jamba-instruct-s-256k-context-w...          True  \n",
       "1  [{'filename': 'introducing-llamaextract-beta-s...          True  \n",
       "2  [{'filename': 'llamaindex-newsletter-2024-08-0...          True  \n",
       "3  [{'filename': 'fine-tuning-a-linear-adapter-fo...          True  \n",
       "4  [{'filename': 'dynamic-retrieval-with-llamaclo...          True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "647cffc3-636a-425a-8830-33dbbb6209e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "069c4ace-f3b7-4859-8d03-0751caa78345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.to_csv(\"./data/ragas_testset_03.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd605f-0325-4796-90f3-9ab2622eee29",
   "metadata": {},
   "source": [
    "## Token counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31c92048-2e14-4903-a87b-215941641006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Tokens:  17890 \n",
      " LLM Prompt Tokens:  25702 \n",
      " LLM Completion Tokens:  946 \n",
      " Total LLM Token Count:  26648 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Embedding Tokens: \",\n",
    "    token_counter.total_embedding_token_count,\n",
    "    \"\\n\",\n",
    "    \"LLM Prompt Tokens: \",\n",
    "    token_counter.prompt_llm_token_count,\n",
    "    \"\\n\",\n",
    "    \"LLM Completion Tokens: \",\n",
    "    token_counter.completion_llm_token_count,\n",
    "    \"\\n\",\n",
    "    \"Total LLM Token Count: \",\n",
    "    token_counter.total_llm_token_count,\n",
    "    \"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d4a73-2767-450f-a4a6-58b7eb7ab30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-py310",
   "language": "python",
   "name": "llm-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
