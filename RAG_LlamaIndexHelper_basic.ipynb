{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5dd759-0768-4504-ab8d-35bb3b4f2797",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Crawl Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67086be6-b182-47e3-a2d8-a578078d2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa24fa6-93f5-4b90-964a-dd275277d113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract and print the main text from each card\n",
    "def get_blog_urls():\n",
    "    # get all blog\n",
    "    base_url = \"https://www.llamaindex.ai\"\n",
    "    response = requests.get(f\"{base_url}/blog\")\n",
    "    html = response.text\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Find all blog post cards\n",
    "    blog_cards = soup.find_all('div', class_='CardBlog_card__mm0Zw')\n",
    "    blog_data = []\n",
    "    for card in blog_cards:\n",
    "        # Extract title\n",
    "        title_element = card.find('p', class_='CardBlog_title__qC51U').find('a')\n",
    "        title = title_element.text.strip()\n",
    "        url = base_url + title_element['href']\n",
    "    \n",
    "        # Extract publication date\n",
    "        date = card.find('p', class_='Text_text__zPO0D Text_text-size-16__PkjFu').text.strip()\n",
    "    \n",
    "        # Print the extracted information\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"URL: {url}\")\n",
    "        print(\"---\")\n",
    "\n",
    "        blog_data.append({\n",
    "            \"title\": title,\n",
    "            \"date\": date,\n",
    "            \"url\": url\n",
    "        })\n",
    "        \n",
    "    return blog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8101d264-9f6b-4624-b526-0a91e6dab9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Remove script and style tags\n",
    "    for script in soup(['script', 'style']):\n",
    "        script.extract()\n",
    "\n",
    "    # Get rid of empty tags\n",
    "    for tag in soup.find_all():\n",
    "        if not tag.text.strip():\n",
    "            tag.extract()\n",
    "\n",
    "    # only get main blog content, ignore related blogs\n",
    "    blog_content = soup.find(\"main\").find(\"div\", class_=\"BlogPost_htmlPost__Z5oDL\")\n",
    "\n",
    "    return blog_content.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5da889f-8a95-4bb2-9210-f0df7404d1be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LlamaIndex Newsletter 2024-07-23\n",
      "Date: Jul 23, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-07-23\n",
      "---\n",
      "Title: Improving Vector Search - Reranking with PostgresML and LlamaIndex\n",
      "Date: Jul 19, 2024\n",
      "URL: https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex\n",
      "---\n",
      "Title: The latest updates to LlamaCloud\n",
      "Date: Jul 19, 2024\n",
      "URL: https://www.llamaindex.ai/blog/the-latest-updates-to-llamacloud\n",
      "---\n",
      "Title: Case Study: How Scaleport.ai Accelerated Development and Improved Sales with LlamaCloud\n",
      "Date: Jul 17, 2024\n",
      "URL: https://www.llamaindex.ai/blog/case-study-how-scaleport-ai-accelerated-development-and-improved-sales-with-llamacloud\n",
      "---\n",
      "Title: Building a multi-agent concierge system\n",
      "Date: Jul 17, 2024\n",
      "URL: https://www.llamaindex.ai/blog/building-a-multi-agent-concierge-system\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-07-16\n",
      "Date: Jul 16, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-07-16\n",
      "---\n",
      "Title: Arize AI and LlamaIndex Roll Out Joint Platform for Evaluating LLM Applications\n",
      "Date: Jul 11, 2024\n",
      "URL: https://www.llamaindex.ai/blog/arize-ai-and-llamaindex-roll-out-joint-platform-for-evaluating-llm-applications\n",
      "---\n",
      "Title: Case study: Lyzr: Taking autonomous AI agents to $1M+ ARR with LlamaIndex\n",
      "Date: Jul 10, 2024\n",
      "URL: https://www.llamaindex.ai/blog/case-study-lyzr-taking-autonomous-ai-agents-to-usd1m-arr-with-llamaindex\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-07-09\n",
      "Date: Jul 9, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-07-09\n",
      "---\n",
      "Title: LlamaCloud - Built for Enterprise LLM App Builders\n",
      "Date: Jul 9, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamacloud-built-for-enterprise-llm-app-builders\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-07-02\n",
      "Date: Jul 2, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-07-02\n",
      "---\n",
      "Title: Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems\n",
      "Date: Jun 26, 2024\n",
      "URL: https://www.llamaindex.ai/blog/introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-06-25\n",
      "Date: Jun 25, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-06-25\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-06-18\n",
      "Date: Jun 18, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-06-18\n",
      "---\n",
      "Title: Customizing property graph index in LlamaIndex\n",
      "Date: Jun 11, 2024\n",
      "URL: https://www.llamaindex.ai/blog/customizing-property-graph-index-in-llamaindex\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-06-11\n",
      "Date: Jun 11, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-06-11\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-06-04\n",
      "Date: Jun 4, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-06-04\n",
      "---\n",
      "Title: Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs\n",
      "Date: May 29, 2024\n",
      "URL: https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms\n",
      "---\n",
      "Title: Simplify your RAG application architecture with LlamaIndex + PostgresML\n",
      "Date: May 28, 2024\n",
      "URL: https://www.llamaindex.ai/blog/simplify-your-rag-application-architecture-with-llamaindex-postgresml\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-05-28\n",
      "Date: May 28, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-05-28\n",
      "---\n",
      "Title: Automate online tasks with MultiOn and LlamaIndex\n",
      "Date: May 23, 2024\n",
      "URL: https://www.llamaindex.ai/blog/automate-online-tasks-with-multion-and-llamaindex\n",
      "---\n",
      "Title: Batch inference with MyMagic AI and LlamaIndex\n",
      "Date: May 22, 2024\n",
      "URL: https://www.llamaindex.ai/blog/batch-inference-with-mymagic-ai-and-llamaindex\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-05-21\n",
      "Date: May 21, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-05-21\n",
      "---\n",
      "Title: Secure code execution in LlamaIndex with Azure Container Apps dynamic sessions\n",
      "Date: May 21, 2024\n",
      "URL: https://www.llamaindex.ai/blog/secure-code-execution-in-llamaindex-with-azure-container-apps-dynamic-sessions\n",
      "---\n",
      "Title: Using LlamaIndex and llamafile to build a local, private research assistant\n",
      "Date: May 14, 2024\n",
      "URL: https://www.llamaindex.ai/blog/using-llamaindex-and-llamafile-to-build-a-local-private-research-assistant\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-05-14\n",
      "Date: May 14, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-05-14\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-05-07\n",
      "Date: May 7, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-05-07\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-04-30\n",
      "Date: Apr 30, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-04-30\n",
      "---\n",
      "Title: Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB\n",
      "Date: Apr 29, 2024\n",
      "URL: https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-04-23\n",
      "Date: Apr 23, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-04-23\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-04-16\n",
      "Date: Apr 16, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-04-16\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-04-09\n",
      "Date: Apr 9, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-04-09\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-04-02\n",
      "Date: Apr 2, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-04-02\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-03-26\n",
      "Date: Mar 26, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-03-26\n",
      "---\n",
      "Title: Secure RAG with LlamaIndex and LLM Guard by Protect AI\n",
      "Date: Mar 20, 2024\n",
      "URL: https://www.llamaindex.ai/blog/secure-rag-with-llamaindex-and-llm-guard-by-protect-ai\n",
      "---\n",
      "Title: Retrieving Privacy-Safe Documents Over A Network\n",
      "Date: Mar 20, 2024\n",
      "URL: https://www.llamaindex.ai/blog/retrieving-privacy-safe-documents-over-a-network\n",
      "---\n",
      "Title: Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations\n",
      "Date: Mar 19, 2024\n",
      "URL: https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-03-19\n",
      "Date: Mar 19, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-03-19\n",
      "---\n",
      "Title: One-click Open Source RAG Observability with Langfuse\n",
      "Date: Mar 18, 2024\n",
      "URL: https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse\n",
      "---\n",
      "Title: LlamaIndex Accelerates Enterprise Generative AI with NVIDIA NIM\n",
      "Date: Mar 18, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-accelerates-enterprise-generative-ai-with-nvidia-nim\n",
      "---\n",
      "Title: PII Detector: hacking privacy in RAG\n",
      "Date: Mar 13, 2024\n",
      "URL: https://www.llamaindex.ai/blog/pii-detector-hacking-privacy-in-rag\n",
      "---\n",
      "Title: Launching the first GenAI-native document parsing platform\n",
      "Date: Mar 13, 2024\n",
      "URL: https://www.llamaindex.ai/blog/launching-the-first-genai-native-document-parsing-platform\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-03-12\n",
      "Date: Mar 12, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-03-12\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024-03-05\n",
      "Date: Mar 5, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-03-05\n",
      "---\n",
      "Title: Towards Long Context RAG\n",
      "Date: Mar 1, 2024\n",
      "URL: https://www.llamaindex.ai/blog/towards-long-context-rag\n",
      "---\n",
      "Title: Unlocking the 3rd Dimension for Generative AI (Part 1)\n",
      "Date: Feb 29, 2024\n",
      "URL: https://www.llamaindex.ai/blog/unlocking-the-3rd-dimension-for-generative-ai-part-1\n",
      "---\n",
      "Title: Querying a network of knowledge with llama-index-networks\n",
      "Date: Feb 27, 2024\n",
      "URL: https://www.llamaindex.ai/blog/querying-a-network-of-knowledge-with-llama-index-networks-d784b4c3006f\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–02–27\n",
      "Date: Feb 27, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-02-27-4b9102a0f824\n",
      "---\n",
      "Title: Bridging the Gap in Crisis Counseling: Introducing Counselor Copilot\n",
      "Date: Feb 24, 2024\n",
      "URL: https://www.llamaindex.ai/blog/bridging-the-gap-in-crisis-counseling-introducing-counselor-copilot-db42e26ab4f3\n",
      "---\n",
      "Title: Introducing LlamaCloud and LlamaParse\n",
      "Date: Feb 20, 2024\n",
      "URL: https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–02–20: introducing LlamaCloud\n",
      "Date: Feb 20, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-02-20-introducing-llamacloud-30511f4662f4\n",
      "---\n",
      "Title: MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB\n",
      "Date: Feb 17, 2024\n",
      "URL: https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–02–13\n",
      "Date: Feb 13, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-02-13-26fa79601ba5\n",
      "---\n",
      "Title: Pioneering the Future of Housing: Introducing GenAI-Driven ADU Planning\n",
      "Date: Feb 12, 2024\n",
      "URL: https://www.llamaindex.ai/blog/pioneering-the-future-of-housing-introducing-genai-driven-adu-planning-ea950be71e2f\n",
      "---\n",
      "Title: LlamaIndex v0.10\n",
      "Date: Feb 12, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-v0-10-838e735948f8\n",
      "---\n",
      "Title: How to build LLM Agents in TypeScript with LlamaIndex.TS\n",
      "Date: Feb 8, 2024\n",
      "URL: https://www.llamaindex.ai/blog/how-to-build-llm-agents-in-typescript-with-llamaindex-ts-a88ed364a7aa\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–02–06\n",
      "Date: Feb 6, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-02-06-9a303130ad9f\n",
      "---\n",
      "Title: RAGArch: Building a No-Code RAG Pipeline Configuration & One-Click RAG Code Generation Tool Powered by LlamaIndex\n",
      "Date: Feb 2, 2024\n",
      "URL: https://www.llamaindex.ai/blog/ragarch-building-a-no-code-rag-pipeline-configuration-one-click-rag-code-generation-tool-powered-b6e8eeb70089\n",
      "---\n",
      "Title: LlamaIndex: Enhancing Retrieval Performance with Alpha Tuning in Hybrid Search in RAG\n",
      "Date: Jan 31, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-enhancing-retrieval-performance-with-alpha-tuning-in-hybrid-search-in-rag-135d0c9b8a00\n",
      "---\n",
      "Title: Building a Fully Open Source Retriever with Nomic Embed and LlamaIndex\n",
      "Date: Jan 30, 2024\n",
      "URL: https://www.llamaindex.ai/blog/building-a-fully-open-source-retriever-with-nomic-embed-and-llamaindex-fc3d7f36d3e4\n",
      "---\n",
      "Title: Agentic RAG With LlamaIndex\n",
      "Date: Jan 30, 2024\n",
      "URL: https://www.llamaindex.ai/blog/agentic-rag-with-llamaindex-2721b8a49ff6\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–01–30\n",
      "Date: Jan 30, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-30-0d01eb0d8cef\n",
      "---\n",
      "Title: Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex\n",
      "Date: Jan 26, 2024\n",
      "URL: https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9\n",
      "---\n",
      "Title: Introducing the LlamaIndex retrieval-augmented generation command-line tool\n",
      "Date: Jan 26, 2024\n",
      "URL: https://www.llamaindex.ai/blog/introducing-the-llamaindex-retrieval-augmented-generation-command-line-tool-a973fa519a41\n",
      "---\n",
      "Title: Building Scalable RAG Applications with LlamaIndex and Zilliz Cloud Pipelines\n",
      "Date: Jan 25, 2024\n",
      "URL: https://www.llamaindex.ai/blog/building-scalable-rag-applications-with-llamaindex-and-zilliz-cloud-pipelines-4879e9768baf\n",
      "---\n",
      "Title: Building a Slack bot that learns with LlamaIndex, Qdrant and Render\n",
      "Date: Jan 25, 2024\n",
      "URL: https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–01–23\n",
      "Date: Jan 23, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-23-11ee2c211bab\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–01–16\n",
      "Date: Jan 16, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-16-752195bed96d\n",
      "---\n",
      "Title: Building Multi-Tenancy RAG System with LlamaIndex\n",
      "Date: Jan 15, 2024\n",
      "URL: https://www.llamaindex.ai/blog/building-multi-tenancy-rag-system-with-llamaindex-0d6ab4e0c44b\n",
      "---\n",
      "Title: AI Voice Assistant: Enhancing Accessibility in AI with LlamaIndex and GPT3.5 (Deployed in Prod on Vercel and Render)\n",
      "Date: Jan 14, 2024\n",
      "URL: https://www.llamaindex.ai/blog/ai-voice-assistant-enhancing-accessibility-in-ai-with-llamaindex-and-gpt3-5-f5509d296f4a\n",
      "---\n",
      "Title: Free Advanced RAG Certification course with Activeloop and LlamaIndex\n",
      "Date: Jan 11, 2024\n",
      "URL: https://www.llamaindex.ai/blog/join-thousands-in-our-free-advanced-rag-certification-created-with-activeloop-ad63f24f27bb\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–01–09\n",
      "Date: Jan 9, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-09-6209000da2e6\n",
      "---\n",
      "Title: Introducing Query Pipelines\n",
      "Date: Jan 8, 2024\n",
      "URL: https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537\n",
      "---\n",
      "Title: A Cheat Sheet and Some Recipes For Building Advanced RAG\n",
      "Date: Jan 5, 2024\n",
      "URL: https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b\n",
      "---\n",
      "Title: Building An Intelligent Query-Response System with LlamaIndex and OpenLLM\n",
      "Date: Jan 3, 2024\n",
      "URL: https://www.llamaindex.ai/blog/building-an-intelligent-query-response-system-with-llamaindex-and-openllm-ff253a200bdf\n",
      "---\n",
      "Title: Scaling LlamaIndex with AWS and Hugging Face\n",
      "Date: Jan 2, 2024\n",
      "URL: https://www.llamaindex.ai/blog/scaling-llamaindex-with-aws-and-hugging-face-e2c71aa64716\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2024–01–02\n",
      "Date: Jan 2, 2024\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-02-f349db8c1842\n",
      "---\n",
      "Title: Running Mixtral 8x7 locally with LlamaIndex and Ollama\n",
      "Date: Dec 21, 2023\n",
      "URL: https://www.llamaindex.ai/blog/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab\n",
      "---\n",
      "Title: Two new llama-datasets and a Gemini vs. GPT showdown\n",
      "Date: Dec 20, 2023\n",
      "URL: https://www.llamaindex.ai/blog/two-new-llama-datasets-and-a-gemini-vs-gpt-showdown-9770302c91a5\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–12–19\n",
      "Date: Dec 19, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-12-19-2965a2d03726\n",
      "---\n",
      "Title: Multimodal RAG pipeline with LlamaIndex and Neo4j\n",
      "Date: Dec 18, 2023\n",
      "URL: https://www.llamaindex.ai/blog/multimodal-rag-pipeline-with-llamaindex-and-neo4j-a2c542eb0206\n",
      "---\n",
      "Title: Transforming Natural Language to SQL and Insights for E-commerce with LlamaIndex, GPT3.5, and Streamlit\n",
      "Date: Dec 17, 2023\n",
      "URL: https://www.llamaindex.ai/blog/transforming-natural-language-to-sql-and-insights-for-e-commerce-with-llamaindex-gpt3-5-e08edefa21f9\n",
      "---\n",
      "Title: LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model\n",
      "Date: Dec 15, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277\n",
      "---\n",
      "Title: How to train a custom GPT on your data with EmbedAI + LlamaIndex\n",
      "Date: Dec 14, 2023\n",
      "URL: https://www.llamaindex.ai/blog/how-to-train-a-custom-gpt-on-your-data-with-embedai-llamaindex-8a701d141070\n",
      "---\n",
      "Title: LlamaIndex + Gemini\n",
      "Date: Dec 13, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-gemini-8d7c3b9ea97e\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–12–12\n",
      "Date: Dec 12, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-12-12-4a5d542fbb1e\n",
      "---\n",
      "Title: Bridging the Language Gap in Programming: Introducing AutoTranslateDoc\n",
      "Date: Dec 8, 2023\n",
      "URL: https://www.llamaindex.ai/blog/bridging-the-language-gap-in-programming-introducing-autotranslatedoc-ccc93fbcd3a8\n",
      "---\n",
      "Title: LlamaIndex + Waii: Combining Structured Data from your Database with PDFs for Enhanced Data Analysis\n",
      "Date: Dec 6, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-waii-combining-structured-data-from-your-database-with-pdfs-for-enhanced-data-647a9e66be82\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–12–05\n",
      "Date: Dec 5, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-12-05-faf5ab930264\n",
      "---\n",
      "Title: Introducing Llama Datasets 🦙📝\n",
      "Date: Dec 4, 2023\n",
      "URL: https://www.llamaindex.ai/blog/introducing-llama-datasets-aadb9994ad9e\n",
      "---\n",
      "Title: OpenAI Cookbook: Evaluating RAG systems\n",
      "Date: Nov 28, 2023\n",
      "URL: https://www.llamaindex.ai/blog/openai-cookbook-evaluating-rag-systems-fe393c61fb93\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–11–28\n",
      "Date: Nov 28, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-28-a31be430a786\n",
      "---\n",
      "Title: Multimodal RAG: Building ‘AInimal Go!’, a Pokémon Go-Inspired App with ResNet, Cohere and Llamaindex\n",
      "Date: Nov 27, 2023\n",
      "URL: https://www.llamaindex.ai/blog/multimodal-rag-building-ainimal-go-fecf8404ed97\n",
      "---\n",
      "Title: Introducing Llama Packs\n",
      "Date: Nov 22, 2023\n",
      "URL: https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a\n",
      "---\n",
      "Title: Introducing RAGs: Your Personalized ChatGPT Experience Over Your Data\n",
      "Date: Nov 21, 2023\n",
      "URL: https://www.llamaindex.ai/blog/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–11–21\n",
      "Date: Nov 21, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-21-aa3a71e339f8\n",
      "---\n",
      "Title: Becoming Proficient in Document Extraction\n",
      "Date: Nov 20, 2023\n",
      "URL: https://www.llamaindex.ai/blog/becoming-proficient-in-document-extraction-32aa13046ed5\n",
      "---\n",
      "Title: Shipping your Retrieval-Augmented Generation app to production with create-llama\n",
      "Date: Nov 20, 2023\n",
      "URL: https://www.llamaindex.ai/blog/shipping-your-retrieval-augmented-generation-app-to-production-with-create-llama-7bbe43b6287d\n",
      "---\n",
      "Title: GPT4-V Experiments with General, Specific questions and Chain Of Thought prompting(COT) techniques.\n",
      "Date: Nov 17, 2023\n",
      "URL: https://www.llamaindex.ai/blog/gpt4-v-experiments-with-general-specific-questions-and-chain-of-thought-prompting-cot-techniques-49d82e6ddcc9\n",
      "---\n",
      "Title: Evaluating Multi-Modal Retrieval-Augmented Generation\n",
      "Date: Nov 16, 2023\n",
      "URL: https://www.llamaindex.ai/blog/evaluating-multi-modal-retrieval-augmented-generation-db3ca824d428\n",
      "---\n",
      "Title: Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex\n",
      "Date: Nov 16, 2023\n",
      "URL: https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b\n",
      "---\n",
      "Title: Announcing LlamaIndex 0.9\n",
      "Date: Nov 15, 2023\n",
      "URL: https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945\n",
      "---\n",
      "Title: create-llama, a command line tool to generate LlamaIndex apps\n",
      "Date: Nov 14, 2023\n",
      "URL: https://www.llamaindex.ai/blog/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–11–14\n",
      "Date: Nov 14, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-14-dad06ae4284a\n",
      "---\n",
      "Title: LlamaIndex turns 1!\n",
      "Date: Nov 13, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-turns-1-f69dcdd45fe3\n",
      "---\n",
      "Title: Multi-Modal RAG\n",
      "Date: Nov 10, 2023\n",
      "URL: https://www.llamaindex.ai/blog/multi-modal-rag-621de7525fea\n",
      "---\n",
      "Title: Building My Own ChatGPT Vision with PaLM, KOSMOS-2 and LlamaIndex\n",
      "Date: Nov 8, 2023\n",
      "URL: https://www.llamaindex.ai/blog/building-my-own-chatgpt-vision-with-palm-kosmos-2-and-llamaindex-9f9fdd13e566\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023-11–07\n",
      "Date: Nov 8, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-07-cf20b9a833aa\n",
      "---\n",
      "Title: LlamaIndex news special edition: OpenAI developer day!\n",
      "Date: Nov 7, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-news-special-edition-openai-developer-day-e955f16db4e2\n",
      "---\n",
      "Title: LongLLMLingua: Bye-bye to Middle Loss and Save on Your RAG Costs via Prompt Compression\n",
      "Date: Nov 6, 2023\n",
      "URL: https://www.llamaindex.ai/blog/longllmlingua-bye-bye-to-middle-loss-and-save-on-your-rag-costs-via-prompt-compression-54b559b9ddf7\n",
      "---\n",
      "Title: Boosting RAG: Picking the Best Embedding & Reranker models\n",
      "Date: Nov 3, 2023\n",
      "URL: https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–10–31\n",
      "Date: Oct 31, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-10-31-36244e2b3f0c\n",
      "---\n",
      "Title: NewsGPT(Neotice): Summarize news articles with LlamaIndex — Hackathon winning app\n",
      "Date: Oct 27, 2023\n",
      "URL: https://www.llamaindex.ai/blog/newsgpt-neotice-summarize-news-articles-with-llamaindex-hackathon-winning-app-9d7c8bcf9f11\n",
      "---\n",
      "Title: LlamaIndex newsletter 2023–10–24\n",
      "Date: Oct 24, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-10-24-4a76204eeaa3\n",
      "---\n",
      "Title: NVIDIA Research: RAG with Long Context LLMs\n",
      "Date: Oct 22, 2023\n",
      "URL: https://www.llamaindex.ai/blog/nvidia-research-rag-with-long-context-llms-7d94d40090c4\n",
      "---\n",
      "Title: Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables with Cutting-Edge Parser\n",
      "Date: Oct 18, 2023\n",
      "URL: https://www.llamaindex.ai/blog/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125\n",
      "---\n",
      "Title: Improving RAG effectiveness with Retrieval-Augmented Dual Instruction Tuning (RA-DIT)\n",
      "Date: Oct 18, 2023\n",
      "URL: https://www.llamaindex.ai/blog/improving-rag-effectiveness-with-retrieval-augmented-dual-instruction-tuning-ra-dit-01e73116655d\n",
      "---\n",
      "Title: How I built the Streamlit LLM Hackathon winning app — FinSight using LlamaIndex.\n",
      "Date: Oct 17, 2023\n",
      "URL: https://www.llamaindex.ai/blog/how-i-built-the-streamlit-llm-hackathon-winning-app-finsight-using-llamaindex-9dcf6c46d7a0\n",
      "---\n",
      "Title: LlamaIndex Newsletter 2023–10–17\n",
      "Date: Oct 17, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-10-17-33514cbc04a2\n",
      "---\n",
      "Title: LlamaIndex update 2023–10–10\n",
      "Date: Oct 10, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-update-2023-10-10-3718a3d19fb9\n",
      "---\n",
      "Title: Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex\n",
      "Date: Oct 5, 2023\n",
      "URL: https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5\n",
      "---\n",
      "Title: LlamaIndex + Laurie Voss: an alpaca joins the llamas\n",
      "Date: Oct 2, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-laurie-voss-an-alpaca-joins-the-llamas-9cae1081adff\n",
      "---\n",
      "Title: Timescale Vector x LlamaIndex: Making PostgreSQL a Better Vector Database for AI Applications\n",
      "Date: Sep 27, 2023\n",
      "URL: https://www.llamaindex.ai/blog/timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0\n",
      "---\n",
      "Title: LlamaIndex Update — 20/09/2023\n",
      "Date: Sep 21, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-update-20-09-2023-86ed66f78bac\n",
      "---\n",
      "Title: LlamaIndex + Vectara\n",
      "Date: Sep 12, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-vectara-7a3889cd34cb\n",
      "---\n",
      "Title: LlamaIndex Update — 09/03/2023\n",
      "Date: Sep 6, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-update-09-03-2023-4a7c21c0f60b\n",
      "---\n",
      "Title: Fine-Tuning a Linear Adapter for Any Embedding Model\n",
      "Date: Sep 6, 2023\n",
      "URL: https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383\n",
      "---\n",
      "Title: ChatGPT’s Knowledge is Two Years Old: What to do if you’re building applications?\n",
      "Date: Sep 1, 2023\n",
      "URL: https://www.llamaindex.ai/blog/chatgpts-knowledge-is-two-year-s-old-what-to-do-if-you-re-building-applications-72ceacde135c\n",
      "---\n",
      "Title: Introducing Airbyte sources within LlamaIndex\n",
      "Date: Aug 29, 2023\n",
      "URL: https://www.llamaindex.ai/blog/introducing-airbyte-sources-within-llamaindex-42209071722f\n",
      "---\n",
      "Title: LlamaIndex: Automatic Knowledge Transfer (KT) Generation for Code Bases\n",
      "Date: Aug 29, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-automatic-knowledge-transfer-kt-generation-for-code-bases-f3d91f21b7af\n",
      "---\n",
      "Title: Fine-Tuning Embeddings for RAG with Synthetic Data\n",
      "Date: Aug 25, 2023\n",
      "URL: https://www.llamaindex.ai/blog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971\n",
      "---\n",
      "Title: LlamaIndex + Metaphor: Towards Automating Knowledge Work with LLMs\n",
      "Date: Aug 21, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-metaphor-towards-automating-knowledge-work-with-llms-5520a32efa2f\n",
      "---\n",
      "Title: Easily Finetune Llama 2 for Your Text-to-SQL Applications\n",
      "Date: Aug 17, 2023\n",
      "URL: https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d\n",
      "---\n",
      "Title: LlamaIndex: Harnessing the Power of Text2SQL and RAG to Analyze Product Reviews\n",
      "Date: Aug 12, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-harnessing-the-power-of-text2sql-and-rag-to-analyze-product-reviews-204feabdf25b\n",
      "---\n",
      "Title: Zep and LlamaIndex: A Vector Store Walkthrough\n",
      "Date: Aug 11, 2023\n",
      "URL: https://www.llamaindex.ai/blog/zep-and-llamaindex-a-vector-store-walkthrough-564edb8c22dc\n",
      "---\n",
      "Title: LlamaIndex Update — 08/01/2023\n",
      "Date: Aug 1, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-update-08-01-2023-185514d9b897\n",
      "---\n",
      "Title: Data Agents + Zapier NLA\n",
      "Date: Jul 25, 2023\n",
      "URL: https://www.llamaindex.ai/blog/data-agents-zapier-nla-67146395ce1\n",
      "---\n",
      "Title: Introducing LlamaIndex.TS\n",
      "Date: Jul 24, 2023\n",
      "URL: https://www.llamaindex.ai/blog/introducing-llamaindex-ts-89f41a1f24ab\n",
      "---\n",
      "Title: Building Better Tools for LLM Agents\n",
      "Date: Jul 17, 2023\n",
      "URL: https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11\n",
      "---\n",
      "Title: Data Agents\n",
      "Date: Jul 12, 2023\n",
      "URL: https://www.llamaindex.ai/blog/data-agents-eed797d7972f\n",
      "---\n",
      "Title: LlamaIndex Update — 07/11/2023\n",
      "Date: Jul 10, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-update-07-10-2023-4ceebdab96cb\n",
      "---\n",
      "Title: LlamaIndex 0.7.0: Better Enabling Bottoms-Up LLM Application Development\n",
      "Date: Jul 4, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-0-7-0-better-enabling-bottoms-up-llm-application-development-959db8f75024\n",
      "---\n",
      "Title: Special Feature: Berkeley Hackathon Projects (LlamaIndex Prize Winners)\n",
      "Date: Jun 30, 2023\n",
      "URL: https://www.llamaindex.ai/blog/special-feature-berkeley-hackathon-projects-llamaindex-prize-winners-c135681bb6f0\n",
      "---\n",
      "Title: Enriching LlamaIndex Models with GraphQL and Graph Databases\n",
      "Date: Jun 30, 2023\n",
      "URL: https://www.llamaindex.ai/blog/enriching-llamaindex-models-from-graphql-and-graph-databases-bcaecec262d7\n",
      "---\n",
      "Title: Build and Scale a Powerful Query Engine with LlamaIndex and Ray\n",
      "Date: Jun 27, 2023\n",
      "URL: https://www.llamaindex.ai/blog/build-and-scale-a-powerful-query-engine-with-llamaindex-and-ray-bfb456404bc4\n",
      "---\n",
      "Title: LlamaIndex Update — 06/26/2023\n",
      "Date: Jun 26, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-update-6-26-2023-ed30a9d45f84\n",
      "---\n",
      "Title: Build and Evaluate LLM Apps with LlamaIndex and TruLens\n",
      "Date: Jun 23, 2023\n",
      "URL: https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c\n",
      "---\n",
      "Title: Llama Index & Prem AI Join Forces\n",
      "Date: Jun 23, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llama-index-prem-ai-join-forces-51702fecedec\n",
      "---\n",
      "Title: LlamaIndex and Weaviate\n",
      "Date: Jun 22, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4\n",
      "---\n",
      "Title: LlamaIndex and Transformers Agents\n",
      "Date: Jun 8, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-and-transformers-agents-67042ee1d8d6\n",
      "---\n",
      "Title: Building the data framework for LLMs\n",
      "Date: Jun 6, 2023\n",
      "URL: https://www.llamaindex.ai/blog/building-the-data-framework-for-llms-bca068e89e0e\n",
      "---\n",
      "Title: Vellum <> LlamaIndex Integration\n",
      "Date: Jun 5, 2023\n",
      "URL: https://www.llamaindex.ai/blog/vellum-llamaindex-integration-58b476a1e33f\n",
      "---\n",
      "Title: Combining Text-to-SQL with Semantic Search for Retrieval Augmented Generation\n",
      "Date: May 28, 2023\n",
      "URL: https://www.llamaindex.ai/blog/combining-text-to-sql-with-semantic-search-for-retrieval-augmented-generation-c60af30ec3b\n",
      "---\n",
      "Title: Dumber LLM Agents Need More Constraints and Better Tools\n",
      "Date: May 23, 2023\n",
      "URL: https://www.llamaindex.ai/blog/dumber-llm-agents-need-more-constraints-and-better-tools-17a524c59e12\n",
      "---\n",
      "Title: Build a ChatGPT with your Private Data using LlamaIndex and MongoDB\n",
      "Date: May 18, 2023\n",
      "URL: https://www.llamaindex.ai/blog/build-a-chatgpt-with-your-private-data-using-llamaindex-and-mongodb-b09850eb154c\n",
      "---\n",
      "Title: Using LLM’s for Retrieval and Reranking\n",
      "Date: May 17, 2023\n",
      "URL: https://www.llamaindex.ai/blog/using-llms-for-retrieval-and-reranking-23cf2d3a14b6\n",
      "---\n",
      "Title: Testing Anthropic Claude’s 100k-token window on SEC 10-K Filings\n",
      "Date: May 12, 2023\n",
      "URL: https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba\n",
      "---\n",
      "Title: LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)\n",
      "Date: May 10, 2023\n",
      "URL: https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595\n",
      "---\n",
      "Title: A New Document Summary Index for LLM-powered QA Systems\n",
      "Date: May 8, 2023\n",
      "URL: https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec\n",
      "---\n",
      "Title: Building and Evaluating a QA System with LlamaIndex\n",
      "Date: May 7, 2023\n",
      "URL: https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "blogs_data = get_blog_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e405ac09-809d-4737-b73a-75b89eb75775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'LlamaIndex Newsletter 2024-07-23',\n",
       " 'date': 'Jul 23, 2024',\n",
       " 'url': 'https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-07-23'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19055589-036d-4020-a47b-64b34e6e35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw blog \n",
    "response = requests.get(blog_data[0][\"url\"])\n",
    "raw_blog = BeautifulSoup(response.text, 'html.parser')\n",
    "with open(f'raw_page.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(raw_blog.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a6c7757-4161-4d54-999a-61b0d04e9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean blog\n",
    " with open(f'sample_clean.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(blog_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba49869a-9ad0-421a-bdcb-cb8f1a129952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Crawling data: 100%|██████████| 159/159 [01:03<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# # extract all blog page and save to folder data\n",
    "# save_folder = \"./data\"\n",
    "# for blog_data in tqdm(blogs_data,desc=\"Crawling data\"):\n",
    "#     cleaned_html = extract_page(blog_data[\"url\"])\n",
    "#     save_name =  blog_data[\"url\"].split(\"/\")[-1]\n",
    "#     with open(f'{save_folder}/{save_name}.html', 'w', encoding='utf-8') as f:\n",
    "#         f.write(cleaned_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d0faa-0c08-40ca-b795-59d584edcdc1",
   "metadata": {},
   "source": [
    "## Loading and Injestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fb95c-56f2-471a-8970-8da382572965",
   "metadata": {},
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601295ac-1023-460f-8a55-fad27c3f5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "855a3fa1-1d14-4e2f-9935-2ed5b63a5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"./data\",\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef332e3c-6e8c-4f92-b6c8-3e6b145a2a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24684, 159)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[0].text), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0738c95-3527-4952-99b1-649016aa3a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': '/workspace/projects/LlamaRAG/data/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.html',\n",
       " 'file_name': 'a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.html',\n",
       " 'file_type': 'text/html',\n",
       " 'file_size': 24708,\n",
       " 'creation_date': '2024-07-21',\n",
       " 'last_modified_date': '2024-07-21'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6886fc-e311-4f3c-9e1b-ef9bc93a4f2b",
   "metadata": {},
   "source": [
    "### Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0395fabd-8de9-45a9-8e9d-84dd2432537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(\n",
    "    chunk_size=2048,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87914dc6-e2b0-48d1-bf8a-5a0836a0b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 427 nodes.\n"
     ]
    }
   ],
   "source": [
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Created {len(nodes)} nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825543b-34a1-408f-9882-1be8273c896a",
   "metadata": {},
   "source": [
    "## Indexing and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7fc44da-6bad-4b6f-abbb-a65345430d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dev/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext, Settings\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.indices import SummaryIndex\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "import chromadb\n",
    "import torch\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b8a6c3-87f0-47e5-8325-378e231f38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ddd85ac-c6f8-495f-b296-0b31b7d1f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model with quantization config from: models/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec96cd063234411aa33f26b7edf41e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = model_utils.load_quantized_model(\n",
    "    model_name_or_path=\"models/Llama-2-7b-chat-hf\",\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d03316b-2def-4137-af00-282781a70f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"models/bge-small-en-v1.5\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cdc895-d167-4947-8697-e7911643bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config llm and embed_model to llamaindex\n",
    "llm_hf = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=512,\n",
    "    query_wrapper_prompt=PromptTemplate(\"<s> [INST] {query_str} [/INST] \"),\n",
    "    generate_kwargs={\n",
    "        \"temperature\": 0.7,\n",
    "        \"do_sample\": True\n",
    "    },\n",
    "    device_map=\"cuda\",\n",
    "    model_name=\"models/Llama-2-7b-chat-hf\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450ad4cb-2a72-4bc5-8204-1b25ae0cc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e82d1d3-bff5-4cbf-820a-7fefb0adcf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.context_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc0b8d-26ee-4262-92bc-da0d337258b7",
   "metadata": {},
   "source": [
    "### Init chromadb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd102e94-0885-4f51-9f13-e54578b29fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Collection(id=3186f0ec-26e5-46fa-b687-281a3a26066f, name=llama_index_blogs),\n",
       " 427)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a persistent instance of Chroma that saves to disk\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "# Get or create a collection with the given name and metadata.\n",
    "vector_collection = chroma_client.get_or_create_collection(\"llama_index_blogs\")\n",
    "vector_collection, vector_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc9e0478-eb8c-4d24-84cd-dedd2b8e7e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Collection(id=cf744ea1-c23d-41c8-8204-363adcd4b3fe, name=llma_blogs_summary),\n",
       " 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_collection = chroma_client.get_or_create_collection(\"llma_blogs_summary\")\n",
    "summary_collection, summary_collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2f600-f9ba-4a7f-9f9a-a507b4211873",
   "metadata": {},
   "source": [
    "### Create vetor store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f2ba770-0961-445e-aa50-1ed6f04d6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init chromadb storage\n",
    "vector_store = ChromaVectorStore(chroma_collection=vector_collection)\n",
    "vector_storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "summary_store = ChromaVectorStore(chroma_collection=summary_collection)\n",
    "summary_storage_context = StorageContext.from_defaults(vector_store=summary_store, persist_dir=\"./chroma_db/summary/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246943c5-ec79-4fbb-8ee7-a096660880bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # First run: Create vector index from documents.\n",
    "# vector_index = VectorStoreIndex(\n",
    "#     nodes, storage_context=storage_context, show_progress=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "911ad45d-c7cf-41f2-938b-146af2f5e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f9d3d3438543afb61bf3648b8a74d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create summary index\n",
    "summary_index = SummaryIndex.from_documents(\n",
    "    documents=documents,\n",
    "    storage_context=summary_storage_context, \n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8647eabc-ca0c-4754-8d74-0578a9f66841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_storage_context.persist(\"./chroma_db/summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6032ce6-a3d7-4d2e-914c-7f685ab2564b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load your index from stored vectors\n",
    "vector_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, storage_context=vector_storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7994e03-73fb-4d08-8ff8-ea139780df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_storage_context = StorageContext.from_defaults(persist_dir=\"./chroma_db/summary/\")\n",
    "# # doc_summary_index = load_index_from_storage(storage_context)\n",
    "summary_index = load_index_from_storage(\n",
    "    storage_context=summary_storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebf49c-fdd9-4aa9-b87b-0fd2c17a9383",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d46be-de18-4f9c-949a-5940816fcb9d",
   "metadata": {},
   "source": [
    "#### Logging setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a6062d9-5c07-4348-9d78-b6de71890257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1da464-bd8b-4f35-a79b-0c19576b5518",
   "metadata": {},
   "source": [
    "#### Compact query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "272336a0-1f07-47db-bbe4-158d4731b41a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6324d2dddcd84b81b48ab6982341a0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the provided context information, the key features of llama-agents are:\n",
       "\n",
       "1. Distributed Service Oriented Architecture: llama-agents allows for the creation of independently running microservices, each with its own LLM-powered control plane that routes and distributes tasks.\n",
       "2. Standardized API Interfaces: llama-agents provides a standardized API interface between agents using a central control plane orchestrator, allowing for seamless communication between agents.\n",
       "3. Define Agentic and Explicit Orchestration Flows: Developers have the flexibility to directly define the sequence of interactions between agents or leave it up to an \"agentic orchestrator\" that decides which agents are relevant to the task.\n",
       "4. Ease of Deployment: llama-agents provides a simple and easy-to-use interface for deploying and managing agents, allowing for efficient and scalable deployment.\n",
       "5. Scalability and Resource Management: llama-agents provide built-in observability tools for monitoring the quality and performance of the system and each individual agent service, enabling efficient scaling and resource management.\n",
       "\n",
       "By leveraging these key features, llama-agents provides a powerful framework for building and deploying multi-agent systems, enabling developers to create complex question-answering systems, collaborative AI assistants, and distributed AI workflows with ease."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compact query\n",
    "query_engine = vector_index.as_query_engine(response_mode=\"compact\")\n",
    "\n",
    "response = query_engine.query(\"What are key features of llama-agents?\")\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86b0c237-06fa-4014-b6f0-24485fae2b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9b674962-37bb-43af-8ef0-a1398491ca21': {'file_path': '/workspace/projects/LlamaRAG/data/introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems.html',\n",
       "  'file_name': 'introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems.html',\n",
       "  'file_type': 'text/html',\n",
       "  'file_size': 18790,\n",
       "  'creation_date': '2024-07-21',\n",
       "  'last_modified_date': '2024-07-21'},\n",
       " '902d9937-03d2-4744-8914-2095f695ae36': {'file_path': '/workspace/projects/LlamaRAG/data/how-to-build-llm-agents-in-typescript-with-llamaindex-ts-a88ed364a7aa.html',\n",
       "  'file_name': 'how-to-build-llm-agents-in-typescript-with-llamaindex-ts-a88ed364a7aa.html',\n",
       "  'file_type': 'text/html',\n",
       "  'file_size': 16248,\n",
       "  'creation_date': '2024-07-21',\n",
       "  'last_modified_date': '2024-07-21'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b3abe13-a1e3-41c9-8bce-2070c60b58e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08352849-38ac-4bc8-8f54-b7583b03cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context information provided, the key features of llama-agents are:\n",
      "\n",
      "1. Distributed Service Oriented Architecture: llama-agents allows for the creation of independently running microservices, each with its own LLM-powered control plane that orchestrates the tasks.\n",
      "2. Standardized API Interfaces: llama-agents provides a standardized API interface for communication between agents using a central control plane orchestrator.\n",
      "3. Define Agentic and Explicit Orchestration Flows: Developers have the flexibility to directly define the sequence of interactions between agents or leave it up to an \"agentic orchestrator\" that decides which agents are relevant to the task.\n",
      "4. Ease of Deployment: llama-agents provides a simple way to launch, scale, and monitor each agent and the control plane independently.\n",
      "5. Scalability and Resource Management: llama-agents provide built-in observability tools to monitor the quality and performance of the system and each individual agent service.\n",
      "\n",
      "These features make llama-agents an ideal framework for building and deploying multi-agent systems, allowing developers to create complex question-answering systems, collaborative AI assistants, or distributed AI workflows with ease.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e738f05-0591-4187-ac61-c927636f7059",
   "metadata": {},
   "source": [
    "#### Refine Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87b4f380-b3de-4bac-8e1f-d60f0ed787f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac51288247b434b9a84b6dc4aec80fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the new context provided, the two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook are:\n",
      "\n",
      "1. Response Generation performance: This area of evaluation assesses the ability of the RAG system to generate coherent and contextually relevant responses to given prompts.\n",
      "2. Contextual Relevance performance: This area of evaluation assesses the ability of the RAG system to retrieve relevant information from the input context.\n",
      "\n",
      "These two areas are critical because they directly impact the quality of the responses generated by the RAG system. A RAG system that can generate coherent and contextually relevant responses is more likely to be useful and accurate in its output, while a RAG system that can retrieve relevant information from the input context is more likely to provide accurate and informative responses.\n",
      "\n",
      "The provided context provides additional information on the importance of these areas and how they can be evaluated using the LlamaIndex, which is a tool for evaluating the performance of RAG systems. The context also provides links to additional resources for learning more about these areas and how to improve the performance of RAG systems.\n",
      "\n",
      "In summary, the two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook are Response Generation performance and Contextual Relevance performance. These areas are critical because they directly impact the quality of the responses generated by the RAG system."
     ]
    }
   ],
   "source": [
    "# compact query\n",
    "query_engine = vector_index.as_query_engine(response_mode=\"refine\", streaming=True)\n",
    "\n",
    "response = query_engine.query('''\n",
    "What are the two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook?\n",
    "''')\n",
    "\n",
    "response.print_response_stream()\n",
    "# display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b55e3-047f-47fd-91a8-d0407766e77f",
   "metadata": {},
   "source": [
    "### Tree summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f873df19-d144-45cc-a7a4-43ce453b2725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ae17c6427b46fd9c0a19576e9b1a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided in the article, the key features of llama-agents are:\n",
      "\n",
      "1. Distributed Service Oriented Architecture: llama-agents are designed to be distributed and independent, allowing each agent to be its own microservice.\n",
      "2. Communication via standardized API interfaces: llama-agents use a standardized API interface for communication between agents, making it easy to define the sequence of interactions between agents.\n",
      "3. Define agentic and explicit orchestration flows: developers have the flexibility to directly define the sequence of interactions between agents or leave it up to an \"agentic orchestrator\" that decides which agents are relevant to the task.\n",
      "4. Ease of deployment: llama-agents can be easily launched and scaled independently, allowing for efficient management of multiple agents.\n",
      "5. Scalability and resource management: llama-agents provide built-in observability tools for monitoring the quality and performance of the system and each individual agent service.\n",
      "6. Basic System Setup: The article provides a basic example of how to set up a multi-agent system using llama-agents, including installing the framework, importing the necessary classes, and creating tools and agents.\n",
      "7. Deploying Your Multi-Agent System: Once the system has been tested locally, it can be deployed as a set of services for real production use."
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine(response_mode=\"tree_summarize\", streaming=True)\n",
    "response = query_engine.query(\"What are key features of llama-agents?\")\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d976b78-c715-4339-a061-9cf67e915c19",
   "metadata": {},
   "source": [
    "## Router query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4bd1ded-80ec-4d0e-8aa2-19e479b6ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03a26096-994b-44cd-a0ca-5a340592cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tool = QueryEngineTool(\n",
    "    query_engine=vector_index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for searching for specific facts.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "summary_tool = QueryEngineTool(\n",
    "    summary_index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarizing an entire document.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73e68449-1e75-4143-8e1c-2a6a73604574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the router query engine.\n"
     ]
    }
   ],
   "source": [
    "# create the router query engine\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "print(\"Created the router query engine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f29593c-aa52-4fad-a908-871f3e2d01ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 0: Llama-agents are useful for summarizing an entire document, which would allow for a quick understanding of the key features and main points of the document..\n",
      "Selecting query engine 0: Llama-agents are useful for summarizing an entire document, which would allow for a quick understanding of the key features and main points of the document..\n",
      "\u001b[1;3;38;5;200mSelecting query engine 0: Llama-agents are useful for summarizing an entire document, which would allow for a quick understanding of the key features and main points of the document..\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are key features of llama-agents?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m response\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/query_engine/router_query_engine.py:201\u001b[0m, in \u001b[0;36mRouterQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select query engine\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     final_response \u001b[38;5;241m=\u001b[39m \u001b[43mselected_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# add selected result\u001b[39;00m\n\u001b[1;32m    204\u001b[0m final_response\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m final_response\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/query_engine/retriever_query_engine.py:190\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    187\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    188\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m    189\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 190\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/response_synthesizers/base.py:241\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    238\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[1;32m    239\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[1;32m    240\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 241\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    250\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/response_synthesizers/tree_summarize.py:215\u001b[0m, in \u001b[0;36mTreeSummarize.get_response\u001b[0;34m(self, query_str, text_chunks, **response_kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         summaries \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    216\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    217\u001b[0m                 summary_template,\n\u001b[1;32m    218\u001b[0m                 context_str\u001b[38;5;241m=\u001b[39mtext_chunk,\n\u001b[1;32m    219\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[1;32m    220\u001b[0m             )\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks\n\u001b[1;32m    222\u001b[0m         ]\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m         summaries \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mstructured_predict(\n\u001b[1;32m    226\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks\n\u001b[1;32m    232\u001b[0m         ]\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/response_synthesizers/tree_summarize.py:216\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         summaries \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 216\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m                \u001b[49m\u001b[43msummary_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks\n\u001b[1;32m    222\u001b[0m         ]\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m         summaries \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mstructured_predict(\n\u001b[1;32m    226\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks\n\u001b[1;32m    232\u001b[0m         ]\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/llms/llm.py:438\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prompt(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[0;32m--> 438\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    440\u001b[0m parsed_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_output(output)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py:429\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    421\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    422\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m     },\n\u001b[1;32m    427\u001b[0m )\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 429\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    431\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    432\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    433\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    434\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    435\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/llama_index/llms/huggingface/base.py:358\u001b[0m, in \u001b[0;36mHuggingFaceLLM.complete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    356\u001b[0m         inputs\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 358\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m completion_tokens \u001b[38;5;241m=\u001b[39m tokens[\u001b[38;5;241m0\u001b[39m][inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) :]\n\u001b[1;32m    365\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mdecode(completion_tokens, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/transformers/generation/utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1755\u001b[0m     )\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/transformers/generation/utils.py:2397\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2394\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2396\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2397\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1164\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1161\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:968\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    957\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    958\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    959\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    965\u001b[0m         cache_position,\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:727\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    725\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    726\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    730\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:216\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:468\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    465\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    467\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m--> 468\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:574\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatMul4Bit\u001b[38;5;241m.\u001b[39mapply(A, B, out, bias, quant_state)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 574\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemv_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m         out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bias\n",
      "File \u001b[0;32m/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/functional.py:1984\u001b[0m, in \u001b[0;36mgemv_4bit\u001b[0;34m(A, B, out, transposed_A, transposed_B, state)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1983\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1984\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1986\u001b[0m         out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(size\u001b[38;5;241m=\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], bout), dtype\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are key features of llama-agents?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd8c7430-338f-4cd7-a1c4-13a043794910",
   "metadata": {},
   "outputs": [],
   "source": [
    "del query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21541a8c-9780-49db-b0be-24aa35863d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_torch230_py310",
   "language": "python",
   "name": "llm_torch230_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
