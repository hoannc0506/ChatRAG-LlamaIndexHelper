{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a3748d-7cd0-4434-b832-266ee0b51b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dev/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import qdrant_client\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "# from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core import Settings\n",
    "from fastembed import TextEmbedding\n",
    "import model_utils\n",
    "import prompt_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d48fbd-f93d-4523-a5a6-d4374a50a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama index ascyncio config\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87988429-cfa2-4497-b2d6-9c78f0557f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings.embed_model = TextEmbedding(\n",
    "#     model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "#     cache_dir=\"models/embed_models/\",\n",
    "#     providers=[\"CUDAExecutionProvider\"]\n",
    "# )\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"models/bge-small-en-v1.5\", device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e233b9ee-9a55-44c7-9ebf-830e505c21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model with quantization config from: models/Meta-Llama-3-8B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:bitsandbytes.cextension:Loading bitsandbytes native library from: /opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "Loading bitsandbytes native library from: /opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43ea8cd99a34e2982b9134a9ffb6378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load local llm llama\n",
    "model_name = \"models/Meta-Llama-3-8B-Instruct\"\n",
    "model, tokenizer = model_utils.load_quantized_model(\n",
    "    model_name_or_path=model_name,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ed0c2c-9466-4037-8236-c917bfe6f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_prompt_template = '''<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{query_str}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976f1d29-abed-424f-9ffa-2ca79996440f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "{query_str}<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llama3_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7be653-7e3f-4d74-80aa-f81b9b9749e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config llm and embed_model to llamaindex\n",
    "llm_hf = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=512,\n",
    "    query_wrapper_prompt=PromptTemplate(llama3_prompt_template),\n",
    "    generate_kwargs={\n",
    "        \"temperature\": 0.7,\n",
    "        \"do_sample\": True\n",
    "    },\n",
    "    device_map=\"cuda\",\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "Settings.llm = llm_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472df0e-2967-42de-8af4-8be4228aa085",
   "metadata": {},
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3a370e-53f6-4079-b36f-dd33a22faea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 159 documents\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"./data\",\n",
    "    filename_as_id=True,\n",
    ").load_data()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb50d4-9701-489e-9e1f-db3564ad1d53",
   "metadata": {},
   "source": [
    "### Build the VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a67ddbd-cd5d-479b-88f6-ba4a6dbb9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(\n",
    "    path=\"./qdrant_db/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bef4d65-f167-411d-b1db-3840f10f4546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x7fe41e188a30>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x7fe41e188730>, vector_stores={'default': QdrantVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=False, collection_name='llamaindex-blogs', url=None, api_key=None, batch_size=64, parallel=1, max_retries=3, client_kwargs={}, enable_hybrid=False, index_doc_id=True, fastembed_sparse_model=None), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x7fe41e188190>, property_graph_store=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(client=client, collection_name=\"llamaindex-blogs\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c3e24b2-52d2-4fd6-b075-7ae1c333f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fde142567049bf92cdbc3a5cfc10dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500bb64f69044a88833e608f0a9e62fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Payload indexes have no effect in the local Qdrant. Please use server Qdrant if you need payload indexes.\n"
     ]
    }
   ],
   "source": [
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents,\n",
    "#     storage_context=storage_context,\n",
    "#     show_progress=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf3c01e-7a11-470b-a0dc-ba1bea0475e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7fe435e3c760>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True\n",
    ")\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33afca6-1c96-4e5f-a0fb-d6eb0a5686a5",
   "metadata": {},
   "source": [
    "### Query Index¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c7fd4a-c3fe-4d03-a57b-639e46933a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee0f780-95be-44c2-bd92-2502999d0f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook?\n"
     ]
    }
   ],
   "source": [
    "question = '''What are the two critical areas of RAG system performance that are assessed \\\n",
    "in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook?'''\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3886cf3c-203f-43ab-a46c-2ebe536497b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7615bb6abdc843adac376d240510d31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
      "> [Node 22acfe61-e268-4876-82c3-773243408439] [Similarity score:             0.849098] <div class=\"BlogPost_htmlPost__Z5oDL\">\n",
      " <p>\n",
      "  We’re excited to unveil our\n",
      "  <a href=\"https://gith...\n",
      "> [Node e4da31d2-778b-4d0a-b41d-4d1a0ad0f53e] [Similarity score:             0.754972] </li>\n",
      "  <li class=\"Text_text__zPO0D Text_text-size-16__PkjFu\">\n",
      "   <a class=\"SanityPortableText_li...\n",
      "> Top 2 nodes:\n",
      "> [Node 22acfe61-e268-4876-82c3-773243408439] [Similarity score:             0.849098] <div class=\"BlogPost_htmlPost__Z5oDL\">\n",
      " <p>\n",
      "  We’re excited to unveil our\n",
      "  <a href=\"https://gith...\n",
      "> [Node e4da31d2-778b-4d0a-b41d-4d1a0ad0f53e] [Similarity score:             0.754972] </li>\n",
      "  <li class=\"Text_text__zPO0D Text_text-size-16__PkjFu\">\n",
      "   <a class=\"SanityPortableText_li...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context information, the two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook are:\n",
      "\n",
      "1. **The Retrieval System**: This area focuses on assessing the performance of the RAG system in retrieving relevant information from the dataset.\n",
      "2. **Response Generation**: This area focuses on assessing the performance of the RAG system in generating responses based on the retrieved information.\n",
      "\n",
      "These two areas are crucial in evaluating the effectiveness of a RAG system, as they ensure that the system can not only retrieve relevant information but also generate coherent and meaningful responses."
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine(use_async=True, streaming=True)\n",
    "streaming_response = query_engine.query(question)\n",
    "streaming_response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4501b38-be4d-42dc-bbda-f03db93263fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'22acfe61-e268-4876-82c3-773243408439': {'file_path': '/workspace/projects/LlamindexHelper/data/openai-cookbook-evaluating-rag-systems-fe393c61fb93.html',\n",
       "  'file_name': 'openai-cookbook-evaluating-rag-systems-fe393c61fb93.html',\n",
       "  'file_type': 'text/html',\n",
       "  'file_size': 2220,\n",
       "  'creation_date': '2024-07-21',\n",
       "  'last_modified_date': '2024-07-21'},\n",
       " 'e4da31d2-778b-4d0a-b41d-4d1a0ad0f53e': {'file_path': '/workspace/projects/LlamindexHelper/data/llamaindex-newsletter-2024-06-11.html',\n",
       "  'file_name': 'llamaindex-newsletter-2024-06-11.html',\n",
       "  'file_type': 'text/html',\n",
       "  'file_size': 11257,\n",
       "  'creation_date': '2024-07-21',\n",
       "  'last_modified_date': '2024-07-21'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_response.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5684b65-fcff-458f-a548-cd5f4cd1f95a",
   "metadata": {},
   "source": [
    "### Combine DocumentSummaryIndex and VectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2511082-d27c-4afd-afe7-92165cb0d2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x7fe41e188a30>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x7fe41e188730>, vector_stores={'default': QdrantVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=False, collection_name='llamaindex-blogs', url=None, api_key=None, batch_size=64, parallel=1, max_retries=3, client_kwargs={}, enable_hybrid=False, index_doc_id=True, fastembed_sparse_model=None), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x7fe41e188190>, property_graph_store=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40492a41-f468-472a-b729-d1da8e67ff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QdrantVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=False, collection_name='llamaindex-blogs', url=None, api_key=None, batch_size=64, parallel=1, max_retries=3, client_kwargs={}, enable_hybrid=False, index_doc_id=True, fastembed_sparse_model=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31a674e-de44-4d57-9017-cf9db925ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document index\n",
    "idex_mapping = storage_context.index_store.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "918863f8-5f2a-41c8-9753-b552f30729f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6089ce48-849d-4b4f-95e9-d84b8ac98b18'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.index_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82596ba5-fe9f-4718-923f-9f7304b52703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_torch230_py310",
   "language": "python",
   "name": "llm_torch230_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
