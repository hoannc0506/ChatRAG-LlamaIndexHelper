{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a3748d-7cd0-4434-b832-266ee0b51b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import qdrant_client\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "# from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "# from fastembed import TextEmbedding\n",
    "import model_utils, agent_utils\n",
    "import prompt_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d48fbd-f93d-4523-a5a6-d4374a50a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama index ascyncio config\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# logging config\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c6f555-91bb-4b02-8294-be90b2999e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"models/Meta-Llama-3.1-8B-Instruct\"\n",
    "embed_model_name = \"models/bge-small-en-v1.5\"\n",
    "device_map = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72e977b-b6cc-4c61-b223-ff140623c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: models/bge-small-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: models/bge-small-en-v1.5\n",
      "Load pretrained SentenceTransformer: models/bge-small-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "Loading LLM: models/Meta-Llama-3.1-8B-Instruct\n",
      "Loading tokenizer and model with quantization config from: models/Meta-Llama-3.1-8B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LLM and embedding models\n"
     ]
    }
   ],
   "source": [
    "Settings.llm, Settings.embed_model = agent_utils.load_llm_embed_models(\n",
    "    llm_name=llm_name,\n",
    "    embed_name=embed_model_name,\n",
    "    device_map=device_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472df0e-2967-42de-8af4-8be4228aa085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3a370e-53f6-4079-b36f-dd33a22faea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 159 documents\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"./data\",\n",
    "    filename_as_id=True,\n",
    ").load_data()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb50d4-9701-489e-9e1f-db3564ad1d53",
   "metadata": {},
   "source": [
    "### Build/Load the VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a67ddbd-cd5d-479b-88f6-ba4a6dbb9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(\n",
    "    path=\"./qdrant_db/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb7c0d4a-cc69-4d72-98e2-f87b8384a1d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 73800.07it/s]\n",
      "\u001b[0;93m2024-08-16 15:23:53.053833375 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-08-16 15:23:53.053869770 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 8545.27it/s]\n",
      "\u001b[0;93m2024-08-16 15:23:53.545331736 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-08-16 15:23:53.545353745 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(\n",
    "    client=client, \n",
    "    collection_name=\"llamaindex-blogs-hybrid-search\",\n",
    "    enable_hybrid=True,\n",
    "    fastembed_sparse_model=\"Qdrant/bm42-all-minilm-l6-v2-attentions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bef4d65-f167-411d-b1db-3840f10f4546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x7f1a532eb820>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x7f1a532eb6d0>, vector_stores={'default': QdrantVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=False, collection_name='llamaindex-blogs-hybrid-search', url=None, api_key=None, batch_size=64, parallel=1, max_retries=3, client_kwargs={}, enable_hybrid=True, index_doc_id=True, fastembed_sparse_model='Qdrant/bm42-all-minilm-l6-v2-attentions'), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x7f1a532ebbb0>, property_graph_store=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3e24b2-52d2-4fd6-b075-7ae1c333f3a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents,\n",
    "#     storage_context=storage_context,\n",
    "#     show_progress=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf3c01e-7a11-470b-a0dc-ba1bea0475e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7f1a529580a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    ")\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8fce5-28cd-4aa9-978a-f0e4ab925c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f33afca6-1c96-4e5f-a0fb-d6eb0a5686a5",
   "metadata": {},
   "source": [
    "### Query Index¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee0f780-95be-44c2-bd92-2502999d0f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook?\n"
     ]
    }
   ],
   "source": [
    "question = '''What are the two critical areas of RAG system performance that are assessed \\\n",
    "in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook?'''\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3886cf3c-203f-43ab-a46c-2ebe536497b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine(use_async=True, response_mode=\"refine\")\n",
    "response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c39a82c5-61f4-406d-9128-8ae7d306fd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook are:\n",
       "\n",
       "1. The Retrieval System\n",
       "2. Response Generation.\n",
       "\n",
       "However, considering the provided context, it seems that the focus is on more advanced aspects of RAG systems, such as agentic knowledge retrieval and multi-step reasoning. Therefore, a more refined answer could be:\n",
       "\n",
       "The two critical areas of RAG system performance that are assessed in the \"Evaluating RAG with LlamaIndex\" section of the OpenAI Cookbook are:\n",
       "\n",
       "1. The Retrieval System\n",
       "2. Advanced Response Generation, including aspects such as agentic reasoning, multi-step reasoning, and complex query handling.\n",
       "\n",
       "This refined answer takes into account the additional context provided, which highlights the importance of advanced capabilities in RAG systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4501b38-be4d-42dc-bbda-f03db93263fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2742526-5479-4dad-b533-1c5c04d33912': {'file_path': '/workspace/projects/LlamindexHelper/data/openai-cookbook-evaluating-rag-systems-fe393c61fb93.html',\n",
       "  'file_name': 'openai-cookbook-evaluating-rag-systems-fe393c61fb93.html',\n",
       "  'file_type': 'text/html',\n",
       "  'file_size': 2220,\n",
       "  'creation_date': '2024-07-21',\n",
       "  'last_modified_date': '2024-07-21'},\n",
       " '2b66388c-fb02-4509-92f6-1c6b0a69cf08': {'file_path': '/workspace/projects/LlamindexHelper/data/llamaindex-newsletter-2024-06-11.html',\n",
       "  'file_name': 'llamaindex-newsletter-2024-06-11.html',\n",
       "  'file_type': 'text/html',\n",
       "  'file_size': 11257,\n",
       "  'creation_date': '2024-07-21',\n",
       "  'last_modified_date': '2024-07-21'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5684b65-fcff-458f-a548-cd5f4cd1f95a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combine DocumentSummaryIndex and VectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2511082-d27c-4afd-afe7-92165cb0d2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x7fe41e188a30>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x7fe41e188730>, vector_stores={'default': QdrantVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=False, collection_name='llamaindex-blogs', url=None, api_key=None, batch_size=64, parallel=1, max_retries=3, client_kwargs={}, enable_hybrid=False, index_doc_id=True, fastembed_sparse_model=None), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x7fe41e188190>, property_graph_store=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40492a41-f468-472a-b729-d1da8e67ff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QdrantVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=False, collection_name='llamaindex-blogs', url=None, api_key=None, batch_size=64, parallel=1, max_retries=3, client_kwargs={}, enable_hybrid=False, index_doc_id=True, fastembed_sparse_model=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31a674e-de44-4d57-9017-cf9db925ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document index\n",
    "idex_mapping = storage_context.index_store.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "918863f8-5f2a-41c8-9753-b552f30729f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6089ce48-849d-4b4f-95e9-d84b8ac98b18'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.index_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a5bc5d-1f55-4797-ad16-8a27bc0d05d8",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "265eb550-6e62-4072-becb-adefe08ee1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core import QueryBundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074abf23-6f5b-424f-8cd2-c29d69b4db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is latest LlamaIndex Newsletter?\"\n",
    "query_bundle = QueryBundle(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959cb28-f8a1-4347-847d-92ce83508111",
   "metadata": {},
   "source": [
    "#### Normal Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd4e0b6f-4a04-41db-9638-68411d292fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.94it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(use_async=True, response_mode=\"refine\")\n",
    "response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cde883d-b2a3-4114-b0d1-7d841ff912be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The latest LlamaIndex newsletter is the one from October 31, 2023."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3683413c-161e-4164-bc35-ad8c32bece2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741100641613752 {'file_path': '/workspace/projects/LlamindexHelper/data/llamaindex-newsletter-2024-01-02-f349db8c1842.html', 'file_name': 'llamaindex-newsletter-2024-01-02-f349db8c1842.html', 'file_type': 'text/html', 'file_size': 17293, 'creation_date': '2024-07-21', 'last_modified_date': '2024-07-21'}\n",
      "0.7739661334334822 {'file_path': '/workspace/projects/LlamindexHelper/data/llamaindex-newsletter-2023-10-31-36244e2b3f0c.html', 'file_name': 'llamaindex-newsletter-2023-10-31-36244e2b3f0c.html', 'file_type': 'text/html', 'file_size': 11836, 'creation_date': '2024-07-21', 'last_modified_date': '2024-07-21'}\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.score, node.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbffca-ea95-40e2-abfa-73c1b3276efc",
   "metadata": {},
   "source": [
    "\n",
    "#### Hybrid Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "534f9730-a54d-4504-be47-e296a85d6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 162.52it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "hybrid_query_engine = index.as_query_engine(\n",
    "    use_async=True, \n",
    "    response_mode=\"refine\", \n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=2, sparse_top_k=12\n",
    ")\n",
    "hybrid_response = hybrid_query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9bc0594-d800-497d-ac96-1f1f3f8e46c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The latest LlamaIndex Newsletter is the special edition for the last two weeks of 2023, which is packed with updates on the latest features, community demos, courses, insightful tutorials, guides, and webinars curated by LlamaIndex.\n",
       "\n",
       "However, based on the provided context, it seems that the latest newsletter is not the special edition for the last two weeks of 2023, but rather the one available on June 18, 2024. This newsletter includes updates on the following topics:\n",
       "\n",
       "- A tutorial by Arkiti on building a dynamic text-to-SQL solution using Llama 3 and GroqInc, highlighting the scalable and fast capabilities of SingleStoreDB Helios for multi-cloud deployments.\n",
       "- A tutorial by Kingzzm on Advanced RAG Patterns detailing effective strategies for handling documents with embedded tables, utilizing tools like LlamaParse and Nougat for enhanced QA performance.\n",
       "- A webinar on The Future of Web Agents with MultiOn, where Div Garg provided a full demo walkthrough and discussed the agentification of the internet.\n",
       "\n",
       "The newsletter is available at the following path: /workspace/projects/LlamindexHelper/data/llamaindex-newsletter-2024-06-18.html."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(hybrid_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c0ea55c-ca25-40ab-82c6-c321c3128a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 {'file_path': '/workspace/projects/LlamindexHelper/data/llamaindex-newsletter-2024-01-02-f349db8c1842.html', 'file_name': 'llamaindex-newsletter-2024-01-02-f349db8c1842.html', 'file_type': 'text/html', 'file_size': 17293, 'creation_date': '2024-07-21', 'last_modified_date': '2024-07-21'}\n",
      "0.5 {'file_path': '/workspace/projects/LlamindexHelper/data/llamaindex-newsletter-2024-06-18.html', 'file_name': 'llamaindex-newsletter-2024-06-18.html', 'file_type': 'text/html', 'file_size': 12216, 'creation_date': '2024-07-21', 'last_modified_date': '2024-07-21'}\n"
     ]
    }
   ],
   "source": [
    "for node in hybrid_response.source_nodes:\n",
    "    print(node.score, node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6c5f0-6af7-4adc-b4dd-478adb221f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-py310",
   "language": "python",
   "name": "llm-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
