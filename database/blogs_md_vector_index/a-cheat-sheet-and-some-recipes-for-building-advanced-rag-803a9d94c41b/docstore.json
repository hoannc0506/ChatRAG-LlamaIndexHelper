{"docstore/data": {"49ab831e-f417-4d68-8620-37bc4509e023": {"__data__": {"id_": "49ab831e-f417-4d68-8620-37bc4509e023", "embedding": null, "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66d529f5-4674-427f-8ac0-55f98aff6d64", "node_type": "1", "metadata": {"Header_1": " Basic RAG"}, "hash": "8ebfa36f7cb42670352f6ce173b849ce63ce6e8a5b32b73e80bf13202829d613", "class_name": "RelatedNodeInfo"}}, "text": "It\u2019s the start of a new year and perhaps you\u2019re looking to break into the RAG\nscene by building your very first RAG system. Or, maybe you\u2019ve built Basic RAG\nsystems and are now looking to enhance them to something more advanced in\norder to better handle your user\u2019s queries and data structures.\n\nIn either case, knowing where or how to begin may be a challenge in and of\nitself! If that\u2019s true, then hopefully this blog post points you in the right\ndirection for your next steps, and moreover, provides for you a mental model\nfor you to anchor your decisions when building advanced RAG systems.\n\nThe RAG cheat sheet shared above was greatly inspired by a recent RAG survey\npaper ( [ \u201cRetrieval-Augmented Generation for Large Language Models: A Survey\u201d\nGao, Yunfan, et al. 2023 ](https://arxiv.org/pdf/2312.10997.pdf) ).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 819, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66d529f5-4674-427f-8ac0-55f98aff6d64": {"__data__": {"id_": "66d529f5-4674-427f-8ac0-55f98aff6d64", "embedding": null, "metadata": {"Header_1": " Basic RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49ab831e-f417-4d68-8620-37bc4509e023", "node_type": "1", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "9531f9c1ceaaedfdec17ca7eb19eb6fa03e90380943e820b2d3ae6a616da32a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "76e68abd-e038-41f1-8f0d-4d90723e09e7", "node_type": "1", "metadata": {"Header_1": " Success Requirements for RAG"}, "hash": "b760521063ed9bd6e1e0ab598c7fdebc0c592c257ed6cd4af1c43b3f833a7f47", "class_name": "RelatedNodeInfo"}}, "text": "Basic RAG\n\nMainstream RAG as defined today involves retrieving documents from an external\nknowledge database and passing these along with the user\u2019s query to an LLM for\nresponse generation. In other words, RAG involves a Retrieval component, an\nExternal Knowledge database and a Generation component.\n\n**LlamaIndex Basic RAG Recipe:**\n\n    \n    \n    from llama_index import SimpleDirectoryReader, VectorStoreIndex\n    \n    # load data\n    documents = SimpleDirectoryReader(input_dir=\"...\").load_data()\n    \n    # build VectorStoreIndex that takes care of chunking documents\n    # and encoding chunks to embeddings for future retrieval\n    index = VectorStoreIndex.from_documents(documents=documents)\n    \n    # The QueryEngine class is equipped with the generator\n    # and facilitates the retrieval and generation steps\n    query_engine = index.as_query_engine()\n    \n    # Use your Default RAG\n    response = query_engine.query(\"A user's query\")", "mimetype": "text/plain", "start_char_idx": 824, "end_char_idx": 1771, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "76e68abd-e038-41f1-8f0d-4d90723e09e7": {"__data__": {"id_": "76e68abd-e038-41f1-8f0d-4d90723e09e7", "embedding": null, "metadata": {"Header_1": " Success Requirements for RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66d529f5-4674-427f-8ac0-55f98aff6d64", "node_type": "1", "metadata": {"Header_1": " Basic RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "7a32891d325a317a484f97e3462fbefa564f467043d7c24938bdf95262e7e2e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07bba14f-5955-4b25-be3c-cff24b7c2f1a", "node_type": "1", "metadata": {"Header_1": " Advanced RAG"}, "hash": "d3ec144a30397bfb26643817c68619f7ad3d45a6253cc662c8f4aa62f37ff5bd", "class_name": "RelatedNodeInfo"}}, "text": "Success Requirements for RAG\n\nIn order for a RAG system to be deemed as a success (in the sense of providing\nuseful and relevant answers to user questions), there are really only two high\nlevel requirements:\n\n  1. Retrieval must be able to find the most relevant documents to a user query. \n  2. Generation must be able to make good use of the retrieved documents to sufficiently answer the user query.", "mimetype": "text/plain", "start_char_idx": 1776, "end_char_idx": 2178, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "07bba14f-5955-4b25-be3c-cff24b7c2f1a": {"__data__": {"id_": "07bba14f-5955-4b25-be3c-cff24b7c2f1a", "embedding": null, "metadata": {"Header_1": " Advanced RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "76e68abd-e038-41f1-8f0d-4d90723e09e7", "node_type": "1", "metadata": {"Header_1": " Success Requirements for RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "efbe247e02f21da5077ab48d3cfb58273124be048ad936adc4e149399322b184", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c7eeea5-24b6-4c06-81c6-635d6e6577b1", "node_type": "1", "metadata": {"Header_1": " Advanced techniques for Retrieval must be able to find the most relevant"}, "hash": "8fbf645a6bf3de74601d772498407a23e74c67553c5c399092439f942a380308", "class_name": "RelatedNodeInfo"}}, "text": "Advanced RAG\n\nWith the success requirements defined, we can then say that building advanced\nRAG is really about the application of more sophisticated techniques and\nstrategies (to the Retrieval or Generation components) to ensure that they are\nultimately met. Furthermore, we can categorize a sophisticated technique as\neither one that addresses one of the two high-level success requirements\nindependent (more or less) of the other, or one that addresses both of these\nrequirements simultaneously.", "mimetype": "text/plain", "start_char_idx": 2184, "end_char_idx": 2682, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8c7eeea5-24b6-4c06-81c6-635d6e6577b1": {"__data__": {"id_": "8c7eeea5-24b6-4c06-81c6-635d6e6577b1", "embedding": null, "metadata": {"Header_1": " Advanced techniques for Retrieval must be able to find the most relevant", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07bba14f-5955-4b25-be3c-cff24b7c2f1a", "node_type": "1", "metadata": {"Header_1": " Advanced RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "fb955f34baff5c17a25d0bb68c46771f009dc8845fafa47d10ad337caab0b748", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca8cd969-64b2-4a80-b3d8-2ab1be4d90fb", "node_type": "1", "metadata": {"Header_1": " Advanced techniques for Generation must be able to make good use of the"}, "hash": "f626a3affb3c6b83f4f6219ec6f616376c1eb874d9e41b64cebfd38167d3a07f", "class_name": "RelatedNodeInfo"}}, "text": "Advanced techniques for Retrieval must be able to find the most relevant\ndocuments to a user query\n\nBelow we briefly describe a couple of the more sophisticated techniques to\nhelp achieve the first success requirement.\n\n  1. **Chunk-Size Optimization:** Since LLMs are restricted by context length, it is necessary to chunk documents when building the External Knowledge database. Chunks that are too big or too small can pose problems for the Generation component leading to in accurate responses. \n\n**LlamaIndex Chunk Size Optimization Recipe** ( [ notebook guide\n](https://github.com/run-\nllama/llama_index/blob/main/docs/examples/param_optimizer/param_optimizer.ipynb)\n) **:**\n\n    \n    \n    from llama_index import ServiceContext\n    from llama_index.param_tuner.base import ParamTuner, RunResult\n    from llama_index.evaluation import SemanticSimilarityEvaluator, BatchEvalRunner\n    \n    ### Recipe\n    ### Perform hyperparameter tuning as in traditional ML via grid-search\n    ### 1. Define an objective function that ranks different parameter combos\n    ### 2. Build ParamTuner object\n    ### 3. Execute hyperparameter tuning with ParamTuner.tune()\n    \n    # 1. Define objective function\n    def objective_function(params_dict):\n        chunk_size = params_dict[\"chunk_size\"]\n        docs = params_dict[\"docs\"]\n        top_k = params_dict[\"top_k\"]\n        eval_qs = params_dict[\"eval_qs\"]\n        ref_response_strs = params_dict[\"ref_response_strs\"]\n    \n        # build RAG pipeline\n        index = _build_index(chunk_size, docs)  # helper function not shown here\n        query_engine = index.as_query_engine(similarity_top_k=top_k)\n      \n        # perform inference with RAG pipeline on a provided questions `eval_qs`\n        pred_response_objs = get_responses(\n            eval_qs, query_engine, show_progress=True\n        )\n    \n        # perform evaluations of predictions by comparing them to reference\n        # responses `ref_response_strs`\n        evaluator = SemanticSimilarityEvaluator(...)\n        eval_batch_runner = BatchEvalRunner(\n            {\"semantic_similarity\": evaluator}, workers=2, show_progress=True\n        )\n        eval_results = eval_batch_runner.evaluate_responses(\n            eval_qs, responses=pred_response_objs, reference=ref_response_strs\n        )\n    \n        # get semantic similarity metric\n        mean_score = np.array(\n            [r.score for r in eval_results[\"semantic_similarity\"]]\n        ).mean()\n    \n        return RunResult(score=mean_score, params=params_dict)\n    \n    # 2. Build ParamTuner object\n    param_dict = {\"chunk_size\": [256, 512, 1024]} # params/values to search over\n    fixed_param_dict = { # fixed hyperparams\n      \"top_k\": 2,\n        \"docs\": docs,\n        \"eval_qs\": eval_qs[:10],\n        \"ref_response_strs\": ref_response_strs[:10],\n    }\n    param_tuner = ParamTuner(\n        param_fn=objective_function,\n        param_dict=param_dict,\n        fixed_param_dict=fixed_param_dict,\n        show_progress=True,\n    )\n    \n    # 3. Execute hyperparameter search\n    results = param_tuner.tune()\n    best_result = results.best_run_result\n    best_chunk_size = results.best_run_result.params[\"chunk_size\"]\n\n**2\\. Structured External Knowledge:** In complex scenarios, it may be\nnecessary to build your external knowledge with a bit more structure than the\nbasic vector index so as to permit recursive retrievals or routed retrieval\nwhen dealing with sensibly separated external knowledge sources.\n\n**LlamaIndex Recursive Retrieval Recipe** ( [ notebook guide\n](https://docs.llamaindex.ai/en/stable/examples/retrievers/recursive_retriever_nodes.html)\n) **:**\n\n    \n    \n    from llama_index import SimpleDirectoryReader, VectorStoreIndex\n    from llama_index.node_parser import SentenceSplitter\n    from llama_index.schema import IndexNode\n    \n    ### Recipe\n    ### Build a recursive retriever that retrieves using small chunks\n    ### but passes associated larger chunks to the generation stage\n    \n    # load data\n    documents = SimpleDirectoryReader(\n      input_file=\"some_data_path/llama2.pdf\"\n    ).load_data()\n    \n    # build parent chunks via NodeParser\n    node_parser = SentenceSplitter(chunk_size=1024)\n    base_nodes = node_parser.get_nodes_from_documents(documents)\n    \n    # define smaller child chunks\n    sub_chunk_sizes = [256, 512]\n    sub_node_parsers = [\n        SentenceSplitter(chunk_size=c, chunk_overlap=20) for c in sub_chunk_sizes\n    ]\n    all_nodes = []\n    for base_node in base_nodes:\n        for n in sub_node_parsers:\n            sub_nodes = n.get_nodes_from_documents([base_node])\n            sub_inodes = [\n                IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n            ]\n            all_nodes.extend(sub_inodes)\n        # also add original node to node\n        original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n        all_nodes.append(original_node)\n    \n    # define a VectorStoreIndex with all of the nodes\n    vector_index_chunk = VectorStoreIndex(\n        all_nodes, service_context=service_context\n    )\n    vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)\n    \n    # build RecursiveRetriever\n    all_nodes_dict = {n.node_id: n for n in all_nodes}\n    retriever_chunk = RecursiveRetriever(\n        \"vector\",\n        retriever_dict={\"vector\": vector_retriever_chunk},\n        node_dict=all_nodes_dict,\n        verbose=True,\n    )\n    \n    # build RetrieverQueryEngine using recursive_retriever\n    query_engine_chunk = RetrieverQueryEngine.from_args(\n        retriever_chunk, service_context=service_context\n    )\n    \n    # perform inference with advanced RAG (i.e. query engine)\n    response = query_engine_chunk.query(\n        \"Can you tell me about the key concepts for safety finetuning\"\n    )\n\n**Other useful links**\n\nWe have several of guides demonstrating the application of other advanced\ntechniques to help ensure accurate retrieval in complex cases. Here are links\nto a select few of them:\n\n  1. [ Building External Knowledge using Knowledge Graphs ](https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine.html)\n  2. [ Performing Mixed Retrieval with Auto Retrievers ](https://docs.llamaindex.ai/en/stable/examples/vector_stores/elasticsearch_auto_retriever.html)\n  3. [ Building Fusion Retrievers ](https://docs.llamaindex.ai/en/stable/examples/retrievers/simple_fusion.html)\n  4. [ Fine-tuning Embedding Models used in Retrieval ](https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding.html)\n  5. [ Transforming Query Embeddings (HyDE) ](https://docs.llamaindex.ai/en/stable/examples/query_transformations/HyDEQueryTransformDemo.html)", "mimetype": "text/plain", "start_char_idx": 2687, "end_char_idx": 9406, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ca8cd969-64b2-4a80-b3d8-2ab1be4d90fb": {"__data__": {"id_": "ca8cd969-64b2-4a80-b3d8-2ab1be4d90fb", "embedding": null, "metadata": {"Header_1": " Advanced techniques for Generation must be able to make good use of the", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c7eeea5-24b6-4c06-81c6-635d6e6577b1", "node_type": "1", "metadata": {"Header_1": " Advanced techniques for Retrieval must be able to find the most relevant", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "b951ad50f32a8701de7589628cff4b84b5b386320085d224d1aee69b082b504f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "98149aa8-99ff-4fb6-af82-d45f38e8c8b0", "node_type": "1", "metadata": {"Header_1": " Advanced techniques for simultaneously addressing Retrieval and Generation"}, "hash": "48b0313b48bb3fe76083a6ac8aad5faf478787db1fa7b2b341d1e3baeaa5dfb0", "class_name": "RelatedNodeInfo"}}, "text": "Advanced techniques for Generation must be able to make good use of the\nretrieved documents\n\nSimilar to previous section, we provide a couple of examples of the\nsophisticated techniques under this category, which can be described as\nensuring that the retrieved documents are well aligned to the LLM of the\nGenerator.\n\n  1. **Information Compression:** Not only are LLMs are restricted by context length, but there can be response degradation if the retrieved documents carry too much noise (i.e. irrelevant information). \n\n**LlamaIndex Information Compression Recipe** ( [ notebook guide\n](https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/LongLLMLingua.html)\n) **:**\n\n    \n    \n    from llama_index import SimpleDirectoryReader, VectorStoreIndex\n    from llama_index.query_engine import RetrieverQueryEngine\n    from llama_index.postprocessor import LongLLMLinguaPostprocessor\n    \n    ### Recipe\n    ### Define a Postprocessor object, here LongLLMLinguaPostprocessor\n    ### Build QueryEngine that uses this Postprocessor on retrieved docs\n    \n    # Define Postprocessor\n    node_postprocessor = LongLLMLinguaPostprocessor(\n        instruction_str=\"Given the context, please answer the final question\",\n        target_token=300,\n        rank_method=\"longllmlingua\",\n        additional_compress_kwargs={\n            \"condition_compare\": True,\n            \"condition_in_question\": \"after\",\n            \"context_budget\": \"+100\",\n            \"reorder_context\": \"sort\",  # enable document reorder\n        },\n    )\n    \n    # Define VectorStoreIndex\n    documents = SimpleDirectoryReader(input_dir=\"...\").load_data()\n    index = VectorStoreIndex.from_documents(documents)\n    \n    # Define QueryEngine\n    retriever = index.as_retriever(similarity_top_k=2)\n    retriever_query_engine = RetrieverQueryEngine.from_args(\n        retriever, node_postprocessors=[node_postprocessor]\n    )\n    \n    # Used your advanced RAG\n    response = retriever_query_engine.query(\"A user query\")\n\n**2\\. Result Re-Rank:** LLMs suffer from the so-called \u201cLost in the Middle\u201d\nphenomena which stipulates that LLMs focus on the extreme ends of the prompts.\nIn light of this, it is beneficial to re-rank retrieved documents before\npassing them off to the Generation component.\n\n**LlamaIndex Re-Ranking For Better Generation Recipe** ( [ notebook guide\n](https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/CohereRerank.html)\n) **:**\n\n    \n    \n    import os\n    from llama_index import SimpleDirectoryReader, VectorStoreIndex\n    from llama_index.postprocessor.cohere_rerank import CohereRerank\n    from llama_index.postprocessor import LongLLMLinguaPostprocessor\n    \n    ### Recipe\n    ### Define a Postprocessor object, here CohereRerank\n    ### Build QueryEngine that uses this Postprocessor on retrieved docs\n    \n    # Build CohereRerank post retrieval processor\n    api_key = os.environ[\"COHERE_API_KEY\"]\n    cohere_rerank = CohereRerank(api_key=api_key, top_n=2)\n    \n    # Build QueryEngine (RAG) using the post processor\n    documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n    index = VectorStoreIndex.from_documents(documents=documents)\n    query_engine = index.as_query_engine(\n        similarity_top_k=10,\n        node_postprocessors=[cohere_rerank],\n    )\n    \n    # Use your advanced RAG\n    response = query_engine.query(\n        \"What did Sam Altman do in this essay?\"\n    )", "mimetype": "text/plain", "start_char_idx": 9411, "end_char_idx": 12824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "98149aa8-99ff-4fb6-af82-d45f38e8c8b0": {"__data__": {"id_": "98149aa8-99ff-4fb6-af82-d45f38e8c8b0", "embedding": null, "metadata": {"Header_1": " Advanced techniques for simultaneously addressing Retrieval and Generation", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca8cd969-64b2-4a80-b3d8-2ab1be4d90fb", "node_type": "1", "metadata": {"Header_1": " Advanced techniques for Generation must be able to make good use of the", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "35e596899b955ee64a67f768915a53dc1b7165f357228ee8f2f21cb92f3777c8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48257832-ce5c-4635-ad4e-778d4d31b415", "node_type": "1", "metadata": {"Header_1": " Measurement Aspects of RAG"}, "hash": "e43d055b14a34621a65bf4158d7dedb9815625b886e732aa030bbd050dd1d0ca", "class_name": "RelatedNodeInfo"}}, "text": "Advanced techniques for simultaneously addressing Retrieval and Generation\nsuccess requirements\n\nIn this sub section, we consider sophisticated methods that use the synergy of\nretrieval and generation in order to achieve both better retrieval as well as\nmore accurate generated responses to user queries).\n\n  1. **Generator-Enhanced Retrieval:** These techniques make use of the LLM\u2019s inherent reasoning abilities to refine the user query before retrieval is performed so as to better indicate what exactly it requires to provide a useful response. \n\n**LlamaIndex Generator-Enhanced Retrieval Recipe** ( [ notebook guide\n](https://docs.llamaindex.ai/en/stable/examples/query_engine/flare_query_engine.html)\n) **:**\n\n    \n    \n    from llama_index.llms import OpenAI\n    from llama_index.query_engine import FLAREInstructQueryEngine\n    from llama_index import (\n        VectorStoreIndex,\n        SimpleDirectoryReader,\n        ServiceContext,\n    )\n    ### Recipe\n    ### Build a FLAREInstructQueryEngine which has the generator LLM play\n    ### a more active role in retrieval by prompting it to elicit retrieval\n    ### instructions on what it needs to answer the user query.\n    \n    # Build FLAREInstructQueryEngine\n    documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()\n    index = VectorStoreIndex.from_documents(documents)\n    index_query_engine = index.as_query_engine(similarity_top_k=2)\n    service_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4\"))\n    flare_query_engine = FLAREInstructQueryEngine(\n        query_engine=index_query_engine,\n        service_context=service_context,\n        max_iterations=7,\n        verbose=True,\n    )\n    \n    # Use your advanced RAG\n    response = flare_query_engine.query(\n        \"Can you tell me about the author's trajectory in the startup world?\"\n    )\n\n**2\\. Iterative Retrieval-Generator RAG:** For some complex cases, multi-step\nreasoning may be required to provide a useful and relevant answer to the user\nquery.\n\n**LlamaIndex Iterative Retrieval-Generator Recipe (** [ notebook guide\n](https://docs.llamaindex.ai/en/stable/examples/evaluation/RetryQuery.html#retry-\nquery-engine) **):**\n\n    \n    \n    from llama_index.query_engine import RetryQueryEngine\n    from llama_index.evaluation import RelevancyEvaluator\n    \n    ### Recipe\n    ### Build a RetryQueryEngine which performs retrieval-generation cycles\n    ### until it either achieves a passing evaluation or a max number of\n    ### cycles has been reached\n    \n    # Build RetryQueryEngine\n    documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()\n    index = VectorStoreIndex.from_documents(documents)\n    base_query_engine = index.as_query_engine()\n    query_response_evaluator = RelevancyEvaluator() # evaluator to critique \n                                                    # retrieval-generation cycles\n    retry_query_engine = RetryQueryEngine(\n        base_query_engine, query_response_evaluator\n    )\n    \n    # Use your advanced rag\n    retry_response = retry_query_engine.query(\"A user query\")", "mimetype": "text/plain", "start_char_idx": 12829, "end_char_idx": 15896, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "48257832-ce5c-4635-ad4e-778d4d31b415": {"__data__": {"id_": "48257832-ce5c-4635-ad4e-778d4d31b415", "embedding": null, "metadata": {"Header_1": " Measurement Aspects of RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "98149aa8-99ff-4fb6-af82-d45f38e8c8b0", "node_type": "1", "metadata": {"Header_1": " Advanced techniques for simultaneously addressing Retrieval and Generation", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "1775016f0cc1d292c8542bb74b12e01b22ce4f094fc3045f3b98d97796e2e7ce", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9fc9f9cf-8665-4c6d-a030-10d30b547052", "node_type": "1", "metadata": {"Header_1": " You\u2019re Now Equipped To Do Advanced RAG"}, "hash": "b803ab4fc21ea67867c90f8d698730b51e17c0f3b738e7e96e2a78deb24f9613", "class_name": "RelatedNodeInfo"}}, "text": "Measurement Aspects of RAG\n\nEvaluating RAG systems are, of course, of utmost importance. In their survey\npaper, Gao, Yunfan et al. indicate 7 measurement aspects as seen in the top-\nright portion of the attached RAG cheat sheet. The llama-index library\nconsists of several evaluation abstractions as well as integrations to RAGAs\nin order to help builders gain an understanding of the level to which their\nRAG system achieves the success requirements through the lens of these\nmeasurement aspects. Below, we list a select few of the evaluation notebook\nguides.\n\n  1. [ Answer Relevancy and Context Relevancy ](https://docs.llamaindex.ai/en/latest/examples/evaluation/answer_and_context_relevancy.html)\n  2. [ Faithfulness ](https://www.notion.so/LlamaIndex-Platform-0754edd9af1c4159bde12649c184c8ef?pvs=21)\n  3. [ Retrieval Evaluation ](https://github.com/run-llama/llama_index/blob/main/docs/examples/evaluation/retrieval/retriever_eval.ipynb)\n  4. [ Batch Evaluations with BatchEvalRunner ](https://docs.llamaindex.ai/en/stable/examples/evaluation/batch_eval.html)", "mimetype": "text/plain", "start_char_idx": 15901, "end_char_idx": 16967, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9fc9f9cf-8665-4c6d-a030-10d30b547052": {"__data__": {"id_": "9fc9f9cf-8665-4c6d-a030-10d30b547052", "embedding": null, "metadata": {"Header_1": " You\u2019re Now Equipped To Do Advanced RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "785f264c-de66-4986-aa74-2119d1b42dde", "node_type": "4", "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5fb578c23f877e180ed6779fe7079c63f0a3d3a02f524c943bfff8d2aab5ee06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48257832-ce5c-4635-ad4e-778d4d31b415", "node_type": "1", "metadata": {"Header_1": " Measurement Aspects of RAG", "filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}, "hash": "5a28224c4864a45b24fcfab92f7203b04b01fae9fd1dd7adcc12250471eca24b", "class_name": "RelatedNodeInfo"}}, "text": "You\u2019re Now Equipped To Do Advanced RAG\n\nAfter reading this blog post, we hope that you feel more equipped and\nconfident to apply some of these sophisticated techniques for building\nAdvanced RAG systems!", "mimetype": "text/plain", "start_char_idx": 16972, "end_char_idx": 17174, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"49ab831e-f417-4d68-8620-37bc4509e023": {"doc_hash": "9531f9c1ceaaedfdec17ca7eb19eb6fa03e90380943e820b2d3ae6a616da32a7", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "66d529f5-4674-427f-8ac0-55f98aff6d64": {"doc_hash": "7a32891d325a317a484f97e3462fbefa564f467043d7c24938bdf95262e7e2e3", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "76e68abd-e038-41f1-8f0d-4d90723e09e7": {"doc_hash": "efbe247e02f21da5077ab48d3cfb58273124be048ad936adc4e149399322b184", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "07bba14f-5955-4b25-be3c-cff24b7c2f1a": {"doc_hash": "fb955f34baff5c17a25d0bb68c46771f009dc8845fafa47d10ad337caab0b748", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "8c7eeea5-24b6-4c06-81c6-635d6e6577b1": {"doc_hash": "b951ad50f32a8701de7589628cff4b84b5b386320085d224d1aee69b082b504f", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "ca8cd969-64b2-4a80-b3d8-2ab1be4d90fb": {"doc_hash": "35e596899b955ee64a67f768915a53dc1b7165f357228ee8f2f21cb92f3777c8", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "98149aa8-99ff-4fb6-af82-d45f38e8c8b0": {"doc_hash": "1775016f0cc1d292c8542bb74b12e01b22ce4f094fc3045f3b98d97796e2e7ce", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "48257832-ce5c-4635-ad4e-778d4d31b415": {"doc_hash": "5a28224c4864a45b24fcfab92f7203b04b01fae9fd1dd7adcc12250471eca24b", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}, "9fc9f9cf-8665-4c6d-a030-10d30b547052": {"doc_hash": "4e2e3d38c23011473842e54987a45b64ea79507a0f5b94fa1b54e5fedb9f83ea", "ref_doc_id": "785f264c-de66-4986-aa74-2119d1b42dde"}}, "docstore/ref_doc_info": {"785f264c-de66-4986-aa74-2119d1b42dde": {"node_ids": ["49ab831e-f417-4d68-8620-37bc4509e023", "66d529f5-4674-427f-8ac0-55f98aff6d64", "76e68abd-e038-41f1-8f0d-4d90723e09e7", "07bba14f-5955-4b25-be3c-cff24b7c2f1a", "8c7eeea5-24b6-4c06-81c6-635d6e6577b1", "ca8cd969-64b2-4a80-b3d8-2ab1be4d90fb", "98149aa8-99ff-4fb6-af82-d45f38e8c8b0", "48257832-ce5c-4635-ad4e-778d4d31b415", "9fc9f9cf-8665-4c6d-a030-10d30b547052"], "metadata": {"filename": "a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b.md", "extension": ".md", "title": "A Cheat Sheet and Some Recipes For Building Advanced RAG", "date": "Jan 5, 2024", "url": "https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b"}}}}