{"docstore/data": {"bf81db47-8c21-4cc4-8ec4-a4391e35187e": {"__data__": {"id_": "bf81db47-8c21-4cc4-8ec4-a4391e35187e", "embedding": null, "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d0f715e6-b023-4693-aa34-4ccd4e6ac08e", "node_type": "1", "metadata": {"Header_1": " Background"}, "hash": "feeb6627dfc7036cf84bc9f8f2ffc3c24902f347406c53cfe6b55ade8cca6a5f", "class_name": "RelatedNodeInfo"}}, "text": "In this blog post, we introduce a brand new LlamaIndex data structure: a\nDocument Summary Index. We describe how it can help offer better retrieval\nperformance compared to traditional semantic search, and also walk through an\nexample.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 234, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d0f715e6-b023-4693-aa34-4ccd4e6ac08e": {"__data__": {"id_": "d0f715e6-b023-4693-aa34-4ccd4e6ac08e", "embedding": null, "metadata": {"Header_1": " Background", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf81db47-8c21-4cc4-8ec4-a4391e35187e", "node_type": "1", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "20c80604edf8f4ce09ce2639165d1e21f2c5ad8622cad56fc078f919d45c6107", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dae9da8a-87d8-4b5d-9f4a-967ab99a0932", "node_type": "1", "metadata": {"Header_1": " Background", "Header_2": " Limitations of Existing Approaches"}, "hash": "15821892a72e2d321764bf9d09d96e7ca5a21dbbb27ac7b462e1585112f18282", "class_name": "RelatedNodeInfo"}}, "text": "Background\n\nOne of the core use cases of Large Language Models (LLMs) is question-\nanswering over your own data. To do this, we pair the LLM with a \u201cretrieval\u201d\nmodel that can perform information retrieval over a knowledge corpus, and\nperform response synthesis over the retrieved texts using the LLM. This\noverall framework is called Retrieval-Augmented Generation.\n\nMost users building LLM-powered QA systems today tend to do some form of the\nfollowing:\n\n  1. Take source documents, split each one into text chunks \n  2. Store text chunks in a vector db \n  3. During query-time, retrieve text chunks by embedding similarity and/or keyword filters. \n  4. Perform response synthesis \n\nFor a variety of reasons, this approach provides limited retrieval\nperformance.", "mimetype": "text/plain", "start_char_idx": 239, "end_char_idx": 1002, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dae9da8a-87d8-4b5d-9f4a-967ab99a0932": {"__data__": {"id_": "dae9da8a-87d8-4b5d-9f4a-967ab99a0932", "embedding": null, "metadata": {"Header_1": " Background", "Header_2": " Limitations of Existing Approaches", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d0f715e6-b023-4693-aa34-4ccd4e6ac08e", "node_type": "1", "metadata": {"Header_1": " Background", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "5e272cbdf64c4b8dd3ef7d19a4af63e0ee30df816a22ee52555aaced4089a9de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f25e0afe-68d1-4eb8-ad4c-dc7df661dfb9", "node_type": "1", "metadata": {"Header_1": " Document Summary Index"}, "hash": "c942db760a96a28cabad921cc20f1d7751762b7442eee6be3baa3bb239f7acaa", "class_name": "RelatedNodeInfo"}}, "text": "Limitations of Existing Approaches\n\nThere are a few limitations of embedding retrieval using text chunks.\n\n  * **Text chunks lack global context.** Oftentimes the question requires context beyond what is indexed in a specific chunk. \n  * **Careful tuning of top-k / similarity score thresholds.** Make the value too small and you\u2019ll miss context. Make the value too big and cost/latency might increase with more irrelevant context. \n  * **Embeddings don\u2019t always select the most relevant context for a question.** Embeddings are inherently determined separately between text and the context. \n\nAdding keyword filters are one way to enhance the retrieval results. But that\ncomes with its own set of challenges. We would need to adequately determine\nthe proper keywords for each document, either manually or through an NLP\nkeyword extraction/topic tagging model. Also we would need to adequately infer\nthe proper keywords from the query.", "mimetype": "text/plain", "start_char_idx": 1008, "end_char_idx": 1943, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f25e0afe-68d1-4eb8-ad4c-dc7df661dfb9": {"__data__": {"id_": "f25e0afe-68d1-4eb8-ad4c-dc7df661dfb9", "embedding": null, "metadata": {"Header_1": " Document Summary Index", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dae9da8a-87d8-4b5d-9f4a-967ab99a0932", "node_type": "1", "metadata": {"Header_1": " Background", "Header_2": " Limitations of Existing Approaches", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "477d2394dd36ed349f333b9cbe23a8b59e1cb2463472f709ebf5b50becf1aac1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f0b8f3c7-3318-4049-8e69-4bf9bac4b528", "node_type": "1", "metadata": {"Header_1": " Document Summary Index", "Header_2": " How It Works"}, "hash": "7524d842256c0c06994aab0ec454ee446ffeb80d3785db18a8010550061f4011", "class_name": "RelatedNodeInfo"}}, "text": "Document Summary Index\n\nA diagram for the Document Summary Index\n\nWe propose a new index in [ LlamaIndex\n](https://github.com/jerryjliu/llama_index) that will extract/index an\n**unstructured text summary for each document** . This index can help enhance\nretrieval performance beyond existing retrieval approaches. It helps to index\nmore information than a single text chunk, and carries more semantic meaning\nthan keyword tags. It also allows for a more flexible form of retrieval: we\ncan do both LLM retrieval and embedding-based retrieval.", "mimetype": "text/plain", "start_char_idx": 1948, "end_char_idx": 2489, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f0b8f3c7-3318-4049-8e69-4bf9bac4b528": {"__data__": {"id_": "f0b8f3c7-3318-4049-8e69-4bf9bac4b528", "embedding": null, "metadata": {"Header_1": " Document Summary Index", "Header_2": " How It Works", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f25e0afe-68d1-4eb8-ad4c-dc7df661dfb9", "node_type": "1", "metadata": {"Header_1": " Document Summary Index", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "72f1ca8b4271b64bb7488912cd65729a02d0583cbe4b210e423ca102f53965c4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b66fcf65-7d1a-47bd-b0e0-4d6b820e845a", "node_type": "1", "metadata": {"Header_1": " Document Summary Index", "Header_2": " Additional Insights"}, "hash": "d388f72fbb139a8581716deaf72adc5c5068854cbc9d4cddb3346da9bcfea5c6", "class_name": "RelatedNodeInfo"}}, "text": "How It Works\n\nDuring build-time, we ingest each document, and use a LLM to extract a summary\nfrom each document. We also split the document up into text chunks (nodes).\nBoth the summary and the nodes are stored within our [ Document Store\n](https://gpt-index.readthedocs.io/en/latest/how_to/storage.html) abstraction.\nWe maintain a mapping from the summary to the source document/nodes.\n\nDuring query-time, we retrieve relevant documents to the query based on their\nsummaries, using the following approaches:\n\n  * **LLM-based Retrieval:** We present sets of document summaries to the LLM, and ask the LLM to determine which documents are relevant + their relevance score. \n  * **Embedding-based Retrieval:** We retrieve relevant documents based on summary embedding similarity (with a top-k cutoff). \n\nNote that this approach of retrieval for document summaries (even with the\nembedding-based approach) is different than embedding-based retrieval over\ntext chunks. The retrieval classes for the document summary index retrieve\n**all nodes** for any selected document, instead of returning relevant chunks\nat the node-level.\n\nStoring summaries for a document also enables **LLM-based retrieval** .\nInstead of feeding the entire document to the LLM in the beginning, we can\nfirst have the LLM inspect the concise document summary to see if it\u2019s\nrelevant to the query at all. This leverages the reasoning capabilities of\nLLM\u2019s which are more advanced than embedding-based lookup, but avoids the\ncost/latency of feeding the entire document to the LLM", "mimetype": "text/plain", "start_char_idx": 2495, "end_char_idx": 4041, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b66fcf65-7d1a-47bd-b0e0-4d6b820e845a": {"__data__": {"id_": "b66fcf65-7d1a-47bd-b0e0-4d6b820e845a", "embedding": null, "metadata": {"Header_1": " Document Summary Index", "Header_2": " Additional Insights", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f0b8f3c7-3318-4049-8e69-4bf9bac4b528", "node_type": "1", "metadata": {"Header_1": " Document Summary Index", "Header_2": " How It Works", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "b29ae22bd0f9f335accabee187b7d434a96c5ee0794b39a518fb8ee17fb2950f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f60ed89c-d9e7-40de-85fa-266ffc8a1d23", "node_type": "1", "metadata": {"Header_1": " Example"}, "hash": "def036327caecdf411ddbc4781727b287b2a1e6e6f7d4dffa15fef0aebf9af42", "class_name": "RelatedNodeInfo"}}, "text": "Additional Insights\n\nDocument retrieval with summaries can be thought of as a \u201cmiddle ground\u201d\nbetween semantic search and brute-force summarization across all docs. We look\nup documents based on summary relevance with the given query, and then return\nall *nodes* corresponding to the retrieved docs.\n\nWhy should we do this? This retrieval method gives user more context than\ntop-k over a text-chunk, by retrieving context at a document-level. But, it\u2019s\nalso a more flexible/automatic approach than topic modeling; no more worrying\nabout whether your text has the right keyword tags!", "mimetype": "text/plain", "start_char_idx": 4047, "end_char_idx": 4629, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f60ed89c-d9e7-40de-85fa-266ffc8a1d23": {"__data__": {"id_": "f60ed89c-d9e7-40de-85fa-266ffc8a1d23", "embedding": null, "metadata": {"Header_1": " Example", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b66fcf65-7d1a-47bd-b0e0-4d6b820e845a", "node_type": "1", "metadata": {"Header_1": " Document Summary Index", "Header_2": " Additional Insights", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "38a590e978e454f1e7107cb611cfda5631f5f1a824c25cb3f11cff3f2e7bc7e9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8a682123-7a9e-484f-8f71-8720617cc229", "node_type": "1", "metadata": {"Header_1": " **Next Steps**"}, "hash": "5a20dd984217c39561f3b6848d650085dc0552337802c1212cceb8b8193d8813", "class_name": "RelatedNodeInfo"}}, "text": "Example\n\nLet\u2019s walk through an example that showcases the document summary index, over\nWikipedia articles about different cities.\n\nThe rest of this guide showcases the relevant code snippets. You can find the\n[ full walkthrough here ](https://gpt-\nindex.readthedocs.io/en/latest/examples/index_structs/doc_summary/DocSummary.html)\n(and here\u2019s the [ notebook link\n](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/index_structs/doc_summary/DocSummary.ipynb)\n).\n\nWe can build the ` GPTDocumentSummaryIndex ` over a set of documents, and pass\nin a ` ResponseSynthesizer ` object to synthesize summaries for the documents.\n\n    \n    \n    from llama_index import (\n        SimpleDirectoryReader,\n        LLMPredictor,\n        ServiceContext,\n        ResponseSynthesizer\n    )\n    from llama_index.indices.document_summary import GPTDocumentSummaryIndex\n    from langchain.chat_models import ChatOpenAI\n    \n    # load docs, define service context\n    ...\n    \n    # build the index\n    response_synthesizer = ResponseSynthesizer.from_args(response_mode=\"tree_summarize\", use_async=True)\n    doc_summary_index = GPTDocumentSummaryIndex.from_documents(\n        city_docs, \n        service_context=service_context,\n        response_synthesizer=response_synthesizer\n    )\n\nOnce the index is built, we can get the summary for any given document:\n\n    \n    \n    summary = doc_summary_index.get_document_summary(\"Boston\")\n\nNext, let\u2019s walk through an example LLM-based retrieval over the index.\n\n    \n    \n    from llama_index.indices.document_summary import DocumentSummaryIndexRetriever\n    \n    retriever = DocumentSummaryIndexRetriever(\n        doc_summary_index,\n        # choice_select_prompt=choice_select_prompt,\n        # choice_batch_size=choice_batch_size,\n        # format_node_batch_fn=format_node_batch_fn,\n        # parse_choice_select_answer_fn=parse_choice_select_answer_fn,\n        # service_context=service_context\n    )\n    retrieved_nodes = retriever.retrieve(\"What are the sports teams in Toronto?\")\n    print(retrieved_nodes[0].score)\n    print(retrieved_nodes[0].node.get_text())The retriever will retrieve a set of relevant nodes for a given index.\n\nNote that the LLM returns relevance scores in addition to the document text:\n\n    \n    \n    8.0\n    Toronto ( (listen) t\u0259-RON-toh; locally [t\u0259\u02c8\u0279\u0252\u027e\u0303\u0259] or [\u02c8t\u0279\u0252\u027e\u0303\u0259]) is the capital city of the Canadian province of Ontario. With a recorded population of 2,794,356 in 2021, it is the most populous city in Canada...\n\nWe can also use the index as part of an overall query engine, to not only\nretrieve the relevant context, but also synthesize a response to a given\nquestion. We can do this through both the high-level API as well as lower-\nlevel API.\n\n**High-level API**\n\n    \n    \n    query_engine = doc_summary_index.as_query_engine(\n      response_mode=\"tree_summarize\", use_async=True\n    )\n    response = query_engine.query(\"What are the sports teams in Toronto?\")\n    print(response)\n\n**Lower-level API**\n\n    \n    \n    # use retriever as part of a query engine\n    from llama_index.query_engine import RetrieverQueryEngine\n    \n    # configure response synthesizer\n    response_synthesizer = ResponseSynthesizer.from_args()\n    \n    # assemble query engine\n    query_engine = RetrieverQueryEngine(\n        retriever=retriever,\n        response_synthesizer=response_synthesizer,\n    )\n    \n    # query\n    response = query_engine.query(\"What are the sports teams in Toronto?\")\n    print(response)", "mimetype": "text/plain", "start_char_idx": 4634, "end_char_idx": 8111, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8a682123-7a9e-484f-8f71-8720617cc229": {"__data__": {"id_": "8a682123-7a9e-484f-8f71-8720617cc229", "embedding": null, "metadata": {"Header_1": " **Next Steps**", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62dde35a-83d7-4810-8266-e06727dfc8c6", "node_type": "4", "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "c13b9e5b53fa64063ee68bbae6febc9982992cf8a33a184c99279a81ee8b9f07", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f60ed89c-d9e7-40de-85fa-266ffc8a1d23", "node_type": "1", "metadata": {"Header_1": " Example", "filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}, "hash": "e42e6d6beaa8b0a56f989cceeb93e170f1baa28b822cf1b008f51dd0c4f1ac78", "class_name": "RelatedNodeInfo"}}, "text": "**Next Steps**\n\nThe approach of autosummarization over any piece of text is really exciting.\nWe\u2019re excited to develop extensions in two areas:\n\n  * Continue exploring autosummarization in different layers. Currently it\u2019s at the doc-level, but what about summarizing a big text chunk into a smaller one? (e.g. a one-liner). \n  * Continue exploring LLM-based retrieval, which summarization helps to unlock. \n\nAlso we\u2019re sharing the example guide/notebook below in case you missed it\nabove:\n\n[ Document Summary Guide ](https://gpt-\nindex.readthedocs.io/en/latest/examples/index_structs/doc_summary/DocSummary.html)\n\n[ Notebook Link\n](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/index_structs/doc_summary/DocSummary.ipynb)", "mimetype": "text/plain", "start_char_idx": 8116, "end_char_idx": 8855, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"bf81db47-8c21-4cc4-8ec4-a4391e35187e": {"doc_hash": "20c80604edf8f4ce09ce2639165d1e21f2c5ad8622cad56fc078f919d45c6107", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}, "d0f715e6-b023-4693-aa34-4ccd4e6ac08e": {"doc_hash": "5e272cbdf64c4b8dd3ef7d19a4af63e0ee30df816a22ee52555aaced4089a9de", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}, "dae9da8a-87d8-4b5d-9f4a-967ab99a0932": {"doc_hash": "477d2394dd36ed349f333b9cbe23a8b59e1cb2463472f709ebf5b50becf1aac1", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}, "f25e0afe-68d1-4eb8-ad4c-dc7df661dfb9": {"doc_hash": "72f1ca8b4271b64bb7488912cd65729a02d0583cbe4b210e423ca102f53965c4", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}, "f0b8f3c7-3318-4049-8e69-4bf9bac4b528": {"doc_hash": "b29ae22bd0f9f335accabee187b7d434a96c5ee0794b39a518fb8ee17fb2950f", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}, "b66fcf65-7d1a-47bd-b0e0-4d6b820e845a": {"doc_hash": "38a590e978e454f1e7107cb611cfda5631f5f1a824c25cb3f11cff3f2e7bc7e9", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}, "f60ed89c-d9e7-40de-85fa-266ffc8a1d23": {"doc_hash": "e42e6d6beaa8b0a56f989cceeb93e170f1baa28b822cf1b008f51dd0c4f1ac78", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}, "8a682123-7a9e-484f-8f71-8720617cc229": {"doc_hash": "73497534b8a91faf26997326dc9421d2ff5fbf5e309a3c3534fce8c1ec5bcfcd", "ref_doc_id": "62dde35a-83d7-4810-8266-e06727dfc8c6"}}, "docstore/ref_doc_info": {"62dde35a-83d7-4810-8266-e06727dfc8c6": {"node_ids": ["bf81db47-8c21-4cc4-8ec4-a4391e35187e", "d0f715e6-b023-4693-aa34-4ccd4e6ac08e", "dae9da8a-87d8-4b5d-9f4a-967ab99a0932", "f25e0afe-68d1-4eb8-ad4c-dc7df661dfb9", "f0b8f3c7-3318-4049-8e69-4bf9bac4b528", "b66fcf65-7d1a-47bd-b0e0-4d6b820e845a", "f60ed89c-d9e7-40de-85fa-266ffc8a1d23", "8a682123-7a9e-484f-8f71-8720617cc229"], "metadata": {"filename": "a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec.md", "extension": ".md", "title": "A New Document Summary Index for LLM-powered QA Systems", "date": "May 8, 2023", "url": "https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"}}}}