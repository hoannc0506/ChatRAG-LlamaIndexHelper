{"docstore/data": {"2fff8992-a5ce-4580-8f96-cb8fa7320a4f": {"__data__": {"id_": "2fff8992-a5ce-4580-8f96-cb8fa7320a4f", "embedding": null, "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "997971fe-57a4-42ff-a584-cafeaffe030d", "node_type": "1", "metadata": {"Header_1": " IngestionPipeline \u2014 New abstraction for purely ingesting data"}, "hash": "a75db9c0167238764f074c3b49da40a98b22136010feb4d168f06095046c5f0a", "class_name": "RelatedNodeInfo"}}, "text": "Our hard-working team is delighted to announce our latest major release,\nLlamaIndex 0.9! You can get it right now:\n\n` pip install --upgrade llama_index `\n\nIn LlamaIndex v0.9, we are taking the time to refine several key aspects of\nthe user experience, including token counting, text splitting, and more!\n\nAs part of this, there are some new features and minor changes to current\nusage that developers should be aware of:\n\n  * New ` IngestionPipline ` concept for ingesting and transforming data \n  * Data ingestion and transforms are now automatically cached \n  * Updated interface for node parsing/text splitting/metadata extraction modules \n  * Changes to the default tokenizer, as well as customizing the tokenizer \n  * Packaging/Installation changes with PyPi (reduced bloat, new install options) \n  * More predictable and consistent import paths \n  * Plus, in beta: MultiModal RAG Modules for handling text and images! \n\nHave questions or concerns? You can [ report an issue\n](https://github.com/run-llama/llama_index/issues) on GitHub or [ ask a\nquestion on our Discord ](https://discord.com/invite/eN6D2HQ4aX) !\n\nRead on for more details on our new features and changes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1177, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "997971fe-57a4-42ff-a584-cafeaffe030d": {"__data__": {"id_": "997971fe-57a4-42ff-a584-cafeaffe030d", "embedding": null, "metadata": {"Header_1": " IngestionPipeline \u2014 New abstraction for purely ingesting data", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2fff8992-a5ce-4580-8f96-cb8fa7320a4f", "node_type": "1", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "619ac3a9f44757245bd569a4d1aca744f99957f35f32d8f29fffb0510813e6c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "49b771dd-5dfe-49c6-8eed-54d8e90454f0", "node_type": "1", "metadata": {"Header_1": " Transformation Caching"}, "hash": "7e8db3baffbb4b24d4a0b5522f76729ccda1a6d2669ecfdb524f8fc33e2d2af3", "class_name": "RelatedNodeInfo"}}, "text": "IngestionPipeline \u2014 New abstraction for purely ingesting data\n\nSometimes, all you want is to ingest and embed nodes from data sources, for\ninstance if your application allows users to upload new data. New in\nLlamaIndex V0.9 is the concept of an ` IngestionPipepline ` .\n\nAn ` IngestionPipeline ` uses a new concept of ` Transformations ` that are\napplied to input data.\n\nWhat is a ` Transformation ` though? It could be a:\n\n  * text splitter \n  * node parser \n  * metadata extractor \n  * embeddings model \n\nHere\u2019s a quick example of the basic usage pattern:\n\n    \n    \n    from llama_index import Document\n    from llama_index.embeddings import OpenAIEmbedding\n    from llama_index.text_splitter import SentenceSplitter\n    from llama_index.extractors import TitleExtractor\n    from llama_index.ingestion import IngestionPipeline, IngestionCache\n    \n    pipeline = IngestionPipeline(\n        transformations=[\n            SentenceSplitter(chunk_size=25, chunk_overlap=0),\n            TitleExtractor(),\n            OpenAIEmbedding(),\n        ]\n    )\n    nodes = pipeline.run(documents=[Document.example()])", "mimetype": "text/plain", "start_char_idx": 1182, "end_char_idx": 2288, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49b771dd-5dfe-49c6-8eed-54d8e90454f0": {"__data__": {"id_": "49b771dd-5dfe-49c6-8eed-54d8e90454f0", "embedding": null, "metadata": {"Header_1": " Transformation Caching", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "997971fe-57a4-42ff-a584-cafeaffe030d", "node_type": "1", "metadata": {"Header_1": " IngestionPipeline \u2014 New abstraction for purely ingesting data", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "405e05cd4e2027c2fcfaa5ef2ee3fd0fe23a97049a32c128ee62d7d93d108b4f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "249f1a39-7f4a-4df8-ad8e-a49b2ef99e6e", "node_type": "1", "metadata": {"Header_1": " Custom Transformations"}, "hash": "f6562ff22a72bbee9714815632723b6bd4904c5f0763f7a1fcc56a380d0ffb45", "class_name": "RelatedNodeInfo"}}, "text": "Transformation Caching\n\nEach time you run the same ` IngestionPipeline ` object, it caches a hash of\nthe input nodes + transformations and the output of that transformation for\neach transformation in the pipeline.\n\nIn subsequent runs, if there is a cache hit, that transformation will be\nskipped and the cached result will be used instead. The greatly speeds up\nduplicate runs, and can help improve iteration times when deciding which\ntransformations to use.\n\nHere\u2019s an example with a saving and loading a local cache:\n\n    \n    \n    from llama_index import Document\n    from llama_index.embeddings import OpenAIEmbedding\n    from llama_index.text_splitter import SentenceSplitter\n    from llama_index.extractors import TitleExtractor\n    from llama_index.ingestion import IngestionPipeline, IngestionCache\n    \n    pipeline = IngestionPipeline(\n        transformations=[\n            SentenceSplitter(chunk_size=25, chunk_overlap=0),\n            TitleExtractor(),\n            OpenAIEmbedding(),\n        ]\n    )\n    # will only execute full pipeline once\n    nodes = pipeline.run(documents=[Document.example()])\n    nodes = pipeline.run(documents=[Document.example()])\n    # save and load\n    pipeline.cache.persist(\"./test_cache.json\")\n    new_cache = IngestionCache.from_persist_path(\"./test_cache.json\")\n    new_pipeline = IngestionPipeline(\n        transformations=[\n            SentenceSplitter(chunk_size=25, chunk_overlap=0),\n            TitleExtractor(),\n        ],\n        cache=new_cache,\n    )\n    # will run instantly due to the cache\n    nodes = pipeline.run(documents=[Document.example()])\n\nAnd here\u2019s another example using Redis as a cache and Qdrant as a vector\nstore. Running this will directly insert the nodes into your vector store and\ncache each transformation step in Redis.\n\n    \n    \n    from llama_index import Document\n    from llama_index.embeddings import OpenAIEmbedding\n    from llama_index.text_splitter import SentenceSplitter\n    from llama_index.extractors import TitleExtractor\n    from llama_index.ingestion import IngestionPipeline, IngestionCache\n    from llama_index.ingestion.cache import RedisCache\n    from llama_index.vector_stores.qdrant import QdrantVectorStore\n    \n    import qdrant_client\n    client = qdrant_client.QdrantClient(location=\":memory:\")\n    vector_store = QdrantVectorStore(client=client, collection_name=\"test_store\")\n    pipeline = IngestionPipeline(\n        transformations=[\n            SentenceSplitter(chunk_size=25, chunk_overlap=0),\n            TitleExtractor(),\n            OpenAIEmbedding(),\n        ],\n        cache=IngestionCache(cache=RedisCache(), collection=\"test_cache\"),\n        vector_store=vector_store,\n    )\n    # Ingest directly into a vector db\n    pipeline.run(documents=[Document.example()])\n    # Create your index\n    from llama_index import VectorStoreIndex\n    index = VectorStoreIndex.from_vector_store(vector_store)", "mimetype": "text/plain", "start_char_idx": 2293, "end_char_idx": 5199, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "249f1a39-7f4a-4df8-ad8e-a49b2ef99e6e": {"__data__": {"id_": "249f1a39-7f4a-4df8-ad8e-a49b2ef99e6e", "embedding": null, "metadata": {"Header_1": " Custom Transformations", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49b771dd-5dfe-49c6-8eed-54d8e90454f0", "node_type": "1", "metadata": {"Header_1": " Transformation Caching", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "08435f4e20a73c758ef7efcc126aee79d31ce113cbee245bc1cfd3131684f3db", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "23b5482a-2ce7-4858-afb8-6a25bba7e226", "node_type": "1", "metadata": {"Header_1": " Node Parsing/Text Splitting \u2014 Flattened and Simplified Interface"}, "hash": "4da332f039ff26170d49a4a219f3b525a266b769c3d6440fd929591801e9a075", "class_name": "RelatedNodeInfo"}}, "text": "Custom Transformations\n\nImplementing custom transformations is easy! Let\u2019s add a transform to remove\nspecial characters from the text before calling embeddings.\n\nThe only real requirement for transformations is that they must accept a list\nof nodes and return a list of nodes.\n\n    \n    \n    import re\n    from llama_index import Document\n    from llama_index.embeddings import OpenAIEmbedding\n    from llama_index.text_splitter import SentenceSplitter\n    from llama_index.ingestion import IngestionPipeline\n    from llama_index.schema import TransformComponent\n    \n    class TextCleaner(TransformComponent):\n      def __call__(self, nodes, **kwargs):\n        for node in nodes:\n          node.text = re.sub(r'[^0-9A-Za-z ]', \"\", node.text)\n        return nodes\n    pipeline = IngestionPipeline(\n        transformations=[\n            SentenceSplitter(chunk_size=25, chunk_overlap=0),\n            TextCleaner(),\n            OpenAIEmbedding(),\n        ],\n    )\n    nodes = pipeline.run(documents=[Document.example()])", "mimetype": "text/plain", "start_char_idx": 5204, "end_char_idx": 6221, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "23b5482a-2ce7-4858-afb8-6a25bba7e226": {"__data__": {"id_": "23b5482a-2ce7-4858-afb8-6a25bba7e226", "embedding": null, "metadata": {"Header_1": " Node Parsing/Text Splitting \u2014 Flattened and Simplified Interface", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "249f1a39-7f4a-4df8-ad8e-a49b2ef99e6e", "node_type": "1", "metadata": {"Header_1": " Custom Transformations", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "ee4771ca9b490a2b3c69628b6544442dc71b3e9a9bb7e07d75a6285f5767bfc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba02079d-2834-4b48-a1bc-dd1c7e3391b6", "node_type": "1", "metadata": {"Header_1": " Before:"}, "hash": "029424f1d82918d1b6b7364b65159ad32679117ed3b87cdcb1ba5f95c3eb8957", "class_name": "RelatedNodeInfo"}}, "text": "Node Parsing/Text Splitting \u2014 Flattened and Simplified Interface\n\nWe\u2019ve made our interface for parsing and splitting text a lot cleaner.", "mimetype": "text/plain", "start_char_idx": 6226, "end_char_idx": 6362, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba02079d-2834-4b48-a1bc-dd1c7e3391b6": {"__data__": {"id_": "ba02079d-2834-4b48-a1bc-dd1c7e3391b6", "embedding": null, "metadata": {"Header_1": " Before:", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "23b5482a-2ce7-4858-afb8-6a25bba7e226", "node_type": "1", "metadata": {"Header_1": " Node Parsing/Text Splitting \u2014 Flattened and Simplified Interface", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "76fc91fb53c1c59979bb5d57ad2df99e037ea77dcd1ef472071a14bccd0385e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "51843e1d-a146-46b6-9402-0a2f946f9a93", "node_type": "1", "metadata": {"Header_1": " After:"}, "hash": "5d5e3090bed754231fe11720af7e6923b1944648e9be93cf29835f03a8ebf5a0", "class_name": "RelatedNodeInfo"}}, "text": "Before:\n\n    \n    \n    from llama_index.node_parser import SimpleNodeParser\n    from llama_index.node_parser.extractors import (\n    \tMetadataExtractor, TitleExtractor\n    ) \n    from llama_index.text_splitter import SentenceSplitter\n    \n    node_parser = SimpleNodeParser(\n      text_splitter=SentenceSplitter(chunk_size=512),\n      metadata_extractor=MetadataExtractor(\n      extractors=[TitleExtractor()]\n     ),\n    )\n    nodes = node_parser.get_nodes_from_documents(documents)", "mimetype": "text/plain", "start_char_idx": 6367, "end_char_idx": 6849, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "51843e1d-a146-46b6-9402-0a2f946f9a93": {"__data__": {"id_": "51843e1d-a146-46b6-9402-0a2f946f9a93", "embedding": null, "metadata": {"Header_1": " After:", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba02079d-2834-4b48-a1bc-dd1c7e3391b6", "node_type": "1", "metadata": {"Header_1": " Before:", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "8affd23e86bf222d83f003cf9d321d3473ca19509ae8e7f7136b8b3ee2b67e9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "336d3c0e-b861-4e6d-afae-fed9a0380039", "node_type": "1", "metadata": {"Header_1": " Tokenization and Token Counting \u2014 Improved defaults and Customization"}, "hash": "9401c6cf0ef435e7506d19616ac943df5d780412870f2a8976fbb40b9285f402", "class_name": "RelatedNodeInfo"}}, "text": "After:\n\n    \n    \n    from llama_index.text_splitter import SentenceSplitter\n    from llama_index.extractors import TitleExtractor \n    \n    node_parser = SentenceSplitter(chunk_size=512)\n    extractor = TitleExtractor()\n    \n    # use transforms directly\n    nodes = node_parser(documents)\n    nodes = extractor(nodes)\n\nPreviously, the ` NodeParser ` object in LlamaIndex had become extremely\nbloated, holding both text splitters and metadata extractors, which caused\nboth pains for users when changing these components, and pains for us trying\nto maintain and develop them.\n\nIn V0.9, we have **flattened** the entire interface into a single `\nTransformComponent ` abstraction, so that these transformations are easier to\nsetup, use, and customize.\n\nWe\u2019ve done our best to minimize the impacts on users, but the main thing to\nnote is that ` **SimpleNodeParser** ` **has been removed** , and other node\nparsers and text splitters have been elevated to have the same features, just\nwith different parsing and splitting techniques.\n\nAny old imports of ` SimpleNodeParser ` will redirect to the most equivalent\nmodule, ` SentenceSplitter ` .\n\nFurthermore, the wrapper object ` **MetadataExtractor** ` **has been removed**\n, in favour of using extractors directly.\n\nFull documentation for all this can be found below:\n\n  * [ Node Parsers and Text Splitters ](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules.html)\n  * [ Metadata Extractors ](https://docs.llamaindex.ai/en/stable/module_guides/indexing/metadata_extraction.html)", "mimetype": "text/plain", "start_char_idx": 6854, "end_char_idx": 8408, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "336d3c0e-b861-4e6d-afae-fed9a0380039": {"__data__": {"id_": "336d3c0e-b861-4e6d-afae-fed9a0380039", "embedding": null, "metadata": {"Header_1": " Tokenization and Token Counting \u2014 Improved defaults and Customization", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51843e1d-a146-46b6-9402-0a2f946f9a93", "node_type": "1", "metadata": {"Header_1": " After:", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "75cd38ef65211eddf4402369e19597f01a7b3abbdd0da1a473a724cca04e5238", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b6f80d9e-8f5f-4ec2-aef6-3a1d991741ae", "node_type": "1", "metadata": {"Header_1": " Packaging \u2014 Reduced Bloat"}, "hash": "82fc3cf73bd0e2270fa19442a2e2b88ff730c5dbcf4ca24c5d2f30da3ed45d5e", "class_name": "RelatedNodeInfo"}}, "text": "Tokenization and Token Counting \u2014 Improved defaults and Customization\n\nA big pain point in LlamaIndex previously was tokenization. Many components\nused a non-configurable ` gpt2 ` tokenizer for token counting, causing\nheadaches for users using non-OpenAI models, or even some hacky fixes [ like\nthis ](https://github.com/run-\nllama/llama_index/blob/336a88db4f13cfc598c473f9b5a3bc073b5d7ef4/llama_index/indices/prompt_helper.py#L119)\nfor OpenAI models too!\n\nIn LlamaIndex V0.9, this **global tokenizer is now configurable and defaults\nto the CL100K tokenizer** to match our default GPT-3.5 LLM.\n\nThe single requirement for a tokenizer is that it is a callable function, that\ntakes a string, and returns a list.\n\nSome examples of configuring this are below:\n\n    \n    \n    from llama_index import set_global_tokenizer\n    \n    # tiktoken\n    import tiktoken\n    set_global_tokenizer(\n      tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n    )\n    # huggingface\n    from transformers import AutoTokenizer\n    set_global_tokenizer(\n      AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\").encode\n    )\n\nFurthermore, the ` TokenCountingHandler ` has gotten an upgrade with better\ntoken counting, as well as using token counts from API responses directly when\navailable.", "mimetype": "text/plain", "start_char_idx": 8413, "end_char_idx": 9693, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b6f80d9e-8f5f-4ec2-aef6-3a1d991741ae": {"__data__": {"id_": "b6f80d9e-8f5f-4ec2-aef6-3a1d991741ae", "embedding": null, "metadata": {"Header_1": " Packaging \u2014 Reduced Bloat", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "336d3c0e-b861-4e6d-afae-fed9a0380039", "node_type": "1", "metadata": {"Header_1": " Tokenization and Token Counting \u2014 Improved defaults and Customization", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "27e85a18f6d455daa9b0a91da643064254311454e48107ef4267786a2da35904", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9b7ba4f8-8544-42d2-93d2-83643e62a6a9", "node_type": "1", "metadata": {"Header_1": " Import Paths \u2014 More Consistent and Predictable"}, "hash": "f8a79189314b18c0e3ddc730c0a33353e50659778c3741a7cae3f0f39151cedf", "class_name": "RelatedNodeInfo"}}, "text": "Packaging \u2014 Reduced Bloat\n\nIn an effort to modernize the packaging of LlamaIndex, V0.9 also comes with\nchanges to installation.\n\nThe biggest change here is that ` LangChain ` is now an optional package, and\nwill not be installed by default.\n\nTo install ` LangChain ` as part of your llama-index installation you can\nfollow the example below. There are also other installation options depending\non your needs, and we are welcoming further contributions to the extras in the\nfuture.\n\n    \n    \n    # installs langchain\n    pip install llama-index[langchain]\n     \n    # installs tools needed for running local models\n    pip install llama-index[local_models]\n    \n    # installs tools needed for postgres\n    pip install llama-index[postgres]\n    \n    # combinations!\n    pip isntall llama-index[local_models,postgres]\n\n**If you were previously importing** ` **langchain** ` **modules** in your\ncode, please update your project packaging requirements appropriately.", "mimetype": "text/plain", "start_char_idx": 9698, "end_char_idx": 10661, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9b7ba4f8-8544-42d2-93d2-83643e62a6a9": {"__data__": {"id_": "9b7ba4f8-8544-42d2-93d2-83643e62a6a9", "embedding": null, "metadata": {"Header_1": " Import Paths \u2014 More Consistent and Predictable", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b6f80d9e-8f5f-4ec2-aef6-3a1d991741ae", "node_type": "1", "metadata": {"Header_1": " Packaging \u2014 Reduced Bloat", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "8090b5475987fdb907bbb5ab60f3fa2b16feae792fee151fa7f72faec915b4e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "479771fd-4030-4cac-9132-f46a6a084431", "node_type": "1", "metadata": {"Header_1": " MultiModal RAG"}, "hash": "81a53b0f6abe16f10baa6c0d47a52bec12a8ca43ca91b01c080bfbabc723f85d", "class_name": "RelatedNodeInfo"}}, "text": "Import Paths \u2014 More Consistent and Predictable\n\nWe are making two changes to our import paths:\n\n  1. We\u2019ve removed uncommonly used imports from the root level to make importing ` llama_index ` faster \n  2. We now have a consistent policy for making \u201cuser-facing\u201d concepts import-able at level-1 modules. \n\n    \n    \n    from llama_index.llms import OpenAI, ...\n    from llama_index.embeddings import OpenAIEmbedding, ...\n    from llama_index.prompts import PromptTemplate, ...\n    from llama_index.readers import SimpleDirectoryReader, ...\n    from llama_index.text_splitter import SentenceSplitter, ...\n    from llama_index.extractors import TitleExtractor, ...\n    from llama_index.vector_stores import SimpleVectorStore, ...\n\nWe still expose some of the most commonly used modules at the root level.\n\n    \n    \n    from llama_index import SimpleDirectoryReader, VectorStoreIndex, ...", "mimetype": "text/plain", "start_char_idx": 10666, "end_char_idx": 11552, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "479771fd-4030-4cac-9132-f46a6a084431": {"__data__": {"id_": "479771fd-4030-4cac-9132-f46a6a084431", "embedding": null, "metadata": {"Header_1": " MultiModal RAG", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9b7ba4f8-8544-42d2-93d2-83643e62a6a9", "node_type": "1", "metadata": {"Header_1": " Import Paths \u2014 More Consistent and Predictable", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "6ab3818bbf4b7a419710a572399e9d1d30ef7b4e47b0ac0581c878fa8f750d5c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4009a13e-d755-48dc-a17f-50202004a9f9", "node_type": "1", "metadata": {"Header_1": " Thanks for all your support!"}, "hash": "ef64a953ede01f25214d18b8c4584192a8db89a0843799f7b9cb78ad0c058774", "class_name": "RelatedNodeInfo"}}, "text": "MultiModal RAG\n\nGiven the recent announcements of the GPT-4V API, multi-modal use cases are\nmore accessible than ever before.\n\nTo help users use these features, we\u2019ve started to introduce a number of new\nmodules to help support use-cases for MultiModal RAG:\n\n  * MultiModal LLMs (GPT-4V, Llava, Fuyu, etc.) \n  * MultiModal Embeddings (i.e clip) for join image-text embedding/retrieval \n  * MultiModal RAG, combining indexes and query engines \n\nOur documentation has a [ full guide to multi-modal retrieval\n](https://docs.llamaindex.ai/en/latest/examples/multi_modal/gpt4v_multi_modal_retrieval.html)\n.", "mimetype": "text/plain", "start_char_idx": 11557, "end_char_idx": 12158, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4009a13e-d755-48dc-a17f-50202004a9f9": {"__data__": {"id_": "4009a13e-d755-48dc-a17f-50202004a9f9", "embedding": null, "metadata": {"Header_1": " Thanks for all your support!", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0", "node_type": "4", "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "5e49a3415c2d7d43f6bcb8e6a604fc8666886f8a2a73294112a3dd03ecdcf2f4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "479771fd-4030-4cac-9132-f46a6a084431", "node_type": "1", "metadata": {"Header_1": " MultiModal RAG", "filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}, "hash": "3ae3353902929c2a1a93fe0ae8ccedaf571c1cfeadc7f39c0406bc43abc29d52", "class_name": "RelatedNodeInfo"}}, "text": "Thanks for all your support!\n\nAs an open-source project we couldn\u2019t exist without our [ hundreds of\ncontributors ](https://github.com/run-llama/llama_index/graphs/contributors) .\nWe are so grateful for them and the support of the hundreds of thousands of\nLlamaIndex users around the world. See you on the Discord!", "mimetype": "text/plain", "start_char_idx": 12163, "end_char_idx": 12476, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"2fff8992-a5ce-4580-8f96-cb8fa7320a4f": {"doc_hash": "619ac3a9f44757245bd569a4d1aca744f99957f35f32d8f29fffb0510813e6c6", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "997971fe-57a4-42ff-a584-cafeaffe030d": {"doc_hash": "405e05cd4e2027c2fcfaa5ef2ee3fd0fe23a97049a32c128ee62d7d93d108b4f", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "49b771dd-5dfe-49c6-8eed-54d8e90454f0": {"doc_hash": "08435f4e20a73c758ef7efcc126aee79d31ce113cbee245bc1cfd3131684f3db", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "249f1a39-7f4a-4df8-ad8e-a49b2ef99e6e": {"doc_hash": "ee4771ca9b490a2b3c69628b6544442dc71b3e9a9bb7e07d75a6285f5767bfc0", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "23b5482a-2ce7-4858-afb8-6a25bba7e226": {"doc_hash": "76fc91fb53c1c59979bb5d57ad2df99e037ea77dcd1ef472071a14bccd0385e3", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "ba02079d-2834-4b48-a1bc-dd1c7e3391b6": {"doc_hash": "8affd23e86bf222d83f003cf9d321d3473ca19509ae8e7f7136b8b3ee2b67e9e", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "51843e1d-a146-46b6-9402-0a2f946f9a93": {"doc_hash": "75cd38ef65211eddf4402369e19597f01a7b3abbdd0da1a473a724cca04e5238", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "336d3c0e-b861-4e6d-afae-fed9a0380039": {"doc_hash": "27e85a18f6d455daa9b0a91da643064254311454e48107ef4267786a2da35904", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "b6f80d9e-8f5f-4ec2-aef6-3a1d991741ae": {"doc_hash": "8090b5475987fdb907bbb5ab60f3fa2b16feae792fee151fa7f72faec915b4e3", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "9b7ba4f8-8544-42d2-93d2-83643e62a6a9": {"doc_hash": "6ab3818bbf4b7a419710a572399e9d1d30ef7b4e47b0ac0581c878fa8f750d5c", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "479771fd-4030-4cac-9132-f46a6a084431": {"doc_hash": "3ae3353902929c2a1a93fe0ae8ccedaf571c1cfeadc7f39c0406bc43abc29d52", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}, "4009a13e-d755-48dc-a17f-50202004a9f9": {"doc_hash": "c716192df1c7c39df19e9cb9ee60690effa8f3879ca381be53295b1806eb3360", "ref_doc_id": "ab894b36-ab2b-447c-ba93-163c3e0b56f0"}}, "docstore/ref_doc_info": {"ab894b36-ab2b-447c-ba93-163c3e0b56f0": {"node_ids": ["2fff8992-a5ce-4580-8f96-cb8fa7320a4f", "997971fe-57a4-42ff-a584-cafeaffe030d", "49b771dd-5dfe-49c6-8eed-54d8e90454f0", "249f1a39-7f4a-4df8-ad8e-a49b2ef99e6e", "23b5482a-2ce7-4858-afb8-6a25bba7e226", "ba02079d-2834-4b48-a1bc-dd1c7e3391b6", "51843e1d-a146-46b6-9402-0a2f946f9a93", "336d3c0e-b861-4e6d-afae-fed9a0380039", "b6f80d9e-8f5f-4ec2-aef6-3a1d991741ae", "9b7ba4f8-8544-42d2-93d2-83643e62a6a9", "479771fd-4030-4cac-9132-f46a6a084431", "4009a13e-d755-48dc-a17f-50202004a9f9"], "metadata": {"filename": "announcing-llamaindex-0-9-719f03282945.md", "extension": ".md", "title": "Announcing LlamaIndex 0.9", "date": "Nov 15, 2023", "url": "https://www.llamaindex.ai/blog/announcing-llamaindex-0-9-719f03282945"}}}}