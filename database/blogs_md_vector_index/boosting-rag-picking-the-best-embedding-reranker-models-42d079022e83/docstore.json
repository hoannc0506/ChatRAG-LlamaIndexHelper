{"docstore/data": {"4e350df2-6978-405d-8b3a-5edc6cec953e": {"__data__": {"id_": "4e350df2-6978-405d-8b3a-5edc6cec953e", "embedding": null, "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "24cffcdd-2b5a-4e17-a89f-cb9423d2c300", "node_type": "1", "metadata": {"Header_1": " Understanding Metrics in Retrieval Evaluation:"}, "hash": "a76fc0dc95bb7dbc8f538cdbffe322bea798f75044b1b3aa2a8c04e55b0d1896", "class_name": "RelatedNodeInfo"}}, "text": "**UPDATE** : The pooling method for the Jina AI embeddings has been adjusted\nto use mean pooling, and the results have been updated accordingly. Notably,\nthe ` JinaAI-v2-base-en ` with ` bge-reranker-large ` now exhibits a Hit Rate\nof 0.938202 and an MRR (Mean Reciprocal Rank) of 0.868539 and with `\nCohereRerank ` exhibits a Hit Rate of 0.932584, and an MRR of 0.873689.\n\nWhen building a Retrieval Augmented Generation (RAG) pipeline, one key\ncomponent is the Retriever. We have a variety of embedding models to choose\nfrom, including OpenAI, CohereAI, and open-source sentence transformers.\nAdditionally, there are several rerankers available from CohereAI and sentence\ntransformers.\n\nBut with all these options, how do we determine the best mix for top-notch\nretrieval performance? How do we know which embedding model fits our data\nbest? Or which reranker boosts our results the most?\n\nIn this blog post, we\u2019ll use the ` Retrieval Evaluation ` module from\nLlamaIndex to swiftly determine the best combination of embedding and reranker\nmodels. Let's dive in!\n\nLet\u2019s first start with understanding the metrics available in ` Retrieval\nEvaluation `", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1150, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "24cffcdd-2b5a-4e17-a89f-cb9423d2c300": {"__data__": {"id_": "24cffcdd-2b5a-4e17-a89f-cb9423d2c300", "embedding": null, "metadata": {"Header_1": " Understanding Metrics in Retrieval Evaluation:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e350df2-6978-405d-8b3a-5edc6cec953e", "node_type": "1", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "4bc3a4781ee50d5cf5b79035f8097cb94f50bfcdd5aa14906edb9365d3a19128", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "80441101-26df-4475-a369-3a7e39844135", "node_type": "1", "metadata": {"Header_1": " Setting Up the Environment"}, "hash": "19a603d717ca3891a57c76034d45f58ee1f99dd9db370cce22d1e1d2de39f1d1", "class_name": "RelatedNodeInfo"}}, "text": "Understanding Metrics in Retrieval Evaluation:\n\nTo gauge the efficacy of our retrieval system, we primarily relied on two\nwidely accepted metrics: **Hit Rate** and **Mean Reciprocal Rank (MRR)** .\nLet\u2019s delve into these metrics to understand their significance and how they\noperate.\n\n**Hit Rate:**\n\nHit rate calculates the fraction of queries where the correct answer is found\nwithin the top-k retrieved documents. In simpler terms, it\u2019s about how often\nour system gets it right within the top few guesses.\n\n**Mean Reciprocal Rank (MRR):**\n\nFor each query, MRR evaluates the system\u2019s accuracy by looking at the rank of\nthe highest-placed relevant document. Specifically, it\u2019s the average of the\nreciprocals of these ranks across all the queries. So, if the first relevant\ndocument is the top result, the reciprocal rank is 1; if it\u2019s second, the\nreciprocal rank is 1/2, and so on.\n\nNow that we\u2019ve established the scope and familiarized ourselves with the\nmetrics, it\u2019s time to dive into the experiment. For a hands-on experience, you\ncan also follow along using our [ Google Colab Notebook\n](https://colab.research.google.com/drive/1TxDVA__uimVPOJiMEQgP5fwHiqgKqm4-?usp=sharing)", "mimetype": "text/plain", "start_char_idx": 1155, "end_char_idx": 2333, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "80441101-26df-4475-a369-3a7e39844135": {"__data__": {"id_": "80441101-26df-4475-a369-3a7e39844135", "embedding": null, "metadata": {"Header_1": " Setting Up the Environment", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "24cffcdd-2b5a-4e17-a89f-cb9423d2c300", "node_type": "1", "metadata": {"Header_1": " Understanding Metrics in Retrieval Evaluation:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "0747aecfdb67d2566bd9ca9999940f9a755ba6b2330ee918337c3e96dc262b3e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "52fe7b4d-42da-4940-acc5-6c5eb5699c2a", "node_type": "1", "metadata": {"Header_1": " Setting Up the Keys"}, "hash": "c3b3c062ddecfddd4f6bbe75a6202870a43072279a4338b54fad2cc8b288066c", "class_name": "RelatedNodeInfo"}}, "text": "Setting Up the Environment\n\n    \n    \n    !pip install llama-index sentence-transformers cohere anthropic voyageai protobuf pypdf", "mimetype": "text/plain", "start_char_idx": 2338, "end_char_idx": 2467, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "52fe7b4d-42da-4940-acc5-6c5eb5699c2a": {"__data__": {"id_": "52fe7b4d-42da-4940-acc5-6c5eb5699c2a", "embedding": null, "metadata": {"Header_1": " Setting Up the Keys", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "80441101-26df-4475-a369-3a7e39844135", "node_type": "1", "metadata": {"Header_1": " Setting Up the Environment", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "d4553b13452767afa9a9f48a79e46e3bd49a0bec1c77db8f8ba5ec61052be702", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5a83a0f2-dc7c-443e-b4ff-5b350f8b41e1", "node_type": "1", "metadata": {"Header_1": " Download the Data"}, "hash": "265dc360235bec8a4253f920c4a9ffd20b6064e7198d4c55d0b0a2676c25e888", "class_name": "RelatedNodeInfo"}}, "text": "Setting Up the Keys\n\n    \n    \n    openai_api_key = 'YOUR OPENAI API KEY'\n    cohere_api_key = 'YOUR COHEREAI API KEY'\n    anthropic_api_key = 'YOUR ANTHROPIC API KEY'\n    openai.api_key = openai_api_key", "mimetype": "text/plain", "start_char_idx": 2472, "end_char_idx": 2675, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5a83a0f2-dc7c-443e-b4ff-5b350f8b41e1": {"__data__": {"id_": "5a83a0f2-dc7c-443e-b4ff-5b350f8b41e1", "embedding": null, "metadata": {"Header_1": " Download the Data", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "52fe7b4d-42da-4940-acc5-6c5eb5699c2a", "node_type": "1", "metadata": {"Header_1": " Setting Up the Keys", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "8b1f3f6ec5b2f40062a9c7148b055578321d7ebbbaf6b8e1a0d18f5f601e6a57", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3efdef6a-ae89-4dfc-85ff-b15faba8950c", "node_type": "1", "metadata": {"Header_1": " Load the Data"}, "hash": "a5f81f1632b207e923688d62fc6e026f5deb78959d2211ad5432425e42965f6a", "class_name": "RelatedNodeInfo"}}, "text": "Download the Data\n\nWe will use Llama2 paper for this experiment. Let\u2019s download the paper.\n\n    \n    \n    !wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"llama2.pdf\"", "mimetype": "text/plain", "start_char_idx": 2680, "end_char_idx": 2869, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3efdef6a-ae89-4dfc-85ff-b15faba8950c": {"__data__": {"id_": "3efdef6a-ae89-4dfc-85ff-b15faba8950c", "embedding": null, "metadata": {"Header_1": " Load the Data", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5a83a0f2-dc7c-443e-b4ff-5b350f8b41e1", "node_type": "1", "metadata": {"Header_1": " Download the Data", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "800a3ada16fad24ecc480bf9a160ea697f1d930a85913d995611c905f7ac6949", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6acb7a17-ef97-44e9-a379-eb37715ecaee", "node_type": "1", "metadata": {"Header_1": " Generating Question-Context Pairs:"}, "hash": "5bd6efcebac3c7c8bd0a4f0675cd3540b1e2bbdab5822100bba53c5c1bec1abc", "class_name": "RelatedNodeInfo"}}, "text": "Load the Data\n\nLet\u2019s load the data. We will use Pages from start to 36 for the experiment\nwhich excludes table of contents, references, and appendix.\n\nThis data was then parsed by converted to nodes, which represent chunks of\ndata we\u2019d like to retrieve. We did use chunk_size as 512.\n\n    \n    \n    documents = SimpleDirectoryReader(input_files=[\"llama2.pdf\"]).load_data()\n    \n    node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n    nodes = node_parser.get_nodes_from_documents(documents)", "mimetype": "text/plain", "start_char_idx": 2874, "end_char_idx": 3376, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6acb7a17-ef97-44e9-a379-eb37715ecaee": {"__data__": {"id_": "6acb7a17-ef97-44e9-a379-eb37715ecaee", "embedding": null, "metadata": {"Header_1": " Generating Question-Context Pairs:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3efdef6a-ae89-4dfc-85ff-b15faba8950c", "node_type": "1", "metadata": {"Header_1": " Load the Data", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "94f52ad94532cf5554e0caf1a4a892db132f4810b99feed37719741a67fcfe86", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "89ecab21-4a88-46ef-ade6-26dbfd95b3ae", "node_type": "1", "metadata": {"Header_1": " Custom Retriever:"}, "hash": "f278cfa984081cd6abf0bc7c3b885a90be0c1e98c7f4410dd0cc07a237854864", "class_name": "RelatedNodeInfo"}}, "text": "Generating Question-Context Pairs:\n\nFor evaluation purposes, we created a dataset of question-context pairs. This\ndataset can be seen as a set of questions and their corresponding context from\nour data. To remove bias for the evaluation of embedding(OpenAI/ CohereAI) and\nReranker (CohereAI), we use Anthropic LLM to generate Question-Context Pairs.\n\nLet\u2019s initialize a prompt template to generate question-context pairs.\n\n    \n    \n    # Prompt to generate questions\n    qa_generate_prompt_tmpl = \"\"\"\\\n    Context information is below.\n    \n    ---------------------\n    {context_str}\n    ---------------------\n    \n    Given the context information and not prior knowledge.\n    generate only questions based on the below query.\n    \n    You are a Professor. Your task is to setup \\\n    {num_questions_per_chunk} questions for an upcoming \\\n    quiz/examination. The questions should be diverse in nature \\\n    across the document. The questions should not contain options, not start with Q1/ Q2. \\\n    Restrict the questions to the context information provided.\\\n    \"\"\"\n    \n    \n    llm = Anthropic(api_key=anthropic_api_key)\n    qa_dataset = generate_question_context_pairs(\n        nodes, llm=llm, num_questions_per_chunk=2\n    )\n\nFunction to filter out sentences such as \u2014 ` Here are 2 questions based on\nprovided context `\n\n    \n    \n    # function to clean the dataset\n    def filter_qa_dataset(qa_dataset):\n        \"\"\"\n        Filters out queries from the qa_dataset that contain certain phrases and the corresponding\n        entries in the relevant_docs, and creates a new EmbeddingQAFinetuneDataset object with\n        the filtered data.\n    \n        :param qa_dataset: An object that has 'queries', 'corpus', and 'relevant_docs' attributes.\n        :return: An EmbeddingQAFinetuneDataset object with the filtered queries, corpus and relevant_docs.\n        \"\"\"\n    \n        # Extract keys from queries and relevant_docs that need to be removed\n        queries_relevant_docs_keys_to_remove = {\n            k for k, v in qa_dataset.queries.items()\n            if 'Here are 2' in v or 'Here are two' in v\n        }\n    \n        # Filter queries and relevant_docs using dictionary comprehensions\n        filtered_queries = {\n            k: v for k, v in qa_dataset.queries.items()\n            if k not in queries_relevant_docs_keys_to_remove\n        }\n        filtered_relevant_docs = {\n            k: v for k, v in qa_dataset.relevant_docs.items()\n            if k not in queries_relevant_docs_keys_to_remove\n        }\n    \n        # Create a new instance of EmbeddingQAFinetuneDataset with the filtered data\n        return EmbeddingQAFinetuneDataset(\n            queries=filtered_queries,\n            corpus=qa_dataset.corpus,\n            relevant_docs=filtered_relevant_docs\n        )\n    \n    # filter out pairs with phrases `Here are 2 questions based on provided context`\n    qa_dataset = filter_qa_dataset(qa_dataset)", "mimetype": "text/plain", "start_char_idx": 3381, "end_char_idx": 6313, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89ecab21-4a88-46ef-ade6-26dbfd95b3ae": {"__data__": {"id_": "89ecab21-4a88-46ef-ade6-26dbfd95b3ae", "embedding": null, "metadata": {"Header_1": " Custom Retriever:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6acb7a17-ef97-44e9-a379-eb37715ecaee", "node_type": "1", "metadata": {"Header_1": " Generating Question-Context Pairs:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "cc56821480494a5af00b32fbca1ffbd8bf613ffcfbb913f56080e19c21114c9d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5aee65b8-929f-4c6e-b929-329b4a361ae2", "node_type": "1", "metadata": {"Header_1": " Evaluation:"}, "hash": "a41e2220c84627ff5665d56435b934287011605877f0e5a6b60f529c2fb321e4", "class_name": "RelatedNodeInfo"}}, "text": "Custom Retriever:\n\nTo identify the optimal retriever, we employ a combination of an embedding\nmodel and a reranker. Initially, we establish a base ` VectorIndexRetriever `\n. Upon retrieving the nodes, we then introduce a reranker to further refine\nthe results. It\u2019s worth noting that for this particular experiment, we\u2019ve set\nsimilarity_top_k to 10 and picked top-5 with reranker. However, feel free to\nadjust this parameter based on the needs of your specific experiment. We are\nshowing the code here with ` OpenAIEmbedding ` , please refer to the [\nnotebook\n](https://colab.research.google.com/drive/1TxDVA__uimVPOJiMEQgP5fwHiqgKqm4-?usp=sharing)\nfor code with other embeddings.\n\n    \n    \n    embed_model = OpenAIEmbedding()\n    service_context = ServiceContext.from_defaults(llm=None, embed_model = embed_model)\n    vector_index = VectorStoreIndex(nodes, service_context=service_context)\n    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k = 10)\n    \n    \n    class CustomRetriever(BaseRetriever):\n        \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n    \n        def __init__(\n            self,\n            vector_retriever: VectorIndexRetriever,\n        ) -&gt; None:\n            \"\"\"Init params.\"\"\"\n    \n            self._vector_retriever = vector_retriever\n    \n        def _retrieve(self, query_bundle: QueryBundle) -&gt; List[NodeWithScore]:\n            \"\"\"Retrieve nodes given query.\"\"\"\n    \n        retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\n    \n        if reranker != 'None':\n          retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n           else:\n              retrieved_nodes = retrieved_nodes[:5]\n             \n           return retrieved_nodes\n    \n        async def _aretrieve(self, query_bundle: QueryBundle) -&gt; List[NodeWithScore]:\n            \"\"\"Asynchronously retrieve nodes given query.\n    \n            Implemented by the user.\n    \n            \"\"\"\n            return self._retrieve(query_bundle)\n    \n        async def aretrieve(self, str_or_query_bundle: QueryType) -&gt; List[NodeWithScore]:\n            if isinstance(str_or_query_bundle, str):\n                str_or_query_bundle = QueryBundle(str_or_query_bundle)\n            return await self._aretrieve(str_or_query_bundle)\n    \n    custom_retriever = CustomRetriever(vector_retriever)", "mimetype": "text/plain", "start_char_idx": 6318, "end_char_idx": 8706, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5aee65b8-929f-4c6e-b929-329b4a361ae2": {"__data__": {"id_": "5aee65b8-929f-4c6e-b929-329b4a361ae2", "embedding": null, "metadata": {"Header_1": " Evaluation:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89ecab21-4a88-46ef-ade6-26dbfd95b3ae", "node_type": "1", "metadata": {"Header_1": " Custom Retriever:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "23d51aca82054ae5f61ed084f0e82b13f3b89a0580d62f6aa366608b462be449", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4dd4c885-d56e-4fa9-9c0a-409254e8a9ad", "node_type": "1", "metadata": {"Header_1": " Results:"}, "hash": "a5baf851b222871011d089790a6c78db69f570984613ff8b93be686db87eefd0", "class_name": "RelatedNodeInfo"}}, "text": "Evaluation:\n\nTo evaluate our retriever, we computed the Mean Reciprocal Rank (MRR) and Hit\nRate metrics:\n\n    \n    \n    retriever_evaluator = RetrieverEvaluator.from_metric_names(\n        [\"mrr\", \"hit_rate\"], retriever=custom_retriever\n    )\n    eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)", "mimetype": "text/plain", "start_char_idx": 8711, "end_char_idx": 9027, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4dd4c885-d56e-4fa9-9c0a-409254e8a9ad": {"__data__": {"id_": "4dd4c885-d56e-4fa9-9c0a-409254e8a9ad", "embedding": null, "metadata": {"Header_1": " Results:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5aee65b8-929f-4c6e-b929-329b4a361ae2", "node_type": "1", "metadata": {"Header_1": " Evaluation:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "ebba29bd47a3a66a662e48a3d3e7f653066804da537848799c2e078cb3d52f8b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a615f7b-9828-4cc1-8f01-f2efff75aafb", "node_type": "1", "metadata": {"Header_1": " Analysis:"}, "hash": "acb370abf8ea18f396ccc5fd4e7e97d424f00738e061d61be88705d16afd5f0c", "class_name": "RelatedNodeInfo"}}, "text": "Results:\n\nWe put various embedding models and rerankers to the test. Here are the models\nwe considered:\n\n**Embedding Models** :\n\n  * [ OpenAI Embedding ](https://platform.openai.com/docs/guides/embeddings)\n  * [ Voyage Embedding ](https://www.voyageai.com/)\n  * [ CohereAI Embedding ](https://txt.cohere.com/introducing-embed-v3/) (v2.0/ v3.0) \n  * [ Jina Embeddings ](https://huggingface.co/jinaai/jina-embeddings-v2-small-en) (small/ base) \n  * [ BAAI/bge-large-en ](https://huggingface.co/BAAI/bge-large-en)\n  * [ Google PaLM Embedding ](https://developers.generativeai.google/tutorials/embeddings_quickstart)\n\n**Rerankers** :\n\n  * [ CohereAI ](https://txt.cohere.com/rerank/)\n  * [ bge-reranker-base ](https://huggingface.co/BAAI/bge-reranker-base)\n  * [ bge-reranker-large ](https://huggingface.co/BAAI/bge-reranker-large)\n\n> It\u2019s worth mentioning that these results provide a solid insight into\n> performance for this particular dataset and task. However, actual outcomes\n> may differ based on data characteristics, dataset size, and other variables\n> like chunk_size, similarity_top_k, and so on.\n\nThe table below showcases the evaluation results based on the metrics of Hit\nRate and Mean Reciprocal Rank (MRR):", "mimetype": "text/plain", "start_char_idx": 9032, "end_char_idx": 10250, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0a615f7b-9828-4cc1-8f01-f2efff75aafb": {"__data__": {"id_": "0a615f7b-9828-4cc1-8f01-f2efff75aafb", "embedding": null, "metadata": {"Header_1": " Analysis:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4dd4c885-d56e-4fa9-9c0a-409254e8a9ad", "node_type": "1", "metadata": {"Header_1": " Results:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "242a18252f8eaabe02ea5d410c04bee15d5913d2d2b1f936e2f170878a636398", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9be075c0-d631-42fd-b042-71aeb18cc43d", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Performance by Embedding:**"}, "hash": "4c8a69d9df677658967c3b83c25a262b0255137934cd315ff9801a48c806b33c", "class_name": "RelatedNodeInfo"}}, "text": "Analysis:", "mimetype": "text/plain", "start_char_idx": 10255, "end_char_idx": 10264, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9be075c0-d631-42fd-b042-71aeb18cc43d": {"__data__": {"id_": "9be075c0-d631-42fd-b042-71aeb18cc43d", "embedding": null, "metadata": {"Header_1": " Analysis:", "Header_2": " **Performance by Embedding:**", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0a615f7b-9828-4cc1-8f01-f2efff75aafb", "node_type": "1", "metadata": {"Header_1": " Analysis:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "eae32213a297ef391e58630025019aac30770b874f5a3528a295ac90902c5741", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "654c66f4-f443-4468-bdab-539cd471d021", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Impact of Rerankers** :"}, "hash": "bdb9a571540ebf134b8d0d20426500a2fb919e2b3260c4dc55f663456bf77e43", "class_name": "RelatedNodeInfo"}}, "text": "**Performance by Embedding:**\n\n  * **OpenAI** : Showcases top-tier performance, especially with the ` **CohereRerank** ` (0.926966 hit rate, 0.86573 MRR) and ` **bge-reranker-large** ` (0.910112 hit rate, 0.855805 MRR), indicating strong compatibility with reranking tools. \n  * **bge-large** : Experiences significant improvement with rerankers, with the best results from ` **CohereRerank** ` (0.876404 hit rate, 0.822753 MRR). \n  * **llm-embedder** : Benefits greatly from reranking, particularly with ` **CohereRerank** ` (0.882022 hit rate, 0.830243 MRR), which offers a substantial performance boost. \n  * **Cohere** : Cohere\u2019s latest v3.0 embeddings outperform v2.0 and, with the integration of native CohereRerank, significantly improve its metrics, boasting a 0.88764 hit rate and a 0.836049 MRR. \n  * **Voyage** : Has strong initial performance that is further amplified by ` **CohereRerank** ` (0.91573 hit rate, 0.851217 MRR), suggesting high responsiveness to reranking. \n  * **JinaAI** : Very strong performance, sees notable gains with ` **bge-reranker-large** ` (0.938202 hit rate, 0.868539 MRR) and ` **CohereRerank** ` (0.932584 hit rate, 0.873689), indicating that reranking significantly boosts its performance. \n  * **Google-PaLM** : The model demonstrates strong performance, with measurable gains when using the ` **CohereRerank** ` (0.910112 hit rate, 0.855712 MRR). This indicates that reranking provides a clear boost to its overall results.", "mimetype": "text/plain", "start_char_idx": 10270, "end_char_idx": 11737, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "654c66f4-f443-4468-bdab-539cd471d021": {"__data__": {"id_": "654c66f4-f443-4468-bdab-539cd471d021", "embedding": null, "metadata": {"Header_1": " Analysis:", "Header_2": " **Impact of Rerankers** :", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9be075c0-d631-42fd-b042-71aeb18cc43d", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Performance by Embedding:**", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "3d0091b7e2401c29b22636e6eaf67d3e0182247272a26cc785f99c9dbbb07b68", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0bab500c-c25c-4af4-9f36-f1808cdf4d2a", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Necessity of Rerankers** :"}, "hash": "be104d7832ae386a9d12e68620df1f888ab3813b57209da9a4dedfdae2e3e0f1", "class_name": "RelatedNodeInfo"}}, "text": "**Impact of Rerankers** :\n\n  * **WithoutReranker** : This provides the baseline performance for each embedding. \n  * **bge-reranker-base** : Generally improves both hit rate and MRR across embeddings. \n  * **bge-reranker-large** : This reranker frequently offers the highest or near-highest MRR for embeddings. For several embeddings, its performance rivals or surpasses that of the ` **CohereRerank** ` . \n  * **CohereRerank** : Consistently enhances performance across all embeddings, often providing the best or near-best results.", "mimetype": "text/plain", "start_char_idx": 11744, "end_char_idx": 12277, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0bab500c-c25c-4af4-9f36-f1808cdf4d2a": {"__data__": {"id_": "0bab500c-c25c-4af4-9f36-f1808cdf4d2a", "embedding": null, "metadata": {"Header_1": " Analysis:", "Header_2": " **Necessity of Rerankers** :", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "654c66f4-f443-4468-bdab-539cd471d021", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Impact of Rerankers** :", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "45ec2e1ae9aaede1ed63e07367905dc42f727c28588afade64c867b25c394f99", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9421567a-072b-4a90-9b50-6fb2cd4e2832", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Overall Superiority** :"}, "hash": "86b8ade61a070f733d9fc3335c07c9d73b1d6d43660f937221e6e72a31401451", "class_name": "RelatedNodeInfo"}}, "text": "**Necessity of Rerankers** :\n\n  * The data clearly indicates the significance of rerankers in refining search results. Nearly all embeddings benefit from reranking, showing improved hit rates and MRRs. \n  * Rerankers, especially ` **CohereRerank** ` , have demonstrated their capability to transform any embedding into a competitive one.", "mimetype": "text/plain", "start_char_idx": 12284, "end_char_idx": 12621, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9421567a-072b-4a90-9b50-6fb2cd4e2832": {"__data__": {"id_": "9421567a-072b-4a90-9b50-6fb2cd4e2832", "embedding": null, "metadata": {"Header_1": " Analysis:", "Header_2": " **Overall Superiority** :", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0bab500c-c25c-4af4-9f36-f1808cdf4d2a", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Necessity of Rerankers** :", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "6f7c133006c127364212c7a0f73f72ab08007aeeab6aadf191ce4a01656de743", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aebd723f-6bd3-406c-8a9d-628a66efeb34", "node_type": "1", "metadata": {"Header_1": " Conclusions:"}, "hash": "3becf76ff371a2ec4ea6f94dae829ad2efb3825f63816c53f1460669e3c5634b", "class_name": "RelatedNodeInfo"}}, "text": "**Overall Superiority** :\n\n  * When considering both hit rate and MRR, the combinations of ` **OpenAI + CohereRerank** ` and ` **JinaAI-Base + bge-reranker-large/ CohereRerank** ` emerge as top contenders. \n  * However, the consistent improvement brought by the ` **CohereRerank/ bge-reranker-large** ` rerankers across various embeddings make them the standout choice for enhancing search quality, regardless of the embedding in use. \n\nIn summary, to achieve the peak performance in both hit rate and MRR, the\ncombination of ` **OpenAI** ` or ` **JinaAI-Base** ` embeddings with the `\n**CohereRerank/bge-reranker-large** ` reranker stands out.\n\n> Please be aware that our benchmarks are intended to offer a reproducible\n> script for your own data. Nevertheless, treat these figures as estimates and\n> proceed with caution when interpreting them.", "mimetype": "text/plain", "start_char_idx": 12628, "end_char_idx": 13474, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aebd723f-6bd3-406c-8a9d-628a66efeb34": {"__data__": {"id_": "aebd723f-6bd3-406c-8a9d-628a66efeb34", "embedding": null, "metadata": {"Header_1": " Conclusions:", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "569ea848-d06d-4e12-8e50-1a5923bdc928", "node_type": "4", "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "144d30c532e0adf91d7eb771ce57dd8cb54f6d894b95775e9e45cd06dfdd2187", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9421567a-072b-4a90-9b50-6fb2cd4e2832", "node_type": "1", "metadata": {"Header_1": " Analysis:", "Header_2": " **Overall Superiority** :", "filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}, "hash": "ab347de1d8c1f76bc44ca0c83f8a0b609eb3c243d67ebe7cab9ee209b4a12c79", "class_name": "RelatedNodeInfo"}}, "text": "Conclusions:\n\nIn this blog post, we have demonstrated how to evaluate and enhance retriever\nperformance using various embeddings and rerankers. Below are our final\nconclusions.\n\n  * **Embeddings** : The ` **OpenAI** ` and ` **JinaAI-Base** ` embeddings, especially when paired with the ` **CohereRerank/bge-reranker-large** ` reranker, set the gold standard for both hit rate and MRR. \n  * **Rerankers** : The influence of rerankers, particularly ` **CohereRerank/bge-reranker-large** ` , cannot be overstated. They play a key role in improving the MRR for many embeddings, showing their importance in making search results better. \n  * **Foundation is Key** : Choosing the right embedding for the initial search is essential; even the best reranker can\u2019t help much if the basic search results aren\u2019t good. \n  * **Working Together:** To get the best out of retrievers, it\u2019s important to find the right mix of embeddings and rerankers. This study shows how important it is to carefully test and find the best pairing.", "mimetype": "text/plain", "start_char_idx": 13479, "end_char_idx": 14495, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"4e350df2-6978-405d-8b3a-5edc6cec953e": {"doc_hash": "4bc3a4781ee50d5cf5b79035f8097cb94f50bfcdd5aa14906edb9365d3a19128", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "24cffcdd-2b5a-4e17-a89f-cb9423d2c300": {"doc_hash": "0747aecfdb67d2566bd9ca9999940f9a755ba6b2330ee918337c3e96dc262b3e", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "80441101-26df-4475-a369-3a7e39844135": {"doc_hash": "d4553b13452767afa9a9f48a79e46e3bd49a0bec1c77db8f8ba5ec61052be702", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "52fe7b4d-42da-4940-acc5-6c5eb5699c2a": {"doc_hash": "8b1f3f6ec5b2f40062a9c7148b055578321d7ebbbaf6b8e1a0d18f5f601e6a57", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "5a83a0f2-dc7c-443e-b4ff-5b350f8b41e1": {"doc_hash": "800a3ada16fad24ecc480bf9a160ea697f1d930a85913d995611c905f7ac6949", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "3efdef6a-ae89-4dfc-85ff-b15faba8950c": {"doc_hash": "94f52ad94532cf5554e0caf1a4a892db132f4810b99feed37719741a67fcfe86", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "6acb7a17-ef97-44e9-a379-eb37715ecaee": {"doc_hash": "cc56821480494a5af00b32fbca1ffbd8bf613ffcfbb913f56080e19c21114c9d", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "89ecab21-4a88-46ef-ade6-26dbfd95b3ae": {"doc_hash": "23d51aca82054ae5f61ed084f0e82b13f3b89a0580d62f6aa366608b462be449", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "5aee65b8-929f-4c6e-b929-329b4a361ae2": {"doc_hash": "ebba29bd47a3a66a662e48a3d3e7f653066804da537848799c2e078cb3d52f8b", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "4dd4c885-d56e-4fa9-9c0a-409254e8a9ad": {"doc_hash": "242a18252f8eaabe02ea5d410c04bee15d5913d2d2b1f936e2f170878a636398", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "0a615f7b-9828-4cc1-8f01-f2efff75aafb": {"doc_hash": "eae32213a297ef391e58630025019aac30770b874f5a3528a295ac90902c5741", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "9be075c0-d631-42fd-b042-71aeb18cc43d": {"doc_hash": "3d0091b7e2401c29b22636e6eaf67d3e0182247272a26cc785f99c9dbbb07b68", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "654c66f4-f443-4468-bdab-539cd471d021": {"doc_hash": "45ec2e1ae9aaede1ed63e07367905dc42f727c28588afade64c867b25c394f99", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "0bab500c-c25c-4af4-9f36-f1808cdf4d2a": {"doc_hash": "6f7c133006c127364212c7a0f73f72ab08007aeeab6aadf191ce4a01656de743", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "9421567a-072b-4a90-9b50-6fb2cd4e2832": {"doc_hash": "ab347de1d8c1f76bc44ca0c83f8a0b609eb3c243d67ebe7cab9ee209b4a12c79", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}, "aebd723f-6bd3-406c-8a9d-628a66efeb34": {"doc_hash": "905b668019b3ebbd2d73cd694bee5198c02b503748c197092ec6264d2aa668be", "ref_doc_id": "569ea848-d06d-4e12-8e50-1a5923bdc928"}}, "docstore/ref_doc_info": {"569ea848-d06d-4e12-8e50-1a5923bdc928": {"node_ids": ["4e350df2-6978-405d-8b3a-5edc6cec953e", "24cffcdd-2b5a-4e17-a89f-cb9423d2c300", "80441101-26df-4475-a369-3a7e39844135", "52fe7b4d-42da-4940-acc5-6c5eb5699c2a", "5a83a0f2-dc7c-443e-b4ff-5b350f8b41e1", "3efdef6a-ae89-4dfc-85ff-b15faba8950c", "6acb7a17-ef97-44e9-a379-eb37715ecaee", "89ecab21-4a88-46ef-ade6-26dbfd95b3ae", "5aee65b8-929f-4c6e-b929-329b4a361ae2", "4dd4c885-d56e-4fa9-9c0a-409254e8a9ad", "0a615f7b-9828-4cc1-8f01-f2efff75aafb", "9be075c0-d631-42fd-b042-71aeb18cc43d", "654c66f4-f443-4468-bdab-539cd471d021", "0bab500c-c25c-4af4-9f36-f1808cdf4d2a", "9421567a-072b-4a90-9b50-6fb2cd4e2832", "aebd723f-6bd3-406c-8a9d-628a66efeb34"], "metadata": {"filename": "boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83.md", "extension": ".md", "title": "Boosting RAG: Picking the Best Embedding & Reranker models", "date": "Nov 3, 2023", "url": "https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"}}}}