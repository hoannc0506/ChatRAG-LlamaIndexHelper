{"docstore/data": {"b4655fa1-c3bf-474c-a925-e3755e9696ef": {"__data__": {"id_": "b4655fa1-c3bf-474c-a925-e3755e9696ef", "embedding": null, "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa64e80-3390-4204-825d-d345674a7700", "node_type": "4", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "409c03c9cd4a855f46a81c8f2da97891a73e5082cf7a403a9cbb1b4cf383f62f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dbb25689-0186-4766-87f8-bec552ff483e", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?"}, "hash": "7ed9352c1d8e96dcbe70ddaa691ea9310590bd6744b2c225cb459b40c40ca330", "class_name": "RelatedNodeInfo"}}, "text": "**Authors:** Anupam Datta, Shayak Sen, Jerry Liu, Simon Suo\n\n**Source Link:** [ https://truera.com/build-and-evaluate-llm-apps-with-\nllamaindex-and-trulens/ ](https://truera.com/build-and-evaluate-llm-apps-with-\nllamaindex-and-trulens/)\n\nLlamaIndex is a popular open source framework for building LLM apps. TruLens\nis an open source library for evaluating, tracking, and iterating on LLM apps\nto improve their quality. The LlamaIndex and TruLens teams are actively\ncollaborating to enable LLM app developers to rapidly build, evaluate, and\niterate on their apps.\n\nIn the latest release of TruLens, we introduce tracing for LlamaIndex based\nLLM applications that allow you to evaluate and track your experiments with\njust a few lines of code. This lets you automatically evaluate a number of\ndifferent components of the application stack including:\n\n  * App inputs and outputs \n  * LLM calls \n  * Retrieved context chunks from an index \n  * Latency \n  * Cost and Token Counts (coming soon!) \n\nCheck out this [ notebook\n](https://github.com/truera/trulens/blob/releases/rc-trulens-\neval-0.3.0/trulens_eval/examples/vector-dbs/llama_index/quickstart.ipynb) to\nget started and read along to get a step by step view.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1211, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dbb25689-0186-4766-87f8-bec552ff483e": {"__data__": {"id_": "dbb25689-0186-4766-87f8-bec552ff483e", "embedding": null, "metadata": {"Header_1": " How do I actually use this?", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa64e80-3390-4204-825d-d345674a7700", "node_type": "4", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "409c03c9cd4a855f46a81c8f2da97891a73e5082cf7a403a9cbb1b4cf383f62f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b4655fa1-c3bf-474c-a925-e3755e9696ef", "node_type": "1", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "5bde997b1d1855ac7c23823086174fd1b5b042d65d3a3ee7d7461a5aa8985a4b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c41e79c-d173-455d-81bf-e0f31b126546", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Build A LlamaIndex App"}, "hash": "5d754435d089fc9188d92f1db60604dc74814d835c6cb39193e0642c1fa148e4", "class_name": "RelatedNodeInfo"}}, "text": "How do I actually use this?", "mimetype": "text/plain", "start_char_idx": 1216, "end_char_idx": 1243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9c41e79c-d173-455d-81bf-e0f31b126546": {"__data__": {"id_": "9c41e79c-d173-455d-81bf-e0f31b126546", "embedding": null, "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Build A LlamaIndex App", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa64e80-3390-4204-825d-d345674a7700", "node_type": "4", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "409c03c9cd4a855f46a81c8f2da97891a73e5082cf7a403a9cbb1b4cf383f62f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dbb25689-0186-4766-87f8-bec552ff483e", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "00feb16338f3c4b0c6fe1ff70d43b43d549dfb837a56534fb06edaab13bd051b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4fe8bc78-9ae3-4515-9ee7-f13a0c3bca9b", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Wrap A LlamaIndex App with TruLens"}, "hash": "3cfa2fb3bfd5ff0eddf91c2e8a7cd7f7f250d75700c6e68009699469ac78207c", "class_name": "RelatedNodeInfo"}}, "text": "Build A LlamaIndex App\n\nLlamaIndex lets you connect your data to LLMs and rapidly build applications\nfor a number of different use cases.\n\n    \n    \n    from llama_index import VectorStoreIndex, SimpleDirectoryReader\n    \n    documents = SimpleDirectoryReader('llama_index/data').load_data()\n    index = VectorStoreIndex.from_documents(documents)\n    \n    query_engine = index.as_query_engine()\n\nOnce you build your app, you can easily query your data:\n\n    \n    \n    response = query_engine.query(\"What did the author do growing up?\")\n    print(response)\n\nAnd you get an appropriate response.\n\n    \n    \n    Growing up, the author wrote short stories, programmed on an IBM 1401, and nagged his father to buy him a TRS-80 microcomputer. He wrote simple games, a program to predict how high his model rockets would fly, and a word processor. He also studied philosophy in college, but switched to AI after becoming bored with it. He then took art classes at Harvard and applied to art schools, eventually attending RISD.", "mimetype": "text/plain", "start_char_idx": 1249, "end_char_idx": 2268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4fe8bc78-9ae3-4515-9ee7-f13a0c3bca9b": {"__data__": {"id_": "4fe8bc78-9ae3-4515-9ee7-f13a0c3bca9b", "embedding": null, "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Wrap A LlamaIndex App with TruLens", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa64e80-3390-4204-825d-d345674a7700", "node_type": "4", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "409c03c9cd4a855f46a81c8f2da97891a73e5082cf7a403a9cbb1b4cf383f62f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c41e79c-d173-455d-81bf-e0f31b126546", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Build A LlamaIndex App", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "7895eb3ba166ba5e0f633851890c122338bdf454f174c274724466d2c4a9064b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fa0211cc-7054-4f6e-ba07-e248f1bf22dc", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Add Feedback Functions"}, "hash": "525b37fe419851cba78e599e9a4ab7bd3e954d1c712062b0c1687f85ba70dcf4", "class_name": "RelatedNodeInfo"}}, "text": "Wrap A LlamaIndex App with TruLens\n\nWith TruLens, you can wrap LlamaIndex query engines with a TruLlama wrapper.\nThis wrapper preserves all LlamaIndex behavior, but traces all of the\nintermediate steps so that they can be individually evaluated.\n\n    \n    \n    from trulens_eval import TruLlama\n    l = TruLlama(query_engine)\n\nThe wrapped app can now be queried in the exact same way:\n\n    \n    \n    response = l.query(\"What did the author do growing up?\")\n    print(response)\n\nExcept, now the details of the query are logged by TruLens.", "mimetype": "text/plain", "start_char_idx": 2274, "end_char_idx": 2811, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fa0211cc-7054-4f6e-ba07-e248f1bf22dc": {"__data__": {"id_": "fa0211cc-7054-4f6e-ba07-e248f1bf22dc", "embedding": null, "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Add Feedback Functions", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa64e80-3390-4204-825d-d345674a7700", "node_type": "4", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "409c03c9cd4a855f46a81c8f2da97891a73e5082cf7a403a9cbb1b4cf383f62f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4fe8bc78-9ae3-4515-9ee7-f13a0c3bca9b", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Wrap A LlamaIndex App with TruLens", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "b9b097d2e64709c62b4a6b0078c5b670491b060480206e947fa76ebc3df2ad3b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8f1de6ac-a744-4987-adba-98ad098463eb", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Explore In Dashboard"}, "hash": "47406ee0a99f8eea7763ad52f8f37a38f37f01f6be87f3436444ec7f1ac52586", "class_name": "RelatedNodeInfo"}}, "text": "Add Feedback Functions\n\nNow to evaluate the behavior of your models, we can add feedback functions to\nyour wrapped application. Note that as a developer you only need to **add a\nfew lines of code** to start using feedback functions in your apps. You can\nalso easily add functions tailored to the needs of your application.\n\nOur goal with feedback functions is to programmatically check the app for\nquality metrics.\n\n  * The first feedback function checks for language match between the prompt and the response. It\u2019s a useful check since a natural user expectation is that the response is in the same language as the prompt. It is implemented with a call to a HuggingFace API that programmatically checks for language match. \n  * The next feedback function checks how relevant the answer is to the question by using an Open AI LLM that is prompted to produce a relevance score. \n  * Finally, the third feedback function checks how relevant individual chunks retrieved from the vector database are to the question, again using an OpenAI LLM in a similar manner. This is useful because the retrieval step from a vector database may produce chunks that are not relevant to the question and the quality of the final response would be better if these chunks are filtered out before producing the final response. \n\n    \n    \n    from trulens_eval import TruLlama, Tru, Query, Feedback, feedback\n    \n    # Initialize Huggingface-based feedback function collection class:\n    hugs = feedback.Huggingface()\n    openai = feedback.OpenAI()\n    # Define a language match feedback function using HuggingFace.\n    f_lang_match = Feedback(hugs.language_match).on_input_output()\n    # By default this will check language match on the main app input and main app\n    # output.\n    \n    # Question/answer relevance between overall question and answer.\n    f_qa_relevance = Feedback(openai.relevance).on_input_output()\n    \n    # Question/statement relevance between question and each context chunk.\n    f_qs_relevance = Feedback(openai.qs_relevance).on_input().on(\n        TruLlama.select_source_nodes().node.text\n    ).aggregate(np.min)\n    \n    \n    feedbacks = [f_lang_match, f_qa_relevance, f_qs_relevance]\n    \n    l = TruLlama(app=query_engine, feedbacks=feedbacks)", "mimetype": "text/plain", "start_char_idx": 2817, "end_char_idx": 5070, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8f1de6ac-a744-4987-adba-98ad098463eb": {"__data__": {"id_": "8f1de6ac-a744-4987-adba-98ad098463eb", "embedding": null, "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Explore In Dashboard", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa64e80-3390-4204-825d-d345674a7700", "node_type": "4", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "409c03c9cd4a855f46a81c8f2da97891a73e5082cf7a403a9cbb1b4cf383f62f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fa0211cc-7054-4f6e-ba07-e248f1bf22dc", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Add Feedback Functions", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "2040cd1784c519993b73692bbd0ce87f81e0ecf88eee8a768c0333b5e04f8c54", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ddb4e097-4d1b-46c1-ad4c-19b1679e59f9", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Iterate on your App"}, "hash": "76a3e5e451bb88c3b603d9b7e735bd9d1af727c3caa029a3d5205c62634fe55b", "class_name": "RelatedNodeInfo"}}, "text": "Explore In Dashboard\n\nEvery query that is tracked can now be viewed in the TruLens dashboard. After\nrunning the feedback functions on a set of records (interactions), you can see\nthe aggregate results of the evaluation on a leaderboard; then drill down into\nan app version and examine how it is performing on individual records. These\nsteps can help you understand the quality of an app version and its failure\nmodes.\n\nIn this example, the model is doing fairly well on the relevance and language\nmatch feedback evaluations, but seems to be doing poorly on qs_relevance. This\ncan be an indicator that the retrieved chunks are often irrelevant. This can\nbe a significant source of \u201challucinations\u201d in retrieval-augmented generative\nAI apps.\n\nWe can now drill down and identify specific instances where this may be an\nissue:\n\nLet\u2019s look at a good example first. \u201cWhat did the author do growing up?\u201d\n\nIn this example, we retrieved two chunks from the index both of which were\nfairly relevant to the the question and as a result the LLM summarizes it into\na relevant and factually correct answer.\n\nOn the other hand, let\u2019s look at an example where this didn\u2019t go so well:\n\u201cWhere was the author born?\u201d. In this example, the app confidently provides an\nincorrect answer.\n\nIn this example, the two pieces of context retrieved had moderate relevance to\nthe question. Further, neither context contained the answer. Even though our\nrelevance feedback function (which doesn\u2019t check for factual correctness)\ndidn\u2019t detect an issue, because the underlying chunks were not very relevant,\nthis was a strong indicator that something was off. Indeed, this is an example\nof the model hallucinating on a question that is fairly easy to fact check.", "mimetype": "text/plain", "start_char_idx": 5076, "end_char_idx": 6804, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ddb4e097-4d1b-46c1-ad4c-19b1679e59f9": {"__data__": {"id_": "ddb4e097-4d1b-46c1-ad4c-19b1679e59f9", "embedding": null, "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Iterate on your App", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa64e80-3390-4204-825d-d345674a7700", "node_type": "4", "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "409c03c9cd4a855f46a81c8f2da97891a73e5082cf7a403a9cbb1b4cf383f62f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8f1de6ac-a744-4987-adba-98ad098463eb", "node_type": "1", "metadata": {"Header_1": " How do I actually use this?", "Header_2": " Explore In Dashboard", "filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}, "hash": "137ce90d2e354fc2eeaa40ea2e588189b6336de4a290c21c7747d6d19d228af6", "class_name": "RelatedNodeInfo"}}, "text": "Iterate on your App\n\nOnce you find issues like this with your app, it can be helpful to iterate on\nyour prompts, models and chunking approaches to optimize your app. As you do\nthis, you can track the performance of each version of your model with\nTruLens. Here is an example of a dashboard with multiple iterations testing\nagainst each other.", "mimetype": "text/plain", "start_char_idx": 6810, "end_char_idx": 7152, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"b4655fa1-c3bf-474c-a925-e3755e9696ef": {"doc_hash": "5bde997b1d1855ac7c23823086174fd1b5b042d65d3a3ee7d7461a5aa8985a4b", "ref_doc_id": "8fa64e80-3390-4204-825d-d345674a7700"}, "dbb25689-0186-4766-87f8-bec552ff483e": {"doc_hash": "00feb16338f3c4b0c6fe1ff70d43b43d549dfb837a56534fb06edaab13bd051b", "ref_doc_id": "8fa64e80-3390-4204-825d-d345674a7700"}, "9c41e79c-d173-455d-81bf-e0f31b126546": {"doc_hash": "7895eb3ba166ba5e0f633851890c122338bdf454f174c274724466d2c4a9064b", "ref_doc_id": "8fa64e80-3390-4204-825d-d345674a7700"}, "4fe8bc78-9ae3-4515-9ee7-f13a0c3bca9b": {"doc_hash": "b9b097d2e64709c62b4a6b0078c5b670491b060480206e947fa76ebc3df2ad3b", "ref_doc_id": "8fa64e80-3390-4204-825d-d345674a7700"}, "fa0211cc-7054-4f6e-ba07-e248f1bf22dc": {"doc_hash": "2040cd1784c519993b73692bbd0ce87f81e0ecf88eee8a768c0333b5e04f8c54", "ref_doc_id": "8fa64e80-3390-4204-825d-d345674a7700"}, "8f1de6ac-a744-4987-adba-98ad098463eb": {"doc_hash": "137ce90d2e354fc2eeaa40ea2e588189b6336de4a290c21c7747d6d19d228af6", "ref_doc_id": "8fa64e80-3390-4204-825d-d345674a7700"}, "ddb4e097-4d1b-46c1-ad4c-19b1679e59f9": {"doc_hash": "2709ef256e1b15dfe7e252cc90943a9970f84f456e365101f480fac54dbd9637", "ref_doc_id": "8fa64e80-3390-4204-825d-d345674a7700"}}, "docstore/ref_doc_info": {"8fa64e80-3390-4204-825d-d345674a7700": {"node_ids": ["b4655fa1-c3bf-474c-a925-e3755e9696ef", "dbb25689-0186-4766-87f8-bec552ff483e", "9c41e79c-d173-455d-81bf-e0f31b126546", "4fe8bc78-9ae3-4515-9ee7-f13a0c3bca9b", "fa0211cc-7054-4f6e-ba07-e248f1bf22dc", "8f1de6ac-a744-4987-adba-98ad098463eb", "ddb4e097-4d1b-46c1-ad4c-19b1679e59f9"], "metadata": {"filename": "build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c.md", "extension": ".md", "title": "Build and Evaluate LLM Apps with LlamaIndex and TruLens", "date": "Jun 23, 2023", "url": "https://www.llamaindex.ai/blog/build-and-evaluate-llm-apps-with-llamaindex-and-trulens-6749e030d83c"}}}}