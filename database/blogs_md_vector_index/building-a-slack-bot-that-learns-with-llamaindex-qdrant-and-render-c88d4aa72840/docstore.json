{"docstore/data": {"7773eeca-52f9-43f8-a9b2-4fa3cb22ed51": {"__data__": {"id_": "7773eeca-52f9-43f8-a9b2-4fa3cb22ed51", "embedding": null, "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7687ebb-f166-4f6d-94db-41b08ce346b6", "node_type": "1", "metadata": {"Header_1": " Things you\u2019ll need to start"}, "hash": "4b8240b4c8706ab60959585eb35c7f0b13c0b2d708cdacf0ea91b6fab7c2d8fa", "class_name": "RelatedNodeInfo"}}, "text": "In this post we\u2019re going to walk you through the process of building and\ndeploying a Slackbot that listens to your conversations, learns from them, and\nuses that knowledge to answer questions about what\u2019s going on in your Slack\nworkspace. We\u2019ll also deploy it to production on Render!", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 284, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7687ebb-f166-4f6d-94db-41b08ce346b6": {"__data__": {"id_": "b7687ebb-f166-4f6d-94db-41b08ce346b6", "embedding": null, "metadata": {"Header_1": " Things you\u2019ll need to start", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7773eeca-52f9-43f8-a9b2-4fa3cb22ed51", "node_type": "1", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "9cb48263960caebb2b7422ac8062f5eef0be745b776c583a3c4055d8552bc16e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "94d0e078-462c-4885-bcd9-3588c6cd535a", "node_type": "1", "metadata": {"Header_1": " Step 1: Create a Slack app, and install it to your workspace"}, "hash": "a9672db670e475532fa47ff79876cdd00e990d6bb1e8a642bee82c370348fcbe", "class_name": "RelatedNodeInfo"}}, "text": "Things you\u2019ll need to start\n\n  * Rudimentary understanding of LlamaIndex. If you haven\u2019t got that, the [ starter tutorial ](https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html) in our documentation will give you as much as you need to understand this tutorial and takes only a few minutes. \n  * A working knowledge of Python, and Python 3.11 or higher installed \n  * A Slack workspace you can install apps to (so you\u2019ll need to be an admin) \n  * A clone of [ our Slackbot repo ](https://github.com/run-llama/llamabot) on your local machine. We\u2019ll be referring to files in this repo throughout the post.", "mimetype": "text/plain", "start_char_idx": 289, "end_char_idx": 913, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "94d0e078-462c-4885-bcd9-3588c6cd535a": {"__data__": {"id_": "94d0e078-462c-4885-bcd9-3588c6cd535a", "embedding": null, "metadata": {"Header_1": " Step 1: Create a Slack app, and install it to your workspace", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7687ebb-f166-4f6d-94db-41b08ce346b6", "node_type": "1", "metadata": {"Header_1": " Things you\u2019ll need to start", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "a2c18bcf2a194c323ea3a43937f28b07718b54f088125ac0f20e3b3600a3be3a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2e92c0dd-051e-4cb1-8cfd-3a5d4deb93bd", "node_type": "1", "metadata": {"Header_1": " Make your app available to Slack"}, "hash": "1e19f924008deaaf79b11f280c12641cd4030af49de6467a408dce5afd7ea872", "class_name": "RelatedNodeInfo"}}, "text": "Step 1: Create a Slack app, and install it to your workspace\n\nThis is the most complicated step, because Slack is very picky about\npermissions.\n\nThe very first version of your Slackbot is going to be only about 20 lines of\ncode. All it does is provide a \u201cchallenge\u201d endpoint that Slack needs to verify\nyour app is available. You can see this code as the file ` 1_flask.py ` in the\nrepo. Let's walk through it.\n\nFirst we bring in your dependencies. You\u2019ll need to install these with pip or\npoetry if you don\u2019t have them already.\n\n    \n    \n    from flask import Flask, request, jsonify\n\nNow we\u2019ll create your flask app and set it up so it can run in development.\n\n    \n    \n    flask_app = Flask(__name__)\n    \n    if __name__ == \"__main__\":\n        flask_app.run(port=3000)\n\nBetween those lines we\u2019ll add our basic route: if a POST request is received\nthat contains a JSON object with a ` challenge ` key, we'll return the value\nof that key. Otherwise we'll do nothing.\n\n    \n    \n    @flask_app.route(\"/\", methods=[\"POST\"])\n    def slack_challenge():\n        if request.json and \"challenge\" in request.json:\n            print(\"Received challenge\")\n            return jsonify({\"challenge\": request.json[\"challenge\"]})\n        else:\n            print(\"Got unknown request incoming\")\n            print(request.json)\n        return", "mimetype": "text/plain", "start_char_idx": 919, "end_char_idx": 2247, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2e92c0dd-051e-4cb1-8cfd-3a5d4deb93bd": {"__data__": {"id_": "2e92c0dd-051e-4cb1-8cfd-3a5d4deb93bd", "embedding": null, "metadata": {"Header_1": " Make your app available to Slack", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "94d0e078-462c-4885-bcd9-3588c6cd535a", "node_type": "1", "metadata": {"Header_1": " Step 1: Create a Slack app, and install it to your workspace", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "307e2cabb1d45f538bdc3a8bb32beb12b6ff1bdd4ce97029356193d0f251cf0b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "492d9d9a-6f6f-431c-9353-d2f033512d05", "node_type": "1", "metadata": {"Header_1": " Register your app with Slack"}, "hash": "4852fe08e390c1a40383530c524e3e9ce06953af058a716db54b58908a8b4e3b", "class_name": "RelatedNodeInfo"}}, "text": "Make your app available to Slack\n\nTo configure a Slack app, it needs to be running somewhere Slack can see it.\nSo let\u2019s run our Slack app:\n\n    \n    \n    python 1_flask.py\n\nAnd we\u2019ll set it up so the world can see it using [ ngrok\n](https://ngrok.com/) . You\u2019ll need to download and install ngrok for this\nstep. Once you have it installed, run the following command so it can find our\napp running on port 3000:\n\n    \n    \n    ngrok http 3000\n\nngrok will give you an HTTPS url like ` https://1bf6-64-38-189-168.ngrok-\nfree.app ` . Make a note of it, because we need to give that to Slack. Also\nkeep in mind that if you stop ngrok and start it again, this URL will change\nand you'll need to tell Slack about that. You'll only need this during\ndevelopment.", "mimetype": "text/plain", "start_char_idx": 2252, "end_char_idx": 3005, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "492d9d9a-6f6f-431c-9353-d2f033512d05": {"__data__": {"id_": "492d9d9a-6f6f-431c-9353-d2f033512d05", "embedding": null, "metadata": {"Header_1": " Register your app with Slack", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2e92c0dd-051e-4cb1-8cfd-3a5d4deb93bd", "node_type": "1", "metadata": {"Header_1": " Make your app available to Slack", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "59868b40f972ac237d3925abfde2a455885b64318e0f4558d603a20517533f88", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c41dc5bc-188e-4692-a0e3-ccd7bbd1eb1c", "node_type": "1", "metadata": {"Header_1": " Step 2: Join a channel, and reply to messages"}, "hash": "f159cbbc92caef04158d945ac944b9c73be79e20cfe4087fa20a301b5cb8d72b", "class_name": "RelatedNodeInfo"}}, "text": "Register your app with Slack\n\nGo to the [ Slack API site ](https://api.slack.com/apps) and click \u201cCreate New\nApp\u201d. You\u2019ll see a screen like this, you\u2019ll want to pick \u201cfrom scratch\u201d:\n\nPick a nice friendly name and the workspace you want to install it to. You\u2019ll\nsee a screen like this:\n\nNext you\u2019ll want to set up what permissions your app needs. Click the\n\u201cPermissions\u201d link in the bottom right:\n\nThis will bring you to the \u201cscopes\u201d screen where you\u2019ll need to add all the\nscopes you see in this picture, namely:\n\n  * channels:read \u2014 the lets your app see what channels are avaialble \n  * channels:join \u2014 this lets your app join channels \n  * channels:history \u2014 this lets your app see previous messages in channels \n  * chat:write \u2014 this lets your app send messages \n  * users:read \u2014 this lets your app see people\u2019s names \n\nOnce you\u2019ve saved those scopes, scroll up to \u201cInstall to workspace\u201d to install\nyour app.\n\nYou now need to tell Slack where your app is so you can receive messages from\nit. Click the \u201cEvent Subscriptions\u201d link in the left nav and fill it out so it\nlooks something like this, specifically:\n\n  * Set your Request URL to that URL that ngrok gave you earlier \n  * Subscribe to the ` message.channels ` event \n\nIf your app is running and ngrok is correctly tunneling, your Request URL\nshould be Verified.\n\nPhew! That was a lot. Your Slack app is now registered and Slack will send it\nmessages. But to get those messages, you have to tell it to join a channel.", "mimetype": "text/plain", "start_char_idx": 3010, "end_char_idx": 4487, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c41dc5bc-188e-4692-a0e3-ccd7bbd1eb1c": {"__data__": {"id_": "c41dc5bc-188e-4692-a0e3-ccd7bbd1eb1c", "embedding": null, "metadata": {"Header_1": " Step 2: Join a channel, and reply to messages", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "492d9d9a-6f6f-431c-9353-d2f033512d05", "node_type": "1", "metadata": {"Header_1": " Register your app with Slack", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "9cf2622b5f456c8a91226d93fa61bb96be8ac592ac4650e78d663088e7161948", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "856c3e64-e67a-48fb-857e-e25f1ea59ed0", "node_type": "1", "metadata": {"Header_1": " Step 3: reply only to messages that mention the bot"}, "hash": "11f8360421a6b64767e1de0b1a1d236d7701aa3344bc5e330efacd49d01a43eb", "class_name": "RelatedNodeInfo"}}, "text": "Step 2: Join a channel, and reply to messages\n\nTo do this we\u2019ll need to extend our app. You can see the final result of this\nstep in ` 2_join_and_reply.py ` . Let's walk through what we've added:\n\n    \n    \n    import dotenv, os\n    dotenv.load_dotenv()\n\nWe need some environment variables, so you\u2019ll need to add these lines and\ninstall ` python-dotenv ` . You'll also need to create a ` .env ` file in the\nroot of your project with three values:\n\n  * ` OPENAI_API_KEY ` : your OpenAI API key. You don't need this quite yet but you may as well [ get it now ](https://platform.openai.com/) . \n  * ` SLACK_BOT_TOKEN ` : you can find this in the \"OAuth and Permissions\" section of your Slack app. \n  * ` SLACK_SIGNING_SECRET ` : you can find this in the \"Basic Information\" section of your Slack app. \n\nWe\u2019re going to use Slack\u2019s handy Python SDK to build our app, so pip install `\nslack-bolt ` and then update all our imports:\n\n    \n    \n    from slack_bolt import App\n    from flask import Flask, request, jsonify\n    from slack_bolt.adapter.flask import SlackRequestHandler\n\nNow initialize a Slack Bolt app using those secrets we set just now:\n\n    \n    \n    app = App(\n        token=os.environ.get(\"SLACK_BOT_TOKEN\"),\n        signing_secret=os.environ.get(\"SLACK_SIGNING_SECRET\")\n    )\n    handler = SlackRequestHandler(app)\n\nTo listen to messages, the bot has to be in a channel. You can get it to join\nany and all public channels, but for the purposes of testing I\u2019ve created a\nchannel called ` #bot-testing ` and that's the one it's joining here:\n\n    \n    \n    channel_list = app.client.conversations_list().data\n    channel = next((channel for channel in channel_list.get('channels') if channel.get(\"name\") == \"bot-testing\"), None)\n    channel_id = channel.get('id')\n    app.client.conversations_join(channel=channel_id)\n\n` app.client ` is the Bolt framework's Slack WebClient, so you can do anything\na WebClient can do directly from within the framework. The final addition here\nis a very simple message listener:\n\n    \n    \n    @app.message()\n    def reply(message, say):\n        print(message)\n        say(\"Yes?\")\n\nIn the Bolt framework, the ` @app.message ` decorator tells the framework to\ntrigger this method when it receives a message event. The ` say ` parameter is\na function that will send a message back to the channel the message came from.\nSo this code will send a message back to the channel saying \"Yes?\" every time\nit receives a message.\n\nLet\u2019s try it out! Stop running ` 1_flask.py ` and run ` python\n2_join_and_reply.py ` instead. You don't need to restart ` ngrok ` , it will\ncontinue to send messages to port 3000 as before. Here's me trying it out:\n\nSuccess! We have a very annoying bot that replies to every single thing\nanybody says. We can do better!", "mimetype": "text/plain", "start_char_idx": 4492, "end_char_idx": 7272, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "856c3e64-e67a-48fb-857e-e25f1ea59ed0": {"__data__": {"id_": "856c3e64-e67a-48fb-857e-e25f1ea59ed0", "embedding": null, "metadata": {"Header_1": " Step 3: reply only to messages that mention the bot", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c41dc5bc-188e-4692-a0e3-ccd7bbd1eb1c", "node_type": "1", "metadata": {"Header_1": " Step 2: Join a channel, and reply to messages", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "2f2d6a204d764fac8069bf47689feadd8f5da25e81b0e9934554c89a845b1e67", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "809a890a-6637-449f-ae3d-c22b7d3cdcd9", "node_type": "1", "metadata": {"Header_1": " Step 4: use LlamaIndex to store facts and answer questions"}, "hash": "75dce5828aebad9d55584dc0198cba6b28a2115486f6aede1b02506f6350bbc3", "class_name": "RelatedNodeInfo"}}, "text": "Step 3: reply only to messages that mention the bot\n\nThis is a pretty simple change on the surface, but Slack\u2019s incoming message\nformat is a little complicated so we have to add a fair bit of code. You can\nsee the final results in ` 3_reply_to_mentions.py ` .\n\nFirst, to tell when our bot is being mentioned, we need our bot\u2019s User ID.\nUnder the hood, Slack doesn\u2019t use user names or even @-handles, but a globally\nunique ID across all Slack installations. We have to get that:\n\n    \n    \n    auth_response = app.client.auth_test()\n    bot_user_id = auth_response[\"user_id\"]\n\nNow we add an annoyingly complicated chunk of code that parses through Slack\u2019s\nmessage object to see what user is mentioned in an incoming message. If it\u2019s\nthe bot, the bot replies, otherwise it just ignores the message. As we go\nfurther, we\u2019ll treat messages to the bot as \u201cqueries\u201d and any other message as\na \u201cfact\u201d for it to store, but we won\u2019t be storing it just yet.\n\n    \n    \n    @app.message()\n    def reply(message, say):\n        if message.get('blocks'):\n            for block in message.get('blocks'):\n                if block.get('type') == 'rich_text':\n                    for rich_text_section in block.get('elements'):\n                        for element in rich_text_section.get('elements'):\n                            if element.get('type') == 'user' and element.get('user_id') == bot_user_id:\n                                for element in rich_text_section.get('elements'):\n                                    if element.get('type') == 'text':\n                                        query = element.get('text')\n                                        print(f\"Somebody asked the bot: {query}\")\n                                        say(\"Yes?\")\n                                        return\n        # otherwise do something else with it\n        print(\"Saw a fact: \", message.get('text'))\n\nOof. That took a while to get right! But now our bot only replies when it\u2019s\nmentioned:", "mimetype": "text/plain", "start_char_idx": 7277, "end_char_idx": 9250, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "809a890a-6637-449f-ae3d-c22b7d3cdcd9": {"__data__": {"id_": "809a890a-6637-449f-ae3d-c22b7d3cdcd9", "embedding": null, "metadata": {"Header_1": " Step 4: use LlamaIndex to store facts and answer questions", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "856c3e64-e67a-48fb-857e-e25f1ea59ed0", "node_type": "1", "metadata": {"Header_1": " Step 3: reply only to messages that mention the bot", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "afb2531622494341c2b365c9b5d16584782dce3b6d5b16fae29f1b8c42df2f96", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "efad1853-7718-4966-b62f-280179eac961", "node_type": "1", "metadata": {"Header_1": " Step 5: use LlamaIndex to store facts and answer questions in Slack"}, "hash": "ef75d8453875f8e13313ee0b172cb9b21165441f5848bb12978e5d48471833a0", "class_name": "RelatedNodeInfo"}}, "text": "Step 4: use LlamaIndex to store facts and answer questions\n\nWe\u2019re all the way at step 4 and we still haven\u2019t done anything with\nLlamaIndex! But now\u2019s the time. In ` 4_incremental_rag.py ` you'll see a\ndemonstration of a simple command-line Python script that uses LlamaIndex to\nstore facts and answer questions. I won't walk you through every line (the\nscript has helpful comments for that), but let's look at the important ones.\nRemember to ` pip install llama-index ` !\n\nFirst we create a new ` VectorStoreIndex ` , an in-memory [ vector store\n](https://docs.llamaindex.ai/en/stable/understanding/indexing/indexing.html#vector-\nstore-index) where we'll be storing our facts. It's empty to start with.\n\n    \n    \n    index = VectorStoreIndex([])\n\nNext we create 3 ` Document ` objects and insert them each into our index.\nReal documents can be huge blocks of text, whole PDFs, even images, but these\nare just some simple, Slack-message-sized facts.\n\n    \n    \n    doc1 = Document(text=\"Molly is a cat\")\n    doc2 = Document(text=\"Doug is a dog\")\n    doc3 = Document(text=\"Carl is a rat\")\n    \n    index.insert(doc1)\n    index.insert(doc2)\n    index.insert(doc3)\n\nAnd finally we create a [ query engine\n](https://docs.llamaindex.ai/en/stable/understanding/querying/querying.html)\nfrom our index and ask it a question:\n\n    \n    \n    # run a query\n    query_engine = index.as_query_engine()\n    response = query_engine.query(\"Who is Molly?\")\n    print(response)\n\nThe result is \u201cMolly is a cat\u201d plus a whole lot of debugging info because we\nturned on noisy debugging in ` 4_incremental_rag.py ` . You can see the prompt\nwe sent to the LLM, the context it retrieved from the index, and the response\nit generated and sent back to us.", "mimetype": "text/plain", "start_char_idx": 9255, "end_char_idx": 10983, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "efad1853-7718-4966-b62f-280179eac961": {"__data__": {"id_": "efad1853-7718-4966-b62f-280179eac961", "embedding": null, "metadata": {"Header_1": " Step 5: use LlamaIndex to store facts and answer questions in Slack", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "809a890a-6637-449f-ae3d-c22b7d3cdcd9", "node_type": "1", "metadata": {"Header_1": " Step 4: use LlamaIndex to store facts and answer questions", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "facdee9746ec44d8c8f69f4f2c98427352b9768aeddb1f3235d6e249d287f42e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1ff22b6-dab2-49af-8a5e-dd8d069e2fd1", "node_type": "1", "metadata": {"Header_1": " Step 6: persist our memory"}, "hash": "c418cb54bd4cdf2df9d4f8050f403302f9331da7d1dac1957d029b7a12f8e19b", "class_name": "RelatedNodeInfo"}}, "text": "Step 5: use LlamaIndex to store facts and answer questions in Slack\n\nIn ` 5_rag_in_slack.py ` we are combining the two things we had before: script\n3, where we reply to queries, and script 4, where we store facts and answer\nquestions. Once again we won't walk through every line, but here are the\nimportant changes:\n\nFirst ` pip install llama-index ` if you didn't already, and bring in your\ndeps. Initialize your index while you're at it:\n\n    \n    \n    from llama_index import VectorStoreIndex, Document\n    \n    index = VectorStoreIndex([])\n\nWhere previously we were just replying with \u201cYes?\u201d (line 73) let\u2019s instead\nsend a query to the query engine and reply with the response:\n\n    \n    \n    query = element.get('text')\n    query_engine = index.as_query_engine()\n    response = query_engine.query(query)\n    say(str(response))\n\nAnd where previously we were just noting that we\u2019d seen a fact (line 82),\nlet\u2019s store it in the index:\n\n    \n    \n    index.insert(Document(text=message.get('text')))\n\nThe result is a Slackbot that can answer questions about what it\u2019s been told:\n\nAmazing! You can easily imagine a bot that listens to everybody\u2019s\nconversations and is able to answer questions about things people said weeks\nor months ago, saving everybody time and effort searching through old\nmessages.", "mimetype": "text/plain", "start_char_idx": 10988, "end_char_idx": 12290, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a1ff22b6-dab2-49af-8a5e-dd8d069e2fd1": {"__data__": {"id_": "a1ff22b6-dab2-49af-8a5e-dd8d069e2fd1", "embedding": null, "metadata": {"Header_1": " Step 6: persist our memory", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "efad1853-7718-4966-b62f-280179eac961", "node_type": "1", "metadata": {"Header_1": " Step 5: use LlamaIndex to store facts and answer questions in Slack", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "7557cc5d497ac98bfe2fea361803d3df5833ec5b337afbdbb5394358bf38afd9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d39cc99b-c065-4854-8d51-dea38aba02c6", "node_type": "1", "metadata": {"Header_1": " Step 7: make recent messages more important"}, "hash": "24f770f5642d1d1537c85ce15ebc886bdba85a904ccf13fd8adbbe74d1bd8a97", "class_name": "RelatedNodeInfo"}}, "text": "Step 6: persist our memory\n\nOur bot has a critical flaw though: the index is stored only in memory. If we\nrestart the bot, it forgets everything:\n\nIn ` 6_qdrant.py ` we bring in [ Qdrant ](https://qdrant.tech/) , an open-\nsource, local vector database that stores these facts on disk instead. That\nway if we restart our bot it remembers what was said before. ` pip install\nqdrant-client ` and bring in some new deps:\n\n    \n    \n    import qdrant_client\n    from llama_index.vector_stores.qdrant import QdrantVectorStore\n\nNow we\u2019ll initialize the Qdrant client, attach it to a storage context, and\ngive that storage context to our index when we initialize it:\n\n    \n    \n    client = qdrant_client.QdrantClient(\n        path=\"./qdrant_data\"\n    )\n    vector_store = QdrantVectorStore(client=client, collection_name=\"slack_messages\")\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n    \n    index = VectorStoreIndex([],storage_context=storage_context)\n\nThat\u2019s it for this step! Your bot now survives reboots, and remembers that I\ntypoed \u201cDoug\u201d as \u201cDough\u201d and was too lazy to fix it for the screenshot:", "mimetype": "text/plain", "start_char_idx": 12295, "end_char_idx": 13424, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d39cc99b-c065-4854-8d51-dea38aba02c6": {"__data__": {"id_": "d39cc99b-c065-4854-8d51-dea38aba02c6", "embedding": null, "metadata": {"Header_1": " Step 7: make recent messages more important", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1ff22b6-dab2-49af-8a5e-dd8d069e2fd1", "node_type": "1", "metadata": {"Header_1": " Step 6: persist our memory", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "01816d9208a4a62591337f9216aed65d3ffb0dbd800103ea1b2850bf97c53f7a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9186321d-033e-4d9b-b59a-acf725b84dde", "node_type": "1", "metadata": {"Header_1": " Step 8: draw the rest of the owl"}, "hash": "dcec58b785e4ccb27573833aacc5d4abee569849ca8e700c859c9467c60cd33b", "class_name": "RelatedNodeInfo"}}, "text": "Step 7: make recent messages more important\n\nWe now have a pretty capable bot! But it has a subtle problem: people can say\nconflicting things, and it doesn\u2019t have a way to decide who was \u201cright\u201d, such\nas when I change my mind about what the dog\u2019s name should be:\n\nIn real Slack conversations, as a situation evolves people might move from\nsaying a project is \u201cin planning\u201d to \u201cunderway\u201d to \u201claunched\u201d. So we need a\nway to tell the bot that more recent messages are more important than older\nones.\n\nTo make this happen we have to do quite a bit of refactoring, the final\nresults of which you can see in ` 7_recency.py ` . First we need a bunch of\nnew deps:\n\n    \n    \n    import datetime, uuid\n    from llama_index.schema import TextNode\n    from llama_index.prompts import PromptTemplate\n    from llama_index.postprocessor import FixedRecencyPostprocessor\n    from llama_index import set_global_handler\n\nTo make recent messages more important, we have to know when a message was\nsent. To do that we are going to stop inserting ` Documents ` into the index\nand instead insert ` Nodes ` , to which we're going to attach the timestamp as\nmetadata (under the hood, our Documents were always being converted into Nodes\nanyway so this doesn't change much):\n\n    \n    \n    dt_object = datetime.datetime.fromtimestamp(float(message.get('ts')))\n    formatted_time = dt_object.strftime('%Y-%m-%d %H:%M:%S')\n    \n    # get the message text\n    text = message.get('text')\n    # create a node with metadata\n    node = TextNode(\n        text=text,\n        id_=str(uuid.uuid4()),\n        metadata={\n            \"when\": formatted_time\n        }\n    )\n    index.insert_nodes([node])\n\nI\u2019ve also factored out the reply logic from message handling into its own\nfunction, ` answer_question ` , just to make things a little easier to read.\nThe first thing we're going to change is the prompt that we give to our LLM:\nwe have to tell it that more recent messages are important. To do this we\ncreate a prompt template:\n\n    \n    \n    template = (\n        \"Your context is a series of chat messages. Each one is tagged with 'who:' \\n\"\n        \"indicating who was speaking and 'when:' indicating when they said it, \\n\"\n        \"followed by a line break and then what they said. There can be up to 20 chat messages.\\n\"\n        \"The messages are sorted by recency, so the most recent one is first in the list.\\n\"\n        \"The most recent messages should take precedence over older ones.\\n\"\n        \"---------------------\\n\"\n        \"{context_str}\"\n        \"\\n---------------------\\n\"\n        \"You are a helpful AI assistant who has been listening to everything everyone has been saying. \\n\"\n        \"Given the most relevant chat messages above, please answer this question: {query_str}\\n\"\n    )\n    qa_template = PromptTemplate(template)\n\nThe fun thing about working with LLMs is how often you end up just describing\nwhat you\u2019re doing in English and that being what you send to the LLM. A prompt\ntemplate will automatically get the ` context_str ` and ` query_str ` from the\nquery engine. But we have to set this template on our query engine, like so:\n\n    \n    \n    query_engine.update_prompts(\n        {\"response_synthesizer:text_qa_template\": qa_template}\n    )\n\nNow there\u2019s two more things we\u2019re going to change. We\u2019re going to take the\nresults we get from the vector store and sort them by recency, something\nLlamaIndex has a built-in class for. It\u2019s called the `\nFixedRecencyPostprocessor ` . We tell it the key that holds the timestamp\n(which we defined earlier on the nodes, above) and how many results it should\nreturn:\n\n    \n    \n    postprocessor = FixedRecencyPostprocessor(\n        top_k=20, \n        date_key=\"when\", # the key in the metadata to find the date\n        service_context=ServiceContext.from_defaults()\n    )\n\nThen we need to create our query engine with the postprocessor attached:\n\n    \n    \n    query_engine = index.as_query_engine(similarity_top_k=20, node_postprocessors=[postprocessor])\n\nWhile we were at it we did our final thing, which was pass `\nsimilarity_top_k=20 ` , which means the vector store will give us 20 Slack\nmessages as context (the default is just 2, because usually the chunks of text\nin a Node are a lot bigger).\n\nTada! Now the bot knows to take more recent statements as the truth.", "mimetype": "text/plain", "start_char_idx": 13429, "end_char_idx": 17734, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9186321d-033e-4d9b-b59a-acf725b84dde": {"__data__": {"id_": "9186321d-033e-4d9b-b59a-acf725b84dde", "embedding": null, "metadata": {"Header_1": " Step 8: draw the rest of the owl", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d39cc99b-c065-4854-8d51-dea38aba02c6", "node_type": "1", "metadata": {"Header_1": " Step 7: make recent messages more important", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "170005cd08c3e12b03fe13b5bb8127108173deeb2dc88e6d8bf7f094abe13768", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9da37590-253d-4084-bbe4-e3f1170e4f17", "node_type": "1", "metadata": {"Header_1": " Step 9: deploy to Render"}, "hash": "aa4baf9415441934a95c9a95f3ffb970a10238ba55b1c1346963278a98ac12e7", "class_name": "RelatedNodeInfo"}}, "text": "Step 8: draw the rest of the owl\n\nThis bot is working pretty well now, but I was having such fun when building\nit I got carried away and added two more features:\n\n  * I attached metadata about _who_ was speaking, not just when, so the bot can answer questions like \u201cWhat did Logan say about the project?\u201d \n  * My colleagues interacting with the bot tried to ask follow-up questions in a thread, like we do with each other. So I added a way for the bot to understand that it\u2019s in a thread, and treat replies in a thread as follow-up questions, even if the user doesn\u2019t mention the bot directly: \n\nThe code to make both of those happen is in ` 8_rest_of_the_owl.py ` but I'm\nnot going to be stepping through it line by line. We have to deploy this\nthing!", "mimetype": "text/plain", "start_char_idx": 17739, "end_char_idx": 18491, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9da37590-253d-4084-bbe4-e3f1170e4f17": {"__data__": {"id_": "9da37590-253d-4084-bbe4-e3f1170e4f17", "embedding": null, "metadata": {"Header_1": " Step 9: deploy to Render", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9186321d-033e-4d9b-b59a-acf725b84dde", "node_type": "1", "metadata": {"Header_1": " Step 8: draw the rest of the owl", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "057510b993ecc622889d1721749892e611f4cbda1fe4bf6f07abc2b9f0dc9ee3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec044d3a-84f1-4821-a299-a33c3f4c07dd", "node_type": "1", "metadata": {"Header_1": " Login to Render"}, "hash": "b017b94596f2f409cd224f66b5f6829aa272577581eb9cc57d38404fc6749d20", "class_name": "RelatedNodeInfo"}}, "text": "Step 9: deploy to Render\n\nUntil now we\u2019ve been working with local scripts running through the ngrok\ntunnel, but even the most dedicated coder turns their laptop off sometimes.\nLet\u2019s put this thing on a real server.", "mimetype": "text/plain", "start_char_idx": 18496, "end_char_idx": 18710, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ec044d3a-84f1-4821-a299-a33c3f4c07dd": {"__data__": {"id_": "ec044d3a-84f1-4821-a299-a33c3f4c07dd", "embedding": null, "metadata": {"Header_1": " Login to Render", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9da37590-253d-4084-bbe4-e3f1170e4f17", "node_type": "1", "metadata": {"Header_1": " Step 9: deploy to Render", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "e37c5a5a7bb4ee30a6f85c80df163284895d814247e2fd47c0f3cf3ee5dff691", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3af46519-0819-4df6-8dfc-51042f0e836b", "node_type": "1", "metadata": {"Header_1": " Create a new GitHub repository"}, "hash": "9a18a46da506617463379653ca2ea63ca5c41079cfb87675029554d9567c153e", "class_name": "RelatedNodeInfo"}}, "text": "Login to Render\n\nWe\u2019ll be deploying to [ Render ](https://render.com/) , a Python-friendly\nhosting service that\u2019s free for small projects. Sign up for an account (I\nrecommend logging in with GitHub).", "mimetype": "text/plain", "start_char_idx": 18715, "end_char_idx": 18914, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3af46519-0819-4df6-8dfc-51042f0e836b": {"__data__": {"id_": "3af46519-0819-4df6-8dfc-51042f0e836b", "embedding": null, "metadata": {"Header_1": " Create a new GitHub repository", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec044d3a-84f1-4821-a299-a33c3f4c07dd", "node_type": "1", "metadata": {"Header_1": " Login to Render", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "87739384577ee02583fc12a6a211eb85646e77d0d4a61378f3a41a4765a4daaf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "728cd613-2fcd-4fbd-a8ef-726e812d4978", "node_type": "1", "metadata": {"Header_1": " Create a new Render web service"}, "hash": "26341aef89b715e536cb16751b03d0c39e51750a6b0ecc7a370332f36293be90", "class_name": "RelatedNodeInfo"}}, "text": "Create a new GitHub repository\n\nRender deploys things from GitHub repositories, so you\u2019ll need to create a new\none and copy 2 files from our existing repo into it:\n\n  * ` pyproject.toml `\n  * ` 8_rest_of_the_owl.py ` which we're going to rename to \"app.py\" for simplicity. \n\nCommit those and push them up to GitHub.", "mimetype": "text/plain", "start_char_idx": 18919, "end_char_idx": 19234, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "728cd613-2fcd-4fbd-a8ef-726e812d4978": {"__data__": {"id_": "728cd613-2fcd-4fbd-a8ef-726e812d4978", "embedding": null, "metadata": {"Header_1": " Create a new Render web service", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3af46519-0819-4df6-8dfc-51042f0e836b", "node_type": "1", "metadata": {"Header_1": " Create a new GitHub repository", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "98fd67d6fc2e82f234fe41d485c49311af2968dbc977a9736210b59fb71baa83", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0159d716-0f9a-4e72-a62b-53590b573b5d", "node_type": "1", "metadata": {"Header_1": " What next?"}, "hash": "7f579893fc284e74e9c6a2120696b1e36f090b632d0c52faae1b13e378ff0f4e", "class_name": "RelatedNodeInfo"}}, "text": "Create a new Render web service\n\nIn Render, create a new web service. Connect it to the repo on GitHub you just\ncreated:\n\nRender will probably automatically detect that this is a Python app but you\nshould make sure the following settings are correct:\n\n  * Name: any name you choose \n  * Region: any region is fine \n  * Branch: main \n  * Root directory: (blank, meaning root) \n  * Runtime: Python 3 \n  * Build command: ` poetry install `\n  * Start command: ` gunicorn app:flask_app ` (this will definitely need to be set) \n\nYou\u2019ll also need to scroll down and set some environment variables:\n\n  * PYTHON_VERSION: 3.11.6 (or whatever version you\u2019re using) \n  * OPENAI_API_KEY: your OpenAI API key \n  * SLACK_BOT_TOKEN: your Slack bot token \n  * SLACK_SIGNING_SECRET: your Slack signing secret from before \n\nThen click deploy and away you go!\n\nYou now have a production Slack bot listening to messages, remembering,\nlearning, and replying. Congratulations!", "mimetype": "text/plain", "start_char_idx": 19239, "end_char_idx": 20192, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0159d716-0f9a-4e72-a62b-53590b573b5d": {"__data__": {"id_": "0159d716-0f9a-4e72-a62b-53590b573b5d", "embedding": null, "metadata": {"Header_1": " What next?", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf", "node_type": "4", "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "bc23faa80294e842959fd6eba4822a0e3594aa3a7660dd15a40f9cee9af7da80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "728cd613-2fcd-4fbd-a8ef-726e812d4978", "node_type": "1", "metadata": {"Header_1": " Create a new Render web service", "filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}, "hash": "e582a713707a9e6d48953a3fe935a8d62c8fd6cef8b97f25079f26afa4a140cf", "class_name": "RelatedNodeInfo"}}, "text": "What next?\n\nThere\u2019s a whole bunch of features you could add to this bot, roughly in\nincreasing order of difficulty:\n\n  * Join every channel instead of just one, clearly! \n  * Add a way to tell the bot to forget things (delete nodes) \n  * Give the bot the ability to use more than one index, such as an index of your documentation, or connected to your email, or your calendar \n  * Give the bot \u201ctags\u201d so it can attach metadata to nodes and answer questions only with (or ignore) things that have been tagged a certain way \n  * Add multi-modal abilities, so the bot can read images and even reply with generated images \n  * And tons more! \n\nThis bot is a lot of fun to play with and was a lot of fun to build, I hope\nyou enjoyed learning about Slackbots and LlamaIndex as much as I enjoyed\nwriting this tutorial!", "mimetype": "text/plain", "start_char_idx": 20197, "end_char_idx": 21008, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"7773eeca-52f9-43f8-a9b2-4fa3cb22ed51": {"doc_hash": "9cb48263960caebb2b7422ac8062f5eef0be745b776c583a3c4055d8552bc16e", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "b7687ebb-f166-4f6d-94db-41b08ce346b6": {"doc_hash": "a2c18bcf2a194c323ea3a43937f28b07718b54f088125ac0f20e3b3600a3be3a", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "94d0e078-462c-4885-bcd9-3588c6cd535a": {"doc_hash": "307e2cabb1d45f538bdc3a8bb32beb12b6ff1bdd4ce97029356193d0f251cf0b", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "2e92c0dd-051e-4cb1-8cfd-3a5d4deb93bd": {"doc_hash": "59868b40f972ac237d3925abfde2a455885b64318e0f4558d603a20517533f88", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "492d9d9a-6f6f-431c-9353-d2f033512d05": {"doc_hash": "9cf2622b5f456c8a91226d93fa61bb96be8ac592ac4650e78d663088e7161948", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "c41dc5bc-188e-4692-a0e3-ccd7bbd1eb1c": {"doc_hash": "2f2d6a204d764fac8069bf47689feadd8f5da25e81b0e9934554c89a845b1e67", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "856c3e64-e67a-48fb-857e-e25f1ea59ed0": {"doc_hash": "afb2531622494341c2b365c9b5d16584782dce3b6d5b16fae29f1b8c42df2f96", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "809a890a-6637-449f-ae3d-c22b7d3cdcd9": {"doc_hash": "facdee9746ec44d8c8f69f4f2c98427352b9768aeddb1f3235d6e249d287f42e", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "efad1853-7718-4966-b62f-280179eac961": {"doc_hash": "7557cc5d497ac98bfe2fea361803d3df5833ec5b337afbdbb5394358bf38afd9", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "a1ff22b6-dab2-49af-8a5e-dd8d069e2fd1": {"doc_hash": "01816d9208a4a62591337f9216aed65d3ffb0dbd800103ea1b2850bf97c53f7a", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "d39cc99b-c065-4854-8d51-dea38aba02c6": {"doc_hash": "170005cd08c3e12b03fe13b5bb8127108173deeb2dc88e6d8bf7f094abe13768", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "9186321d-033e-4d9b-b59a-acf725b84dde": {"doc_hash": "057510b993ecc622889d1721749892e611f4cbda1fe4bf6f07abc2b9f0dc9ee3", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "9da37590-253d-4084-bbe4-e3f1170e4f17": {"doc_hash": "e37c5a5a7bb4ee30a6f85c80df163284895d814247e2fd47c0f3cf3ee5dff691", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "ec044d3a-84f1-4821-a299-a33c3f4c07dd": {"doc_hash": "87739384577ee02583fc12a6a211eb85646e77d0d4a61378f3a41a4765a4daaf", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "3af46519-0819-4df6-8dfc-51042f0e836b": {"doc_hash": "98fd67d6fc2e82f234fe41d485c49311af2968dbc977a9736210b59fb71baa83", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "728cd613-2fcd-4fbd-a8ef-726e812d4978": {"doc_hash": "e582a713707a9e6d48953a3fe935a8d62c8fd6cef8b97f25079f26afa4a140cf", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}, "0159d716-0f9a-4e72-a62b-53590b573b5d": {"doc_hash": "a250ef30291bc1a79852627b04bfec93f5f574b0ba154c56107b7033137ae399", "ref_doc_id": "f1395dcf-8e75-4b7c-b7cb-598736a941cf"}}, "docstore/ref_doc_info": {"f1395dcf-8e75-4b7c-b7cb-598736a941cf": {"node_ids": ["7773eeca-52f9-43f8-a9b2-4fa3cb22ed51", "b7687ebb-f166-4f6d-94db-41b08ce346b6", "94d0e078-462c-4885-bcd9-3588c6cd535a", "2e92c0dd-051e-4cb1-8cfd-3a5d4deb93bd", "492d9d9a-6f6f-431c-9353-d2f033512d05", "c41dc5bc-188e-4692-a0e3-ccd7bbd1eb1c", "856c3e64-e67a-48fb-857e-e25f1ea59ed0", "809a890a-6637-449f-ae3d-c22b7d3cdcd9", "efad1853-7718-4966-b62f-280179eac961", "a1ff22b6-dab2-49af-8a5e-dd8d069e2fd1", "d39cc99b-c065-4854-8d51-dea38aba02c6", "9186321d-033e-4d9b-b59a-acf725b84dde", "9da37590-253d-4084-bbe4-e3f1170e4f17", "ec044d3a-84f1-4821-a299-a33c3f4c07dd", "3af46519-0819-4df6-8dfc-51042f0e836b", "728cd613-2fcd-4fbd-a8ef-726e812d4978", "0159d716-0f9a-4e72-a62b-53590b573b5d"], "metadata": {"filename": "building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840.md", "extension": ".md", "title": "Building a Slack bot that learns with LlamaIndex, Qdrant and Render", "date": "Jan 25, 2024", "url": "https://www.llamaindex.ai/blog/building-a-slack-bot-that-learns-with-llamaindex-qdrant-and-render-c88d4aa72840"}}}}