{"docstore/data": {"bac3c6fc-45f5-41c6-904d-4c34fa39ed73": {"__data__": {"id_": "bac3c6fc-45f5-41c6-904d-4c34fa39ed73", "embedding": null, "metadata": {"Header_1": " **Introduction**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6191b731-0837-4bb2-ae92-f7ea19fd9b5c", "node_type": "1", "metadata": {"Header_1": " **1\\. Question Generation**"}, "hash": "44cb277a004cd4a95187daabed4eb55b952efab7b231a9d069f12426fa57cb8f", "class_name": "RelatedNodeInfo"}}, "text": "**Introduction**\n\n[ LlamaIndex (GPT Index) ](https://github.com/jerryjliu/llama_index) offers an\ninterface to connect your Large Language Models (LLMs) with external data.\nLlamaIndex provides various data structures to index your data, such as the\nlist index, vector index, keyword index, and tree index. It offers both a\nhigh-level API and low-level API \u2014 the high-level API allows you to build a\nQuestion-Answering (QA) system in just five lines of code, whereas the lower-\nlevel API allows you to customize various aspects of retrieval and synthesis.\n\nHowever, taking these systems into production requires careful evaluation of\nthe performance of the overall system \u2014 the quality of the outputs given the\ninputs. Evaluation of retrieval-augmented generation can be challenging\nbecause the user would need to come up with a dataset of relevant questions\nfor a given context. To overcome these obstacles, LlamaIndex provides Question\nGeneration and label-free Evaluation modules.\n\nIn this blog, we will discuss the three-step evaluation process using Question\nGeneration and Evaluation modules:\n\n  1. Question Generation from the document \n  2. Generate answers/source nodes for questions using LlamaIndex QueryEngine abstractions, which manage the interaction between the LLM and data indices. \n  3. Evaluate if the question (query), answer, and source nodes are matching/inline", "mimetype": "text/plain", "start_char_idx": 3, "end_char_idx": 1384, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6191b731-0837-4bb2-ae92-f7ea19fd9b5c": {"__data__": {"id_": "6191b731-0837-4bb2-ae92-f7ea19fd9b5c", "embedding": null, "metadata": {"Header_1": " **1\\. Question Generation**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bac3c6fc-45f5-41c6-904d-4c34fa39ed73", "node_type": "1", "metadata": {"Header_1": " **Introduction**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "2c1353ace424810ac7e6c0d12582c90d05837b44489951de6d2e34fc95dbb7ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7fa675bc-49b9-4371-9c17-a2dd4a66b67a", "node_type": "1", "metadata": {"Header_1": " **2\\. Generate Answers/Source Nodes (Context)**"}, "hash": "668c905f826ea450e0882a06e3bf3d14b59071ec32c6816683eb2f70db3b78da", "class_name": "RelatedNodeInfo"}}, "text": "**1\\. Question Generation**\n\nIt should be noted that this approach does not require ground-truth labels.\nThe purpose of question generation is to generate an initial dataset of inputs\nover context that can be used to evaluate the question-answering system.\n\nLlamaIndex offers the DataGenerator class, which generates questions from a\ngiven document using ListIndex. By default, it uses OpenAI ChatGPT\n(get-3.5-turbo) for question generation.\n\n    \n    \n    from llama_index.evaluation import DatasetGenerator\n    from llama_index import SimpleDirectoryReader\n    \n    # Load documents\n    reader = SimpleDirectoryReader(\"./data\")\n    documents = reader.load_data()\n    \n    # Generate Question\n    data_generator = DatasetGenerator.from_documents(documents)\n    question = data_generator.generate_questions_from_nodes()", "mimetype": "text/plain", "start_char_idx": 1390, "end_char_idx": 2209, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7fa675bc-49b9-4371-9c17-a2dd4a66b67a": {"__data__": {"id_": "7fa675bc-49b9-4371-9c17-a2dd4a66b67a", "embedding": null, "metadata": {"Header_1": " **2\\. Generate Answers/Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6191b731-0837-4bb2-ae92-f7ea19fd9b5c", "node_type": "1", "metadata": {"Header_1": " **1\\. Question Generation**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "d0e668041a832fcd94af8f9ab6e06865f5cf6955c681481fdc478c23d5a28fdd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bdf12505-7ee8-4f7f-947a-ec00690f7819", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**"}, "hash": "2de59ac853415d9b1f8c21994271f2cb0c10fffd43c805a6c39ea3c1078507e9", "class_name": "RelatedNodeInfo"}}, "text": "**2\\. Generate Answers/Source Nodes (Context)**\n\nUsing List Index, we generate answers and source nodes for the generated\nquestions in the response object.\n\n    \n    \n    from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, load_index_from_storage, StorageContext\n    \n    # load documents\n    documents = SimpleDirectoryReader('./data').load_data()\n    \n    # Create Index\n    index = GPTVectorStoreIndex.from_documents(documents)\n    \n    # save index to disk\n    index.set_index_id(\"vector_index\")\n    index.storage_context.persist('storage')\n    \n    # rebuild storage context\n    storage_context = StorageContext.from_defaults(persist_dir='storage')\n    # load index\n    index = load_index_from_storage(storage_context, index_id=\"vector_index\")\n    \n    # Query the index\n    query_engine = index.as_query_engine(similarity_top_k=3)\n    response = query_engine.query(&lt;Query&gt;)\n    \n    # Response object has both response and source nodes.", "mimetype": "text/plain", "start_char_idx": 2214, "end_char_idx": 3178, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bdf12505-7ee8-4f7f-947a-ec00690f7819": {"__data__": {"id_": "bdf12505-7ee8-4f7f-947a-ec00690f7819", "embedding": null, "metadata": {"Header_1": " **3\\. Evaluation**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7fa675bc-49b9-4371-9c17-a2dd4a66b67a", "node_type": "1", "metadata": {"Header_1": " **2\\. Generate Answers/Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "c4e8df496d14a5f497381b09a5e2415b4adea5ecc6dbd0e9ae03462308b9f930", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3b48ef63-ce6b-4cdb-874c-b5885610a3a4", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Response + Source Nodes (Context)**"}, "hash": "9a45ed8150010b34f98ac4d794027a1245b6d51bd70bf267a251e80e6baf98cf", "class_name": "RelatedNodeInfo"}}, "text": "**3\\. Evaluation**\n\nThe evaluation module can be used to answer the following three questions:\n\n  1. Are the response generated and source nodes (context) matching? \u2014 Response + Source Nodes (Context) \n  2. Are response generated, source nodes (context), and query matching? \u2014 Query + Response + Source Nodes (Context) \n  3. Which source nodes of the retrieved source nodes are used to generate a response? \u2014 Query + Response + Individual Source Nodes (Context) \n\nEvaluation can be done with some combination of the query, context, and\nresponse, combining these with LLM calls.", "mimetype": "text/plain", "start_char_idx": 3183, "end_char_idx": 3760, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3b48ef63-ce6b-4cdb-874c-b5885610a3a4": {"__data__": {"id_": "3b48ef63-ce6b-4cdb-874c-b5885610a3a4", "embedding": null, "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Response + Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bdf12505-7ee8-4f7f-947a-ec00690f7819", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "2957d0f45d224086489f6442e38683c08b3645bb364615c1cc92d296c08f60ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a7e0616e-c67e-4e65-82b2-e5c2b816c0a2", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Query + Response + Source Nodes (Context)**"}, "hash": "bb90c86d1c0c3503b2f5508d3fb7f80b3cc39812bd55736455bd5a79bfbb3cff", "class_name": "RelatedNodeInfo"}}, "text": "**Response + Source Nodes (Context)**\n\nThis function answers the question: Are the response generated and source\nnodes (context) matching?\n\nThe response object for a given query returns both the response and source\nnodes (context) with which it generated the response. We can now evaluate the\nresponse against the retrieved sources \u2014 without taking into account the\nquery! This allows you to measure hallucination \u2014 if the response does not\nmatch the retrieved sources, this means that the model may be \u201challucinating\u201d\nan answer since it is not rooting the answer in the context provided to it in\nthe prompt.\n\nThe result is a binary response \u2014 either \u201cYES/NO\u201d.\n\n  * YES \u2014 Response and Source Nodes (Context) are matching. \n  * NO \u2014 Response and Source Nodes (Context) are not matching. \n\n    \n    \n    from llama_index.evaluation import ResponseEvaluator\n    \n    # build service context\n    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))\n    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n    \n    # Build index and get response object\n    ...\n    \n    # define evaluator\n    evaluator = ResponseEvaluator(service_context=service_context)\n    \n    # evaluate using the response object\n    eval_result = evaluator.evaluate(response)", "mimetype": "text/plain", "start_char_idx": 3766, "end_char_idx": 5060, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a7e0616e-c67e-4e65-82b2-e5c2b816c0a2": {"__data__": {"id_": "a7e0616e-c67e-4e65-82b2-e5c2b816c0a2", "embedding": null, "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Query + Response + Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3b48ef63-ce6b-4cdb-874c-b5885610a3a4", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Response + Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "b7e80aa8cf1945d2a9f194a50d5d4048bf35370a826909175a18a81332b65218", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1a911b7-0baf-4a95-ae3a-65942bdc1707", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Query + Response + Individual Source Nodes (Context)**"}, "hash": "8d2446880645109f3364bdd1abe1c47df00edd450798de175a6129fe7c1f48f0", "class_name": "RelatedNodeInfo"}}, "text": "**Query + Response + Source Nodes (Context)**\n\nThis function answers the question: Are response generated, source nodes\n(context), and query matching?\n\nOften with the \u201cResponse + Source Nodes (Context)\u201d approach, the response\ngenerated is in line with the source nodes but may not be the answer to the\nquery. Therefore, considering the query along with the response and source\nnodes is a good approach for a more accurate analysis.\n\nThe goal is to determine if the response + source context answers the query.\nThe result is a binary response \u2014 either \u201cYES/NO\u201d.\n\n  * YES \u2014 Query, Response, and Source Nodes (Context) are matching. \n  * NO \u2014 Query, Response, and Source Nodes (Context) are not matching. \n\n    \n    \n    from llama_index.evaluation import QueryResponseEvaluator\n    \n    # build service context\n    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))\n    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n    \n    # Build index and get response object\n    ...\n    \n    # define evaluator\n    evaluator = QueryResponseEvaluator(service_context=service_context)\n    \n    # evaluate using the response object\n    eval_result = evaluator.evaluate(query, response)", "mimetype": "text/plain", "start_char_idx": 5066, "end_char_idx": 6293, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a1a911b7-0baf-4a95-ae3a-65942bdc1707": {"__data__": {"id_": "a1a911b7-0baf-4a95-ae3a-65942bdc1707", "embedding": null, "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Query + Response + Individual Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a7e0616e-c67e-4e65-82b2-e5c2b816c0a2", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Query + Response + Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "648613959a983c44f27a75dbeb3b9b3f2898e066e01e4d7457a2fa8409ea22f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fbd07613-60ea-410f-ba06-922a9de90a54", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": "[ Google Colaboratory  Evaluating QA systems using LlamaIndex"}, "hash": "12173e294be1c1c448bfe5d49db50bdf6b9b5acb451cac2a4cf6a904be4b0645", "class_name": "RelatedNodeInfo"}}, "text": "**Query + Response + Individual Source Nodes (Context)**\n\nThis function answers the question: Which source nodes of the retrieved source\nnodes are used to generate a response?\n\nOften in the real world, the source nodes can be nodes from different\ndocuments. In these cases, it\u2019s important to understand which source nodes are\nrelevant and show those documents to the users. This mode of evaluation will\nlook at each source node and see if each source node contains an answer to the\nquery.\n\n    \n    \n    from llama_index.evaluation import QueryResponseEvaluator\n    \n    # build service context\n    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))\n    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n    \n    # build index and get response object \n    ...\n    \n    # define evaluator\n    evaluator = QueryResponseEvaluator(service_context=service_context)\n    \n    # evaluate using the response object\n    eval_result = evaluator.evaluate_source_nodes(response)\n\nGoogle Colab notebook for Evaluating QA systems using LlamaIndex \u2014", "mimetype": "text/plain", "start_char_idx": 6299, "end_char_idx": 7387, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fbd07613-60ea-410f-ba06-922a9de90a54": {"__data__": {"id_": "fbd07613-60ea-410f-ba06-922a9de90a54", "embedding": null, "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": "[ Google Colaboratory  Evaluating QA systems using LlamaIndex", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1a911b7-0baf-4a95-ae3a-65942bdc1707", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": " **Query + Response + Individual Source Nodes (Context)**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "ab11081a9eab2561734d53930b2e0c1684c3a6e1a55a23ba2a0b00a92c465290", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ffa342f-9497-49f1-a8c9-36dbed7ff9f3", "node_type": "1", "metadata": {"Header_1": " **Conclusion**"}, "hash": "2a4d56f36e784755b95041e60b66a0d7085e8035818895f392132185c1163e0a", "class_name": "RelatedNodeInfo"}}, "text": "[ Google Colaboratory  Evaluating QA systems using LlamaIndex\n](https://colab.research.google.com/drive/1J7ZaTx746T9Xaglr-9PhdB5knnHs25ws?usp=sharing&source=post_page\n-----3f02e9d87ce1--------------------------------)", "mimetype": "text/plain", "start_char_idx": 7392, "end_char_idx": 7609, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6ffa342f-9497-49f1-a8c9-36dbed7ff9f3": {"__data__": {"id_": "6ffa342f-9497-49f1-a8c9-36dbed7ff9f3", "embedding": null, "metadata": {"Header_1": " **Conclusion**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb", "node_type": "4", "metadata": {"filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "a29d03441466ea20013e11aeec73c50e734a7f8c3b9eea3061b778ada215ba31", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbd07613-60ea-410f-ba06-922a9de90a54", "node_type": "1", "metadata": {"Header_1": " **3\\. Evaluation**", "Header_2": "[ Google Colaboratory  Evaluating QA systems using LlamaIndex", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}, "hash": "64d0e756a2205edcc3c018916e515c43796942988a12f1dc10e872318125f6bf", "class_name": "RelatedNodeInfo"}}, "text": "**Conclusion**\n\nLlamaIndex provides a comprehensive solution for building and evaluating QA\nsystems without the need for ground-truth labels. By using the Question\nGeneration and Evaluation modules, you can ensure that your system is accurate\nand reliable, making it suitable for production environments.", "mimetype": "text/plain", "start_char_idx": 7614, "end_char_idx": 7918, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"bac3c6fc-45f5-41c6-904d-4c34fa39ed73": {"doc_hash": "2c1353ace424810ac7e6c0d12582c90d05837b44489951de6d2e34fc95dbb7ee", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "6191b731-0837-4bb2-ae92-f7ea19fd9b5c": {"doc_hash": "d0e668041a832fcd94af8f9ab6e06865f5cf6955c681481fdc478c23d5a28fdd", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "7fa675bc-49b9-4371-9c17-a2dd4a66b67a": {"doc_hash": "c4e8df496d14a5f497381b09a5e2415b4adea5ecc6dbd0e9ae03462308b9f930", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "bdf12505-7ee8-4f7f-947a-ec00690f7819": {"doc_hash": "2957d0f45d224086489f6442e38683c08b3645bb364615c1cc92d296c08f60ab", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "3b48ef63-ce6b-4cdb-874c-b5885610a3a4": {"doc_hash": "b7e80aa8cf1945d2a9f194a50d5d4048bf35370a826909175a18a81332b65218", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "a7e0616e-c67e-4e65-82b2-e5c2b816c0a2": {"doc_hash": "648613959a983c44f27a75dbeb3b9b3f2898e066e01e4d7457a2fa8409ea22f9", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "a1a911b7-0baf-4a95-ae3a-65942bdc1707": {"doc_hash": "ab11081a9eab2561734d53930b2e0c1684c3a6e1a55a23ba2a0b00a92c465290", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "fbd07613-60ea-410f-ba06-922a9de90a54": {"doc_hash": "64d0e756a2205edcc3c018916e515c43796942988a12f1dc10e872318125f6bf", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}, "6ffa342f-9497-49f1-a8c9-36dbed7ff9f3": {"doc_hash": "405224a1473c95bcd6123d0b55f41451f63c15f4ff6bcfd95795e1984165d077", "ref_doc_id": "8e86a5a2-1b61-4b2f-b407-f2bda77429eb"}}, "docstore/ref_doc_info": {"8e86a5a2-1b61-4b2f-b407-f2bda77429eb": {"node_ids": ["bac3c6fc-45f5-41c6-904d-4c34fa39ed73", "6191b731-0837-4bb2-ae92-f7ea19fd9b5c", "7fa675bc-49b9-4371-9c17-a2dd4a66b67a", "bdf12505-7ee8-4f7f-947a-ec00690f7819", "3b48ef63-ce6b-4cdb-874c-b5885610a3a4", "a7e0616e-c67e-4e65-82b2-e5c2b816c0a2", "a1a911b7-0baf-4a95-ae3a-65942bdc1707", "fbd07613-60ea-410f-ba06-922a9de90a54", "6ffa342f-9497-49f1-a8c9-36dbed7ff9f3"], "metadata": {"Header_1": " **Introduction**", "filename": "building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1.md", "extension": ".md", "title": "Building and Evaluating a QA System with LlamaIndex", "date": "May 7, 2023", "url": "https://www.llamaindex.ai/blog/building-and-evaluating-a-qa-system-with-llamaindex-3f02e9d87ce1"}}}}