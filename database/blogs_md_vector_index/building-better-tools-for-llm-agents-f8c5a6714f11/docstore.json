{"docstore/data": {"a3aa3d77-98cc-4079-9aa0-278da375a818": {"__data__": {"id_": "a3aa3d77-98cc-4079-9aa0-278da375a818", "embedding": null, "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0996ec55-7678-4a9f-9e8e-0daabf5607d0", "node_type": "1", "metadata": {"Header_1": " Context on LlamaHub Tools"}, "hash": "e90b6add7a75ba2d6aad8b94dee1b0f596b72bd3bd778579ae36089e159c06fc", "class_name": "RelatedNodeInfo"}}, "text": "Over the past month I\u2019ve been diving into the world of Large Language Model\n(LLM) Agents and building out LlamaIndex\u2019s library of tools for use with\nagents. I helped to lead the LlamaHub Tools effort as part of broader [ Data\nAgents launch ](https://medium.com/llamaindex-blog/data-agents-eed797d7972f)\nlast week.\n\nIn the process of building out LlamaHub Tools I\u2019ve collected some techniques\nfor creating effective and easy to use tools, and want to share some of my\nthoughts.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 476, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0996ec55-7678-4a9f-9e8e-0daabf5607d0": {"__data__": {"id_": "0996ec55-7678-4a9f-9e8e-0daabf5607d0", "embedding": null, "metadata": {"Header_1": " Context on LlamaHub Tools", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3aa3d77-98cc-4079-9aa0-278da375a818", "node_type": "1", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "5e0e23d5cace4a48235f2579a16aa8426aaed9af0af3d1fff99ae04c30d1f6f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6770c30c-b43b-4df8-aaa8-8c2f50f7b1f0", "node_type": "1", "metadata": {"Header_1": " Context on LlamaHub Tools", "Header_2": " Overview of tool abstractions"}, "hash": "f9701bc345b2b2f7e31b0a9eefbe8dfe64d0d0f55a4e9eef349e144d6afa3607", "class_name": "RelatedNodeInfo"}}, "text": "Context on LlamaHub Tools\n\n[ LlamaHub Tools ](https://llamahub.ai/) allow LLMs like ChatGPT to connect to\nAPIs and act on a user\u2019s behalf to create, read, update and delete data.\nExamples of tools that we\u2019ve put together include [ drafting and sending\nemails ](https://llamahub.ai/l/tools-gmail) , [ reading and creating Google\nCalendar invite ](https://llamahub.ai/l/tools-google_calendar) s, [ searching\nWikipedia ](https://llamahub.ai/l/tools-wikipedia) , and that\u2019s just a few of\nthe 15 tools we are releasing on launch.", "mimetype": "text/plain", "start_char_idx": 481, "end_char_idx": 1005, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6770c30c-b43b-4df8-aaa8-8c2f50f7b1f0": {"__data__": {"id_": "6770c30c-b43b-4df8-aaa8-8c2f50f7b1f0", "embedding": null, "metadata": {"Header_1": " Context on LlamaHub Tools", "Header_2": " Overview of tool abstractions", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0996ec55-7678-4a9f-9e8e-0daabf5607d0", "node_type": "1", "metadata": {"Header_1": " Context on LlamaHub Tools", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "fa4f2d913b9b83048a6a39edc40a3acd8091dfa20fd1f4f4412a3222d54cbe92", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d6aa1899-08f9-4a6c-873e-e04d45caecb6", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools"}, "hash": "ead41289331a7f4690f6e6f35fba9bdfd1692999f64be83199aff981c1723c8b", "class_name": "RelatedNodeInfo"}}, "text": "Overview of tool abstractions\n\nSo how exactly do LlamaHub Tools work? The LlamaHub tool abstractions allow\nyou to easily write Python functions that can be understood and called by\nAgents. Instead of trying to make an Agent do complicated mathematics for\nexample, we can provide the Agent with a Tool that calls Wolfram Alpha and\nprovides the result to the Agent:\n\n    \n    \n    from llama_index.tools.base import BaseToolSpec\n    \n    QUERY_URL_TMPL = \"http://api.wolframalpha.com/v1/result?appid={app_id}&amp;i={query}\"\n    \n    # Inherit from the LlamaIndex BaseToolSpec abstraction\n    class WolframAlphaToolSpec(BaseToolSpec):\n    \n      # Define the functions that we export to the LLM\n        spec_functions = [\"wolfram_alpha_query\"]\n    \n      # Initialize with our wolfram alpha API key\n        def __init__(self, app_id: Optional[str] = None) -&gt; None:\n            \"\"\"Initialize with parameters.\"\"\"\n            self.token = app_id\n      \n      # Our function to be called by the Agent\n      def wolfram_alpha_query(self, query: str):\n              \"\"\"\n              Make a query to wolfram alpha about a mathematical or scientific problem.\n      \n              Example inputs:\n                  \"(7 * 12 ^ 10) / 321\"\n                  \"How many calories are there in a pound of strawberries\"\n      \n              Args:\n                  query (str): The query to be passed to wolfram alpha.\n      \n              \"\"\"\n              response = requests.get(QUERY_URL_TMPL.format(app_id=self.token, query=urllib.parse.quote_plus(query)))\n              return response.text\n\nThe above code is enough to define a LlamaIndex Tool that allows the Agent to\nquery to Wolfram Alpha. No more incorrect guesses at math problems! We can\ninitialize an instance of the Tool Spec like this:\n\n    \n    \n    # Initialize an instance of the Tool\n    wolfram_spec = WolframAlphaToolSpec(app_id=\"your-key\")\n    # Convert the Tool Spec to a list of tools. In this case we just have one tool.\n    tools = wolfram_spec.to_tool_list()\n    # Convert the tool to an OpenAI function and inspect\n    print(tools[0].metadata.to_openai_function())\n\nHere\u2019s the cleaned up output of the print statement:\n\n    \n    \n    {\n      'description': '\n        Make a query to wolfram alpha about a mathematical or scientific problem.\n      \n              Example inputs:\n                  \"(7 * 12 ^ 10) / 321\"\n                  \"How many calories are there in a pound of strawberries\"\n      \n              Args:\n                  query (str): The query to be passed to wolfram alpha.',\n      'name': 'wolfram_alpha_query',\n      'parameters': {\n        'properties': {'query': {'title': 'Query', 'type': 'string'}},\n        'title': 'wolfram_alpha_query',\n        'type': 'object'\n      }\n    }\n\nWe can see that the [ docstring ](https://en.wikipedia.org/wiki/Docstring)\ndescribing how to use the Tool get passed to the Agent. Additionally, the\nparameters, type info and function name are passed along to give the Agent a\nstrong idea on how it can use this function. All of this information is\nessentially acting as the prompt for how the agent understands the tool.\n\nInheriting from the BaseToolSpec class means it\u2019s very simple to write Tools\nfor Agents to use. In fact, the above tool definition is only 9 lines of code,\nignoring white space, imports and comments. We can easily get the function\nready for Agents to use without any heavy boilerplate or modifications. Let\u2019s\nlook at loading the Tool into an OpenAI Agent:\n\n    \n    \n    agent = OpenAIAgent.from_tools(tools, verbose=True)\n    agent.chat('What is (7 * 12 ^ 10) / 321')\n    \"\"\" OUTPUT:\n    === Calling Function ===\n    Calling function: wolfram_alpha_query with args: {\n      \"query\": \"(7 * 12 ^ 10) / 14\"\n    }\n    Got output: 30958682112\n    ========================\n    Response(response='The result of the expression (7 * 12 ^ 10) / 14 is 30,958,682,112.', source_nodes=[], metadata=None)\n    \"\"\"\n\nAnd we can test out passing this query to ChatGPT without the tools:\n\n    \n    \n    &gt; 'What is (7 * 12 ^ 10) / 321'\n    \"\"\"\n    To calculate the expression (7 * 12^10) / 14, you need to follow the order of operations, which is parentheses, exponents, multiplication, and division (from left to right).\n    \n    Step 1: Calculate the exponent 12^10.\n    12^10 = 619,173,642,24.\n    \n    Step 2: Multiply 7 by the result from Step 1.\n    7 * 619,173,642,24 = 4,333,215,496,68.\n    \n    Step 3: Divide the result from Step 2 by 14.\n    4,333,215,496,68 / 14 = 309,515,392,62.\n    \n    Therefore, the result of the expression (7 * 12^10) / 14 is 309,515,392,62.\n    \"\"\"\n\nThis example should show how easily you can write new Tools for use with\nAgents. For the rest of the blog post I\u2019ll be talking about tips and tricks\nI\u2019ve found to write more functional and effective tools. Hopefully by the end\nof the blog post you are excited to write and contribute some Tools of your\nown!", "mimetype": "text/plain", "start_char_idx": 1011, "end_char_idx": 5928, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d6aa1899-08f9-4a6c-873e-e04d45caecb6": {"__data__": {"id_": "d6aa1899-08f9-4a6c-873e-e04d45caecb6", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6770c30c-b43b-4df8-aaa8-8c2f50f7b1f0", "node_type": "1", "metadata": {"Header_1": " Context on LlamaHub Tools", "Header_2": " Overview of tool abstractions", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "72c26e54975666b300b9a7bc8472dd9f8d0a4e2fb568c772909ac78dba30a754", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4baf4cac-1c5d-4260-8e03-869e44b5802a", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Writing useful tool prompts"}, "hash": "094ee56097d39aaa19fa13301b647a9127e37f1e47addaa825b0f9d0d3e1c464", "class_name": "RelatedNodeInfo"}}, "text": "Techniques for building better tools\n\nBelow are a variety of tactics for writing more usable and functional tools to\nminimize friction when interfacing with the Agent. Not all of the tactics\napply to every tool, but usually at least a few of the techniques below will\nprove valuable.", "mimetype": "text/plain", "start_char_idx": 5933, "end_char_idx": 6216, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4baf4cac-1c5d-4260-8e03-869e44b5802a": {"__data__": {"id_": "4baf4cac-1c5d-4260-8e03-869e44b5802a", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Writing useful tool prompts", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d6aa1899-08f9-4a6c-873e-e04d45caecb6", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4e5e8e78deae77251170d86fd782f015d8d3040a393d0d0f5e44c86637f6eaee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4fc1399f-e81c-4c2b-930c-306ebae56fa7", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Making tools tolerant of partial inputs"}, "hash": "5dbf274626e495ab48e74ac651ca6a19d5cec181665cba15aecb855107e1768f", "class_name": "RelatedNodeInfo"}}, "text": "Writing useful tool prompts\n\nHere\u2019s an example of the function signature and docstring for a tool that an\nAgent can call to create a draft email.\n\n    \n    \n    def create_draft(\n            self,\n            to: List[str],\n            subject: str,\n            message: str\n        ) -&gt; str:\n            \"\"\"Create and insert a draft email.\n               Print the returned draft's message and id.\n               Returns: Draft object, including draft id and message meta data.\n    \n            Args:\n                to (List[str]): The email addresses to send the message to, eg ['adam@example.com']\n                subject (str): The subject for the event\n                message (str): The message for the event\n            \"\"\"\n\nThis prompt takes advantage of a few different patterns to ensure that the\nagent can use the tool effectively:\n\n  * Give a concise description of the function and its purpose \n  * Inform the Agent on what data will be returned from this function \n  * List the arguments that the function accepts, with descriptions and type information \n  * Give example values for arguments with a specific format, eg adam@example.com \n\nTool prompts should be concise as to not take up too much length in context,\nbut also informative enough that the agent can use the tool without making\nmistakes.", "mimetype": "text/plain", "start_char_idx": 6222, "end_char_idx": 7540, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4fc1399f-e81c-4c2b-930c-306ebae56fa7": {"__data__": {"id_": "4fc1399f-e81c-4c2b-930c-306ebae56fa7", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Making tools tolerant of partial inputs", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4baf4cac-1c5d-4260-8e03-869e44b5802a", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Writing useful tool prompts", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "1e3ed1d4da1d5bd35926c6f10e9d4529aef18efeb68fa7843bee33724f0832e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aa1be76e-dbbf-4201-938a-e4f84b55e38d", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Validating input and Agent error handling"}, "hash": "9f311cb049b9b98923e86969312c805befb0840cec717da9e1cedbdc9554b4dd", "class_name": "RelatedNodeInfo"}}, "text": "Making tools tolerant of partial inputs\n\nOne way to help Agents make fewer mistakes is to write tools that are more\n_tolerant_ of their inputs, for example by making inputs optional when the\nvalue can be inferred from somewhere else. Take the example of drafting an\nemail, but this time let\u2019s consider a tool that updates a draft email:\n\n    \n    \n    def update_draft(\n            self,\n            draft_id: str,\n            to: Optional[List[str]] = None,\n            subject: Optional[str] = None,\n            message: Optional[str] = None,\n        ) -&gt; str:\n            \"\"\"Update a draft email.\n               Print the returned draft's message and id.\n               This function is required to be passed a draft_id that is obtained when creating messages\n               Returns: Draft object, including draft id and message meta data.\n    \n            Args:\n                draft_id (str): the id of the draft to be updated\n                to (Optional[str]): The email addresses to send the message to\n                subject (Optional[str]): The subject for the event\n                message (Optional[str]): The message for the event\n            \"\"\"\n\nThe Gmail API **requires** all of the above values when updating a draft,\nhowever using just the ` draft_id ` we can fetch the current content of the\ndraft and use the existing values as defaults if the Agent did not provide the\nvalues when updating the draft:\n\n    \n    \n    def update_draft(...):\n      ...\n      draft = self.get_draft(draft_id)\n      headers = draft['message']['payload']['headers']\n      for header in headers:\n          if header['name'] == 'To' and not to:\n              to = header['value']\n          elif header['name'] == 'Subject' and not subject:\n              subject = header['value']\n        elif header['name'] == 'Message' and not message:\n          message = header['values']\n      ...\n\nBy providing the above logic in the ` update_draft ` function, the Agent can\ninvoke ` update_draft ` with only one of the fields (and the ` draft_id ` ),\nand we can update the draft as the user expects. This means that in more\ncircumstances the Agent can complete the task successfully, instead of\nreturning an error or needing to ask for more information.", "mimetype": "text/plain", "start_char_idx": 7546, "end_char_idx": 9788, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa1be76e-dbbf-4201-938a-e4f84b55e38d": {"__data__": {"id_": "aa1be76e-dbbf-4201-938a-e4f84b55e38d", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Validating input and Agent error handling", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4fc1399f-e81c-4c2b-930c-306ebae56fa7", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Making tools tolerant of partial inputs", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "6c671fb4cda0a666e0e7511facdcb41f26a0203e363ade38243d46b7a70c49d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7d3cf575-d2d6-4a98-8354-861705f299a4", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Providing simple functions related to the tool"}, "hash": "77af529aa8202d5d5a47626c475216969523d9bceea4cfd0711161b416f36b57", "class_name": "RelatedNodeInfo"}}, "text": "Validating input and Agent error handling\n\nDespite best efforts at prompting and tolerance, we can end up in\ncircumstances where the Agent invokes a tool in a way that it can\u2019t complete\nthe task at hand. However, we can detect this and prompt the Agent to recover\nthe error on its own.\n\nFor example, in the ` update_draft ` example above, what do we do if the agent\ncalls the function without a ` draft_id ` ? We could simply pass along the\nnull value and return an error from the Gmail API library, but we could also\ndetect that a null ` draft_id ` will invariably cause an error, and return a\nprompt for the agent instead:\n\n    \n    \n    def update_draft(...):\n      if draft_id == None:\n        return \"You did not provide a draft id when calling this function. If you previously created or retrieved the draft, the id is available in context\"\n\nNow, if the Agent invokes ` update_draft ` without a ` draft_id ` , it is made\naware of the exact mistake it made and given instructions on how it can\ncorrect the issue.\n\nIn my experience working with this tool, the Agent will often immediately call\nthe ` update_draft ` function in the correct way when receiving this prompt,\nor if there is no ` draft_id ` available, it will inform the user of the issue\nand ask the user for a ` draft_id ` . Either scenario is much better than\ncrashing or returning an opaque error from a library to the user.", "mimetype": "text/plain", "start_char_idx": 9794, "end_char_idx": 11187, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7d3cf575-d2d6-4a98-8354-861705f299a4": {"__data__": {"id_": "7d3cf575-d2d6-4a98-8354-861705f299a4", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Providing simple functions related to the tool", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aa1be76e-dbbf-4201-938a-e4f84b55e38d", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Validating input and Agent error handling", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "be38cbf79b11f6c6e4b1f22af28ead86eba09ab6ebc06c6d2a779059e3ea16df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b4714371-749e-4d3d-8653-afd10cf63218", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Returning prompts from functions that perform mutations"}, "hash": "55b1a1e558ba3291b73c31f4fad7ad859e14861ccaab8dc1f44da54cc6afd96c", "class_name": "RelatedNodeInfo"}}, "text": "Providing simple functions related to the tool\n\nAgents can struggle at what would otherwise be simple functions for a computer\nto calculate. For example, when building a tool for creating events in Google\nCalendar, a user may prompt the Agent with something like this:\n\n> _Create an event on my Calendar to discuss the Tools PR with_ [\n> _adam@example.com_ ](mailto:adam@example.com) _tomorrow at 4pm_\n\nCan you see the problem? If we try asking ChatGPT what day it is:\n\n    \n    \n    agent.chat('what day is it?')\n    # > I apologize for the confusion. As an AI language model, I don't have real-time data or access to the current date. My responses are based on the information I was last trained on, which is up until September 2021. To find out the current day, I recommend checking your device's clock, referring to a calendar, or checking an online source for the current date.\n\nAgents won\u2019t know what the current date is, and so the Agent would either call\nthe function incorrectly, providing a string like ` tomorrow ` for the date,\nhallucinate a date sometime in the past based on when it was trained, or put\nthe burden on the user to tell it the date. All of the above actions cause\nfriction and frustration for the user.\n\nInstead, in the Google Calendar Tool Spec we provide a simple deterministic\nfunction for the agent to call if it needs to fetch the date:\n\n    \n    \n    def get_date(self):\n            \"\"\"\n            A function to return todays date.\n            Call this before any other functions if you are unaware of the current date\n            \"\"\"\n            return datetime.date.today()\n\nNow, when the Agent tries to handle the prompt above, it can first call the\nfunction to get the date and then create the event as the user requested,\ninferring the date for \u201ctomorrow\u201d or \u201ca week from now\u201d. No errors, no guesses\nand no need for further user interaction!", "mimetype": "text/plain", "start_char_idx": 11193, "end_char_idx": 13075, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4714371-749e-4d3d-8653-afd10cf63218": {"__data__": {"id_": "b4714371-749e-4d3d-8653-afd10cf63218", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Returning prompts from functions that perform mutations", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d3cf575-d2d6-4a98-8354-861705f299a4", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Providing simple functions related to the tool", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "2ca11bd48436b82f131960e8ac64f5fe0587aed743c1ee1090506088fc289fe7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2ab445d2-fa9f-4fb7-b2b2-7811b960761f", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Storing large responses in indices for the Agent to read"}, "hash": "719fa0259631fadd824e85d037930c78ee08a5dd376195a3d39a312ca7c9dec7", "class_name": "RelatedNodeInfo"}}, "text": "Returning prompts from functions that perform mutations\n\nSome functions perform mutations to data in a way that it isn\u2019t clear what\nuseful data can be returned from the function, back to the agent. For example,\nin the Google Calendar tool if an event is successfully created it doesn\u2019t\nmake sense to return the content of the event back to the Agent, as the agent\njust passed in all of the information and thus has it in context.\n\nGenerally with functions that are focused on mutations (create, update,\ndelete) we can help the Agent understand its actions better by using the\nreturn value of these functions to further prompt the agent. For example, from\nthe Google Calendar ` create_event ` tool we could do the following:\n\n    \n    \n    def create_event(...):\n      ...\n      return 'Event created succesfully! You can move onto the next step.'  \n\nThis helps the agent register that the action succeeded and encourages it to\ncomplete the action it was prompted for, especially if creating the google\ncalendar event is only a single step in a multiple step instruction. We can\nstill return ids as part of these prompts as well:\n\n    \n    \n    def create_event(...):\n      ...\n      event = service.events().insert(...).execute()\n      return 'Event created with id {event.id}! You can move onto the next step.'", "mimetype": "text/plain", "start_char_idx": 13081, "end_char_idx": 14392, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ab445d2-fa9f-4fb7-b2b2-7811b960761f": {"__data__": {"id_": "2ab445d2-fa9f-4fb7-b2b2-7811b960761f", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Storing large responses in indices for the Agent to read", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b4714371-749e-4d3d-8653-afd10cf63218", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Returning prompts from functions that perform mutations", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "19a1c42cd33329d7352dc8ac069c5e0a835e717a071c5dc1a5f567f52376f6b5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07c55aae-a762-41d3-85ad-0453893c6317", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Verify how the Agent understands the tool"}, "hash": "c42311897dea64f0c42960f4f9ad96ceaac6bc2c8af2d471745a7094dd3df908", "class_name": "RelatedNodeInfo"}}, "text": "Storing large responses in indices for the Agent to read\n\nOne consideration when building tools that has been mentioned already is the\nsize of the context window the Agent has. Currently, LLMs tend to have context\nwindows from 4k-16k tokens, however it can certainly be larger or smaller. If\nthe size of the data that a tool would return is larger than the context\nwindow, the Agent will be unable to process the data and error out.\n\nOne consideration when building tools that has been mentioned already is the\nsize of the context window the Agent has. Currently, LLMs tend to have context\nwindows from 4k-16k tokens, however it can certainly be larger or smaller. If\nthe size of the data that a tool would return is larger than the context\nwindow, the Agent will be unable to process the data and error out.\n\nThe only consideration that needs to be made when creating tools that might\nneed to be wrapped by the LoadAndSearchTool, is they need to return a list of\nLlamaIndex documents. For a tool that returns a string, the only modification\nyou need to make to have it be compatible with the LoadAndSearchTool is\nwrapping it in a document and an array:\n\n    \n    \n    from llama_index.readers.schema.base import Document\n    \n    # Not compatible\n    def large_text_response_function():\n      ...\n      return result\n    \n    # LoadAndSearch compatible\n    def large_text_response_function():\n      ...\n      return [Document(text=result)]", "mimetype": "text/plain", "start_char_idx": 14398, "end_char_idx": 15838, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "07c55aae-a762-41d3-85ad-0453893c6317": {"__data__": {"id_": "07c55aae-a762-41d3-85ad-0453893c6317", "embedding": null, "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Verify how the Agent understands the tool", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2ab445d2-fa9f-4fb7-b2b2-7811b960761f", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Storing large responses in indices for the Agent to read", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "bbe3289ea473ce4108c3f0e9cc0b7ea26955812c89673b2d1dcce6e7c39ce37f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7f2d044a-2041-4b05-a4ca-cde154d2ece0", "node_type": "1", "metadata": {"Header_1": " Concluding thoughts"}, "hash": "d6025f9a4c60537e74445b7ca9d08b2ab4e04e1f31ee9c71d045ecfaeac2d02e", "class_name": "RelatedNodeInfo"}}, "text": "Verify how the Agent understands the tool\n\nA useful technique for debugging tools in development is to **ask the Agent\nabout its own tools** : the tools it has available, what arguments the tools\naccept, what those arguments represent, and what the tool is used for. The\nresponses of the Agent are useful in determining where your prompts might be\nlacking or helping pinpoint why an Agent is failing to successfully use a tool\nthat you are developing.\n\nAn example conversation debugging the Google Calendar Tool Spec, assuming you\nhave setup an Agent similar to the example notebook:\n\n    \n    \n    agent.chat('what tools do you have available')\n    # I have the following tools available\n    #   1. `load_data`: This tool allows me to load data from your calendar. It can retrieve a specified number of events starting from a given date.\n    #   2. `create_event`: This tool allows me to create an event on your calendar. You can provide details such as the title, description, location, start datetime, end datetime, and attendees.\n    #   3. `get_date`: This tool returns today's date. It can be used to ensure that the correct date is used when working with other tools.\n    # Please let me know if you would like more information about any of these tools or if you have any specific requests.\n    agent.chat('what arguments does the load_data tool take')\n    # 'The `load_data` tool takes the following arguments:\n    #   1. `number_of_results` (optional, default: 100): Specifies the number of events to return from your calendar.\n    #   2. `start_date` (optional): Specifies the start date from which to retrieve events. It can be provided as a string in ISO format (e.g., \"2023-07-05\") or as a `datetime.date` object.\n    # You can use these arguments to customize the number of events and the start date for retrieving data from your calendar.", "mimetype": "text/plain", "start_char_idx": 15844, "end_char_idx": 17697, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f2d044a-2041-4b05-a4ca-cde154d2ece0": {"__data__": {"id_": "7f2d044a-2041-4b05-a4ca-cde154d2ece0", "embedding": null, "metadata": {"Header_1": " Concluding thoughts", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f", "node_type": "4", "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "4bba3d2eaf26665ed83c98bd1b80247119a34975f2e360140d22bf6c706ba553", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07c55aae-a762-41d3-85ad-0453893c6317", "node_type": "1", "metadata": {"Header_1": " Techniques for building better tools", "Header_2": " Verify how the Agent understands the tool", "filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}, "hash": "cdf8a2d8a8306bc4c48781733e6e89d31d31ac0ffbe1c541fe26240c701684aa", "class_name": "RelatedNodeInfo"}}, "text": "Concluding thoughts\n\nBuilding tools for Agents requires you to think critically about how users\nwill interact with the Agent, and to try and anticipate any possible usage\npatterns. Building well thought out tools that can be resilient to errors and\nissues requires careful consideration and testing of possible use cases. I\nhope that these reflections and techniques assist you in creating new tools\nfor Agents, and don\u2019t forget to share your tools on [ LlamaHub\n](https://llama-hub-ui.vercel.app/) .", "mimetype": "text/plain", "start_char_idx": 17702, "end_char_idx": 18202, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"a3aa3d77-98cc-4079-9aa0-278da375a818": {"doc_hash": "5e0e23d5cace4a48235f2579a16aa8426aaed9af0af3d1fff99ae04c30d1f6f1", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "0996ec55-7678-4a9f-9e8e-0daabf5607d0": {"doc_hash": "fa4f2d913b9b83048a6a39edc40a3acd8091dfa20fd1f4f4412a3222d54cbe92", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "6770c30c-b43b-4df8-aaa8-8c2f50f7b1f0": {"doc_hash": "72c26e54975666b300b9a7bc8472dd9f8d0a4e2fb568c772909ac78dba30a754", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "d6aa1899-08f9-4a6c-873e-e04d45caecb6": {"doc_hash": "4e5e8e78deae77251170d86fd782f015d8d3040a393d0d0f5e44c86637f6eaee", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "4baf4cac-1c5d-4260-8e03-869e44b5802a": {"doc_hash": "1e3ed1d4da1d5bd35926c6f10e9d4529aef18efeb68fa7843bee33724f0832e4", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "4fc1399f-e81c-4c2b-930c-306ebae56fa7": {"doc_hash": "6c671fb4cda0a666e0e7511facdcb41f26a0203e363ade38243d46b7a70c49d2", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "aa1be76e-dbbf-4201-938a-e4f84b55e38d": {"doc_hash": "be38cbf79b11f6c6e4b1f22af28ead86eba09ab6ebc06c6d2a779059e3ea16df", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "7d3cf575-d2d6-4a98-8354-861705f299a4": {"doc_hash": "2ca11bd48436b82f131960e8ac64f5fe0587aed743c1ee1090506088fc289fe7", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "b4714371-749e-4d3d-8653-afd10cf63218": {"doc_hash": "19a1c42cd33329d7352dc8ac069c5e0a835e717a071c5dc1a5f567f52376f6b5", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "2ab445d2-fa9f-4fb7-b2b2-7811b960761f": {"doc_hash": "bbe3289ea473ce4108c3f0e9cc0b7ea26955812c89673b2d1dcce6e7c39ce37f", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "07c55aae-a762-41d3-85ad-0453893c6317": {"doc_hash": "cdf8a2d8a8306bc4c48781733e6e89d31d31ac0ffbe1c541fe26240c701684aa", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}, "7f2d044a-2041-4b05-a4ca-cde154d2ece0": {"doc_hash": "989315141eedc1c91e8b84e267f5b858b62a4ef2a328c8a3eba8783c2078f6a8", "ref_doc_id": "38817cfc-46a9-4b19-8ecc-cd6bcefee81f"}}, "docstore/ref_doc_info": {"38817cfc-46a9-4b19-8ecc-cd6bcefee81f": {"node_ids": ["a3aa3d77-98cc-4079-9aa0-278da375a818", "0996ec55-7678-4a9f-9e8e-0daabf5607d0", "6770c30c-b43b-4df8-aaa8-8c2f50f7b1f0", "d6aa1899-08f9-4a6c-873e-e04d45caecb6", "4baf4cac-1c5d-4260-8e03-869e44b5802a", "4fc1399f-e81c-4c2b-930c-306ebae56fa7", "aa1be76e-dbbf-4201-938a-e4f84b55e38d", "7d3cf575-d2d6-4a98-8354-861705f299a4", "b4714371-749e-4d3d-8653-afd10cf63218", "2ab445d2-fa9f-4fb7-b2b2-7811b960761f", "07c55aae-a762-41d3-85ad-0453893c6317", "7f2d044a-2041-4b05-a4ca-cde154d2ece0"], "metadata": {"filename": "building-better-tools-for-llm-agents-f8c5a6714f11.md", "extension": ".md", "title": "Building Better Tools for LLM Agents", "date": "Jul 17, 2023", "url": "https://www.llamaindex.ai/blog/building-better-tools-for-llm-agents-f8c5a6714f11"}}}}