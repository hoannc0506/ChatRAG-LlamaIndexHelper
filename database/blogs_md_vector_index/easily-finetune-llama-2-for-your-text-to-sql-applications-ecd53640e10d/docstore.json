{"docstore/data": {"7f744ba5-8a1e-42a4-853c-a85604581dc3": {"__data__": {"id_": "7f744ba5-8a1e-42a4-853c-a85604581dc3", "embedding": null, "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5d973638-ad14-4572-a42a-740d0bbf1050", "node_type": "1", "metadata": {"Header_1": " Context: Llama-2\u20137B is Not Good at Text-to-SQL"}, "hash": "9eb7ebc68aa0a1f66e98d11533e8022c7eebc4bdf885e549a63d681d8af5588b", "class_name": "RelatedNodeInfo"}}, "text": "[ Llama 2 ](https://ai.meta.com/llama/) is a huge milestone in the advancement\nof open-source LLMs. The biggest model and its finetuned variants sit at the\ntop of the [ Hugging Face Open LLM Leaderboard\n](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) . Multiple\nbenchmarks show that it is approaching GPT-3.5 (or in some cases even\nsurpassing it) in terms of performance. All of this means that open-source\nLLMs are an increasingly viable and reliable option for use in complex LLM\napplications, from RAG systems to agents.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 543, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5d973638-ad14-4572-a42a-740d0bbf1050": {"__data__": {"id_": "5d973638-ad14-4572-a42a-740d0bbf1050", "embedding": null, "metadata": {"Header_1": " Context: Llama-2\u20137B is Not Good at Text-to-SQL", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f744ba5-8a1e-42a4-853c-a85604581dc3", "node_type": "1", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "58ffb3dda5fa4781f7a7e71bb12a00942b5317cda1503828e5dc8105ab9fae5b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7a4888b7-b8b5-49e1-800b-cf864a27ccf7", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview"}, "hash": "9ac9b96fcf8644fd5e9681fe7ffe8b585c0f74019e9d0bfe11567192ee812631", "class_name": "RelatedNodeInfo"}}, "text": "Context: Llama-2\u20137B is Not Good at Text-to-SQL\n\nA downside of the smallest Llama 2 model (7B parameters), however, is that\nit\u2019s not very good at generating SQL, making it impractical for structured\nanalytics use cases. As an example, we tried prompting Llama 2 to generate the\ncorrect SQL statement given the following prompt template:\n\n    \n    \n    You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables. \n    \n    You must output the SQL query that answers the question.\n    \n    ### Input:\n    {input}\n    \n    ### Context:\n    {context}\n    \n    ### Response:\n\nHere we plugged in a sample entry from the [ sql-create-context dataset\n](https://huggingface.co/datasets/b-mc2/sql-create-context) .\n\n    \n    \n    input: In 1981 which team picked overall 148?\n    context: CREATE TABLE table_name_8 (team VARCHAR, year VARCHAR, overall_pick VARCHAR)\n\nMeanwhile, here is the generated output vs. correct output:\n\n    \n    \n    Generated output: SELECT * FROM `table_name_8` WHERE '1980' = YEAR AND TEAM = \"Boston Celtics\" ORDER BY OVERALL_PICK DESC LIMIT 1;\n    \n    Correct output: SELECT team FROM table_name_8 WHERE year = 1981 AND overall_pick = \"148\"\n\nThis is clearly not ideal. Unlike ChatGPT and GPT-4, Llama 2 does not reliably\nproduce well-formatted and correct SQL outputs.\n\nThis is exactly where fine-tuning comes in \u2014 given a proper corpus of text-to-\nSQL data, we can teach Llama 2 to be better at generating SQL outputs from\nnatural language. At a high-level, fine-tuning involves modifying the weights\nof the model in some capacity. There are different ways to finetune models,\nfrom updating all parameters of the network, to a subset of the parameters, to\nonly finetuning additional parameters (e.g. [ how LoRA works\n](https://arxiv.org/abs/2106.09685) ).\n\nOnce the model is finetuned, it can still be plugged into a downstream LLM\napplication. That is exactly what this tutorial aims to show. It is a step\nmore involved than our existing tutorials which have primarily focused on \u201cin-\ncontext learning\u201d and \u201cretrieval-augmentation\u201d use cases \u2014 freezing the model\nitself but focusing on the orchestration of data into the input prompt.\nFinetuning can have a high learning curve and also require a lot of compute.\nThis tutorial makes it as easy as possible to get started.", "mimetype": "text/plain", "start_char_idx": 548, "end_char_idx": 2934, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7a4888b7-b8b5-49e1-800b-cf864a27ccf7": {"__data__": {"id_": "7a4888b7-b8b5-49e1-800b-cf864a27ccf7", "embedding": null, "metadata": {"Header_1": " Tutorial Overview", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5d973638-ad14-4572-a42a-740d0bbf1050", "node_type": "1", "metadata": {"Header_1": " Context: Llama-2\u20137B is Not Good at Text-to-SQL", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "cb2a00b278e0b2aec7746847dc7caae3f27bf083e2d692858496a07e59be8eec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8320266c-037d-453e-b6e9-1b4871af1c7f", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 1: Loading Training Data for Finetuning LLaMa"}, "hash": "910c958bf5f92199ede9d5cd22c5b58f311538aec4677cdd3a1917aca4cd09f2", "class_name": "RelatedNodeInfo"}}, "text": "Tutorial Overview\n\nIn this tutorial, we show you how you can finetune Llama 2 on a text-to-SQL\ndataset, and then use it for structured analytics against any SQL database\nusing the capabilities of [ LlamaIndex\n](https://github.com/jerryjliu/llama_index) .\n\nHere is the stack that we use:\n\n  * ` [ b-mc2/sql-create-context ](https://huggingface.co/datasets/b-mc2/sql-create-context) ` [ from Hugging Face datasets ](https://huggingface.co/datasets/b-mc2/sql-create-context) as the training dataset \n  * [ OpenLLaMa ](https://github.com/openlm-research/open_llama) ` open_llama_7b_v2 ` as the base model \n  * [ PEFT for efficient finetuning ](https://github.com/huggingface/peft)\n  * [ Modal ](https://modal.com/) for handling all cloud compute/orchestration for finetuning. And also for the excellent reference [ doppel-bot repo ](https://github.com/modal-labs/doppel-bot) . \n  * [ LlamaIndex ](https://www.llamaindex.ai/) for text-to-SQL inference against any SQL database. \n\nSpecial mention to the awesome [ Llama 2 tutorial from Anyscale that helped to\ninspire this project ](https://www.anyscale.com/blog/fine-tuning-\nllama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-\napplications) .\n\nAll of our materials can be found in our Github repo: [\nhttps://github.com/run-llama/modal_finetune_sql ](https://github.com/run-\nllama/modal_finetune_sql) (again emphasizing that this is adapted from [\ndoppel-bot ](https://github.com/modal-labs/doppel-bot) ). Also, the full\ntutorial can be found in our [ Jupyter notebook guide\n](https://github.com/run-llama/modal_finetune_sql/blob/main/tutorial.ipynb) .\nMake sure to check it out!\n\nAs mentioned above, performing finetuning does require quite a few steps. Our\ngoal is to make this as straightforward as possible to follow and use out of\nthe box. We don\u2019t cover all the nitty gritty detailsof Modal, PEFT, the\nfinetuning procedure itself, etc. but we do give a rough overview.\n\nThere are also certainly higher-level APIs that we could\u2019ve used (e.g. OpenAI,\nLamini) in order to achieve this task. There\u2019s plenty of room for followup\ntutorials to cover these topics!", "mimetype": "text/plain", "start_char_idx": 2939, "end_char_idx": 5060, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8320266c-037d-453e-b6e9-1b4871af1c7f": {"__data__": {"id_": "8320266c-037d-453e-b6e9-1b4871af1c7f", "embedding": null, "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 1: Loading Training Data for Finetuning LLaMa", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7a4888b7-b8b5-49e1-800b-cf864a27ccf7", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "cd6668526002239297f44415ee817c3ccd53c7ace79afc96602ad5479ffb41d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8944f71-98bc-4655-ae2c-c630f0574d27", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 2: Run Finetuning Script"}, "hash": "3f1eef2cf085eb2aa9fc17293272b5cd994a397eeec1664bcd4e7be7403521a9", "class_name": "RelatedNodeInfo"}}, "text": "Step 1: Loading Training Data for Finetuning LLaMa\n\nThe first step here is to open up the [ Jupyter notebook\n](https://github.com/run-llama/modal_finetune_sql/blob/main/tutorial.ipynb) .\nThe notebook is organized into a series of runnable scripts that each perform\nthe steps needed to load data.\n\nOur code uses Modal for every step of the orchestration, and Modal is best\nused on top of the Python scripts themselves. That is why a lot of these cells\ndon\u2019t contain Python blocks of their own.\n\nFirst we use Modal to load in the ` b-mc2/sql-create-context ` dataset. This\nis a simple task that just loads in the dataset and formats it into a ` .jsonl\n` file.\n\n    \n    \n    modal run src.load_data_sql --data-dir \"data_sql\"\n\nAs we can see, under the hood the task is quite straightforward:\n\n    \n    \n    # Modal stubs allow our function to run remotely\n    @stub.function(\n        retries=Retries(\n            max_retries=3,\n            initial_delay=5.0,\n            backoff_coefficient=2.0,\n        ),\n        timeout=60 * 60 * 2,\n        network_file_systems={VOL_MOUNT_PATH.as_posix(): output_vol},\n        cloud=\"gcp\",\n    )\n    def load_data_sql(data_dir: str = \"data_sql\"):\n        from datasets import load_dataset\n    \n        dataset = load_dataset(\"b-mc2/sql-create-context\")\n    \n        dataset_splits = {\"train\": dataset[\"train\"]}\n        out_path = get_data_path(data_dir)\n    \n        out_path.parent.mkdir(parents=True, exist_ok=True)\n    \n        for key, ds in dataset_splits.items():\n            with open(out_path, \"w\") as f:\n                for item in ds:\n                    newitem = {\n                        \"input\": item[\"question\"],\n                        \"context\": item[\"context\"],\n                        \"output\": item[\"answer\"],\n                    }\n                    f.write(json.dumps(newitem) + \"\\n\")", "mimetype": "text/plain", "start_char_idx": 5066, "end_char_idx": 6907, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f8944f71-98bc-4655-ae2c-c630f0574d27": {"__data__": {"id_": "f8944f71-98bc-4655-ae2c-c630f0574d27", "embedding": null, "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 2: Run Finetuning Script", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8320266c-037d-453e-b6e9-1b4871af1c7f", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 1: Loading Training Data for Finetuning LLaMa", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "2e5048699412108f70ae87f80d7d484368f5cf5aee6fee341b1b168a0649e8f2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1f2d5f06-a193-4335-92f3-715c28f9f845", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 3: Evaluation"}, "hash": "5033a656ed6759bccfa796235dc9742c3a9633f5f84e5cd5cad957b489ee0c63", "class_name": "RelatedNodeInfo"}}, "text": "Step 2: Run Finetuning Script\n\nThe next step is to run our finetuning script on the parsed dataset.\n\n    \n    \n    modal run src.finetune_sql --data-dir \"data_sql\" --model-dir \"model_sql\"\n\nThe finetuning script performs the following steps.\n\n**Splits the dataset into training and validation splits**\n\n    \n    \n    train_val = data[\"train\"].train_test_split(test_size=val_set_size, shuffle=True, seed=42)\n    train_data = train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n    val_data = train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n\n**Formats each split into tuples of (input prompt, label):** The input query\nand context are formatted into the same input prompt. The input prompt is then\ntokenized, and the labels are set to the exact same as the input prompt \u2014 this\nallows the model to train on next-token prediction.\n\n    \n    \n    def generate_and_tokenize_prompt(data_point):\n      full_prompt = generate_prompt_sql(\n          data_point[\"input\"],\n          data_point[\"context\"],\n          data_point[\"output\"],\n      )\n      tokenized_full_prompt = tokenize(full_prompt)\n      if not train_on_inputs:\n          raise NotImplementedError(\"not implemented yet\")\n      return tokenized_full_prompt\n\nThe input prompt is the exact same as what was given at the top of this blog.\n\nWhen the finetuning script is run, the model is saved in the remote cloud\ndirectory specified by model_dir (which is set to a default value if not\nspecified).", "mimetype": "text/plain", "start_char_idx": 6913, "end_char_idx": 8384, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1f2d5f06-a193-4335-92f3-715c28f9f845": {"__data__": {"id_": "1f2d5f06-a193-4335-92f3-715c28f9f845", "embedding": null, "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 3: Evaluation", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8944f71-98bc-4655-ae2c-c630f0574d27", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 2: Run Finetuning Script", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "63ad7b890f014e5f436d42e769c349b3478dee8bfb99e12ff5e835717c7a8ce5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "02b903cd-6d42-49d9-b039-bae507279ddd", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 4: Integrating the Finetuned Model with LlamaIndex"}, "hash": "df717f1fd3b97167ac2b1457d8fee950e7955e832780bc064c1b6e24fa7065ae", "class_name": "RelatedNodeInfo"}}, "text": "Step 3: Evaluation\n\nThe model has been finetuned and can be served from the cloud. We can run some\nbasic evaluations using sample data from sql-create-context to compare the\nperformance of the finetuned model vs. the baseline Llama 2 model.\n\n    \n    \n    modal run src.eval_sql::main\n\nThe results demonstrate a massive improvement for the finetuned model:\n\n    \n    \n    Input 1: {'input': 'Which region (year) has Abigail at number 7, Sophia at number 1 and Aaliyah at number 5?', 'context': 'CREATE TABLE table_name_12 (region__year_ VARCHAR, no_5 VARCHAR, no_7 VARCHAR, no_1 VARCHAR)', 'output': 'SELECT region__year_ FROM table_name_12 WHERE no_7 = \"abigail\" AND no_1 = \"sophia\" AND\n    no_5 = \"aaliyah\"'}\n    Output 1 (finetuned model): SELECT region__year_ FROM table_name_12 WHERE no_7 = \"abigail\" AND no_1 = \"aaliyah\" AND no_5 = \"sophia\"\n    Output 1 (base model): SELECT * FROM table_name_12 WHERE region__year = '2018' AND no_5 = 'Abigail' AND no_7 = 'Sophia' AND no_1 = 'Aaliyah';\n    \n    \n    Input 2: {'input': 'Name the result/games for 54741', 'context': 'CREATE TABLE table_21436373_11 (result_games VARCHAR, attendance VARCHAR)', 'output': 'SELECT result_games FROM table_21436373_11 WHERE attendance = 54741'}\n    Output 2 (finetuned model): SELECT result_games FROM table_21436373_11 WHERE attendance = \"54741\"\n    Output 2 (base model): SELECT * FROM table_21436373_11 WHERE result_games = 'name' AND attendance &gt; 0;\n\nWhereas the base model produces wrongly formatted outputs, or incorrect SQL\nstatements,\n\nthe finetuned model is able to produce outputs that are much closer to that of\nthe expected output.", "mimetype": "text/plain", "start_char_idx": 8390, "end_char_idx": 10021, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "02b903cd-6d42-49d9-b039-bae507279ddd": {"__data__": {"id_": "02b903cd-6d42-49d9-b039-bae507279ddd", "embedding": null, "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 4: Integrating the Finetuned Model with LlamaIndex", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1f2d5f06-a193-4335-92f3-715c28f9f845", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 3: Evaluation", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "acc6323aff1675b8e7ca9a6ac0c100a79fe0c9f3eb24375c5083954ccd18cc01", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "088b31c2-13f1-4bb5-9160-741ded3192c6", "node_type": "1", "metadata": {"Header_1": " Conclusion"}, "hash": "9d79ba4ff284bae5c4d685b6f4a3cc54af418f040c0e36d436d8d575460d3458", "class_name": "RelatedNodeInfo"}}, "text": "Step 4: Integrating the Finetuned Model with LlamaIndex\n\nWe can now use this model in LlamaIndex for text-to-SQL over any database.\n\nWe first define a test SQL database that we can then use to test the inference\ncapabilities of the model.\n\nWe create a toy ` city_stats ` table that contains city name, population, and\ncountry information, and populate it with a few sample cities.\n\n    \n    \n    db_file = \"cities.db\"\n    engine = create_engine(f\"sqlite:///{db_file}\")\n    metadata_obj = MetaData()\n    # create city SQL table\n    table_name = \"city_stats\"\n    city_stats_table = Table(\n        table_name,\n        metadata_obj,\n        Column(\"city_name\", String(16), primary_key=True),\n        Column(\"population\", Integer),\n        Column(\"country\", String(16), nullable=False),\n    )\n    metadata_obj.create_all(engine)\n\nThis is stored in a ` cities.db ` file.\n\nWe can then use Modal to load both the finetuned model and this database file\ninto the ` NLSQLTableQueryEngine ` in LlamaIndex - this query engine allows\nusers easily start performing text-to-SQL over a given database.\n\n    \n    \n    modal run src.inference_sql_llamaindex::main --query \"Which city has the highest population?\" --sqlite-file-path \"nbs/cities.db\" --model-dir \"model_sql\" --use-finetuned-model True\n\nWe get a response like the following:\n\n    \n    \n    SQL Query: SELECT MAX(population) FROM city_stats WHERE country = \"United States\"\n    Response: [(2679000,)]", "mimetype": "text/plain", "start_char_idx": 10027, "end_char_idx": 11469, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "088b31c2-13f1-4bb5-9160-741ded3192c6": {"__data__": {"id_": "088b31c2-13f1-4bb5-9160-741ded3192c6", "embedding": null, "metadata": {"Header_1": " Conclusion", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71044af9-d3af-49e2-a6c5-6749df92c94f", "node_type": "4", "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "8f07bd4121d226435365b3fbb47f1c14641cb90eb089de88843541dcc3b449c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "02b903cd-6d42-49d9-b039-bae507279ddd", "node_type": "1", "metadata": {"Header_1": " Tutorial Overview", "Header_2": " Step 4: Integrating the Finetuned Model with LlamaIndex", "filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}, "hash": "0df8c7f8a4aff6ce7811f2f5534b5b8316f8e41357693d9bbdab0a30bf4dad0a", "class_name": "RelatedNodeInfo"}}, "text": "Conclusion\n\nAnd that\u2019s basically it! This tutorial provides a very high-level way for you\nto get started finetuning a Llama 2 model on generating SQL statements, and\nshowcases end-to-end how you can plug it into your text-to-SQL workflows with\nLlamaIndex.\n\n**Resources**\n\nFor the sake of completeness we\u2019re linking all of our resources again here.\n\nTutorial repo: [ https://github.com/run-llama/modal_finetune_sql\n](https://github.com/run-llama/modal_finetune_sql) (adapted from [ doppel-bot\n](https://modal.com/) ).\n\n[ Jupyter notebook guide ](https://github.com/run-\nllama/modal_finetune_sql/blob/main/tutorial.ipynb) .\n\nStack:\n\n  * ` [b-mc2/sql-create-context ` from Hugging Face datasets]( [ https://huggingface.co/datasets/b-mc2/sql-create-context ](https://huggingface.co/datasets/b-mc2/sql-create-context) ) \n  * [ OpenLLaMa ](https://github.com/openlm-research/open_llama)\n  * [ PEFT ](https://github.com/huggingface/peft)\n  * [ Modal ](https://modal.com/) (+ [ doppel-bot repo ](https://github.com/modal-labs/doppel-bot) ). \n  * [ LlamaIndex ](https://www.llamaindex.ai/)\n\nSpecial mention: [ Llama 2 tutorial from Anyscale\n](https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-\nstudy-for-tailoring-models-to-unique-applications) .", "mimetype": "text/plain", "start_char_idx": 11474, "end_char_idx": 12732, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"7f744ba5-8a1e-42a4-853c-a85604581dc3": {"doc_hash": "58ffb3dda5fa4781f7a7e71bb12a00942b5317cda1503828e5dc8105ab9fae5b", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}, "5d973638-ad14-4572-a42a-740d0bbf1050": {"doc_hash": "cb2a00b278e0b2aec7746847dc7caae3f27bf083e2d692858496a07e59be8eec", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}, "7a4888b7-b8b5-49e1-800b-cf864a27ccf7": {"doc_hash": "cd6668526002239297f44415ee817c3ccd53c7ace79afc96602ad5479ffb41d6", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}, "8320266c-037d-453e-b6e9-1b4871af1c7f": {"doc_hash": "2e5048699412108f70ae87f80d7d484368f5cf5aee6fee341b1b168a0649e8f2", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}, "f8944f71-98bc-4655-ae2c-c630f0574d27": {"doc_hash": "63ad7b890f014e5f436d42e769c349b3478dee8bfb99e12ff5e835717c7a8ce5", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}, "1f2d5f06-a193-4335-92f3-715c28f9f845": {"doc_hash": "acc6323aff1675b8e7ca9a6ac0c100a79fe0c9f3eb24375c5083954ccd18cc01", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}, "02b903cd-6d42-49d9-b039-bae507279ddd": {"doc_hash": "0df8c7f8a4aff6ce7811f2f5534b5b8316f8e41357693d9bbdab0a30bf4dad0a", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}, "088b31c2-13f1-4bb5-9160-741ded3192c6": {"doc_hash": "c13a7358a3e39cc50586482fdd491dccb3861ef26ff5e74efff11d8c42771e37", "ref_doc_id": "71044af9-d3af-49e2-a6c5-6749df92c94f"}}, "docstore/ref_doc_info": {"71044af9-d3af-49e2-a6c5-6749df92c94f": {"node_ids": ["7f744ba5-8a1e-42a4-853c-a85604581dc3", "5d973638-ad14-4572-a42a-740d0bbf1050", "7a4888b7-b8b5-49e1-800b-cf864a27ccf7", "8320266c-037d-453e-b6e9-1b4871af1c7f", "f8944f71-98bc-4655-ae2c-c630f0574d27", "1f2d5f06-a193-4335-92f3-715c28f9f845", "02b903cd-6d42-49d9-b039-bae507279ddd", "088b31c2-13f1-4bb5-9160-741ded3192c6"], "metadata": {"filename": "easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d.md", "extension": ".md", "title": "Easily Finetune Llama 2 for Your Text-to-SQL Applications", "date": "Aug 17, 2023", "url": "https://www.llamaindex.ai/blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d"}}}}