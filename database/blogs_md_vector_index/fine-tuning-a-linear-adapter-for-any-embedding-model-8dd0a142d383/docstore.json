{"docstore/data": {"5fa414c6-0bc8-4975-9e67-4baa2bcbc196": {"__data__": {"id_": "5fa414c6-0bc8-4975-9e67-4baa2bcbc196", "embedding": null, "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc434ea6-8d78-4291-8150-34d17e8dd81f", "node_type": "1", "metadata": {"Header_1": " Context"}, "hash": "b9c979be9e5b26ad105e648d2444354afb3673372f3deb7198619641490fe388", "class_name": "RelatedNodeInfo"}}, "text": "We\u2019ve added capabilities in LlamaIndex allowing you to fine-tune a linear\nadapter on top of embeddings produced from _any_ model ( `\nsentence_transformers ` , OpenAI, and more).\n\nThis allows you to transform your embedding representations into a new latent\nspace that\u2019s optimized for retrieval over your specific data and queries. This\ncan lead to small increases in retrieval performance that in turn translate to\nbetter performing RAG systems.\n\nA nice bonus: you do _not_ need to re-embed your documents by using this\nadapter! Simply transform the query instead.\n\nWe have a [ full end-to-end guide ](https://gpt-\nindex.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding_adapter.html)\nshowing how you can generate a synthetic dataset, fine-tune the linear\nadapter, and evaluate its performance.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 819, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fc434ea6-8d78-4291-8150-34d17e8dd81f": {"__data__": {"id_": "fc434ea6-8d78-4291-8150-34d17e8dd81f", "embedding": null, "metadata": {"Header_1": " Context", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5fa414c6-0bc8-4975-9e67-4baa2bcbc196", "node_type": "1", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "4b88f33ac653c801e44660dbe8d7c7afc060c03e4cf14d180129e1845e55795a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "39e8667e-ed85-4919-9fea-23ed53ce57eb", "node_type": "1", "metadata": {"Header_1": " Approach"}, "hash": "cd4b8409b846d92b337438edd8833c4b87f6e91c0ac0ea47ae9ae2f3109a2845", "class_name": "RelatedNodeInfo"}}, "text": "Context\n\nThe concept of fine-tuning your embedding model is powerful. In fact, we were\ninspired to both add a [ full example repository ](https://github.com/run-\nllama/finetune-embedding) / [ blog post ](https://medium.com/llamaindex-\nblog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971) as well\nas [ native abstractions in LlamaIndex ](https://gpt-\nindex.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html)\nshowing how you can fine-tune a sentence_transformers model over any\nunstructured text corpus (with our ` SentenceTransformersFinetuneEngine ` ).\n\nHowever, this approach has some limitations:\n\n  * The ` SentenceTransformersFinetuneEngine ` is limited to fine-tuning ` sentence_transformers ` models. \n  * After finetuning the embedding model, you will need to re-embed your document corpus. \n\nDuring our [ Finetuning + RAG webinar\n](https://www.youtube.com/watch?v=mndiDJ5k26A) last Friday, Jo (Vespa)\nmentioned the exact same problem: fine-tuning the embeddings model requires\nyou to reindex your documents. However, his work with Vespa [ explored the\nconcept of \u201cfreezing\u201d document embeddings using a foundation model\n](https://blog.vespa.ai/tailoring-frozen-embeddings-with-vespa/) , and instead\ntraining a transformation on the query embedding.\n\nThis inspired us to explore a similar embedding fine-tuning approach that was\nsimultaneously more general but also allowed us to freeze existing document\nembeddings.", "mimetype": "text/plain", "start_char_idx": 824, "end_char_idx": 2293, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "39e8667e-ed85-4919-9fea-23ed53ce57eb": {"__data__": {"id_": "39e8667e-ed85-4919-9fea-23ed53ce57eb", "embedding": null, "metadata": {"Header_1": " Approach", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc434ea6-8d78-4291-8150-34d17e8dd81f", "node_type": "1", "metadata": {"Header_1": " Context", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "78afae966d6c132f323be2afc15a4faba383cf8c45a4805e257ee48ef4b0855b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b368a52a-6eeb-4901-9f92-8c397ed66203", "node_type": "1", "metadata": {"Header_1": " Approach", "Header_2": " Technical Details"}, "hash": "6aac8d5b0c8cd279ee1a41c551670156b850776141f109f954abfef2fa6dd345", "class_name": "RelatedNodeInfo"}}, "text": "Approach\n\nOur brand-new ` EmbeddingAdapterFinetuneEngine ` fine-tunes a **linear\nadapter** on top of query embeddings produced by any model. The **linear\nadapter** is simply a linear transformation that specifically transforms the\nquery embedding _while keeping document embeddings fixed_ .\n\nThe linear adapter can be used on top of any existing embeddings model: SBERT\nembeddings, OpenAI embeddings, Cohere embeddings, and more. As a result you\ncan just plug this in on top of any embedding model that you\u2019re already using!\n\nSince document embeddings are unchanged, this means that you can always fine-\ntune this linear adapter _after_ you\u2019ve generated embeddings for your\ndocuments. You can choose to arbitrarily re-train this adapter on top of\nchanging data distributions, without needing to re-embed all your documents.", "mimetype": "text/plain", "start_char_idx": 2298, "end_char_idx": 3121, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b368a52a-6eeb-4901-9f92-8c397ed66203": {"__data__": {"id_": "b368a52a-6eeb-4901-9f92-8c397ed66203", "embedding": null, "metadata": {"Header_1": " Approach", "Header_2": " Technical Details", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "39e8667e-ed85-4919-9fea-23ed53ce57eb", "node_type": "1", "metadata": {"Header_1": " Approach", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "ffbd1bb147097246339dbf7ee4bba860aefb47ffaf32f58f755916f0a1318884", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "abb8f649-4b8a-4a78-adcb-a40a988d480e", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough"}, "hash": "b08571a2fd91900636027b38a8e23148e345d062e009f7271da01b994a1a880a", "class_name": "RelatedNodeInfo"}}, "text": "Technical Details\n\nAs mentioned above, the linear adapter simply performs a linear transformation\non top of the query embedding while keeping the Document embeddings fixed\n(with a weight matrix W + bias term b):\n\nAnd that\u2019s it! If document embeddings can be represented as a (n x d) matrix\nD, where n is number of documents and d is the embedding dimension, then\nembedding similarity is just measured by\n\nThe linear adapter is trained using a similar loss term as the `\nMultipleNegativesRankingLoss ` function in ` sentence_transformers ` \u2014 given a\nbatch of positive (question, context) examples, the function uses cross-\nentropy loss under the hood to penalize the ground-truth (question, context)\npairs for being far apart and swapped pairs for being too close.\n\n**Additional Notes:** We ended up writing the bulk of this fine-tuning logic\nin plain PyTorch, but taking heavy inspiration from the `\nsentence_transformers ` [ source code ](https://github.com/UKPLab/sentence-\ntransformers) . We couldn\u2019t use sentence_transformers directly since we take\nin embeddings as inputs rather than raw text. You can take a look at some of\nour training code here.", "mimetype": "text/plain", "start_char_idx": 3127, "end_char_idx": 4280, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "abb8f649-4b8a-4a78-adcb-a40a988d480e": {"__data__": {"id_": "abb8f649-4b8a-4a78-adcb-a40a988d480e", "embedding": null, "metadata": {"Header_1": " Notebook Walkthrough", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b368a52a-6eeb-4901-9f92-8c397ed66203", "node_type": "1", "metadata": {"Header_1": " Approach", "Header_2": " Technical Details", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "5f2b2eaba79ad338f413fb8198d732fc7bbab4276eaac091bccb8d3e9646827d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b76f0ee-47d3-4b7b-8f15-389aad75b02d", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Generate a Synthetic Dataset for Trraining and Evaluation"}, "hash": "15b7dcf5c367c08d7c8be1748fd3cdb69abc85174cd9d26e172e522d669d7d41", "class_name": "RelatedNodeInfo"}}, "text": "Notebook Walkthrough\n\nIn this notebook walkthrough, we follow a similar set of steps as our [\nprevious blog post on embedding fine-tuning ](https://medium.com/llamaindex-\nblog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971) :\n\n  1. Generate a synthetic question-context dataset for both training and evaluation. \n  2. Fine-tuning our linear adapter on top of an existing model (e.g. SBERT) \n  3. Getting the embedding model, and evaluating it. \n\nAs with the previous post, we use the UBER and LYFT 10K as example data. We\nuse Lyft to generate our training dataset and Uber to generate our evaluation\ndataset.\n\nThe full guide is here: [ https://gpt-\nindex.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding_adapter.html\n](https://gpt-\nindex.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding_adapter.html)", "mimetype": "text/plain", "start_char_idx": 4285, "end_char_idx": 5154, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b76f0ee-47d3-4b7b-8f15-389aad75b02d": {"__data__": {"id_": "0b76f0ee-47d3-4b7b-8f15-389aad75b02d", "embedding": null, "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Generate a Synthetic Dataset for Trraining and Evaluation", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "abb8f649-4b8a-4a78-adcb-a40a988d480e", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "9639b3c64f5d2e1cc686426e3f71c34cc3d405240c34b783b615bf57d483f05d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4cc11d1c-7d33-49b2-9068-367bb5e5ecaf", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Fine-tuning our Linear Adapter"}, "hash": "31da150c2dc91565d53dd41c40b23c0652ab08043cac6cf0a4f3a964bdcee3f0", "class_name": "RelatedNodeInfo"}}, "text": "Generate a Synthetic Dataset for Trraining and Evaluation\n\nWe use our helper abstractions, ` generate_qa_embedding_pairs ` , to generate\nour training and evaluation dataset. This function takes in any set of text\nnodes (chunks) and generates a structured dataset containing (question,\ncontext) pairs.\n\n    \n    \n    from llama_index.finetuning import (\n        generate_qa_embedding_pairs,\n        EmbeddingQAFinetuneDataset,\n    )\n    \n    # generate\n    train_dataset = generate_qa_embedding_pairs(train_nodes)\n    val_dataset = generate_qa_embedding_pairs(val_nodes)\n    \n    # save\n    train_dataset.save_json(\"train_dataset.json\")\n    val_dataset.save_json(\"val_dataset.json\")\n    \n    # load \n    train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n    val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")", "mimetype": "text/plain", "start_char_idx": 5160, "end_char_idx": 6012, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4cc11d1c-7d33-49b2-9068-367bb5e5ecaf": {"__data__": {"id_": "4cc11d1c-7d33-49b2-9068-367bb5e5ecaf", "embedding": null, "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Fine-tuning our Linear Adapter", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b76f0ee-47d3-4b7b-8f15-389aad75b02d", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Generate a Synthetic Dataset for Trraining and Evaluation", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "727e3b3292cfeda0b731f2c98ca12434b2044fb7bb37205efa6a52dbd2278840", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d407761-167f-49aa-862a-3ec9749da6fb", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Getting the Embedding Model, and Evaluating it"}, "hash": "72c336374b2fe7475afa0afd3ee7841cb4c2dcbfccb003c0c0442ee8cd120e1e", "class_name": "RelatedNodeInfo"}}, "text": "Fine-tuning our Linear Adapter\n\nWe then fine-tune our linear adapter on top of an existing embedding model. We\nimport our new ` EmbeddingAdapterFinetuneEngine ` abstraction, which takes in\nan existing embedding model and a set of training parameters.\n\nIn this example we use the ` bge-small-en ` sentence-transformers model, but\nwe can also use any embedding model in LlamaIndex/LangChain.\n\n    \n    \n    from llama_index.finetuning import EmbeddingAdapterFinetuneEngine\n    from llama_index.embeddings import resolve_embed_model\n    import torch\n    \n    base_embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n    # alternative: use OpenAI\n    # from llama_index.embeddings import OpenAIEmbedding\n    # openai = OpenAIEmbedding()\n    \n    finetune_engine = EmbeddingAdapterFinetuneEngine(\n        train_dataset,\n        base_embed_model,\n        model_output_path=\"&lt;model_output_path&gt;\",\n        epochs=4,\n        verbose=True,\n        # can optionally pass along any parameters that go into `train_model`\n        # optimizer_class=torch.optim.SGD,\n        # optimizer_params={\"lr\": 0.01}\n    )\n\nWe can then call fine-tune to kick off the fine-tuning job. Training a linear\nmodel is quite straightforward and doesn\u2019t require heavy machinery \u2014 this can\neasily run on a Macbook.\n\n    \n    \n    finetune_engine.finetune()", "mimetype": "text/plain", "start_char_idx": 6018, "end_char_idx": 7353, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9d407761-167f-49aa-862a-3ec9749da6fb": {"__data__": {"id_": "9d407761-167f-49aa-862a-3ec9749da6fb", "embedding": null, "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Getting the Embedding Model, and Evaluating it", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4cc11d1c-7d33-49b2-9068-367bb5e5ecaf", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Fine-tuning our Linear Adapter", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "d61eaa338d68ce4c94c2e24399321dcac73a0e1b4eab8e6ac6aff07a59cc7fb7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ac50f4ce-c979-431b-b8f9-fe0618cff0a9", "node_type": "1", "metadata": {"Header_1": " Conclusion"}, "hash": "34440071751ae7131faa55f161e0d5da3239225d3cba8aee7501e79762dae61c", "class_name": "RelatedNodeInfo"}}, "text": "Getting the Embedding Model, and Evaluating it\n\nOnce the fine-tuning job is then, we can then fetch our embedding model.\n\nWe can either directly fetch it from our ` finetune_engine ` , or import our\nnew ` LinearAdapterEmbeddingModel ` and construct it in a more manual fashion.\n\nOption 1:\n\n    \n    \n    embed_model = finetune_engine.get_finetuned_model()\n\nOption 2:\n\n    \n    \n    from llama_index.embeddings import LinearAdapterEmbeddingModel\n    \n    embed_model = LinearAdapterEmbeddingModel(base_embed_model, \"&lt;model_output_path&gt;\")\n\nThe next step is to evaluate it. We compare the fine-tuned model against the\nbase model, as well as against ` text-embedding-ada-002 ` .\n\nWe evaluate with two ranking metrics:\n\n  * **Hit-rate metric:** For each (query, context) pair, we retrieve the top-k documents with the query. It\u2019s a _hit_ if the results contain the ground-truth context. \n  * **Mean Reciprocal Rank** : A slightly more granular ranking metric that looks at the \u201creciprocal rank\u201d of the ground-truth context in the top-k retrieved set. The reciprocal rank is defined as 1/rank. Of course, if the results don\u2019t contain the context, then the reciprocal rank is 0. \n\nSome additional comments:\n\n  * We ran with 4 epochs over the Lyft documents \n  * We used Adam as an optimizer with the default learning rate (we tried SGD and it didn\u2019t work as well) \n\n**Results**\n\nQuantiative metrics (hit-rate and MRR) for ada, bge, and our fine-tuned model\n\nIn terms of hit-rate, the base model gets 78.7% hit-rate on the validation\ndataset, and the fine-tuned model gets 79.8%. In the meantime ` text-\nembedding-ada-002 ` gets 87.0%.\n\nIn terms of MRR, the base model gets 64.3%, and the fine-tuned model gets 66%.\n` text-embedding-ada-002 ` gets 68.4%.\n\nThere is some performance bump from the fine-tuned model, though admittedly it\nis small \u2014 it is smaller than the performance bump gained through fine-tuning\nsentence_transformers directly on the latest dataset.\n\nThat said, a performance bump is still a performance bump, and it\u2019s very cheap\nfor you to spin up and try yourself! So you can decide whether or not this\nwould make sense for you.", "mimetype": "text/plain", "start_char_idx": 7359, "end_char_idx": 9504, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ac50f4ce-c979-431b-b8f9-fe0618cff0a9": {"__data__": {"id_": "ac50f4ce-c979-431b-b8f9-fe0618cff0a9", "embedding": null, "metadata": {"Header_1": " Conclusion", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d407761-167f-49aa-862a-3ec9749da6fb", "node_type": "1", "metadata": {"Header_1": " Notebook Walkthrough", "Header_2": " Getting the Embedding Model, and Evaluating it", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "9520c41ff81f1efa61a0b60c97b9510249c588526c813f894fc58b8e5546f771", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54715b6c-4b4e-410f-81cb-d6d2d0d83be5", "node_type": "1", "metadata": {"Header_1": " Conclusion", "Header_2": " Resources"}, "hash": "77a48dc6d8cf4d1198aaef8a57327eba15b05f785c0c91db49edcb32f6b52675", "class_name": "RelatedNodeInfo"}}, "text": "Conclusion\n\nWe created a brand-new module in LlamaIndex that allows you fine-tune a linear\nadapter on top of any embedding model.\n\nIt can help you eke out some marginal improvement in retrieval metrics;\nimportantly, it allows you to keep document embeddings fixed and only\ntransform the query.", "mimetype": "text/plain", "start_char_idx": 9509, "end_char_idx": 9802, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54715b6c-4b4e-410f-81cb-d6d2d0d83be5": {"__data__": {"id_": "54715b6c-4b4e-410f-81cb-d6d2d0d83be5", "embedding": null, "metadata": {"Header_1": " Conclusion", "Header_2": " Resources", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "10b8a67e-1881-4c14-b1d2-174994d397e4", "node_type": "4", "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "c4917863fa86a62af2a02e0254bd75cf2bf169b6fdc8c51524e182cede9c9015", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac50f4ce-c979-431b-b8f9-fe0618cff0a9", "node_type": "1", "metadata": {"Header_1": " Conclusion", "filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}, "hash": "81dd2b62d06fba2cf6c8d2fbbef6168445f021b3a78001a0ea1bfd06bce77206", "class_name": "RelatedNodeInfo"}}, "text": "Resources\n\nGuide: [ https://gpt-\nindex.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding_adapter.html\n](https://gpt-\nindex.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding_adapter.html)\n\nTraining code (if you want to take a look for yourself): [\nhttps://github.com/jerryjliu/llama_index/blob/main/llama_index/finetuning/embeddings/adapter_utils.py\n](https://github.com/jerryjliu/llama_index/blob/main/llama_index/finetuning/embeddings/adapter_utils.py)", "mimetype": "text/plain", "start_char_idx": 9808, "end_char_idx": 10311, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"5fa414c6-0bc8-4975-9e67-4baa2bcbc196": {"doc_hash": "4b88f33ac653c801e44660dbe8d7c7afc060c03e4cf14d180129e1845e55795a", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "fc434ea6-8d78-4291-8150-34d17e8dd81f": {"doc_hash": "78afae966d6c132f323be2afc15a4faba383cf8c45a4805e257ee48ef4b0855b", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "39e8667e-ed85-4919-9fea-23ed53ce57eb": {"doc_hash": "ffbd1bb147097246339dbf7ee4bba860aefb47ffaf32f58f755916f0a1318884", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "b368a52a-6eeb-4901-9f92-8c397ed66203": {"doc_hash": "5f2b2eaba79ad338f413fb8198d732fc7bbab4276eaac091bccb8d3e9646827d", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "abb8f649-4b8a-4a78-adcb-a40a988d480e": {"doc_hash": "9639b3c64f5d2e1cc686426e3f71c34cc3d405240c34b783b615bf57d483f05d", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "0b76f0ee-47d3-4b7b-8f15-389aad75b02d": {"doc_hash": "727e3b3292cfeda0b731f2c98ca12434b2044fb7bb37205efa6a52dbd2278840", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "4cc11d1c-7d33-49b2-9068-367bb5e5ecaf": {"doc_hash": "d61eaa338d68ce4c94c2e24399321dcac73a0e1b4eab8e6ac6aff07a59cc7fb7", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "9d407761-167f-49aa-862a-3ec9749da6fb": {"doc_hash": "9520c41ff81f1efa61a0b60c97b9510249c588526c813f894fc58b8e5546f771", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "ac50f4ce-c979-431b-b8f9-fe0618cff0a9": {"doc_hash": "81dd2b62d06fba2cf6c8d2fbbef6168445f021b3a78001a0ea1bfd06bce77206", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}, "54715b6c-4b4e-410f-81cb-d6d2d0d83be5": {"doc_hash": "62d61d359d78ba286557a293ca799f450acec9c7f301e7d8db763840c415f3cf", "ref_doc_id": "10b8a67e-1881-4c14-b1d2-174994d397e4"}}, "docstore/ref_doc_info": {"10b8a67e-1881-4c14-b1d2-174994d397e4": {"node_ids": ["5fa414c6-0bc8-4975-9e67-4baa2bcbc196", "fc434ea6-8d78-4291-8150-34d17e8dd81f", "39e8667e-ed85-4919-9fea-23ed53ce57eb", "b368a52a-6eeb-4901-9f92-8c397ed66203", "abb8f649-4b8a-4a78-adcb-a40a988d480e", "0b76f0ee-47d3-4b7b-8f15-389aad75b02d", "4cc11d1c-7d33-49b2-9068-367bb5e5ecaf", "9d407761-167f-49aa-862a-3ec9749da6fb", "ac50f4ce-c979-431b-b8f9-fe0618cff0a9", "54715b6c-4b4e-410f-81cb-d6d2d0d83be5"], "metadata": {"filename": "fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383.md", "extension": ".md", "title": "Fine-Tuning a Linear Adapter for Any Embedding Model", "date": "Sep 6, 2023", "url": "https://www.llamaindex.ai/blog/fine-tuning-a-linear-adapter-for-any-embedding-model-8dd0a142d383"}}}}