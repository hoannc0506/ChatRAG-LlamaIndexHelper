{"docstore/data": {"f9001329-ec04-4b55-9c56-33d202fdad70": {"__data__": {"id_": "f9001329-ec04-4b55-9c56-33d202fdad70", "embedding": null, "metadata": {"Header_1": " Introduction:", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5084c453-dee4-4102-95bd-a755013d2d20", "node_type": "1", "metadata": {"Header_1": " Setting Up the Environment"}, "hash": "7fe9613d7ff42bb3991e816ef98f1b0d2ee57bc42ee46dac6f53c17dcd60777a", "class_name": "RelatedNodeInfo"}}, "text": "Introduction:\n\nAchieving an efficient Retrieval-Augmented-Generation (RAG) pipeline is\nheavily dependent on robust retrieval performance. As we explored in our\nprevious [ blog post ](https://medium.com/llamaindex-blog/boosting-rag-\npicking-the-best-embedding-reranker-models-42d079022e83) , rerankers have a\nsignificant impact on boosting retrieval performance. But what if we could\ntake it a step further? What if our reranker was not just any reranker, but\none tuned specifically to our domain or dataset? Could this specialization\nenhance the retrieval performance even more?\n\nTo answer these questions, we turn to CohereAI\u2019s beta release of fine-tuning\nreranker(Custom reranker) models. By integrating these with LlamaIndex, we now\noffer the ability to build your very own Cohere custom reranker using our\nstreamlined process.\n\nIn this blog post, we\u2019ll guide you through the steps to create a Cohere custom\nreranker with LlamaIndex and evaluate the retrieval performance.\n\nFor a hands-on walkthrough, you can follow the tutorial on [ Google Colab\nNotebook ](https://colab.research.google.com/github/run-\nllama/llama_index/blob/main/docs/examples/finetuning/rerankers/cohere_custom_reranker.ipynb)\n.\n\nLet\u2019s start fine-tuning a Cohere reranker (custom reranker) with LlamaIndex.\n\n> N  OTE: This is a guide for fine-tuning a Cohere reranker (custom reranker).\n> The results presented at the end of this tutorial are unique to the chosen\n> dataset and parameters. We suggest experimenting with your dataset and\n> various parameters before deciding to incorporate it into your RAG pipeline.", "mimetype": "text/plain", "start_char_idx": 3, "end_char_idx": 1592, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5084c453-dee4-4102-95bd-a755013d2d20": {"__data__": {"id_": "5084c453-dee4-4102-95bd-a755013d2d20", "embedding": null, "metadata": {"Header_1": " Setting Up the Environment", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f9001329-ec04-4b55-9c56-33d202fdad70", "node_type": "1", "metadata": {"Header_1": " Introduction:", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "d97b89b39100fd7b045e39bbf0ac17fff20b72674c8590f17c40a108311fad4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb91b657-f421-4eed-af07-d809d22df2f3", "node_type": "1", "metadata": {"Header_1": " Setting Up the Keys"}, "hash": "7e451566db3f72c99383c6c369a0b8b7b8abeab2e0d4c32d33b89709fde3b41e", "class_name": "RelatedNodeInfo"}}, "text": "Setting Up the Environment\n\n    \n    \n    !pip install llama-index cohere pypdf", "mimetype": "text/plain", "start_char_idx": 1597, "end_char_idx": 1676, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eb91b657-f421-4eed-af07-d809d22df2f3": {"__data__": {"id_": "eb91b657-f421-4eed-af07-d809d22df2f3", "embedding": null, "metadata": {"Header_1": " Setting Up the Keys", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5084c453-dee4-4102-95bd-a755013d2d20", "node_type": "1", "metadata": {"Header_1": " Setting Up the Environment", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "4c8289b9608a35df3c255d4ca38f27ccca73d3911e01f77ade9a1a637ec34c6d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "79fab4ce-42de-4b7f-b6d6-c3985780d258", "node_type": "1", "metadata": {"Header_1": " Download the Data"}, "hash": "9cacf49a872844b03d472de7bf67bfd85ae14fc31dc1049da21c23173228110a", "class_name": "RelatedNodeInfo"}}, "text": "Setting Up the Keys\n\n    \n    \n    openai_api_key = 'YOUR OPENAI API KEY'\n    cohere_api_key = 'YOUR COHEREAI API KEY'\n    \n    import os\n    \n    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n    os.environ[\"COHERE_API_KEY\"] = cohere_api_key", "mimetype": "text/plain", "start_char_idx": 1681, "end_char_idx": 1923, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "79fab4ce-42de-4b7f-b6d6-c3985780d258": {"__data__": {"id_": "79fab4ce-42de-4b7f-b6d6-c3985780d258", "embedding": null, "metadata": {"Header_1": " Download the Data", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb91b657-f421-4eed-af07-d809d22df2f3", "node_type": "1", "metadata": {"Header_1": " Setting Up the Keys", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "f8e3829cd7d432670bcbc75abaa1b7366518af129e0bfcd3788a6345c1d7af47", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1ef407b7-694e-4694-a434-73a11ce5d71f", "node_type": "1", "metadata": {"Header_1": " Load the Data"}, "hash": "499752520405411ee37ac68bd1f37b46f41101c40299056652ae04e9daa0eafa", "class_name": "RelatedNodeInfo"}}, "text": "Download the Data\n\nWe will use Lyft 2021 10K SEC Filings for training and Uber 2021 10K SEC\nFilings for evaluation.\n\n    \n    \n    !mkdir -p 'data/10k/'\n    !wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'\n    !wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf' -O 'data/10k/lyft_2021.pdf'", "mimetype": "text/plain", "start_char_idx": 1928, "end_char_idx": 2356, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1ef407b7-694e-4694-a434-73a11ce5d71f": {"__data__": {"id_": "1ef407b7-694e-4694-a434-73a11ce5d71f", "embedding": null, "metadata": {"Header_1": " Load the Data", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "79fab4ce-42de-4b7f-b6d6-c3985780d258", "node_type": "1", "metadata": {"Header_1": " Download the Data", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "a9a3922c755a109592a3d1bd1d438853f33bd79a92ea4bf407f4c4adb3d6d4f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "46631af0-41c6-4a4f-872e-3e8a04d02b79", "node_type": "1", "metadata": {"Header_1": " Data Curation"}, "hash": "fbee7d558aca86178bd804f33309a87e486a5e63064c32ea9fa21cde60ab59e8", "class_name": "RelatedNodeInfo"}}, "text": "Load the Data\n\n    \n    \n    lyft_docs = SimpleDirectoryReader(input_files=['./data/10k/lyft_2021.pdf']).load_data()\n    uber_docs = SimpleDirectoryReader(input_files=['./data/10k/uber_2021.pdf']).load_data()", "mimetype": "text/plain", "start_char_idx": 2361, "end_char_idx": 2569, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "46631af0-41c6-4a4f-872e-3e8a04d02b79": {"__data__": {"id_": "46631af0-41c6-4a4f-872e-3e8a04d02b79", "embedding": null, "metadata": {"Header_1": " Data Curation", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1ef407b7-694e-4694-a434-73a11ce5d71f", "node_type": "1", "metadata": {"Header_1": " Load the Data", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "952f3ca1faa127af064e3904ce2d6e73d71c1b0a233dde23527d9c12fa2879b6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "311af6b9-1639-45a8-afb0-1971dc10aec3", "node_type": "1", "metadata": {"Header_1": " Data Format and Requirements"}, "hash": "7f75596ffa2ca888fecff6b0a7fef6522b3c2bfca7e014ad2ea6841f06200aba", "class_name": "RelatedNodeInfo"}}, "text": "Data Curation\n\n**Create Nodes.**\n\nThe [ documentation ](https://docs.cohere.com/docs/rerank-models) mentions\nthat Query + Relevant Passage/ Query + Hard Negatives should be less than 510\ntokens. To accommodate that we limit ` chunk_size ` to 400 tokens. (Each chunk\nwill eventually be treated as a Relevant Passage/ Hard Negative)\n\n    \n    \n    # Limit chunk size to 400\n    node_parser = SimpleNodeParser.from_defaults(chunk_size=400)\n    \n    # Create nodes\n    lyft_nodes = node_parser.get_nodes_from_documents(lyft_docs)\n    uber_nodes = node_parser.get_nodes_from_documents(uber_docs)\n\nWe will use gpt-4 to create questions from chunks.\n\n    \n    \n    llm = OpenAI(api_key=openai_api_key, temperature=0, model='gpt-4')\n\nPrompt to generate questions from each Node/ chunk.\n\n    \n    \n    # Prompt to generate questions\n    qa_generate_prompt_tmpl = \"\"\"\\\n    Context information is below.\n    \n    ---------------------\n    {context_str}\n    ---------------------\n    \n    Given the context information and not prior knowledge.\n    generate only questions based on the below query.\n    \n    You are a Professor. Your task is to setup \\\n    {num_questions_per_chunk} questions for an upcoming \\\n    quiz/examination. The questions should be diverse in nature \\\n    across the document. The questions should not contain options, not start with Q1/ Q2. \\\n    Restrict the questions to the context information provided.\\\n    \"\"\"\n\nIt expects a minimum of 256 (Query + Relevant passage) pairs with or without\nhard negatives for training and 64 pairs for validation. Please note that the\nvalidation is optional.\n\n**Training:** We use the first 256 nodes from Lyft for creating training\npairs.\n\n**Validation:** We will use the next 64 nodes from Lyft for validation.\n\n**Testing:** We will use the first 150 nodes from Uber.\n\n    \n    \n    # Training dataset\n    qa_dataset_lyft_train = generate_question_context_pairs(\n        lyft_nodes[:256], llm=llm, num_questions_per_chunk=1, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl\n    )\n    \n    # Save [Optional]\n    qa_dataset_lyft_train.save_json(\"lyft_train_dataset.json\")\n    \n    # Validation dataset\n    qa_dataset_lyft_val = generate_question_context_pairs(\n        lyft_nodes[257:321], llm=llm, num_questions_per_chunk=1, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl\n    )\n    \n    # Save [Optional]\n    qa_dataset_lyft_val.save_json(\"lyft_val_dataset.json\")\n    \n    # Testing dataset\n    qa_dataset_uber_val = generate_question_context_pairs(\n        uber_nodes[:150], llm=llm, num_questions_per_chunk=1, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl\n    )\n    \n    # Save [Optional]\n    qa_dataset_uber_val.save_json(\"uber_val_dataset.json\")\n\nNow that we have compiled questions from each chunk, we will format the data\naccording to the specifications required for training and validation.", "mimetype": "text/plain", "start_char_idx": 2574, "end_char_idx": 5424, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "311af6b9-1639-45a8-afb0-1971dc10aec3": {"__data__": {"id_": "311af6b9-1639-45a8-afb0-1971dc10aec3", "embedding": null, "metadata": {"Header_1": " Data Format and Requirements", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46631af0-41c6-4a4f-872e-3e8a04d02b79", "node_type": "1", "metadata": {"Header_1": " Data Curation", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "9cda0deb902154478765db2dea5bf750aaede464ea5480df3c2dee3398bf8b8b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc83353b-56a8-4d6e-b365-b1898b2b27a1", "node_type": "1", "metadata": {"Header_1": " Fine-tuning Reranker (Custom Reranker)"}, "hash": "6dd0a5ba0ae09c2e4ae51a86ccb1909929e96cd403621376657b6612af511fcb", "class_name": "RelatedNodeInfo"}}, "text": "Data Format and Requirements\n\nFor both training and validation, it currently accepts data in the format of\ntriplets, every row should have the following\n\n**query:** This represents the question or target.\n\n**relevant_passages:** This represents a list of documents or passages that\ncontain information that answers the query. For every query, there must be at\nleast one relevant_passage\n\n**hard_negatives:** This represents chunks or passages that don\u2019t contain\nanswers for the query. It should be noted that Hard negatives are optional but\nproviding at least ~5 hard negatives will lead to meaningful improvement.\n\nYou can check the [ documentation ](https://docs.cohere.com/docs/rerank-\nmodels) for more details.\n\nWe need to have an embedding model for creating hard negatives with a cosine\nsimilarity approach.\n\n    \n    \n    # Initialize the Cohere embedding model which we use it for creating Hard Negatives.\n    embed_model = CohereEmbedding(\n        cohere_api_key=cohere_api_key,\n        model_name=\"embed-english-v3.0\",\n        input_type=\"search_document\",\n    )\n\nLet\u2019s create 3 datasets.\n\n  1. Dataset without hard negatives. \n  2. Dataset with hard negatives selected at random. \n  3. Dataset with hard negatives selected based on cosine similarity. \n\n    \n    \n    # Train and val datasets without hard negatives.\n    generate_cohere_reranker_finetuning_dataset(\n        qa_dataset_lyft_train,\n        finetune_dataset_file_name = \"train.jsonl\"\n    )\n    \n    generate_cohere_reranker_finetuning_dataset(\n        qa_dataset_lyft_val,\n        finetune_dataset_file_name = \"val.jsonl\"\n    )\n    \n    # Train and val datasets with hard negatives selected at random.\n    generate_cohere_reranker_finetuning_dataset(\n        qa_dataset_lyft_train,\n        num_negatives = 5,\n        hard_negatives_gen_method = \"random\",\n        finetune_dataset_file_name = \"train_5_random.jsonl\",\n        embed_model = embed_model,\n    )\n    \n    generate_cohere_reranker_finetuning_dataset(\n        qa_dataset_lyft_val,\n        num_negatives = 5,\n        hard_negatives_gen_method = \"random\",\n        finetune_dataset_file_name = \"val_5_random.jsonl\",\n        embed_model = embed_model,\n    )\n    \n    # Train and val datasets with hard negatives selected based on cosine similarity.\n    generate_cohere_reranker_finetuning_dataset(\n        qa_dataset_lyft_train,\n        num_negatives = 5,\n        hard_negatives_gen_method = \"cosine_similarity\",\n        finetune_dataset_file_name = \"train_5_cosine_similarity.jsonl\",\n        embed_model = embed_model,\n    )\n    \n    generate_cohere_reranker_finetuning_dataset(\n        qa_dataset_lyft_val,\n        num_negatives = 5,\n        hard_negatives_gen_method = \"cosine_similarity\",\n        finetune_dataset_file_name = \"val_5_cosine_similarity.jsonl\",\n        embed_model = embed_model,\n    )", "mimetype": "text/plain", "start_char_idx": 5429, "end_char_idx": 8261, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dc83353b-56a8-4d6e-b365-b1898b2b27a1": {"__data__": {"id_": "dc83353b-56a8-4d6e-b365-b1898b2b27a1", "embedding": null, "metadata": {"Header_1": " Fine-tuning Reranker (Custom Reranker)", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "311af6b9-1639-45a8-afb0-1971dc10aec3", "node_type": "1", "metadata": {"Header_1": " Data Format and Requirements", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "d44d87799ccb197e11dd73cfb21bd1dd33a6a3b9904f23de51fe98618f78feb0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e5cffeb3-2af6-414f-b419-d00bb6b873ea", "node_type": "1", "metadata": {"Header_1": " Testing"}, "hash": "8a562ad5dd4071d1a12d5b739f0efa4bb4387e4825671b7dd31b40263e91c720", "class_name": "RelatedNodeInfo"}}, "text": "Fine-tuning Reranker (Custom Reranker)\n\nWith our training and validation datasets ready, we\u2019re set to proceed with the\ntraining process. Be aware that this training is expected to take\napproximately 25 to 45 minutes.\n\n    \n    \n    # Reranker model with 0 hard negatives.\n    finetune_model_no_hard_negatives = CohereRerankerFinetuneEngine(\n        train_file_name=\"train.jsonl\",\n        val_file_name=\"val.jsonl\",\n        model_name=\"lyft_reranker_0_hard_negatives1\",\n        model_type=\"RERANK\",\n        base_model=\"english\",\n        api_key = cohere_api_key\n    )\n    finetune_model_no_hard_negatives.finetune()\n    \n    # Reranker model with 5 hard negatives selected at random\n    finetune_model_random_hard_negatives = CohereRerankerFinetuneEngine(\n        train_file_name=\"train_5_random.jsonl\",\n        val_file_name=\"val_5_random.jsonl\",\n        model_name=\"lyft_reranker_5_random_hard_negatives1\",\n        model_type=\"RERANK\",\n        base_model=\"english\",\n    )\n    finetune_model_random_hard_negatives.finetune()\n    \n    # Reranker model with 5 hard negatives selected based on cosine similarity\n    finetune_model_cosine_hard_negatives = CohereRerankerFinetuneEngine(\n        train_file_name=\"train_5_cosine_similarity.jsonl\",\n        val_file_name=\"val_5_cosine_similarity.jsonl\",\n        model_name=\"lyft_reranker_5_cosine_hard_negatives1\",\n        model_type=\"RERANK\",\n        base_model=\"english\",\n    )\n    finetune_model_cosine_hard_negatives.finetune()\n\nOnce the jobs are submitted, you can check the training status in the ` models\n` section of the [ dashboard ](https://dashboard.cohere.com/models) . You can\ncheck the status of the job in the dashboard and you should see an image\nsomething similar to the following one.\n\nYou then need to get the Cohere Reranker model for testing.\n\n    \n    \n    reranker_base = CohereRerank(top_n=5)\n    reranker_model_0 = finetune_model_no_hard_negatives.get_finetuned_model(\n        top_n=5\n    )\n    reranker_model_5_random = (\n        finetune_model_random_hard_negatives.get_finetuned_model(top_n=5)\n    )\n    reranker_model_5_cosine = (\n        finetune_model_cosine_hard_negatives.get_finetuned_model(top_n=5)\n    )", "mimetype": "text/plain", "start_char_idx": 8266, "end_char_idx": 10447, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e5cffeb3-2af6-414f-b419-d00bb6b873ea": {"__data__": {"id_": "e5cffeb3-2af6-414f-b419-d00bb6b873ea", "embedding": null, "metadata": {"Header_1": " Testing", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc83353b-56a8-4d6e-b365-b1898b2b27a1", "node_type": "1", "metadata": {"Header_1": " Fine-tuning Reranker (Custom Reranker)", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "331fd5a4bba630e4e9f5ee5a7c78d0a3fd138628f1d69cf35df7c028a10f4ed6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b30d0eea-5547-465e-9397-de2ff330f556", "node_type": "1", "metadata": {"Header_1": " Results:"}, "hash": "32cae22452ca719a15ce6c9dcde2fdbbe20a78e8e9cc89ee99627cf5afd9d02a", "class_name": "RelatedNodeInfo"}}, "text": "Testing\n\nWe will conduct tests on the first 150 nodes from Uber using the following\ndifferent rerankers.\n\n  1. Without Reranker. \n  2. Cohere Reranker. \n  3. Fine-tuned reranker (Custom reranker) without hard negatives. \n  4. Fine-tuned reranker (Custom reranker) with hard negatives selected at random. \n  5. Fine-tuned reranker (Custom reranker) with hard negatives selected based on cosine similarity. \n\nLet\u2019s define the rerankers.\n\n    \n    \n    RERANKERS = {\n        \"WithoutReranker\": \"None\",\n        \"CohereRerank\": reranker_base,\n        \"CohereRerank_0\": reranker_model_0,\n        \"CohereRerank_5_random\": reranker_model_5_random,\n        \"CohereRerank_5_cosine\": reranker_model_5_cosine,\n    }\n\nCreate an Index and Retriever for evaluation purposes.\n\n    \n    \n    # Initialize the Cohere embedding model, `input_type` is different for indexing and retrieval.\n    index_embed_model = CohereEmbedding(\n        cohere_api_key=cohere_api_key,\n        model_name=\"embed-english-v3.0\",\n        input_type=\"search_document\",\n    )\n    \n    query_embed_model = CohereEmbedding(\n        cohere_api_key=cohere_api_key,\n        model_name=\"embed-english-v3.0\",\n        input_type=\"search_query\",\n    )\n    \n    service_context_index = ServiceContext.from_defaults(llm=None, embed_model=index_embed_model)\n    service_context_query = ServiceContext.from_defaults(llm=None, embed_model=query_embed_model)\n    \n    vector_index = VectorStoreIndex(uber_nodes[:150], service_context=service_context_index)\n    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=10, service_context=service_context_query)\n\nDefine a function to display the results\n\n    \n    \n    def display_results(embedding_name, reranker_name, eval_results):\n        \"\"\"Display results from evaluate.\"\"\"\n    \n        metric_dicts = []\n        for eval_result in eval_results:\n            metric_dict = eval_result.metric_vals_dict\n            metric_dicts.append(metric_dict)\n    \n        full_df = pd.DataFrame(metric_dicts)\n    \n        hit_rate = full_df[\"hit_rate\"].mean()\n        mrr = full_df[\"mrr\"].mean()\n    \n        metric_df = pd.DataFrame(\n            {\"Embedding\": [embedding_name], \"Reranker\": [reranker_name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}\n        )\n    \n        return metric_df\n\nLoop over different rerankers and evaluate retrieval performance using Custom\nRetriever.\n\n    \n    \n    results_df = pd.DataFrame()\n    \n    embed_name = 'CohereEmbedding'\n    \n    # Loop over rerankers\n    for rerank_name, reranker in RERANKERS.items():\n    \n        print(f\"Running Evaluation for Reranker: {rerank_name}\")\n    \n        # Define Retriever\n        class CustomRetriever(BaseRetriever):\n            \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n    \n            def __init__(\n                self,\n                vector_retriever: VectorIndexRetriever,\n            ) -&gt; None:\n                \"\"\"Init params.\"\"\"\n    \n                self._vector_retriever = vector_retriever\n    \n            def _retrieve(self, query_bundle: QueryBundle) -&gt; List[NodeWithScore]:\n                \"\"\"Retrieve nodes given query.\"\"\"\n    \n                retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\n    \n                if reranker != 'None':\n                    retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\n                else:\n                    retrieved_nodes = retrieved_nodes[:5]\n    \n                return retrieved_nodes\n    \n            async def _aretrieve(self, query_bundle: QueryBundle) -&gt; List[NodeWithScore]:\n                \"\"\"Asynchronously retrieve nodes given query.\n                \"\"\"\n                return self._retrieve(query_bundle)\n    \n            async def aretrieve(self, str_or_query_bundle: QueryType) -&gt; List[NodeWithScore]:\n                if isinstance(str_or_query_bundle, str):\n                    str_or_query_bundle = QueryBundle(str_or_query_bundle)\n                return await self._aretrieve(str_or_query_bundle)\n    \n        custom_retriever = CustomRetriever(vector_retriever)\n    \n        retriever_evaluator = RetrieverEvaluator.from_metric_names(\n            [\"mrr\", \"hit_rate\"], retriever=custom_retriever\n        )\n        eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset_uber_val)\n    \n        current_df = display_results(embed_name, rerank_name, eval_results)\n        results_df = pd.concat([results_df, current_df], ignore_index=True)", "mimetype": "text/plain", "start_char_idx": 10452, "end_char_idx": 14951, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b30d0eea-5547-465e-9397-de2ff330f556": {"__data__": {"id_": "b30d0eea-5547-465e-9397-de2ff330f556", "embedding": null, "metadata": {"Header_1": " Results:", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5cffeb3-2af6-414f-b419-d00bb6b873ea", "node_type": "1", "metadata": {"Header_1": " Testing", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6627fd5d69d2982a387286fc5374eeb2f3b41f448d2d171c319dd2a0e075fc68", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f23d9e9c-d4e1-4dd5-ad44-5cb905d143a8", "node_type": "1", "metadata": {"Header_1": " Summary:"}, "hash": "2f0f8c6eabb5fe167264664c86c125eaea5f6fb60f811b3cbe91a237d6aef806", "class_name": "RelatedNodeInfo"}}, "text": "Results:\n\nFrom the above table (1- without reranker, 2 \u2014 with base cohere reranker, 3\u20135:\nFine-tuned rerankers (Custom rerankers)), we can see that the Fine-tuned\nrerankers (custom rerankers) have resulted in performance improvements. It\u2019s\ncrucial to note that the choice of the optimal number of hard negatives, as\nwell as the decision between random or cosine sampling, should be grounded in\nempirical evidence. This guide offers a structured approach for improving\nretrieval systems through the fine-tuning of the Cohere re-ranker.", "mimetype": "text/plain", "start_char_idx": 14956, "end_char_idx": 15489, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f23d9e9c-d4e1-4dd5-ad44-5cb905d143a8": {"__data__": {"id_": "f23d9e9c-d4e1-4dd5-ad44-5cb905d143a8", "embedding": null, "metadata": {"Header_1": " Summary:", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8", "node_type": "4", "metadata": {"filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "6d9d6d197d824d8a61003850fc5abc390ae6b815231ef8cfcb4808c136c4aa38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b30d0eea-5547-465e-9397-de2ff330f556", "node_type": "1", "metadata": {"Header_1": " Results:", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}, "hash": "f42edfd3ecb6b7fd5978b9268de876689bcb701c8e4f67ed6bd88b2183adb8eb", "class_name": "RelatedNodeInfo"}}, "text": "Summary:\n\nIn this blog post, we\u2019ve demonstrated fine-tuning a Cohere reranker (custom\nreranker) using LlamaIndex, which has improved retrieval performance metrics.\nWe eagerly anticipate the community\u2019s use of these abilities to boost their\nretrieval efficiency within RAG pipelines. Additionally, there is room for\nadvancement in selecting hard negatives, and we invite the community to\ncontribute.", "mimetype": "text/plain", "start_char_idx": 15494, "end_char_idx": 15892, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"f9001329-ec04-4b55-9c56-33d202fdad70": {"doc_hash": "d97b89b39100fd7b045e39bbf0ac17fff20b72674c8590f17c40a108311fad4c", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "5084c453-dee4-4102-95bd-a755013d2d20": {"doc_hash": "4c8289b9608a35df3c255d4ca38f27ccca73d3911e01f77ade9a1a637ec34c6d", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "eb91b657-f421-4eed-af07-d809d22df2f3": {"doc_hash": "f8e3829cd7d432670bcbc75abaa1b7366518af129e0bfcd3788a6345c1d7af47", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "79fab4ce-42de-4b7f-b6d6-c3985780d258": {"doc_hash": "a9a3922c755a109592a3d1bd1d438853f33bd79a92ea4bf407f4c4adb3d6d4f5", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "1ef407b7-694e-4694-a434-73a11ce5d71f": {"doc_hash": "952f3ca1faa127af064e3904ce2d6e73d71c1b0a233dde23527d9c12fa2879b6", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "46631af0-41c6-4a4f-872e-3e8a04d02b79": {"doc_hash": "9cda0deb902154478765db2dea5bf750aaede464ea5480df3c2dee3398bf8b8b", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "311af6b9-1639-45a8-afb0-1971dc10aec3": {"doc_hash": "d44d87799ccb197e11dd73cfb21bd1dd33a6a3b9904f23de51fe98618f78feb0", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "dc83353b-56a8-4d6e-b365-b1898b2b27a1": {"doc_hash": "331fd5a4bba630e4e9f5ee5a7c78d0a3fd138628f1d69cf35df7c028a10f4ed6", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "e5cffeb3-2af6-414f-b419-d00bb6b873ea": {"doc_hash": "6627fd5d69d2982a387286fc5374eeb2f3b41f448d2d171c319dd2a0e075fc68", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "b30d0eea-5547-465e-9397-de2ff330f556": {"doc_hash": "f42edfd3ecb6b7fd5978b9268de876689bcb701c8e4f67ed6bd88b2183adb8eb", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}, "f23d9e9c-d4e1-4dd5-ad44-5cb905d143a8": {"doc_hash": "6e7c038fad9c000cd14c3da48c510593bdd0a44e3eb3ad2b9c69ce7bf8f4c26e", "ref_doc_id": "c4c4ccef-b058-4bbe-8b4a-599d55a776b8"}}, "docstore/ref_doc_info": {"c4c4ccef-b058-4bbe-8b4a-599d55a776b8": {"node_ids": ["f9001329-ec04-4b55-9c56-33d202fdad70", "5084c453-dee4-4102-95bd-a755013d2d20", "eb91b657-f421-4eed-af07-d809d22df2f3", "79fab4ce-42de-4b7f-b6d6-c3985780d258", "1ef407b7-694e-4694-a434-73a11ce5d71f", "46631af0-41c6-4a4f-872e-3e8a04d02b79", "311af6b9-1639-45a8-afb0-1971dc10aec3", "dc83353b-56a8-4d6e-b365-b1898b2b27a1", "e5cffeb3-2af6-414f-b419-d00bb6b873ea", "b30d0eea-5547-465e-9397-de2ff330f556", "f23d9e9c-d4e1-4dd5-ad44-5cb905d143a8"], "metadata": {"Header_1": " Introduction:", "filename": "improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b.md", "extension": ".md", "title": "Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex", "date": "Nov 16, 2023", "url": "https://www.llamaindex.ai/blog/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b"}}}}