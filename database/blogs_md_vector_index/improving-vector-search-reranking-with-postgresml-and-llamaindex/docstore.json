{"docstore/data": {"786c770d-cc01-42b3-aed8-ab7820c4d39b": {"__data__": {"id_": "786c770d-cc01-42b3-aed8-ab7820c4d39b", "embedding": null, "metadata": {"Header_2": " Search and Reranking: Improving Result Relevance", "filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2809f3b-ef3b-435c-a9e9-9f186f829d88", "node_type": "4", "metadata": {"filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "hash": "b051274d3600a91a43173fd3547b2410a90c87b4935e88606bb1ba784a1161e1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "35957b2f-1d91-44eb-bd44-2d69ef1960d9", "node_type": "1", "metadata": {"Header_2": " Implementing Reranking"}, "hash": "1b3cee15f2cc19056bbcfba0463b71b7611d27e557e2c0f7f83d997607b17a60", "class_name": "RelatedNodeInfo"}}, "text": "Search and Reranking: Improving Result Relevance\n\nSearch systems typically employ two main methods: keyword and semantic.\nKeyword search matches exact query terms to indexed database content, while\nsemantic search uses NLP and machine learning to understand query context and\nintent. Many effective systems combine both approaches for optimal results.\n\nAfter initial retrieval, reranking can further improve result relevance.\nTraditional reranking relies on historical user interaction data, but this\napproach struggles with new content and requires substantial data to train\neffectively. An advanced alternative is using cross-encoders, which directly\ncompare query-result pairs for similarity.\n\nCross-encoders directly compare two pieces of text and compute a similarity\nscore. Unlike traditional semantic search methods, we cannot precompute\nembeddings for cross-encoders and reuse them later. Instead, we must run the\ncross-encoder for every pair of texts we want to compare, making this method\ncomputationally expensive and impractical for large-scale searches. However,\nit is highly effective for reranking a subset of our dataset because it excels\nat evaluating new, unseen data without the need for extensive user interaction\ndata for fine-tuning.\n\nCross-encoders complement and enhance traditional reranking systems by\naddressing their limitations in deep text analysis, particularly for novel or\nhighly specific content. They do not rely on large datasets of user\ninteractions for training (though such data can still be beneficial) and are\nadept at handling new and previously unseen data. This makes cross-encoders an\nexcellent choice for enhancing the relevance of search results in a reranking\ncontext.", "mimetype": "text/plain", "start_char_idx": 4, "end_char_idx": 1720, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "35957b2f-1d91-44eb-bd44-2d69ef1960d9": {"__data__": {"id_": "35957b2f-1d91-44eb-bd44-2d69ef1960d9", "embedding": null, "metadata": {"Header_2": " Implementing Reranking", "filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2809f3b-ef3b-435c-a9e9-9f186f829d88", "node_type": "4", "metadata": {"filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "hash": "b051274d3600a91a43173fd3547b2410a90c87b4935e88606bb1ba784a1161e1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "786c770d-cc01-42b3-aed8-ab7820c4d39b", "node_type": "1", "metadata": {"Header_2": " Search and Reranking: Improving Result Relevance", "filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "hash": "bded4c45008a5e2050093826a77631f4710039db40444a0e12fed64dd77982e9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4bd9276c-e372-47d4-9b0f-7c960916d2ff", "node_type": "1", "metadata": {"Header_2": " Reranking Leads to Better Results"}, "hash": "9e705377a7cd130740aa1c6085800a177f6e9d0f2f1f357b5f0ee653812bf050", "class_name": "RelatedNodeInfo"}}, "text": "Implementing Reranking\n\nWe are going to implement a simple reranking example using LlamaIndex and the\nPostgresML managed index. For more info on the PostgresML managed index. Check\nout our announcement with LlamaIndex: [ Simplify your RAG application\narchitecture with LlamaIndex + PostgresML\n](https://www.llamaindex.ai/blog/simplify-your-rag-application-architecture-\nwith-llamaindex-postgresml) .\n\nInstall the required dependencies to get started:\n\n    \n    \n    pip install llama_index llama-index-indices-managed-postgresml\n\nWe will be using the Paul Graham dataset which can be downloaded with curl:\n\n    \n    \n    mkdir data\n    \n    curl -o data/paul_graham_essay.txt https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n\nThe PostgresML Managed Index will handle storing, splitting, embedding, and\nquerying our documents. All we need is a database connection string. If you\nhaven\u2019t already, [ create your PostgresML account\n](https://postgresml.org/signup) . You\u2019ll get $100 in free credits when you\ncomplete your profile.\n\nSet the PGML_DATABASE_URL environment variable:\n\n    \n    \n    export PGML_DATABASE_URL=\"{YOUR_CONNCECTION_STRING}\"\n\nLet\u2019s create our index:\n\n    \n    \n    from llama_index.core.readers import SimpleDirectoryReader\n    from llama_index.indices.managed.postgresml import PostgresMLIndex\n    \n    \n    documents = SimpleDirectoryReader(\"data\").load_data()\n    index = PostgresMLIndex.from_documents(\n        documents, collection_name=\"llama-index-rerank-example\"\n    )\n\nNote the collection_name is used to uniquely identify the index you are\nworking with.\n\nHere we are using the SimpleDirectoryReader to load in the documents and then\nwe construct the PostgresMLIndex from those documents.\n\nThis workflow does not require document preprocessing. Instead, the documents\nare sent directly to PostgresML where they are stored, split, and embedded per\nthe pipeline specification. This is a unique quality of using the PostgresML\nmanaged index.\n\nNow let\u2019s search! We can perform semantic search and get the top 2 results by\ncreating a retriever from our index.\n\n    \n    \n    retriever = index.as_retriever(limit=2)\n    docs = retriever.retrieve(\"What did the author do as a child?\")\n    for doc in docs:\n        print(\"---------\")\n        print(f\"Id: {doc.id_}\")\n        print(f\"Score: {doc.score}\")\n        print(f\"Text: {doc.text}\")\n    \n\nDoing this we get:\n\n    \n    \n    ---------\n    \n    Id: de01b7e1-95f8-4aa0-b4ec-45ef64816e0e\n    \n    Score: 0.7793415653313153\n    \n    Text: Wow, I thought, there's an audience. If I write something and put it on the web, anyone can read it. That may seem obvious now, but it was surprising then. In the print era there was a narrow channel to readers, guarded by fierce monsters known as editors. The only way to get an audience for anything you wrote was to get it published as a book, or in a newspaper or magazine. Now anyone could publish anything.\n    \n    \n    \n    This had been possible in principle since 1993, but not many people had realized it yet. I had been intimately involved with building the infrastructure of the web for most of that time, and a writer as well, and it had taken me 8 years to realize it. Even then it took me several years to understand the implications. It meant there would be a whole new generation of essays. [11]\n    \n    \n    \n    In the print era, the channel for publishing essays had been vanishingly small. Except for a few officially anointed thinkers who went to the right parties in New York, the only people allowed to publish essays were specialists writing about their specialties. There were so many essays that had never been written, because there had been no way to publish them. Now they could be, and I was going to write them. [12]\n    \n    \n    \n    I've worked on several different things, but to the extent there was a turning point where I figured out what to work on, it was when I started publishing essays online. From then on I knew that whatever else I did, I'd always write essays too.\n    \n    \n    \n    ---------\n    \n    Id: de01b7e1-95f8-4aa0-b4ec-45ef64816e0e\n    \n    Score: 0.7770352826735559\n    \n    Text: Asterix comics begin by zooming in on a tiny corner of Roman Gaul that turns out not to be controlled by the Romans. You can do something similar on a map of New York City: if you zoom in on the Upper East Side, there's a tiny corner that's not rich, or at least wasn't in 1993. It's called Yorkville, and that was my new home. Now I was a New York artist \u2014 in the strictly technical sense of making paintings and living in New York.\n    \n    \n    \n    I was nervous about money, because I could sense that Interleaf was on the way down. Freelance Lisp hacking work was very rare, and I didn't want to have to program in another language, which in those days would have meant C++ if I was lucky. So with my unerring nose for financial opportunity, I decided to write another book on Lisp. This would be a popular book, the sort of book that could be used as a textbook. I imagined myself living frugally off the royalties and spending all my time painting. (The painting on the cover of this book, ANSI Common Lisp, is one that I painted around this time.)\n    \n    \n    \n    The best thing about New York for me was the presence of Idelle and Julian Weber. Idelle Weber was a painter, one of the early photorealists, and I'd taken her painting class at Harvard. I've never known a teacher more beloved by her students. Large numbers of former students kept in touch with her, including me. After I moved to New York I became her de facto studio assistant.\n\nThese aren\u2019t bad results, but they aren\u2019t perfect. Let\u2019s try reranking with a\ncross-encoder.\n\n    \n    \n    retriever = index.as_retriever(\n        limit=2,\n        rerank={\n            \"model\": \"mixedbread-ai/mxbai-rerank-base-v1\",\n            \"num_documents_to_rerank\": 100\n        }\n    )\n    docs = retriever.retrieve(\"What did the author do as a child?\")\n    for doc in docs:\n        print(\"---------\")\n        print(f\"Id: {doc.id_}\")\n        print(f\"Score: {doc.score}\")\n        print(f\"Text: {doc.text}\")\n    \n\nHere, we configure our retriever to return the top two documents, but this\ntime, we add a rerank parameter to use the mixedbread-ai/mxbai-rerank-base-v1\nmodel. This means our initial semantic search will return 100 results, which\nwill then be reranked by the mixedbread-ai/mxbai-rerank-base-v1 model, and\nonly the top two results will be presented.\n\nRunning this outputs:\n\n    \n    \n    Id: de01b7e1-95f8-4aa0-b4ec-45ef64816e0e\n    Score: 0.17803585529327393\n    Text: What I Worked On\n    \n    February 2021\n    \n    Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n    \n    The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines \u2014 CPU, disk drives, printer, card reader \u2014 sitting up on a raised floor under bright fluorescent lights.\n    \n    The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\n    \n    \n    ---------\n    Id: de01b7e1-95f8-4aa0-b4ec-45ef64816e0e\n    Score: 0.1057136133313179\n    Text: I wanted not just to build things, but to build things that would last.\n    \n    In this dissatisfied state I went in 1988 to visit Rich Draves at CMU, where he was in grad school. One day I went to visit the Carnegie Institute, where I'd spent a lot of time as a kid. While looking at a painting there I realized something that might seem obvious, but was a big surprise to me. There, right on the wall, was something you could make that would last. Paintings didn't become obsolete. Some of the best ones were hundreds of years old.\n    \n    And moreover this was something you could make a living doing. Not as easily as you could by writing software, of course, but I thought if you were really industrious and lived really cheaply, it had to be possible to make enough to survive. And as an artist you could be truly independent. You wouldn't have a boss, or even need to get research funding.\n    \n    I had always liked looking at paintings. Could I make them? I had no idea. I'd never imagined it was even possible. I knew intellectually that people made art \u2014 that it didn't just appear spontaneously \u2014 but it was as if the people who made it were a different species. They either lived long ago or were mysterious geniuses doing strange things in profiles in Life magazine. The idea of actually being able to make art, to put that verb before that noun, seemed almost miraculous.\n    \n\nThese are much better results! We can see that the top document has the answer\nto the user\u2019s question. Notice that we did not have to specify a third party\nAPI to use for reranking. Once again, PostgresML handles the reranking using\ncross-encoders in the database.\n\nWe can use re-ranking directly in RAG:\n\n    \n    \n    query_engine = index.as_query_engine(\n        streaming=True,\n        vector_search_limit=2,\n        vector_search_rerank={\n            \"model\": \"mixedbread-ai/mxbai-rerank-base-v1\",\n            \"num_documents_to_rerank\": 100,\n        },\n    )\n    results = query_engine.query(\"What did the author do as a child?\")\n    for text in results.response_gen:\n        print(text, end=\"\", flush=True)\n    \n\nRunning this outputs:\n\n    \n    \n    Based on the context information, as a child, the author worked on writing (writing short stories) and programming (on the IBM 1401 using Fortran) outside of school.\n\nThat is the exact answer we wanted!", "mimetype": "text/plain", "start_char_idx": 1726, "end_char_idx": 12049, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4bd9276c-e372-47d4-9b0f-7c960916d2ff": {"__data__": {"id_": "4bd9276c-e372-47d4-9b0f-7c960916d2ff", "embedding": null, "metadata": {"Header_2": " Reranking Leads to Better Results", "filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2809f3b-ef3b-435c-a9e9-9f186f829d88", "node_type": "4", "metadata": {"filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "hash": "b051274d3600a91a43173fd3547b2410a90c87b4935e88606bb1ba784a1161e1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "35957b2f-1d91-44eb-bd44-2d69ef1960d9", "node_type": "1", "metadata": {"Header_2": " Implementing Reranking", "filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}, "hash": "86a7045335db4c71a3fbcd4f1383fb0c39c4649f7b49f648d9d3d65b1c5041a4", "class_name": "RelatedNodeInfo"}}, "text": "Reranking Leads to Better Results\n\nSearch can be complicated. Reranking with cross-encoders improves search by\ncomparing text pairs and effectively handling new data. Implementing reranking\nwith LlamaIndex and PostgresML improves search results, providing more precise\nanswers in retrieval-augmented generation applications.\n\nTo get started with PostgresML and LlamaIndex, you can follow the PostgresML\nintro [ guide ](https://postgresml.org/docs/introduction/getting-started/) to\nsetup your account, and use the examples above with your own data.", "mimetype": "text/plain", "start_char_idx": 12055, "end_char_idx": 12602, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"786c770d-cc01-42b3-aed8-ab7820c4d39b": {"doc_hash": "bded4c45008a5e2050093826a77631f4710039db40444a0e12fed64dd77982e9", "ref_doc_id": "d2809f3b-ef3b-435c-a9e9-9f186f829d88"}, "35957b2f-1d91-44eb-bd44-2d69ef1960d9": {"doc_hash": "86a7045335db4c71a3fbcd4f1383fb0c39c4649f7b49f648d9d3d65b1c5041a4", "ref_doc_id": "d2809f3b-ef3b-435c-a9e9-9f186f829d88"}, "4bd9276c-e372-47d4-9b0f-7c960916d2ff": {"doc_hash": "732060203ee68921dfdb7ae92d8ca5c4e753d1e0154a1ec5f2064243655a5de3", "ref_doc_id": "d2809f3b-ef3b-435c-a9e9-9f186f829d88"}}, "docstore/ref_doc_info": {"d2809f3b-ef3b-435c-a9e9-9f186f829d88": {"node_ids": ["786c770d-cc01-42b3-aed8-ab7820c4d39b", "35957b2f-1d91-44eb-bd44-2d69ef1960d9", "4bd9276c-e372-47d4-9b0f-7c960916d2ff"], "metadata": {"Header_2": " Search and Reranking: Improving Result Relevance", "filename": "improving-vector-search-reranking-with-postgresml-and-llamaindex.md", "extension": ".md", "title": "Improving Vector Search - Reranking with PostgresML and LlamaIndex", "date": "Jul 19, 2024", "url": "https://www.llamaindex.ai/blog/improving-vector-search-reranking-with-postgresml-and-llamaindex"}}}}