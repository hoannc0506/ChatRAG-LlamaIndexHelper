{"docstore/data": {"fb8cf909-5a91-4685-94f4-aac376bf3a94": {"__data__": {"id_": "fb8cf909-5a91-4685-94f4-aac376bf3a94", "embedding": null, "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "264719f3-73bc-420f-8fad-625f7f1ceb71", "node_type": "4", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "dfd84dc63aac309773d38d58f1cab23f8f019e6c3b55400f94f42b152c0e9c5e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b4cf3d4-3ace-4726-ba83-18b80570d4d3", "node_type": "1", "metadata": {"Header_1": " Context"}, "hash": "0652faca970a8651a6203597330c9406e14848f7fe289398141c126b3155a7ed", "class_name": "RelatedNodeInfo"}}, "text": "Today we\u2019re excited to introduce **Llama Packs \u2014** a community-driven hub of\nprepackaged modules that you can use to kickstart your LLM application. Import\nthem for a wide variety of use cases, from building a Streamlit app to\nbuilding advanced retrieval over Weaviate to a resume parser that does\nstructured data extraction. Just as important, inspect and customize them to\nyour liking.\n\nThey\u2019re available on [ LlamaHub ](https://llamahub.ai/) : we\u2019ve launched 16+\ntemplates with our launch partners already, and we\u2019re going to be adding a lot\nmore!\n\n(To those of you in the states, Happy Thanksgiving )", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 604, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b4cf3d4-3ace-4726-ba83-18b80570d4d3": {"__data__": {"id_": "5b4cf3d4-3ace-4726-ba83-18b80570d4d3", "embedding": null, "metadata": {"Header_1": " Context", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "264719f3-73bc-420f-8fad-625f7f1ceb71", "node_type": "4", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "dfd84dc63aac309773d38d58f1cab23f8f019e6c3b55400f94f42b152c0e9c5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb8cf909-5a91-4685-94f4-aac376bf3a94", "node_type": "1", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "f780ca1fbff2111ce904fce31229c73953d63cd28db034c0d4a590d6258a090f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ed3f5f48-b22f-4cd5-bca5-6543b7a14aab", "node_type": "1", "metadata": {"Header_1": " Overview"}, "hash": "bade6f4f91ba519fa232429e4713322c99fc8fb715b46b80a43de3a936d0f30d", "class_name": "RelatedNodeInfo"}}, "text": "Context\n\nThere are so many choices when building an LLM app that it can be daunting to\nget started building for a specific use case. Even for RAG the user needs to\nmake the following decisions:\n\n  * Which LLM should I use? Embedding model? \n  * Vector database? \n  * Chunking/parsing strategy \n  * Retrieval Algorithm \n  * Wrapping in surrounding application \n\nEvery use case requires different parameters, and LlamaIndex as a core LLM\nframework offers a comprehensive set of unopinionated modules to let users\ncompose an application.\n\nBut we needed a way for users to get started more easily for their use case.\nAnd that\u2019s exactly where Llama Packs comes in.", "mimetype": "text/plain", "start_char_idx": 609, "end_char_idx": 1268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ed3f5f48-b22f-4cd5-bca5-6543b7a14aab": {"__data__": {"id_": "ed3f5f48-b22f-4cd5-bca5-6543b7a14aab", "embedding": null, "metadata": {"Header_1": " Overview", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "264719f3-73bc-420f-8fad-625f7f1ceb71", "node_type": "4", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "dfd84dc63aac309773d38d58f1cab23f8f019e6c3b55400f94f42b152c0e9c5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b4cf3d4-3ace-4726-ba83-18b80570d4d3", "node_type": "1", "metadata": {"Header_1": " Context", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "6e778b7866b3584ff305b81cdd8c7ce738707301e846554cfb5af98cd1ab4fb4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fe33061b-150f-4da8-83a0-dbb17934f2ed", "node_type": "1", "metadata": {"Header_1": " **Example Walkthrough**"}, "hash": "1172c554e955642c432d4e4ee035b9a52a038c5d00d4aa69a83ddb55559fc916", "class_name": "RelatedNodeInfo"}}, "text": "Overview\n\nLlama Packs can be described in two ways:\n\n  * On one hand, they are prepackaged **modules** that can be initialized with parameters and run out of the box to achieve a given use case (whether that\u2019s a full RAG pipeline, application template, and more). You can also import **submodules** (e.g. LLMs, query engines) to use directly **.**\n  * On another hand, LlamaPacks are **templates** that you can inspect, modify, and use. \n\nThey can be downloaded either through our ` llama_index ` Python library or\nthe CLI in _one line of code:_\n\n**CLI:**\n\n    \n    \n    llamaindex-cli download-llamapack <pack_name> --download-dir <pack_directory>\n\n**Python**\n\n    \n    \n    from llama_index.llama_pack import download_llama_pack\n    \n    # download and install dependencies\n    VoyageQueryEnginePack = download_llama_pack(\n      \"&lt;pack_name&gt;\", \"&lt;pack_directory&gt;\"\n    )\n\nLlama Packs can span abstraction levels \u2014 some are full prepackaged templates\n(full Streamlit / Gradio apps), and some combine a few smaller modules\ntogether (e.g. our SubQuestionQueryEngine with Weaviate). All of them are\nfound in [ LlamaHub ](https://llamahub.ai/) . You can filter by packs by\nselecting \u201cLlama Packs\u201d from the dropdown.\n\nLlama Packs on LlamaHub\n\nWe\u2019re excited to partner with the following companies/contributors for our\nlaunch, featuring **16+ templates.** We highlight some examples below:\n\n  * **Streamlit / Snowflake (Caroline F.):** [ Streamlit Chatbot ](https://llamahub.ai/l/llama_packs-streamlit_chatbot)\n  * **Arize (Mikyo K., Xander S.):** [ Arize Phoenix ](https://llamahub.ai/l/llama_packs-arize_phoenix_query_engine)\n  * **ActiveLoop / DeepLake (Mikayel H., Adhilkhan S.):** [ DeepMemory Pack ](https://llamahub.ai/l/llama_packs-deeplake_deepmemory_retriever) , [ Multi-modal Retrieval ](https://llamahub.ai/l/llama_packs-deeplake_multimodal_retrieval)\n  * **Weaviate (Erika C.):** [ Sub Question Query Engine ](https://llamahub.ai/l/llama_packs-sub_question_weaviate) , [ Retry Query Engine ](https://llamahub.ai/l/llama_packs-retry_engine_weaviate)\n  * **Voyage AI (Hong L.):** [ Voyage AI Pack ](https://llamahub.ai/l/llama_packs-voyage_query_engine)\n  * **TruEra (Josh R.):** [ TruLens Eval Pack ](https://llamahub.ai/l/llama_packs-trulens_eval_packs) (this is 3 packs in one) \n  * **Timescale (Matvey A.):** [ Timescale Vector AutoRetrieval ](https://llamahub.ai/l/llama_packs-timescale_vector_autoretrieval)\n  * **Wenqi G.:** [ LLaVa Completion Pack ](https://llamahub.ai/l/llama_packs-llava_completion)\n\nThere\u2019s not enough room in this blog post to feature every template, we\u2019ll be\nrunning features on every pack in the next few days.\n\nSpecial thanks to Logan Markewich and Andrei Fajardo on the LlamaIndex team\nfor getting Llama Packs up and running.", "mimetype": "text/plain", "start_char_idx": 1273, "end_char_idx": 4047, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fe33061b-150f-4da8-83a0-dbb17934f2ed": {"__data__": {"id_": "fe33061b-150f-4da8-83a0-dbb17934f2ed", "embedding": null, "metadata": {"Header_1": " **Example Walkthrough**", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "264719f3-73bc-420f-8fad-625f7f1ceb71", "node_type": "4", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "dfd84dc63aac309773d38d58f1cab23f8f019e6c3b55400f94f42b152c0e9c5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ed3f5f48-b22f-4cd5-bca5-6543b7a14aab", "node_type": "1", "metadata": {"Header_1": " Overview", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "c3e596da2de9a4b6e6872853e516cdfa439e8600fbb5cff92fc25181fe55572b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b1803159-98f3-4022-84f1-0d36c970eb5c", "node_type": "1", "metadata": {"Header_1": " Conclusion"}, "hash": "e13893cffe36fc03feae9c6fd04fb5db681453027346ea1fb1b80e33702edc58", "class_name": "RelatedNodeInfo"}}, "text": "**Example Walkthrough**\n\nThe best way to highlight LlamaPack features is to showcase an example. We\u2019ll\nwalk through a simple [ Llama Pack ](https://llamahub.ai/l/llama_packs-\nvoyage_query_engine) that gives the user a RAG pipeline setup with Voyage AI\nembeddings.\n\nVoyage AI Pack. Every Pack has a detailed README on how to use / modules.\n\nFirst, we download and initialize the Pack over a set of documents:\n\n    \n    \n    from llama_index.llama_pack import download_llama_pack\n    \n    # download pack\n    VoyageQueryEnginePack = download_llama_pack(\"VoyageQueryEnginePack\", \"./voyage_pack\")\n    # initialize pack (assume documents is defined)\n    voyage_pack = VoyageQueryEnginePack(documents)\n\nEvery Llama Pack implements a ` get_modules() ` function allowing you to\ninspect/use the modules.\n\n    \n    \n    modules = voyage_pack.get_modules()\n    display(modules)\n    \n    # get LLM, vector index\n    llm = modules[\"llm\"]\n    vector_index = modules[\"index\"]\n\nThe Llama Pack can be run in an **out of the box** fashion. By calling ` run `\n, we\u2019ll execute the RAG pipeline and get back a response. In this setting, you\ndon\u2019t need to worry about the internals.\n\n    \n    \n    # this will run the full pack\n    response = voyage_pack.run(\"What did the author do growing up?\", similarity_top_k=2)\n    print(str(response))\n    \n    \n    \n    The author spent his time outside of school mainly writing and programming. He wrote short stories and attempted to write programs on an IBM 1401. Later, he started programming on a TRS-80, creating simple games and a word processor. He also painted still lives while studying at the Accademia.\n\nThe second important thing is that you have **full access to the code of the\nLlama Pack** . This allows you to customize the Llama Pack, rip out code, or\njust use it as reference to build your own app. Let\u2019s take a look at the\ndownloaded pack in ` voyage_pack/base.py ` , and swap out the OpenAI LLM for\nAnthropic:\n\n    \n    \n    from llama_index.llms import Anthropic\n    ...\n    \n    class VoyageQueryEnginePack(BaseLlamaPack):\n        def __init__(self, documents: List[Document]) -&gt; None:\n            llm = Anthropic()\n            embed_model = VoyageEmbedding(\n                model_name=\"voyage-01\", voyage_api_key=os.environ[\"VOYAGE_API_KEY\"]\n            )\n            service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n            self.llm = llm\n            self.index = VectorStoreIndex.from_documents(\n                documents, service_context=service_context\n            )\n    \n        def get_modules(self) -&gt; Dict[str, Any]:\n            \"\"\"Get modules.\"\"\"\n            return {\"llm\": self.llm, \"index\": self.index}\n    \n        def run(self, query_str: str, **kwargs: Any) -&gt; Any:\n            \"\"\"Run the pipeline.\"\"\"\n            query_engine = self.index.as_query_engine(**kwargs)\n            return query_engine.query(query_str)\n\nYou can re-import the module directly and run it again:\n\n    \n    \n    from voyage_pack.base import VoyageQueryEnginePack\n    \n    voyage_pack = VoyageQueryEnginePack(documents)\n    response = voyage_pack.run(\"What did the author do during his time in RISD?\")\n    print(str(response))", "mimetype": "text/plain", "start_char_idx": 4052, "end_char_idx": 7254, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b1803159-98f3-4022-84f1-0d36c970eb5c": {"__data__": {"id_": "b1803159-98f3-4022-84f1-0d36c970eb5c", "embedding": null, "metadata": {"Header_1": " Conclusion", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "264719f3-73bc-420f-8fad-625f7f1ceb71", "node_type": "4", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "dfd84dc63aac309773d38d58f1cab23f8f019e6c3b55400f94f42b152c0e9c5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fe33061b-150f-4da8-83a0-dbb17934f2ed", "node_type": "1", "metadata": {"Header_1": " **Example Walkthrough**", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "aebf2a8a6adabaad1b4ccbb5013cba146453c89abc34d550dae5bd6e9a6c51c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd8e3492-3e8a-4017-9481-ac811f777f7f", "node_type": "1", "metadata": {"Header_1": " Conclusion", "Header_2": " Contributing"}, "hash": "a8cdb62fb3ada3ffd810a71adf9fd1648dd38f991c59bea10ccf9001c01bd7e1", "class_name": "RelatedNodeInfo"}}, "text": "Conclusion\n\nTry it out and let us know what you think!", "mimetype": "text/plain", "start_char_idx": 7259, "end_char_idx": 7313, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd8e3492-3e8a-4017-9481-ac811f777f7f": {"__data__": {"id_": "bd8e3492-3e8a-4017-9481-ac811f777f7f", "embedding": null, "metadata": {"Header_1": " Conclusion", "Header_2": " Contributing", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "264719f3-73bc-420f-8fad-625f7f1ceb71", "node_type": "4", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "dfd84dc63aac309773d38d58f1cab23f8f019e6c3b55400f94f42b152c0e9c5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1803159-98f3-4022-84f1-0d36c970eb5c", "node_type": "1", "metadata": {"Header_1": " Conclusion", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "9cd761df46fad3b93f542544947b84b6de1752af95d4b02ddf7e890c21072d95", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "96f644b6-09ef-4d52-adbe-d21b5f5110f0", "node_type": "1", "metadata": {"Header_1": " Conclusion", "Header_2": " Resources"}, "hash": "a1f51d4dc19a0c21bc78259e0aa7c647ecb068ad0d0a0eb1a1662cbb50303239", "class_name": "RelatedNodeInfo"}}, "text": "Contributing\n\nNot on here yet? We\u2019d _love_ to feature you! If you have any templates with\nLlamaIndex, adding it is almost as simple as copying/pasting your existing\ncode over into a ` BaseLlamaPack ` subclass. Take a look at this folder for a\nfull set of examples: [ https://github.com/run-llama/llama-\nhub/tree/main/llama_hub/llama_packs ](https://github.com/run-llama/llama-\nhub/tree/main/llama_hub/llama_packs)", "mimetype": "text/plain", "start_char_idx": 7319, "end_char_idx": 7732, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "96f644b6-09ef-4d52-adbe-d21b5f5110f0": {"__data__": {"id_": "96f644b6-09ef-4d52-adbe-d21b5f5110f0", "embedding": null, "metadata": {"Header_1": " Conclusion", "Header_2": " Resources", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "264719f3-73bc-420f-8fad-625f7f1ceb71", "node_type": "4", "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "dfd84dc63aac309773d38d58f1cab23f8f019e6c3b55400f94f42b152c0e9c5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd8e3492-3e8a-4017-9481-ac811f777f7f", "node_type": "1", "metadata": {"Header_1": " Conclusion", "Header_2": " Contributing", "filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}, "hash": "0e56bfb05a5585f0264f44f91f3ce4531245e8202ef6b7c9370733937409278e", "class_name": "RelatedNodeInfo"}}, "text": "Resources\n\nAll Llama Packs can be found on LlamaHub: [ https://llamahub.ai/\n](https://llamahub.ai/)\n\nThe full notebook walkthrough is here: [ https://github.com/run-\nllama/llama_index/blob/main/docs/examples/llama_hub/llama_packs_example.ipynb\n](https://github.com/run-\nllama/llama_index/blob/main/docs/examples/llama_hub/llama_packs_example.ipynb)", "mimetype": "text/plain", "start_char_idx": 7738, "end_char_idx": 8086, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"fb8cf909-5a91-4685-94f4-aac376bf3a94": {"doc_hash": "f780ca1fbff2111ce904fce31229c73953d63cd28db034c0d4a590d6258a090f", "ref_doc_id": "264719f3-73bc-420f-8fad-625f7f1ceb71"}, "5b4cf3d4-3ace-4726-ba83-18b80570d4d3": {"doc_hash": "6e778b7866b3584ff305b81cdd8c7ce738707301e846554cfb5af98cd1ab4fb4", "ref_doc_id": "264719f3-73bc-420f-8fad-625f7f1ceb71"}, "ed3f5f48-b22f-4cd5-bca5-6543b7a14aab": {"doc_hash": "c3e596da2de9a4b6e6872853e516cdfa439e8600fbb5cff92fc25181fe55572b", "ref_doc_id": "264719f3-73bc-420f-8fad-625f7f1ceb71"}, "fe33061b-150f-4da8-83a0-dbb17934f2ed": {"doc_hash": "aebf2a8a6adabaad1b4ccbb5013cba146453c89abc34d550dae5bd6e9a6c51c6", "ref_doc_id": "264719f3-73bc-420f-8fad-625f7f1ceb71"}, "b1803159-98f3-4022-84f1-0d36c970eb5c": {"doc_hash": "9cd761df46fad3b93f542544947b84b6de1752af95d4b02ddf7e890c21072d95", "ref_doc_id": "264719f3-73bc-420f-8fad-625f7f1ceb71"}, "bd8e3492-3e8a-4017-9481-ac811f777f7f": {"doc_hash": "0e56bfb05a5585f0264f44f91f3ce4531245e8202ef6b7c9370733937409278e", "ref_doc_id": "264719f3-73bc-420f-8fad-625f7f1ceb71"}, "96f644b6-09ef-4d52-adbe-d21b5f5110f0": {"doc_hash": "29b08208039fb783d90e5a119c27671a327aa65e259ea38f685f94985dd2e89e", "ref_doc_id": "264719f3-73bc-420f-8fad-625f7f1ceb71"}}, "docstore/ref_doc_info": {"264719f3-73bc-420f-8fad-625f7f1ceb71": {"node_ids": ["fb8cf909-5a91-4685-94f4-aac376bf3a94", "5b4cf3d4-3ace-4726-ba83-18b80570d4d3", "ed3f5f48-b22f-4cd5-bca5-6543b7a14aab", "fe33061b-150f-4da8-83a0-dbb17934f2ed", "b1803159-98f3-4022-84f1-0d36c970eb5c", "bd8e3492-3e8a-4017-9481-ac811f777f7f", "96f644b6-09ef-4d52-adbe-d21b5f5110f0"], "metadata": {"filename": "introducing-llama-packs-e14f453b913a.md", "extension": ".md", "title": "Introducing Llama Packs", "date": "Nov 22, 2023", "url": "https://www.llamaindex.ai/blog/introducing-llama-packs-e14f453b913a"}}}}