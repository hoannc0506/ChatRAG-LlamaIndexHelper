{"docstore/data": {"1a322b4a-bb8a-4ed3-8f91-943f64048ffa": {"__data__": {"id_": "1a322b4a-bb8a-4ed3-8f91-943f64048ffa", "embedding": null, "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7f3a9ae-e117-415b-827b-98804c5c7eae", "node_type": "1", "metadata": {"Header_1": " RAG is Only as Good as your Data"}, "hash": "9d0192a9b4fecd1704a2fe97bb687989bd4f3f72284da12f03a951bb0e6dcf51", "class_name": "RelatedNodeInfo"}}, "text": "Today is a big day for the LlamaIndex ecosystem: we are announcing LlamaCloud,\na new generation of managed parsing, ingestion, and retrieval services,\ndesigned to bring **production-grade** **context-augmentation** to your LLM\nand RAG applications.\n\nUsing LlamaCloud as an enterprise AI engineer, you can focus on writing the\nbusiness logic and not on data wrangling. Process large volumes of production\ndata, immediately leading to better response quality. LlamaCloud launches with\nthe following key components:\n\n  1. **LlamaParse:** Proprietary parsing for complex documents with embedded objects such as tables and figures. LlamaParse directly integrates with LlamaIndex ingestion and retrieval to let you build retrieval over complex, semi-structured documents. You\u2019ll be able to answer complex questions that simply weren\u2019t possible previously. \n  2. **Managed Ingestion and Retrieval API:** An API which allows you to easily load, process, and store data for your RAG app and consume it in any language. Backed by data sources in [ LlamaHub ](https://llamahub.ai/) , including LlamaParse, and our data storage integrations. \n\nLlamaParse is available in a public preview setting starting today. It can\ncurrently handle PDFs and usage is capped for public use; [ contact us\n](https://llamaindex.ai/contact) for commercial terms. The managed ingestion\nand retrieval API is available as a private preview; we are offering access to\na limited set of enterprise design partners. If you\u2019re interested, [ get in\ntouch ](https://llamaindex.ai/contact) . (We\u2019ve also launched a [ new version\nof our website ](https://www.llamaindex.ai/) !)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1635, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c7f3a9ae-e117-415b-827b-98804c5c7eae": {"__data__": {"id_": "c7f3a9ae-e117-415b-827b-98804c5c7eae", "embedding": null, "metadata": {"Header_1": " RAG is Only as Good as your Data", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1a322b4a-bb8a-4ed3-8f91-943f64048ffa", "node_type": "1", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "a644811f76dc12c6e0381eab9f882bbbbfdb09c832d503d5b95bb236c9515dbc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc350019-1023-4944-a299-178d52ead84b", "node_type": "1", "metadata": {"Header_1": " Data Pipelines to Bring you to Production"}, "hash": "39a36d1c9ca9a846838f8f9939bed34d6ec534189658302d1a2ad9b9b2537935", "class_name": "RelatedNodeInfo"}}, "text": "RAG is Only as Good as your Data\n\nA core promise of LLMs is the ability to automate knowledge search, synthesis,\nextraction, and planning over any source of unstructured data. Over the past\nyear a new data stack has emerged to power these context-augmented LLM\napplications, popularly referred to as Retrieval-Augmented Generation (RAG).\nThis stack includes loading data, processing it, embedding it, and loading\ninto a vector database. This enables downstream orchestration of retrieval and\nprompting to provide context within an LLM app.\n\nThis stack is different from any ETL stack before it, because unlike\ntraditional software, every decision in the data stack directly **affects the\naccuracy** of the full LLM-powered system. Every decision like chunk size and\nembedding model affects LLM outputs, and since LLMs are black boxes, you can\u2019t\nunit test your way to correct behavior.\n\nWe\u2019ve spent the past year hard at work at the forefront of providing tooling\nand educating users on how to build high-performing, advanced RAG for various\nuse cases. We crossed the 2M monthly download mark, and are used by large\nenterprises to startups, including Adyen, T-Systems, Jasper.ai, Weights and\nBiases, DataStax, and many more.\n\nBut while getting started with our famous 5-line starter example is easy,\nbuilding production-grade RAG remains a complex and subtle problem. In our\nhundreds of user conversations, we learned the biggest pain points:\n\n  * **Results aren\u2019t accurate enough:** The application was not able to produce satisfactory results for a long-tail of input tasks/queries. \n  * **The number of parameters to tune is overwhelming:** It\u2019s not clear which parameters across the data parsing, ingestion, retrieval. \n  * **PDFs are specifically a problem:** I have complex docs with lots of messy formatting. How do I represent this in the right way so the LLM can understand it? \n  * **Data syncing is a challenge:** Production data often updates regularly, and continuously syncing new data brings a new set of challenges. \n\nThese are the problems we set out to solve with LlamaCloud.", "mimetype": "text/plain", "start_char_idx": 1640, "end_char_idx": 3732, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dc350019-1023-4944-a299-178d52ead84b": {"__data__": {"id_": "dc350019-1023-4944-a299-178d52ead84b", "embedding": null, "metadata": {"Header_1": " Data Pipelines to Bring you to Production", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7f3a9ae-e117-415b-827b-98804c5c7eae", "node_type": "1", "metadata": {"Header_1": " RAG is Only as Good as your Data", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "8a98610c7c76ab3e5ce6835aa2dc19a57f925f6be1922390e5fd6ea35dcc58fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "80d853e1-034a-40fb-8d98-af481ac32dc5", "node_type": "1", "metadata": {"Header_1": " LlamaParse"}, "hash": "e24459bcdb41adcb4b20a89d30d8c527abb4faf0f6150c35d25c9102380e209b", "class_name": "RelatedNodeInfo"}}, "text": "Data Pipelines to Bring you to Production\n\nWe built LlamaCloud and LlamaParse as the data pipelines to get your RAG\napplication to production more quickly.", "mimetype": "text/plain", "start_char_idx": 3737, "end_char_idx": 3892, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "80d853e1-034a-40fb-8d98-af481ac32dc5": {"__data__": {"id_": "80d853e1-034a-40fb-8d98-af481ac32dc5", "embedding": null, "metadata": {"Header_1": " LlamaParse", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc350019-1023-4944-a299-178d52ead84b", "node_type": "1", "metadata": {"Header_1": " Data Pipelines to Bring you to Production", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "4928dc4121c3994496aad365cf161dd814d31ccae5967a7cdedc9a3faab6d695", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "89182522-2c05-4559-a4c1-74d2b6751003", "node_type": "1", "metadata": {"Header_1": " Managed Ingestion and Retrieval"}, "hash": "b9c461c61db5a5e33c9b6fb7652ddd71c2ca22d034cffa2d341d1678481e5fb3", "class_name": "RelatedNodeInfo"}}, "text": "LlamaParse\n\nLlamaParse is a state-of-the-art parser designed to specifically unlock RAG\nover complex PDFs with embedded tables and charts. This simply wasn\u2019t possible\nbefore with other approaches, and we\u2019re incredibly excited about this\ntechnology.\n\nLlamaParse Demo. Given a PDF file, returns a parsed markdown file that\nmaintains semantic structure within the document.\n\nFor the past few months we\u2019ve been obsessed with this problem. This is a\nsurprisingly prevalent use case across a variety of data types and verticals,\nfrom ArXiv papers to 10K filings to medical reports.\n\nNaive chunking and retrieval algorithms do terribly. We were the first to\npropose a [ novel recursive retrieval RAG technique\n](https://docs.llamaindex.ai/en/stable/examples/query_engine/pdf_tables/recursive_retriever.html)\nfor being able to hierarchically index and query over tables and text in a\ndocument. The only challenge that remained was how to properly parse out\ntables and text in the first place.\n\nComparison of LlamaParse vs. PyPDF over the Apple 10K filing. [ Full\ncomparisons are here\n](https://drive.google.com/file/d/1fyQAg7nOtChQzhF2Ai7HEeKYYqdeWsdt/view?usp=sharing)\n. A green highlight in a cell means that the RAG pipeline correctly returned\nthe cell value as the answer to a question over that cell. A red highlight\nmeans that the question was answered incorrectly.\n\nThis is where LlamaParse comes in. We\u2019ve developed a proprietary parsing\nservice that is incredibly good at parsing PDFs with complex tables into a\nwell-structured markdown format. This representation directly plugs into the\nadvanced Markdown parsing and recursive retrieval algorithms available in the\nopen-source library. The end result is that you are able to build RAG over\ncomplex documents that can answer questions over both tabular and unstructured\ndata. Check out the results below for a comparison:\n\nComparison of baseline PDF approach (top) vs. LlamaParse + advanced retrieval\n(bottom)  Results over the [ Uber 10K Dataset ](https://github.com/run-\nllama/llama-hub/tree/main/llama_hub/llama_datasets/10k/uber_2021) . For more\ninformation on our evaluation metrics check out our [ evaluation page\n](https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html)\nhere.\n\nThis service is available in a **public preview mode:** available to everyone,\nbut with a usage limit (1k pages per day). It operates as a standalone service\nthat also plugs into our managed ingestion and retrieval API (see below).\nCheck out our [ LlamaParse onboarding here\n](https://docs.cloud.llamaindex.ai/llamaparse/) for more details.\n\n    \n    \n    from llama_parse import LlamaParse\n    \n    parser = LlamaParse(\n        api_key=\"llx-...\",  # can also be set in your env as LLAMA_CLOUD_API_KEY\n        result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n        verbose=True\n    )\n\nFor unlimited commercial use of LlamaParse, [ get in touch\n](https://llamaindex.ai/contact) with us.\n\n**Next Steps**\n\nOur early users have already given us important feedback on what they\u2019d like\nto see next. Currently we primarily support PDFs with tables, but we are also\nbuilding out better support for figures, and and an expanded set of the most\npopular document types: .docx, .pptx, .html.", "mimetype": "text/plain", "start_char_idx": 3897, "end_char_idx": 7146, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89182522-2c05-4559-a4c1-74d2b6751003": {"__data__": {"id_": "89182522-2c05-4559-a4c1-74d2b6751003", "embedding": null, "metadata": {"Header_1": " Managed Ingestion and Retrieval", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "80d853e1-034a-40fb-8d98-af481ac32dc5", "node_type": "1", "metadata": {"Header_1": " LlamaParse", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "bcaa1385dad8599997bf1ae7af2502def521c6e2156de30b651f01ad0c8bc91a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2bc17dce-8e42-4b90-9e95-6f5baa16e709", "node_type": "1", "metadata": {"Header_1": " Launch Partners and Collaborators"}, "hash": "2f423f12c35a299946ce16aea580ffc52b0d457279ca6a59a71aff51df5d7097", "class_name": "RelatedNodeInfo"}}, "text": "Managed Ingestion and Retrieval\n\nOur other main offering in LlamaCloud is a managed ingestion and retrieval API\nwhich allows you to easily declare performant data pipelines for any context-\naugmented LLM application.\n\nGet clean data for your LLM application, so you can spend less time wrangling\ndata and more time writing core application logic. LlamaCloud empowers\nenterprise developers with the following benefits:\n\n  * **Engineering Time Savings:** Instead of having to write custom connectors and parsing logic in Python, our APIs allow you to directly connect to different data sources. \n  * **Performance:** we provide good out-of-the-box performance for different data types, while offering an intuitive path for experimentation, evaluation, and improvement. \n  * **Ease Systems Complexity:** Handle a large number of data sources with incremental updates. \n\nLet\u2019s do a brief tour through the core components!\n\n  1. **Ingestion:** Declare a managed pipeline to process and transform/chunk/embed data backed by our 150+ data sources in LlamaHub and our 40+ storage integrations as destinations. Automatically handle syncing and load balancing. Define through the UI or our open-source library. \n  2. **Retrieval:** Get access to state-of-the-art, advanced retrieval backed by our open-source library and your data storage. Wrap it in an easy-to-use REST API that you can consume from any language. \n  3. **Playground:** Interactive UI to test and refine your ingestion/retrieval strategies pre-deployment, with evaluations in the loop. \n\nLlamaCloud Playground: configure, evaluate, and optimize your\ningestion/retrieval pipeline before deployment.  LlamaCloud Retrieval: Access\nadvanced retrieval over your storage system via an API.\n\nWe are opening up a private beta to a limited set of enterprise partners for\nthe managed ingestion and retrieval API. If you\u2019re interested in centralizing\nyour data pipelines and spending more time working on your actual RAG use\ncases, come [ talk to us ](https://llamaindex.ai/contact) .", "mimetype": "text/plain", "start_char_idx": 7151, "end_char_idx": 9181, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2bc17dce-8e42-4b90-9e95-6f5baa16e709": {"__data__": {"id_": "2bc17dce-8e42-4b90-9e95-6f5baa16e709", "embedding": null, "metadata": {"Header_1": " Launch Partners and Collaborators", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89182522-2c05-4559-a4c1-74d2b6751003", "node_type": "1", "metadata": {"Header_1": " Managed Ingestion and Retrieval", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "ed07ef75667df06b57940a7b068b5cec6e8af52946c4a9c75dda68e0fb70f773", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "52655261-d924-481d-a332-d900a66b0dbf", "node_type": "1", "metadata": {"Header_1": " FAQ"}, "hash": "fb3d3ba66566bad347eed82f0c5c0c9a6817f6cde00e441624c31e4671520bef", "class_name": "RelatedNodeInfo"}}, "text": "Launch Partners and Collaborators\n\nWe opened up access to LlamaParse at [ our hackathon ](https://rag-a-\nthon.devpost.com/) we co-hosted with [ Futureproof Labs\n](https://www.futureproofsv.com/) and [ Datastax ](https://www.datastax.com/)\nat the beginning of February. We saw some incredible applications of\nLlamaParse in action, [ including parsing building codes for Accessory\nDwelling Unit (ADU) planning ](/pioneering-the-future-of-housing-introducing-\ngenai-driven-adu-planning-ea950be71e2f) , [ parsing real-estate disclosures\nfor home buying ](https://devpost.com/software/home-ai) , and dozens more.\n\nEric Ciarla, co-founder at Mendable AI, incorporated LlamaParse into\nMendable\u2019s data stack: \u201cWe integrated LlamaParse into our [ open source data\nconnector repo ](https://github.com/mendableai/data-connectors) which powers\nour production ingestion suite. It was easy to integrate and more powerful\nthan any of the alternatives we tried.\u201d\n\nWe\u2019re also excited to be joined by initial launch partners and collaborators\nin the LLM and AI ecosystem, from storage to compute.\n\n**DataStax**\n\nDatastax has incorporated LlamaParse into their RAGStack to bring a privacy-\npreserving out-of-the-box RAG solution for enterprises: \"Last week one of our\ncustomers Imprompt has launched a pioneering 'Chat-to-Everything' platform\nleveraging RAGStack powered by LlamaIndex to enhance their enterprise\nofferings while prioritizing privacy.\" said Davor Bonaci, CTO and executive\nvice president, DataStax. \"We're thrilled to partner with LlamaIndex to bring\na streamlined solution to market. By incorporating LlamaIndex into RAGStack,\nwe are providing enterprise developers with a comprehensive Gen AI stack that\nsimplifies the complexities of RAG implementation, while offering long-term\nsupport and compatibility assurance.\u201d\n\n**MongoDB**\n\n\u201cMongoDB\u2019s partnership with LlamaIndex allows for the ingestion of data into\nthe MongoDB Atlas Vector database, and the retrieval of the index from Atlas\nvia LlamaParse and LlamaCloud, enabling the development of RAG systems and\nother AI applications,\u201d said Greg Maxson, Global Lead, AI Ecosystems at\nMongoDB. \u201cNow, developers can abstract complexities associated with data\ningestion, simplify RAG pipeline implementations, and more cost effectively\ndevelop large language model applications, ultimately accelerating generative\nAI app development and more quickly bringing apps to market.\u201d\n\n**Qdrant**\n\nAndr\u00e9 Zayarni, CEO of Qdrant, says \u201cThe Qdrant team is excited to partner with\nLlamaIndex to combine the power of optimal data preprocessing, vectorization,\nand ingestion with Qdrant for a powerful fullstack RAG solution.\u201d\n\n**NVIDIA**\n\nWe are also excited to collaborate with NVIDIA to integrate LlamaIndex with\nthe [ NVIDIA AI Enterprise ](https://www.nvidia.com/en-us/data-\ncenter/products/ai-enterprise/) software platform for production AI:\n\u201cLlamaCloud will help enterprises get generative AI applications from\ndevelopment into production with connectors that link proprietary data to the\npower of large language models,\u201d said Justin Boitano, vice president,\nEnterprise and Edge Computing, NVIDIA. \u201cPairing LlamaCloud with NVIDIA AI\nEnterprise can accelerate the end-to-end LLM pipeline \u2014 including data\nprocessing, embedding creation, indexing, and model inference on accelerated\ncomputing across clouds, data centers and out to the edge.\u201d", "mimetype": "text/plain", "start_char_idx": 9186, "end_char_idx": 12564, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "52655261-d924-481d-a332-d900a66b0dbf": {"__data__": {"id_": "52655261-d924-481d-a332-d900a66b0dbf", "embedding": null, "metadata": {"Header_1": " FAQ", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2bc17dce-8e42-4b90-9e95-6f5baa16e709", "node_type": "1", "metadata": {"Header_1": " Launch Partners and Collaborators", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "ebfed574cea5e2dad99d736523bc9c02f2c66957ad1fffc6a4e9115b4e867fa2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "72e0e1b7-876a-4ea5-a3d8-3196444c3c50", "node_type": "1", "metadata": {"Header_1": " Next Steps"}, "hash": "68fcc87181e464e57a39218ed66e34436c9efc76c1ad3c13c5afcd9010473e3c", "class_name": "RelatedNodeInfo"}}, "text": "FAQ\n\n**Is this competitive with vector databases?**\n\nNo. LlamaCloud is focused primarily on data parsing and ingestion, which is a\ncomplementary layer to any vector storage provider. The retrieval layer is\norchestration on top of an existing storage system. LlamaIndex open-source\nintegrates with 40+ of the most popular vector databases, and we are working\nhard to do the following:\n\n  1. Integrate LlamaCloud with storage providers of existing design partners \n  2. Make LlamaCloud available in a more \u201cself-serve\u201d manner.", "mimetype": "text/plain", "start_char_idx": 12569, "end_char_idx": 13093, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "72e0e1b7-876a-4ea5-a3d8-3196444c3c50": {"__data__": {"id_": "72e0e1b7-876a-4ea5-a3d8-3196444c3c50", "embedding": null, "metadata": {"Header_1": " Next Steps", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47548502-0bbf-49e1-924c-d4108e806c80", "node_type": "4", "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "dd36f5832f90e7453706f7ef2c229023e283222702b5381a97fe030b8c5ae902", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "52655261-d924-481d-a332-d900a66b0dbf", "node_type": "1", "metadata": {"Header_1": " FAQ", "filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}, "hash": "f37c9af5348d658642f650314e2baf7df4c0ca6f400351871b17c1027ee3f902", "class_name": "RelatedNodeInfo"}}, "text": "Next Steps\n\nAs mentioned in the above sections, LlamaParse is available for public preview\nstarting today with a usage cap. LlamaCloud is in a private preview mode; we\nare offering access to a limited set of enterprise design partners. If you\u2019re\ninterested come talk to us!\n\nLlamaParse: [ Repo ](https://github.com/run-llama/llama_parse) , [ Cookbook\n](https://github.com/run-\nllama/llama_parse/blob/main/examples/demo_advanced.ipynb) , [ Contact Us\n](https://www.llamaindex.ai/contact)\n\nLlamaCloud: [ Contact Us ](https://www.llamaindex.ai/contact)", "mimetype": "text/plain", "start_char_idx": 13099, "end_char_idx": 13648, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"1a322b4a-bb8a-4ed3-8f91-943f64048ffa": {"doc_hash": "a644811f76dc12c6e0381eab9f882bbbbfdb09c832d503d5b95bb236c9515dbc", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}, "c7f3a9ae-e117-415b-827b-98804c5c7eae": {"doc_hash": "8a98610c7c76ab3e5ce6835aa2dc19a57f925f6be1922390e5fd6ea35dcc58fd", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}, "dc350019-1023-4944-a299-178d52ead84b": {"doc_hash": "4928dc4121c3994496aad365cf161dd814d31ccae5967a7cdedc9a3faab6d695", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}, "80d853e1-034a-40fb-8d98-af481ac32dc5": {"doc_hash": "bcaa1385dad8599997bf1ae7af2502def521c6e2156de30b651f01ad0c8bc91a", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}, "89182522-2c05-4559-a4c1-74d2b6751003": {"doc_hash": "ed07ef75667df06b57940a7b068b5cec6e8af52946c4a9c75dda68e0fb70f773", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}, "2bc17dce-8e42-4b90-9e95-6f5baa16e709": {"doc_hash": "ebfed574cea5e2dad99d736523bc9c02f2c66957ad1fffc6a4e9115b4e867fa2", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}, "52655261-d924-481d-a332-d900a66b0dbf": {"doc_hash": "f37c9af5348d658642f650314e2baf7df4c0ca6f400351871b17c1027ee3f902", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}, "72e0e1b7-876a-4ea5-a3d8-3196444c3c50": {"doc_hash": "2ccfcfdc44d7fbb7088cd0a6d7165f0a4a1fe05128d5d1e3dac3c78f3333dc82", "ref_doc_id": "47548502-0bbf-49e1-924c-d4108e806c80"}}, "docstore/ref_doc_info": {"47548502-0bbf-49e1-924c-d4108e806c80": {"node_ids": ["1a322b4a-bb8a-4ed3-8f91-943f64048ffa", "c7f3a9ae-e117-415b-827b-98804c5c7eae", "dc350019-1023-4944-a299-178d52ead84b", "80d853e1-034a-40fb-8d98-af481ac32dc5", "89182522-2c05-4559-a4c1-74d2b6751003", "2bc17dce-8e42-4b90-9e95-6f5baa16e709", "52655261-d924-481d-a332-d900a66b0dbf", "72e0e1b7-876a-4ea5-a3d8-3196444c3c50"], "metadata": {"filename": "introducing-llamacloud-and-llamaparse-af8cedf9006b.md", "extension": ".md", "title": "Introducing LlamaCloud and LlamaParse", "date": "Feb 20, 2024", "url": "https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b"}}}}