{"docstore/data": {"b1c2cbae-f707-4c38-a9a2-d52023b408ce": {"__data__": {"id_": "b1c2cbae-f707-4c38-a9a2-d52023b408ce", "embedding": null, "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4a63efca-5f68-4751-8873-d360c5e7a521", "node_type": "1", "metadata": {"Header_1": " Context"}, "hash": "07c04309032a35fc1539acfafe62395456ba53173ffd4de81ea5208eb482951e", "class_name": "RelatedNodeInfo"}}, "text": "Today we introduce **Query Pipelines,** a new declarative API within\nLlamaIndex that allows you to **concisely orchestrate simple-to-advanced query\nworkflows over your data for different use cases** (RAG, structured data\nextraction, and more).\n\nAt the core of all this is our ` QueryPipeline ` abstraction. It can take in\nmany LlamaIndex modules (LLMs, prompts, query engines, retrievers, itself). It\ncan create a computational graph over these modules (e.g. a sequential chain\nor a DAG). It has callback support and native support with our [ observability\npartners\n](https://docs.llamaindex.ai/en/latest/module_guides/observability/observability.html)\n.\n\nThe end goal is that it\u2019s even easier to build LLM workflows over your data.\nCheck out our comprehensive [ introduction guide\n](https://docs.llamaindex.ai/en/latest/examples/pipeline/query_pipeline.html)\n, as well as our [ docs page\n](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/root.html)\nfor more details.\n\nExample `QueryPipeline` setup for an advanced RAG pipeline", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1048, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a63efca-5f68-4751-8873-d360c5e7a521": {"__data__": {"id_": "4a63efca-5f68-4751-8873-d360c5e7a521", "embedding": null, "metadata": {"Header_1": " Context", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1c2cbae-f707-4c38-a9a2-d52023b408ce", "node_type": "1", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "26fdacc656306b04be4d08a653fe6a42a806bed83dca7a5986e678bdc095e85b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27104217-9184-4a59-8280-e92553ec9dbf", "node_type": "1", "metadata": {"Header_1": " Context", "Header_2": " Previous State of LlamaIndex"}, "hash": "aec49c5c05162180e0938b214f4e0eccd3a8b01dad7111e85678ca0aaedc253b", "class_name": "RelatedNodeInfo"}}, "text": "Context\n\nOver the past year AI engineers have developed customized, complex\norchestration flows with LLMs to solve a variety of different use cases. Over\ntime some common patterns developed. At a top-level, paradigms emerged to\nquery a user\u2019s data \u2014 this includes RAG (in a narrow definition) to query\nunstructured data, and text-to-SQL to query structured data. Other paradigms\nemerged around use cases like structured data extraction (e.g. prompt the LLM\nto output JSON, and parse it), prompt chaining (e.g. chain-of-thought), and\nagents that could interact with external services (combine prompt chaining\n\n**There is a lot of query orchestration in RAG.** Even within RAG itself there\ncan be a lot of work to build an advanced RAG pipeline optimized for\nperformance. Starting from the user query, we may want to run query\nunderstanding/transformations (re-writing, routing). We also may want to run\nmulti-stage retrieval algorithms \u2014 e.g. top-k lookup + reranking. We may also\nwant to use prompts + LLMs to do response synthesis in different ways. Here\u2019s\na great blog on advanced RAG [ components\n](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-\noverview-04d193d8fec6) .\n\n[ Source: \u201cAdvanced RAG Techniques: an Illustrated Overview\u201d by Ivan Ilin\n](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-\noverview-04d193d8fec6)\n\n**RAG has become more modular:** Instead of a single way to do retrieval/RAG,\ndevelopers are encouraged to pick and choose the best modules for their use\ncases. This sentiment is echoed in the [ RAG Survey paper by Gao et al.\n](https://arxiv.org/pdf/2312.10997.pdf)\n\nThis leads to creative new patterns like [ DSP\n](https://github.com/stanfordnlp/dspy) , [ Rewrite-Retrieve-Read\n](https://arxiv.org/abs/2305.14283) , or [ interleaving retrieval+generation\nmultiple times ](https://arxiv.org/abs/2305.15294) .", "mimetype": "text/plain", "start_char_idx": 1053, "end_char_idx": 2921, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "27104217-9184-4a59-8280-e92553ec9dbf": {"__data__": {"id_": "27104217-9184-4a59-8280-e92553ec9dbf", "embedding": null, "metadata": {"Header_1": " Context", "Header_2": " Previous State of LlamaIndex", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a63efca-5f68-4751-8873-d360c5e7a521", "node_type": "1", "metadata": {"Header_1": " Context", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "73824da61a7c7aa9728a0a1b0c07146dda72d370f94a464ea5aeda8240a8b960", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e8780176-e238-4101-9108-33eb955c2585", "node_type": "1", "metadata": {"Header_1": " Query Pipeline"}, "hash": "8d63ac67cfebd3c07583d51ea6436ce3da1fa60a5105d9b58b736b1f9b9c1456", "class_name": "RelatedNodeInfo"}}, "text": "Previous State of LlamaIndex\n\nLlamaIndex itself has hundreds of RAG guides and 16+ Llama Pack recipes\nletting users setup [ different RAG pipelines ](/a-cheat-sheet-and-some-\nrecipes-for-building-advanced-rag-803a9d94c41b) , and has been at the\nforefront of establishing advanced RAG patterns.\n\nWe\u2019ve also exposed low-level modules such as [ LLMs\n](https://docs.llamaindex.ai/en/latest/module_guides/models/llms.html) , [\nprompts\n](https://docs.llamaindex.ai/en/stable/module_guides/models/prompts.html#prompts)\n, [ embeddings\n](https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html) ,\n[ postprocessors\n](https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/root.html)\nand easy subclassability of core components like [ retrievers\n](https://docs.llamaindex.ai/en/stable/examples/query_engine/CustomRetrievers.html)\nand [ query engines\n](https://docs.llamaindex.ai/en/stable/examples/query_engine/custom_query_engine.html)\nso that users can define their own workflows.\n\nBut up until now, we didn\u2019t explicitly have an orchestration abstraction.\nUsers were responsible for figuring out their own workflows by reading the API\nguides of each module, converting outputs to the right inputs, and using the\nmodules imperatively.", "mimetype": "text/plain", "start_char_idx": 2927, "end_char_idx": 4194, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8780176-e238-4101-9108-33eb955c2585": {"__data__": {"id_": "e8780176-e238-4101-9108-33eb955c2585", "embedding": null, "metadata": {"Header_1": " Query Pipeline", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "27104217-9184-4a59-8280-e92553ec9dbf", "node_type": "1", "metadata": {"Header_1": " Context", "Header_2": " Previous State of LlamaIndex", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "edbed869a5ddb7431a1ef8c2e78d6ec19ba8965aabf6f6db1c3eb3251a714df8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "84bea255-8fd3-454c-9417-87497e5cde45", "node_type": "1", "metadata": {"Header_1": " Usage"}, "hash": "bd0f282d46ad03d61831f2da5fc57b05ff191cb5b6d259df2295bb26891de5a9", "class_name": "RelatedNodeInfo"}}, "text": "Query Pipeline\n\nAs a result, our QueryPipeline provides a declarative query orchestration\nabstraction. You can use it to compose both sequential chains and directed\nacyclic graphs (DAGs) of arbitrary complexity.\n\nYou can already compose these workflows imperatively with LlamaIndex modules,\nbut the QueryPipeline allows you to do it efficiently with fewer lines of\ncode.\n\nIt has the following benefits:\n\n  * **Express common query workflows with fewer lines of code/boilerplate:** Stop writing converter logic between outputs/inputs, and figuring out the exact typing of arguments for each module! \n  * **Greater readability:** Reduced boilerplate leads to greater readability. \n  * **End-to-end observability:** Get callback integration across the entire pipeline (even for arbitrarily nested DAGs), so you stop fiddling around with our observability integrations. \n  * **[In the future] Easy Serializability:** A declarative interface allows the core components to be serialized/redeployed on other systems much more easily. \n  * **[In the future] Caching:** This interface also allows us to build a caching layer under the hood, allowing input re-use. \n\nVisualization of our advanced RAG QueryPipeline using `networkx` and `pyvis`", "mimetype": "text/plain", "start_char_idx": 4199, "end_char_idx": 5432, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "84bea255-8fd3-454c-9417-87497e5cde45": {"__data__": {"id_": "84bea255-8fd3-454c-9417-87497e5cde45", "embedding": null, "metadata": {"Header_1": " Usage", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e8780176-e238-4101-9108-33eb955c2585", "node_type": "1", "metadata": {"Header_1": " Query Pipeline", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "8792772e213a1ece9111276d6bab946cee207d1d28481d566d55bc14ec7d114a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff288bf1-c418-46c5-bf9b-beba0a610ec4", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Sequential Chain"}, "hash": "79b437641d6f172a92d533d32f9b626159cbb2c844715263e724c2dcf15e1329", "class_name": "RelatedNodeInfo"}}, "text": "Usage\n\nThe QueryPipeline allows you to a DAG-based query workflow using LlamaIndex\nmodules. There are two main ways to use it:\n\n  * As a sequential chain (easiest/most concise) \n  * As a full DAG (more expressive) \n\nSee our [ usage pattern guide\n](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/usage_pattern.html)\nfor more details.", "mimetype": "text/plain", "start_char_idx": 5437, "end_char_idx": 5791, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ff288bf1-c418-46c5-bf9b-beba0a610ec4": {"__data__": {"id_": "ff288bf1-c418-46c5-bf9b-beba0a610ec4", "embedding": null, "metadata": {"Header_1": " Usage", "Header_2": " Sequential Chain", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "84bea255-8fd3-454c-9417-87497e5cde45", "node_type": "1", "metadata": {"Header_1": " Usage", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "2276955754fa4aabb039299ff8c2afb4cd4a9b4d0a71419ec0fcf169507d4619", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b3a0a597-79a0-460b-8d47-eb46e41cc5f0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Setting up a DAG for an Advanced RAG Workflow"}, "hash": "3490c58868db10ac4f98daf17c7d1163c2432a31c5ad606582de49d7da4514b7", "class_name": "RelatedNodeInfo"}}, "text": "Sequential Chain\n\nSome simple pipelines are purely linear in nature \u2014 the output of the previous\nmodule directly goes into the input of the next module.\n\nSome examples:\n\n  * Prompt \u2192 LLM \u2192 Output parsing \n  * Retriever \u2192Response synthesizer \n\nHere\u2019s the most basic example, chaining a prompt with LLM. Simply initialize `\nQueryPipeline ` with the ` chain ` parameter.\n\n    \n    \n    # try chaining basic prompts\n    prompt_str = \"Please generate related movies to {movie_name}\"\n    prompt_tmpl = PromptTemplate(prompt_str)\n    llm = OpenAI(model=\"gpt-3.5-turbo\")\n    \n    p = QueryPipeline(chain=[prompt_tmpl, llm], verbose=True)", "mimetype": "text/plain", "start_char_idx": 5797, "end_char_idx": 6426, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b3a0a597-79a0-460b-8d47-eb46e41cc5f0": {"__data__": {"id_": "b3a0a597-79a0-460b-8d47-eb46e41cc5f0", "embedding": null, "metadata": {"Header_1": " Usage", "Header_2": " Setting up a DAG for an Advanced RAG Workflow", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff288bf1-c418-46c5-bf9b-beba0a610ec4", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Sequential Chain", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "0973f3d48af97cbc889ad5c621497b9bc1c4696f90ab6d025cdcf5eebf63b952", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20eea007-d94d-4c47-8f53-af0685eea6d0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " **Running the Pipeline**"}, "hash": "cc4bc3df8e20f0de449bce4e13c38fd304c5e48fcb6710c8318f7484d16375b0", "class_name": "RelatedNodeInfo"}}, "text": "Setting up a DAG for an Advanced RAG Workflow\n\nGenerally setting up a query workflow will require using our lower-level\nfunctions to build a DAG.\n\nFor instance, to build an \u201cadvanced RAG\u201d consisting of query\nrewriting/retrieval/reranking/synthesis, you\u2019d do something like the\nfollowing.\n\n    \n    \n    from llama_index.postprocessor import CohereRerank\n    from llama_index.response_synthesizers import TreeSummarize\n    from llama_index import ServiceContext\n    \n    # define modules\n    prompt_str = \"Please generate a question about Paul Graham's life regarding the following topic {topic}\"\n    prompt_tmpl = PromptTemplate(prompt_str)\n    llm = OpenAI(model=\"gpt-3.5-turbo\")\n    retriever = index.as_retriever(similarity_top_k=3)\n    reranker = CohereRerank()\n    summarizer = TreeSummarize(\n        service_context=ServiceContext.from_defaults(llm=llm)\n    )\n    \n    # define query pipeline\n    p = QueryPipeline(verbose=True)\n    p.add_modules(\n        {\n            \"llm\": llm,\n            \"prompt_tmpl\": prompt_tmpl,\n            \"retriever\": retriever,\n            \"summarizer\": summarizer,\n            \"reranker\": reranker,\n        }\n    )\n    # add edges \n    p.add_link(\"prompt_tmpl\", \"llm\")\n    p.add_link(\"llm\", \"retriever\")\n    p.add_link(\"retriever\", \"reranker\", dest_key=\"nodes\")\n    p.add_link(\"llm\", \"reranker\", dest_key=\"query_str\")\n    p.add_link(\"reranker\", \"summarizer\", dest_key=\"nodes\")\n    p.add_link(\"llm\", \"summarizer\", dest_key=\"query_str\")\n\nIn this code block we 1) add modules, and then 2) define relationships between\nmodules. Note that by ` source_key ` and ` dest_key ` are **optional** and are\nonly required if first module has more than one output / the second module has\nmore than one input respectively.", "mimetype": "text/plain", "start_char_idx": 6432, "end_char_idx": 8175, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20eea007-d94d-4c47-8f53-af0685eea6d0": {"__data__": {"id_": "20eea007-d94d-4c47-8f53-af0685eea6d0", "embedding": null, "metadata": {"Header_1": " Usage", "Header_2": " **Running the Pipeline**", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b3a0a597-79a0-460b-8d47-eb46e41cc5f0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Setting up a DAG for an Advanced RAG Workflow", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "cff65a73bff8fc5cf554038e3ea4eed7bd479e11c708f4a99a6024b651473418", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd1df999-4e6e-43d8-89c7-e1f77daac0e0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Defining a Custom Query Component"}, "hash": "ed3e9d5eee425b4323fc52d35ed21170bb4a1036273246bc57b5ad2a5bf40a57", "class_name": "RelatedNodeInfo"}}, "text": "**Running the Pipeline**\n\nIf the pipeline has one \u201croot\u201d node and one output node, use ` run ` . Using\nthe previous example,\n\n    \n    \n    output = p.run(topic=\"YC\")\n    # output type is Response\n    type(output)\n\nIf the pipeline has multiple root nodes and/or multiple output nodes, use `\nrun_multi ` .\n\n    \n    \n    output_dict = p.run_multi({\"llm\": {\"topic\": \"YC\"}})\n    print(output_dict)", "mimetype": "text/plain", "start_char_idx": 8181, "end_char_idx": 8575, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd1df999-4e6e-43d8-89c7-e1f77daac0e0": {"__data__": {"id_": "bd1df999-4e6e-43d8-89c7-e1f77daac0e0", "embedding": null, "metadata": {"Header_1": " Usage", "Header_2": " Defining a Custom Query Component", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20eea007-d94d-4c47-8f53-af0685eea6d0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " **Running the Pipeline**", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "f3408bf40cb86d9c89bd6663c5d5d05021f6d01cf75f96cfb781b4d17065e42a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a387228-6d3c-4861-998e-1297f36f56b0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Supported Modules"}, "hash": "b86fd6d4c761586809aa1646b7bde6b0136f82739afafaf98b34e708f753cdce", "class_name": "RelatedNodeInfo"}}, "text": "Defining a Custom Query Component\n\nIt\u2019s super easy to subclass ` CustomQueryComponent ` so you can plug it into\nthe QueryPipeline.\n\nCheck out [ our walkthrough\n](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/usage_pattern.html#defining-\na-custom-query-component) for more details.", "mimetype": "text/plain", "start_char_idx": 8581, "end_char_idx": 8884, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3a387228-6d3c-4861-998e-1297f36f56b0": {"__data__": {"id_": "3a387228-6d3c-4861-998e-1297f36f56b0", "embedding": null, "metadata": {"Header_1": " Usage", "Header_2": " Supported Modules", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd1df999-4e6e-43d8-89c7-e1f77daac0e0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Defining a Custom Query Component", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "c8685ec924d12453cfd7621f66d41eaec9a36508ad6d6ede13ad2ff945e6c00b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "37616a92-f7ef-4434-a73f-73f86b7c4b2d", "node_type": "1", "metadata": {"Header_1": " Walkthrough Example"}, "hash": "9ddd5dc4d15829e24518721bed6a97ce24f98f2b2550e579b13931f530d9ca97", "class_name": "RelatedNodeInfo"}}, "text": "Supported Modules\n\nCurrently the following LlamaIndex modules are supported within a\nQueryPipeline. Remember, you can define your own!\n\n  1. LLMs (both completion and chat) ( ` LLM ` ) \n  2. Prompts ( ` PromptTemplate ` ) \n  3. Query Engines ( ` BaseQueryEngine ` ) \n  4. Query Transforms ( ` BaseQueryTransform ` ) \n  5. Retrievers ( ` BaseRetriever ` ) \n  6. Output Parsers ( ` BaseOutputParser ` ) \n  7. Postprocessors/Rerankers ( ` BaseNodePostprocessor ` ) \n  8. Response Synthesizers ( ` BaseSynthesizer ` ) \n  9. Other ` QueryPipeline ` objects \n  10. Custom components ( ` CustomQueryComponent ` ) \n\nCheck out the [ module usage guide\n](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/module_usage.html)\nfor more details.", "mimetype": "text/plain", "start_char_idx": 8890, "end_char_idx": 9640, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "37616a92-f7ef-4434-a73f-73f86b7c4b2d": {"__data__": {"id_": "37616a92-f7ef-4434-a73f-73f86b7c4b2d", "embedding": null, "metadata": {"Header_1": " Walkthrough Example", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a387228-6d3c-4861-998e-1297f36f56b0", "node_type": "1", "metadata": {"Header_1": " Usage", "Header_2": " Supported Modules", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "891d2f8812fc7ccbce810069df9db3ae6a1674bbbb0436f2f966f9cede93aea6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6cd09930-34db-4c98-97f2-0890a6780a13", "node_type": "1", "metadata": {"Header_1": " Related Work"}, "hash": "fc76b3068b33384f09b3094186c7edc6cddeb4e3361bef8323b2148ee963c64f", "class_name": "RelatedNodeInfo"}}, "text": "Walkthrough Example\n\nMake sure to check out our [ Introduction to Query Pipelines guide\n](https://docs.llamaindex.ai/en/latest/examples/pipeline/query_pipeline.html)\nfor full details. We go over all the steps above with concrete examples!\n\nThe notebook guide also logs traces through [ Arize Phoenix\n](https://github.com/Arize-ai/phoenix) . You can see the full run of each\nQueryPipeline in the Phoenix dashboard. Our full callback support throughout\nevery component in a QueryComponent allows you to easily integrate with any\nobservability provider.", "mimetype": "text/plain", "start_char_idx": 9645, "end_char_idx": 10195, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6cd09930-34db-4c98-97f2-0890a6780a13": {"__data__": {"id_": "6cd09930-34db-4c98-97f2-0890a6780a13", "embedding": null, "metadata": {"Header_1": " Related Work", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37616a92-f7ef-4434-a73f-73f86b7c4b2d", "node_type": "1", "metadata": {"Header_1": " Walkthrough Example", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "31a02ae51b8c50c6a028ae823ce175998897314271317fee894896d93be0c9f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b1c3323d-4203-4593-b537-050f3af258d3", "node_type": "1", "metadata": {"Header_1": " FAQ"}, "hash": "e234044e72f09ecce3153f5db7c13696cff01a74e35a315bd928510dc230144f", "class_name": "RelatedNodeInfo"}}, "text": "Related Work\n\nThe idea of a declarative syntax for building LLM-powered pipelines is not\nnew. Related works include [ Haystack\n](https://docs.haystack.deepset.ai/docs/pipelines) as well as the [ LangChain\nExpression Language ](https://python.langchain.com/docs/expression_language/)\n. Other related works include pipelines that are setup in the no-code/low-code\nsetting such as [ Langflow ](https://github.com/logspace-ai/langflow) / [\nFlowise ](https://flowiseai.com/) .\n\nOur main goal here was highlighted above: provide a convenient dev UX to\ndefine common query workflows over your data. There\u2019s a lot of\noptimizations/guides to be done here!", "mimetype": "text/plain", "start_char_idx": 10200, "end_char_idx": 10846, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b1c3323d-4203-4593-b537-050f3af258d3": {"__data__": {"id_": "b1c3323d-4203-4593-b537-050f3af258d3", "embedding": null, "metadata": {"Header_1": " FAQ", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6cd09930-34db-4c98-97f2-0890a6780a13", "node_type": "1", "metadata": {"Header_1": " Related Work", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "ccef07f7aa19133ecef32c5d95063da826c5181f6e2666bcb4f93acdcad5031b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "60094469-3b1b-4850-869f-1a6f9d558832", "node_type": "1", "metadata": {"Header_1": " Conclusion + Resources"}, "hash": "09c0e7c922f0b5b4618e7fc9d18fbd2b1510ffeaff5e52e01849cfcd45070e26", "class_name": "RelatedNodeInfo"}}, "text": "FAQ\n\n**What\u2019s the difference between a** ` **QueryPipeline** ` **and** ` [\n**IngestionPipeline**\n](https://docs.llamaindex.ai/en/stable/module_guides/loading/ingestion_pipeline/root.html)\n` **?**\n\nGreat question. Currently the IngestionPipeline operates during the data\ningestion stage, and the QueryPipeline operates during the query stage. That\nsaid, there\u2019s potentially some shared abstractions we\u2019ll develop for both!", "mimetype": "text/plain", "start_char_idx": 10851, "end_char_idx": 11272, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "60094469-3b1b-4850-869f-1a6f9d558832": {"__data__": {"id_": "60094469-3b1b-4850-869f-1a6f9d558832", "embedding": null, "metadata": {"Header_1": " Conclusion + Resources", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b511f700-08fe-4754-a875-32d056eae32f", "node_type": "4", "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "1d10a8242ea930dc9e0522a78e6390d701ed21adc725131456e1473a5c92827c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1c3323d-4203-4593-b537-050f3af258d3", "node_type": "1", "metadata": {"Header_1": " FAQ", "filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}, "hash": "67b6aa84c072545ec68439cb2b8c64b8d92c3ff8471fbe5ab769f113ea182c7f", "class_name": "RelatedNodeInfo"}}, "text": "Conclusion + Resources\n\nThat\u2019s it! As mentioned above we\u2019ll be adding a lot more resources and guides\nsoon. In the meantime check out our current guides:\n\n  * [ Query Pipelines Guide ](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/root.html)\n  * [ Query Pipelines Walkthrough ](https://docs.llamaindex.ai/en/latest/examples/pipeline/query_pipeline.html)\n  * [ Query Pipeline Usage Pattern ](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/usage_pattern.html)\n  * [ Query Pipelines Module Usage Guide ](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/module_usage.html)", "mimetype": "text/plain", "start_char_idx": 11277, "end_char_idx": 11910, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"b1c2cbae-f707-4c38-a9a2-d52023b408ce": {"doc_hash": "26fdacc656306b04be4d08a653fe6a42a806bed83dca7a5986e678bdc095e85b", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "4a63efca-5f68-4751-8873-d360c5e7a521": {"doc_hash": "73824da61a7c7aa9728a0a1b0c07146dda72d370f94a464ea5aeda8240a8b960", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "27104217-9184-4a59-8280-e92553ec9dbf": {"doc_hash": "edbed869a5ddb7431a1ef8c2e78d6ec19ba8965aabf6f6db1c3eb3251a714df8", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "e8780176-e238-4101-9108-33eb955c2585": {"doc_hash": "8792772e213a1ece9111276d6bab946cee207d1d28481d566d55bc14ec7d114a", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "84bea255-8fd3-454c-9417-87497e5cde45": {"doc_hash": "2276955754fa4aabb039299ff8c2afb4cd4a9b4d0a71419ec0fcf169507d4619", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "ff288bf1-c418-46c5-bf9b-beba0a610ec4": {"doc_hash": "0973f3d48af97cbc889ad5c621497b9bc1c4696f90ab6d025cdcf5eebf63b952", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "b3a0a597-79a0-460b-8d47-eb46e41cc5f0": {"doc_hash": "cff65a73bff8fc5cf554038e3ea4eed7bd479e11c708f4a99a6024b651473418", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "20eea007-d94d-4c47-8f53-af0685eea6d0": {"doc_hash": "f3408bf40cb86d9c89bd6663c5d5d05021f6d01cf75f96cfb781b4d17065e42a", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "bd1df999-4e6e-43d8-89c7-e1f77daac0e0": {"doc_hash": "c8685ec924d12453cfd7621f66d41eaec9a36508ad6d6ede13ad2ff945e6c00b", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "3a387228-6d3c-4861-998e-1297f36f56b0": {"doc_hash": "891d2f8812fc7ccbce810069df9db3ae6a1674bbbb0436f2f966f9cede93aea6", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "37616a92-f7ef-4434-a73f-73f86b7c4b2d": {"doc_hash": "31a02ae51b8c50c6a028ae823ce175998897314271317fee894896d93be0c9f6", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "6cd09930-34db-4c98-97f2-0890a6780a13": {"doc_hash": "ccef07f7aa19133ecef32c5d95063da826c5181f6e2666bcb4f93acdcad5031b", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "b1c3323d-4203-4593-b537-050f3af258d3": {"doc_hash": "67b6aa84c072545ec68439cb2b8c64b8d92c3ff8471fbe5ab769f113ea182c7f", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}, "60094469-3b1b-4850-869f-1a6f9d558832": {"doc_hash": "b56885a464286f0835740c807b0eb4960a9126baeaa2815f2933c3e2cd3921a6", "ref_doc_id": "b511f700-08fe-4754-a875-32d056eae32f"}}, "docstore/ref_doc_info": {"b511f700-08fe-4754-a875-32d056eae32f": {"node_ids": ["b1c2cbae-f707-4c38-a9a2-d52023b408ce", "4a63efca-5f68-4751-8873-d360c5e7a521", "27104217-9184-4a59-8280-e92553ec9dbf", "e8780176-e238-4101-9108-33eb955c2585", "84bea255-8fd3-454c-9417-87497e5cde45", "ff288bf1-c418-46c5-bf9b-beba0a610ec4", "b3a0a597-79a0-460b-8d47-eb46e41cc5f0", "20eea007-d94d-4c47-8f53-af0685eea6d0", "bd1df999-4e6e-43d8-89c7-e1f77daac0e0", "3a387228-6d3c-4861-998e-1297f36f56b0", "37616a92-f7ef-4434-a73f-73f86b7c4b2d", "6cd09930-34db-4c98-97f2-0890a6780a13", "b1c3323d-4203-4593-b537-050f3af258d3", "60094469-3b1b-4850-869f-1a6f9d558832"], "metadata": {"filename": "introducing-query-pipelines-025dc2bb0537.md", "extension": ".md", "title": "Introducing Query Pipelines", "date": "Jan 8, 2024", "url": "https://www.llamaindex.ai/blog/introducing-query-pipelines-025dc2bb0537"}}}}