{"docstore/data": {"576f5464-c6ff-4d53-bac5-eaa5e21ac057": {"__data__": {"id_": "576f5464-c6ff-4d53-bac5-eaa5e21ac057", "embedding": null, "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "06aad225-d411-4d5e-ba77-950fba23024b", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex"}, "hash": "dd6960abb518190a32d7470d791286f4f47004229ac6d8d156283edd59f257b8", "class_name": "RelatedNodeInfo"}}, "text": "**Co-authors:**\n\n  * Jerry Liu (co-founder/CEO of LlamaIndex) \n  * Erika Cardenas (Developer Advocate, Weaviate) \n\nWhile large language models (LLMs) like GPT-4 have impressive capabilities in\ngeneration and reasoning, they have limitations in terms of their ability to\naccess and retrieve specific facts, figures, or contextually relevant\ninformation. A popular solution to this problem is setting up a retrieval-\naugmented generation (RAG) system: combine the language model with an external\nstorage provider, and create an overall software system that can orchestrate\nthe interactions with and between these components in order to create a \u201cchat\nwith your data\u201d experience.\n\nThe combination of Weaviate and LlamaIndex provide the critical components\nneeded to easily setup a powerful and reliable RAG stack, so that you can\neasily deliver powerful LLM-enabled experiences over your data, such as search\nengines, chatbots, and more. First, we can use Weaviate as the vector database\nthat acts as the external storage provider. Next, we can use a powerful data\nframework such as LlamaIndex to help with data management and orchestration\naround Weaviate when building the LLM app.\n\nIn this blog post, we walk through an overview of LlamaIndex and some of the\ncore data management and query modules. We then go through an initial demo\nnotebook.\n\nWe\u2019re kicking off a new series to guide you on how to use LlamaIndex and\nWeaviate for your LLM applications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1453, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "06aad225-d411-4d5e-ba77-950fba23024b": {"__data__": {"id_": "06aad225-d411-4d5e-ba77-950fba23024b", "embedding": null, "metadata": {"Header_1": " An Introduction to LlamaIndex", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "576f5464-c6ff-4d53-bac5-eaa5e21ac057", "node_type": "1", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "7e3a88a518363d265913def7f6de3617872efbf97c63b5f93b9eaabce5878793", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9b831ea5-3b1f-407a-b6e2-e64439f0060c", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Ingestion"}, "hash": "884a5852df7ec4b358273ed4c235dfd4380ada1cc36250d8709528b39cf9af0d", "class_name": "RelatedNodeInfo"}}, "text": "An Introduction to LlamaIndex\n\nLlamaIndex is a data framework for building LLM applications. It provides a\ncomprehensive toolkit for ingestion, management, and querying of your external\ndata so that you can use it with your LLM app.", "mimetype": "text/plain", "start_char_idx": 1458, "end_char_idx": 1690, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9b831ea5-3b1f-407a-b6e2-e64439f0060c": {"__data__": {"id_": "9b831ea5-3b1f-407a-b6e2-e64439f0060c", "embedding": null, "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Ingestion", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "06aad225-d411-4d5e-ba77-950fba23024b", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "7fdac0044b0ec76b26b58ef053c4418c7f92f961894677768c871020c612a332", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ce915ed2-ec50-4189-97fc-40635ca54613", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Indexing"}, "hash": "881b4c9a0a813081bced897d7e5c460789ad6adcd2975b56c03452284ce6afc0", "class_name": "RelatedNodeInfo"}}, "text": "Data Ingestion\n\nOn data ingestion, LlamaIndex offers connectors to 100+ data sources, ranging\nfrom different file formats (.pdf, .docx, .pptx) to APIs (Notion, Slack,\nDiscord, etc.) to web scrapers (Beautiful Soup, Readability, etc.). These data\nconnectors are primarily hosted on [LlamaHub]( [ https://llamahub.ai/\n](https://llamahub.ai/) ). This makes it easy for users to integrate data from\ntheir existing files and applications.", "mimetype": "text/plain", "start_char_idx": 1696, "end_char_idx": 2129, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ce915ed2-ec50-4189-97fc-40635ca54613": {"__data__": {"id_": "ce915ed2-ec50-4189-97fc-40635ca54613", "embedding": null, "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Indexing", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9b831ea5-3b1f-407a-b6e2-e64439f0060c", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Ingestion", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "1a7a69c5c8701b454a47b8668e4e6c22a8dcd4bafbe12751df8fbda9dd16a9ed", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d56e2b7-ae0a-48dd-8fd7-6d9f2787c858", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Querying"}, "hash": "b2784c6043d86eb91a3b2f5211a15a2fff2fa0b6d341cbb61d5a6ab1286171ac", "class_name": "RelatedNodeInfo"}}, "text": "Data Indexing\n\nOnce the data is loaded, LlamaIndex offers the ability to index this data with\na wide variety of data structures and storage integration options (including\nWeaviate). LlamaIndex supports indexing unstructured, semi-structured, and\nstructured data. A standard way to index unstructured data is to split the\nsource documents into text \u201cchunks\u201d, embed each chunk, and store each\nchunk/embedding in a vector database.", "mimetype": "text/plain", "start_char_idx": 2135, "end_char_idx": 2563, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4d56e2b7-ae0a-48dd-8fd7-6d9f2787c858": {"__data__": {"id_": "4d56e2b7-ae0a-48dd-8fd7-6d9f2787c858", "embedding": null, "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Querying", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ce915ed2-ec50-4189-97fc-40635ca54613", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Indexing", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "9bed5db59b73721bb56791ce573f4925dc63af122392e00677394dc9593b3b9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1a838830-c298-4ddf-b75d-fa19f6a73c0f", "node_type": "1", "metadata": {"Header_1": " Demo Notebook Walkthrough"}, "hash": "a42691aee3106223f5f203433c806bca47c816705a0cd77a1a9d2bc0a8884b76", "class_name": "RelatedNodeInfo"}}, "text": "Data Querying\n\nOnce your data is ingested/stored, LlamaIndex provides the tools to define an\nadvanced retrieval / query \u201cengine\u201d over your data. Our retriever constructs\nallow you to retrieve data from your knowledge base given an input prompt. A\nquery engine construct allows you to define an interface that can take in an\ninput prompt, and output a knowledge-augmented response \u2014 it can use retrieval\nand synthesis (LLM) modules under the hood.\n\nSome examples of query engine \u201ctasks\u201d are given below, in rough order from\neasy to advanced:\n\n  * Semantic Search: Retrieve the top-k most similar items from the knowledge corpus by embedding similarity to the query, and synthesize a response over these contexts. \n  * Structured Analytics: Convert natural language to a SQL query that can be executed \n  * Query Decomposition over Documents: Break down a query into sub-questions, each over a subset of underlying documents. Each sub-question can be executed against its own query engine.", "mimetype": "text/plain", "start_char_idx": 2569, "end_char_idx": 3556, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a838830-c298-4ddf-b75d-fa19f6a73c0f": {"__data__": {"id_": "1a838830-c298-4ddf-b75d-fa19f6a73c0f", "embedding": null, "metadata": {"Header_1": " Demo Notebook Walkthrough", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d56e2b7-ae0a-48dd-8fd7-6d9f2787c858", "node_type": "1", "metadata": {"Header_1": " An Introduction to LlamaIndex", "Header_2": " Data Querying", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "4ac3cd053fff8eaadd8bd31d525b9376aaf1fc0194d852d9824b656c841fa36c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "28f1b3dd-3d73-427d-9d2d-fdc1af577bdc", "node_type": "1", "metadata": {"Header_1": " Next Up in this Series"}, "hash": "bcbe36c1cf28209fcdedf5e1c3b6686d2a08232c257faf040cd18601cc38fa33", "class_name": "RelatedNodeInfo"}}, "text": "Demo Notebook Walkthrough\n\nLet\u2019s walk through a simple example of how LlamaIndex can be used with\nWeaviate to build a simple Question-Answering (QA) system over the Weaviate\nblogs!\n\nThe full code can be found in the [ Weaviate recipes repo\n](https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/upload.py)\n.\n\nThe first step is to setup your Weaviate client. In this example, we connect\nto a local Weaviate instance through port ` http://localhost:8080 ` :\n\n    \n    \n    import weaviate\n    # connect to your weaviate instance\n    client = weaviate.Client(\"http://localhost:8080\")\n\nThe next step is to ingest the Weaviate documentation and parse the documents\ninto chunks. You can choose to use one of our many web page readers to scrape\nany website yourself \u2014 but luckily, the downloaded files are already readily\navailable in the recipes repo.\n\n    \n    \n    from llama_index.node_parser import SimpleNodeParser\n    # load the blogs in using the reader\n    blogs = SimpleDirectoryReader('./data').load_data()\n    # chunk up the blog posts into nodes\n    parser = SimpleNodeParser()\n    nodes = parser.get_nodes_from_documents(blogs)\n\nHere, we use the SimpleDirectoryReader to load in all documents from a given\ndirectory. We then use our ` SimpleNodeParser ` to chunk up the source\ndocuments into Node objects (text chunks).\n\nThe next step is to 1) define a ` WeaviateVectorStore ` , and 2) build a\nvector index over this vector store using LlamaIndex.\n\n    \n    \n    # construct vector store\n    vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"BlogPost\", text_key=\"content\")\n    # setting up the storage for the embeddings\n    storage_context = StorageContext.from_defaults(vector_store = vector_store)\n    # set up the index\n    index = VectorStoreIndex(nodes, storage_context = storage_context)\n\nOur WeaviateVectorStore abstraction creates a central interface between our\ndata abstractions and the Weaviate service. Note that the ` VectorStoreIndex `\nis initialized from both the nodes and the storage context object containing\nthe Weaviate vector store. During the initialization phase, the nodes are\nloaded into the vector store.\n\nFinally, we can define a query engine on top of our index. This query engine\nwill perform semantic search and response synthesis, and output an answer.\n\n    \n    \n    \u200b\u200bquery_engine = index.as_query_engine()\n    response = query_engine.query(\"What is the intersection between LLMs and search?\")\n    print(response)\n\nYou should get an answer like the following:\n\n    \n    \n    The intersection between LLMs and search is the ability to use LLMs to improve search capabilities, such as retrieval-augmented generation, query understanding, index construction, LLMs in re-ranking, and search result compression. LLMs can also be used to manage document updates, rank search results, and compress search results. LLMs can be used to prompt the language model to extract or formulate a question based on the prompt and then send that question to the search engine, or to prompt the model with a description of the search engine tool and how to use it with a special `[SEARCH]` token. LLMs can also be used to prompt the language model to rank search results according to their relevance with the query, and to classify the most likely answer span given a question and text passage as input.", "mimetype": "text/plain", "start_char_idx": 3562, "end_char_idx": 6926, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "28f1b3dd-3d73-427d-9d2d-fdc1af577bdc": {"__data__": {"id_": "28f1b3dd-3d73-427d-9d2d-fdc1af577bdc", "embedding": null, "metadata": {"Header_1": " Next Up in this Series", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1a838830-c298-4ddf-b75d-fa19f6a73c0f", "node_type": "1", "metadata": {"Header_1": " Demo Notebook Walkthrough", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "f4fae704f111b8eae262c3618cc7df3432558ef22e897b6032b48952b47079d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "034d840a-c399-4e67-b938-76f1ef816459", "node_type": "1", "metadata": {"Header_1": " Next Up in this Series", "Header_2": " What\u2019s next [ \u200b ](https://weaviate.io/blog/llamaindex-and-weaviate#whats-"}, "hash": "a50d340424cc1856abfebd973ea31d6d2f150981414db162d9ffac8698898d5b", "class_name": "RelatedNodeInfo"}}, "text": "Next Up in this Series\n\nThis blog post shared an initial overview of the LlamaIndex and Weaviate\nintegration. We covered an introduction to the toolkits offered in LlamaIndex\nand a notebook on how to build a simple QA engine over Weaviate\u2019s blog posts.\nNow that we have a baseline understanding, we will build on this by sharing\nmore advanced guides soon. Stay tuned!", "mimetype": "text/plain", "start_char_idx": 6931, "end_char_idx": 7298, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "034d840a-c399-4e67-b938-76f1ef816459": {"__data__": {"id_": "034d840a-c399-4e67-b938-76f1ef816459", "embedding": null, "metadata": {"Header_1": " Next Up in this Series", "Header_2": " What\u2019s next [ \u200b ](https://weaviate.io/blog/llamaindex-and-weaviate#whats-", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87", "node_type": "4", "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "da2e947a2d099ca48cce36c15c24560aa33fb951f6155cb12b449a11e5eab594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "28f1b3dd-3d73-427d-9d2d-fdc1af577bdc", "node_type": "1", "metadata": {"Header_1": " Next Up in this Series", "filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}, "hash": "b6f749e9cfeeed6eaa4f5eaeedc047e75f4d52ffdb8d972ab2998e1c54f33516", "class_name": "RelatedNodeInfo"}}, "text": "What\u2019s next [ \u200b ](https://weaviate.io/blog/llamaindex-and-weaviate#whats-\nnext)\n\nCheck out [ Getting Started with Weaviate\n](https://weaviate.io/developers/weaviate/quickstart) , and begin building\namazing apps with Weaviate.\n\nYou can reach out to us on [ Slack ](https://weaviate.io/slack) or [ Twitter\n](https://twitter.com/weaviate_io) , or [ join the community forum\n](https://forum.weaviate.io/) .\n\nWeaviate is open source, and you can follow the project on [ GitHub\n](https://github.com/weaviate/weaviate) . Don\u2019t forget to give us a while you\nare there!", "mimetype": "text/plain", "start_char_idx": 7304, "end_char_idx": 7864, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"576f5464-c6ff-4d53-bac5-eaa5e21ac057": {"doc_hash": "7e3a88a518363d265913def7f6de3617872efbf97c63b5f93b9eaabce5878793", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}, "06aad225-d411-4d5e-ba77-950fba23024b": {"doc_hash": "7fdac0044b0ec76b26b58ef053c4418c7f92f961894677768c871020c612a332", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}, "9b831ea5-3b1f-407a-b6e2-e64439f0060c": {"doc_hash": "1a7a69c5c8701b454a47b8668e4e6c22a8dcd4bafbe12751df8fbda9dd16a9ed", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}, "ce915ed2-ec50-4189-97fc-40635ca54613": {"doc_hash": "9bed5db59b73721bb56791ce573f4925dc63af122392e00677394dc9593b3b9e", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}, "4d56e2b7-ae0a-48dd-8fd7-6d9f2787c858": {"doc_hash": "4ac3cd053fff8eaadd8bd31d525b9376aaf1fc0194d852d9824b656c841fa36c", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}, "1a838830-c298-4ddf-b75d-fa19f6a73c0f": {"doc_hash": "f4fae704f111b8eae262c3618cc7df3432558ef22e897b6032b48952b47079d2", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}, "28f1b3dd-3d73-427d-9d2d-fdc1af577bdc": {"doc_hash": "b6f749e9cfeeed6eaa4f5eaeedc047e75f4d52ffdb8d972ab2998e1c54f33516", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}, "034d840a-c399-4e67-b938-76f1ef816459": {"doc_hash": "6aa4ce3492b07ed74549aab3778a734aa3c8d6a2fa1adbc1bb45b49890036707", "ref_doc_id": "1bc559ea-0cfe-44a0-ab03-e11959e69b87"}}, "docstore/ref_doc_info": {"1bc559ea-0cfe-44a0-ab03-e11959e69b87": {"node_ids": ["576f5464-c6ff-4d53-bac5-eaa5e21ac057", "06aad225-d411-4d5e-ba77-950fba23024b", "9b831ea5-3b1f-407a-b6e2-e64439f0060c", "ce915ed2-ec50-4189-97fc-40635ca54613", "4d56e2b7-ae0a-48dd-8fd7-6d9f2787c858", "1a838830-c298-4ddf-b75d-fa19f6a73c0f", "28f1b3dd-3d73-427d-9d2d-fdc1af577bdc", "034d840a-c399-4e67-b938-76f1ef816459"], "metadata": {"filename": "llamaindex-and-weaviate-ba3ff1cbf5f4.md", "extension": ".md", "title": "LlamaIndex and Weaviate", "date": "Jun 22, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-and-weaviate-ba3ff1cbf5f4"}}}}