{"docstore/data": {"03c8b554-539b-4162-a8d8-8ee2428a683d": {"__data__": {"id_": "03c8b554-539b-4162-a8d8-8ee2428a683d", "embedding": null, "metadata": {"filename": "llamaindex-newsletter-2023-11-07-cf20b9a833aa.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023-11\u201307", "date": "Nov 8, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-07-cf20b9a833aa"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0302f702-fa36-4074-9a4f-75b289b66dd6", "node_type": "4", "metadata": {"filename": "llamaindex-newsletter-2023-11-07-cf20b9a833aa.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023-11\u201307", "date": "Nov 8, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-07-cf20b9a833aa"}, "hash": "bd85325d0c2aa85efa8035e9e9f247c38881dce8e15c725a80cf2452e159193a", "class_name": "RelatedNodeInfo"}}, "text": "Hi again Llama Fans!\n\nWe hope you enjoyed our [ OpenAI Dev Day special edition ](/llamaindex-news-\nspecial-edition-openai-developer-day-e955f16db4e2) yesterday! Here\u2019s our wrap-\nup of everything else that happened last week. As always, if you\u2019ve got a\nproject, article, or video that\u2019s turning heads? We\u2019re all ears! Drop us a\nline at [ news@llamaindex.ai ](mailto:news@llamaindex.ai) .\n\nAnd for all this goodness delivered directly to you, don\u2019t forget to subscribe\nto our newsletter via our [ website ](https://www.llamaindex.ai/) .\n\n**First, the highlights:**\n\n  1. **LlamaIndex Chat:** We unveiled a customizable LLM chatbot template with system prompts and avatars, all within an open-source MIT-licensed framework using LlamaIndex for TypeScript. Explore the [ Demo ](https://chat.llamaindex.ai/) or check the [ Tweet ](https://x.com/llama_index/status/1719021921462067654?s=20) . \n  2. **Evaluator Fine-Tuning:** We launched a method to enhance LLM output assessment by distilling GPT-4 into GPT-3.5, optimizing both cost and speed. See our [ Tweet ](https://x.com/llama_index/status/1719868813318271242?s=20) . \n  3. **ParamTuner:** We introduced a new hyperparameter tuning abstraction to refine RAG pipeline performance, featuring objective functions, grid search, and Ray Tune integration. Check out the [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/param_optimizer/param_optimizer.ipynb) and [ Tweet ](https://twitter.com/llama_index/status/1721209688703062234?s=20) . \n  4. **CohereAI Embed v3 & Voyage AI Integration: ** We strengthened the LlamaIndex RAG pipeline with two powerful embedding model additions: the latest Embed v3 from CohereAI and the high-performing embedding model from Voyage AI. [ Tweet ](https://twitter.com/llama_index/status/1720216603584069875?s=20) and [ tweet ](https://x.com/llama_index/status/1720578050180686129?s=20) . \n\n**Feature Releases and Enhancements:**\n\n  * We introduced LlamaIndex Chat, a new feature allowing users to create and share custom LLM chatbots tailored to their data, complete with personalized system prompts and avatars. Additionally, we\u2019re proud to share that it\u2019s a fully open-source template under the MIT license, crafted using LlamaIndexTS for a seamless start to LLM application development. [ Demo ](https://chat.llamaindex.ai/) , [ Tweet ](https://x.com/llama_index/status/1719021921462067654?s=20) . \n  * We introduced a method for fine-tuning an Evaluator to distill GPT-4 into GPT-3.5, enhancing LLM output assessment while reducing costs and improving speed. [ Tweet ](https://x.com/llama_index/status/1719868813318271242?s=20) . \n  * We introduced ` ParamTuner ` , a hyperparameter tuning abstraction for LlamaIndex RAG, streamlining the process with objective functions and support for grid search, including integration with Ray Tune for enhanced optimization. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/param_optimizer/param_optimizer.ipynb) , [ Tweet ](https://twitter.com/llama_index/status/1721209688703062234?s=20) . \n\n**** Demos:\n\n  * GPTDiscord is a versatile LLM-powered Discord bot with over 20 features, including multi-modal image understanding and advanced data analysis. It boasts an infinite conversational memory and the ability to interact with various file types and internet services. [ Tweet ](https://twitter.com/llama_index/status/1720151524280881335?s=20) . \n\n**Guides:**\n\n  * We shared a [ guide ](https://docs.llamaindex.ai/en/latest/examples/retrievers/deep_memory.html) for integrating Activeloop\u2019s Deep Memory with LlamaIndex, a module that enhances your embeddings at ingestion and can improve RAG metrics by 15%, all while seamlessly fitting into LlamaIndex\u2019s automated dataset and vector store features. \n  * We shared a [ guide ](https://docs.llamaindex.ai/en/latest/examples/prompts/prompt_optimization.html) inspired by [ **Chengrun Yang** ](https://twitter.com/chengrun_yang) and GoogleDeepMind\u2019s ` Optimization by Prompting ` paper, demonstrating how to automate prompt tuning in LlamaIndex RAG pipelines using meta-prompting, boosting evaluation performance while acknowledging the experimental nature of this technique. \n  * We shared a [ guide ](https://docs.llamaindex.ai/en/latest/examples/prompts/emotion_prompt.html) on how to implement Emotion Prompting in LlamaIndex, allowing you to enhance your RAG pipeline with various emotional stimuli and evaluate their impact on task performance. \n  * We showcased MongoDB [ starter ](https://github.com/run-llama/mongodb-demo) kit, a comprehensive LlamaIndex RAG setup with Flask backend, Next frontend, and easy deployment to Render. \n\n**Tutorials:**\n\n  * [ Wenqi Glantz ](https://medium.com/@wenqiglantz) made a [ blog post ](https://levelup.gitconnected.com/optimizing-text-embeddings-with-huggingfaces-text-embeddings-inference-server-and-llamaindex-ef7df35882a4) on deploying the HuggingFace ` **text-embeddings-inference** ` server on an AWS EC2 GPU instance, enhancing LlamaIndex RAG pipeline's performance and results. \n  * [ Sophia Yang\u2019s ](https://twitter.com/sophiamyang) [ tutorial ](https://www.youtube.com/watch?v=QqDZVg9S_Vk) on Zephyr-7b-beta showcases its leading capabilities in LLM technology, including how it\u2019s benchmarked with LlamaIndex for diverse AI tasks. \n  * [ Sudarshan Koirala ](https://twitter.com/mesudarshan) gave a [ tutorial ](https://www.youtube.com/watch?v=vJz9WVgsu9g) on how to build a multi-modal retrieval system with LlamaIndex, Qdrant, and bge/CLIP embeddings. \n  * [ Sophia Yang\u2019s ](https://twitter.com/sophiamyang) gave another [ tutorial ](https://www.youtube.com/watch?v=ihSiRrOUwmg) , this time on Small-to-Big Retrieval with LlamaIndex in building advanced RAG systems. \n  * [ Ravi Theja\u2019s ](https://www.linkedin.com/in/ravidesetty/) [ tutorial ](https://www.youtube.com/watch?v=X8BHWGXXdW0) on the Router Query Engine that helps you to set up multiple indices/ query engines for your dataset, allowing the LLM to choose the most suitable one for each specific question. \n\n**Integrations & Collaborations: **\n\n  * We integrated the [ **Tavily AI** ](https://tavily.com/) research API into the LlamaIndex RAG pipeline, offering a robust tool for web research to enhance LLM agent automation. [ Notebook ](https://github.com/run-llama/llama-hub/blob/main/llama_hub/tools/notebooks/tavily.ipynb) , [ Tweet ](https://x.com/llama_index/status/1719745197729599681?s=20) . \n  * We integrated [ **Noam Gat** ](https://twitter.com/noamgat) \u2019s LLM Enforcer into the LlamaIndex RAG pipeline to ensure structured outputs for various models. [ Docs ](https://docs.llamaindex.ai/en/latest/community/integrations/lmformatenforcer.html) , [ Tweet ](https://twitter.com/llama_index/status/1720103157412647265?s=20) . \n  * We integrated the latest Embed v3 model from CohereAI, enhancing document retrieval quality within the LlamaIndex RAG pipeline. [ Notebook ](https://t.co/NOQxN9RJi3) , [ Tweet ](https://twitter.com/llama_index/status/1720216603584069875?s=20) . \n  * We integrated the new Voyage AI embedding model, a top-performing option for RAG pipelines. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/embeddings/voyageai.ipynb) , [ Tweet ](https://x.com/llama_index/status/1720578050180686129?s=20) .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 7309, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"03c8b554-539b-4162-a8d8-8ee2428a683d": {"doc_hash": "a1128b21a76fc08906a8790bd07f5df531c1a8a3a9a80d4a685fa52192151f18", "ref_doc_id": "0302f702-fa36-4074-9a4f-75b289b66dd6"}}, "docstore/ref_doc_info": {"0302f702-fa36-4074-9a4f-75b289b66dd6": {"node_ids": ["03c8b554-539b-4162-a8d8-8ee2428a683d"], "metadata": {"filename": "llamaindex-newsletter-2023-11-07-cf20b9a833aa.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023-11\u201307", "date": "Nov 8, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-07-cf20b9a833aa"}}}}