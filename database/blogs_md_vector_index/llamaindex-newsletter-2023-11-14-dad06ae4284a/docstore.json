{"docstore/data": {"9576f537-4a68-4d83-b2bb-87e5d04e257c": {"__data__": {"id_": "9576f537-4a68-4d83-b2bb-87e5d04e257c", "embedding": null, "metadata": {"filename": "llamaindex-newsletter-2023-11-14-dad06ae4284a.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023\u201311\u201314", "date": "Nov 14, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-14-dad06ae4284a"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ba8efef6-ba88-46c9-9107-d66392c5612d", "node_type": "4", "metadata": {"filename": "llamaindex-newsletter-2023-11-14-dad06ae4284a.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023\u201311\u201314", "date": "Nov 14, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-14-dad06ae4284a"}, "hash": "51be5609b1e2814f99951b512d12c4ec416fbf941e2e02db3ce820b2ac19b373", "class_name": "RelatedNodeInfo"}}, "text": "Hello Llama Friends\n\nLlamaIndex is 1 year old this week! To celebrate, we\u2019re taking a stroll down\nmemory lane on our [ blog ](/llamaindex-turns-1-f69dcdd45fe3) with twelve\nmilestones from our first year. Be sure to check it out.\n\nLast week we had a blast with all the new things from OpenAI Dev day to learn\nand explore at LlamaIndex. There was a [ special edition newsletter\n](/llamaindex-news-special-edition-openai-developer-day-e955f16db4e2) with the\nthings we released the same day as the conference, but this week\u2019s newsletter\nis full of follow-up releases and explorations \u2014 don\u2019t miss our slide deck\nsumming up all the new features!\n\nAs always, if you\u2019ve got a cool project or a video to share we\u2019d love to see\nit! Just drop us a line at [ news@llamaindex.ai ](mailto:news@llamaindex.ai) .\n\n**First, the highlights:**\n\n  1. **Multi-Modal RAG Stack:** we unveiled Multi-Modal RAG ****for complex Q&A on documents and images, with new text/image queries and retrieval solutions. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/gpt4v_multi_modal_retrieval.ipynb) , [ Tweet ](https://x.com/jerryjliu0/status/1723076174698672417?s=20) , [ Blog post ](/multi-modal-rag-621de7525fea) . \n  2. **OpenAIAssistantAgent Abstractions:** we released new abstractions to connect OpenAI Assistant API with any vector database. [ Docs ](https://t.co/W78d2WCpnn) , [ Tweet ](https://twitter.com/jerryjliu0/status/1722276583883657388?s=20) . \n  3. **Parallel Function Calling:** we enhanced our data extraction and tool execution using OpenAI\u2019s parallel function calling. [ Tweet ](https://x.com/llama_index/status/1722686015276753073?s=20) . \n  4. **MechGPT Project:** Prof. [ **Markus J. Buehler** ](https://twitter.com/ProfBuehlerMIT) \u2019s work merges LLM fine-tuning with knowledge graphs for scientific discovery. [ Tweet ](https://x.com/llama_index/status/1723379654550245719?s=20) , [ Paper ](https://t.co/l8J55BqUfn) . \n  5. **Feature Slide Deck:** Released a [ slide deck ](https://docs.google.com/presentation/d/1i1bUDWXeCYPd6O8pio57ST6AQIuSTWXM3rvvkvrBpBM/edit#slide=id.p) with 10+ new features and guides post-OpenAI updates. \n\n**Feature Releases and Enhancements:**\n\n  * We introduced a multi-modal RAG stack for complex document and image QA, featuring text/image queries, joint text/ image embeddings, and versatile storage and retrieval options. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/gpt4v_multi_modal_retrieval.ipynb) , [ Tweet ](https://x.com/jerryjliu0/status/1723076174698672417?s=20) , [ Blog post ](/multi-modal-rag-621de7525fea) . \n  * We now offer experimental GPT-4-vision support in [ chat.llamaindex.ai ](http://chat.llamaindex.ai) . Users can now upload images for enhanced chatbot interactions. [ Tweet ](https://x.com/llama_index/status/1723120887988384177?s=20) . \n  * We integrated OpenAI\u2019s parallel function calling for efficient extraction of structured data from unstructured text and improving tool execution with agents. [ Tweet ](https://x.com/llama_index/status/1722686015276753073?s=20) . \n  * We introduced ` **OpenAIAssistantAgent** ` abstractions for seamless connection of OpenAI Assistants API with your chosen vector database. [ Docs ](https://t.co/W78d2WCpnn) , [ Tweet ](https://twitter.com/jerryjliu0/status/1722276583883657388?s=20) . \n  * We introduced a new agent leveraging OpenAI Assistants API with features like in-house code interpretation, file retrieval, and function calling for external tools integration. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb) , [ Tweet ](https://x.com/llama_index/status/1721949693754917035?s=20) . \n\n**** Demos:\n\n  * MechGPT by Professor [ **Markus J. Buehler** ](https://twitter.com/ProfBuehlerMIT) showcases the integration of LLM fine-tuning and knowledge graph creation with LlamaIndex, leading to interesting insights in cross-disciplinary scientific research and hypothesis generation. [ Tweet ](https://x.com/llama_index/status/1723379654550245719?s=20) , [ Paper ](https://t.co/l8J55BqUfn) . \n\n**Guides:**\n\n  * We released a concise [ slide deck ](https://docs.google.com/presentation/d/1i1bUDWXeCYPd6O8pio57ST6AQIuSTWXM3rvvkvrBpBM/edit#slide=id.p) that aggregates over 10+ newly shipped features, guides, and analyses, complete with links to accompanying notebooks for developer use based on OpenAI\u2019s recent updates. \n  * We also released a full [ cookbook ](https://docs.llamaindex.ai/en/latest/examples/agent/openai_assistant_query_cookbook.html) showing how you can build advanced RAG with the Assistants API \u2014 beyond just using the in-house Retrieval tool. \n  * We produced a [ guide ](https://docs.llamaindex.ai/en/latest/examples/agent/openai_retrieval_benchmark.html) on evaluating the OpenAI Assistant API vs RAG with LlamaIndex. \n  * Here\u2019s a [ guide ](https://github.com/run-llama/llama_index/blob/main/docs/examples/response_synthesizers/long_context_test.ipynb) on evaluating How well long-context LLMs (gpt-4-turbo, claude-2) recall specifics in BIG documents? (>= 250k tokens). \n  * Here\u2019s another [ guide ](https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/openai_json_vs_function_calling.ipynb) that highlights how function calling simplifies structured data extraction, while JSON mode ensures format correctness without schema enforcement. \n  * Finally, we released a guide to craft a GPT Builder, enabling an agent to programmatically construct another task-specific agent. This builder streamlines the creation of systems for specific functions. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb) , [ Tweet ](https://x.com/jerryjliu0/status/1721639447207583882?s=20) . \n\n**Tutorials:**\n\n  * [ **Bhavesh Bhat** ](https://twitter.com/_bhaveshbhatt) gave us a [ tutorial ](https://twitter.com/_bhaveshbhatt/status/1721551513103839392) on How to Chat with YouTube Videos Using LlamaIndex. \n  * [ David Garnitz ](https://twitter.com/DGarnitz) \u2019s tutorial blog explores the use of VectorFlow alongside ArizePhoenix, Weaviate, and LlamaIndex to manage large data sets. \n  * [ Harshad Suryawanshi ](https://harshadsuryawanshi.medium.com/) \u2019s [ tutorial ](/building-my-own-chatgpt-vision-with-palm-kosmos-2-and-llamaindex-9f9fdd13e566) covers Building My Own ChatGPT Vision with PaLM, KOSMOS-2 and LlamaIndex. \n  * [ Sudarshan Koirala ](https://twitter.com/mesudarshan) \u2019s made a [ tutorial ](https://www.youtube.com/watch?v=LRP-0iSVQaA) on Creating OpenAI Assistant Agent with LlamaIndex. \n  * Our own [ Ravi Theja ](https://twitter.com/ravithejads) released his [ tutorial ](/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83) on Boosting RAG with Embeddings & Rerankers. \n\n**** Webinars:\n\n  * Check out our [ webinar ](https://www.youtube.com/watch?v=upPK6pRbZYQ) with Dan Shipper, CEO of [ every ](http://every.to/) to talk about the implications of OpenAI\u2019s release updates. \n  * A second [ webinar ](https://www.youtube.com/watch?v=rBpZvMAim5E) with Victoria Lin, author of the RA-DIT paper on Fine-tuning + RAG. \n  * Last but not least, [ Mayo Oshin ](https://twitter.com/mayowaoshin) \u2019s [ webinar ](https://www.youtube.com/watch?v=xT6JpDELKPg&t=61s) with [ Jerry Liu ](https://twitter.com/jerryjliu0) on How to Analyze Tables In Large Financial Reports Using GPT-4.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 7422, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"9576f537-4a68-4d83-b2bb-87e5d04e257c": {"doc_hash": "4f6baff8a081e1c8bab780de05806fa31ce59bb603d5ac8bda7e11338355bc06", "ref_doc_id": "ba8efef6-ba88-46c9-9107-d66392c5612d"}}, "docstore/ref_doc_info": {"ba8efef6-ba88-46c9-9107-d66392c5612d": {"node_ids": ["9576f537-4a68-4d83-b2bb-87e5d04e257c"], "metadata": {"filename": "llamaindex-newsletter-2023-11-14-dad06ae4284a.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023\u201311\u201314", "date": "Nov 14, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-11-14-dad06ae4284a"}}}}