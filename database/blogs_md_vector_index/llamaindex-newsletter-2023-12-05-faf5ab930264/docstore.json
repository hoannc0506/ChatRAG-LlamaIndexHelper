{"docstore/data": {"02724515-7eb1-4490-9400-228d88ac6885": {"__data__": {"id_": "02724515-7eb1-4490-9400-228d88ac6885", "embedding": null, "metadata": {"filename": "llamaindex-newsletter-2023-12-05-faf5ab930264.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023\u201312\u201305", "date": "Dec 5, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-12-05-faf5ab930264"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "646a8dfd-94e9-473b-9050-454993214e1e", "node_type": "4", "metadata": {"filename": "llamaindex-newsletter-2023-12-05-faf5ab930264.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023\u201312\u201305", "date": "Dec 5, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-12-05-faf5ab930264"}, "hash": "51cea6ad3bedb71934cededff05ef54070ae7c93498a506d9806fbf728f4f7c7", "class_name": "RelatedNodeInfo"}}, "text": "Hello Llama Community ,\n\nWe are excited to collaborate with DeepLearningAI and TruEraAI to launch an\nextensive course on advanced Retrieval-Augmented Generation (RAG) and its\nevaluations. The course includes Sentence Window Retrieval, Auto-merging\nRetrieval, and Evaluations with TruLensML, providing practical tools for\nenhanced learning and application. To make the most of this learning\nopportunity, we invite you to [ take the course\n](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-\nrag/?utm_campaign=truerallamaindex-\nlaunch&utm_medium=video&utm_source=youtube&utm_content=teaser) .\n\nWe appreciate your support and are always excited to see your projects and\nvideos. Feel free to share them at [ news@llamaindex.ai\n](mailto:news@llamaindex.ai) . Also, remember to subscribe to our newsletter\non our [ website ](https://www.llamaindex.ai/) for the latest updates and to\nconnect with our vibrant community.\n\n**First, the highlights:**\n\n  1. **Launch of Seven Advanced Retrieval LlamaPacks** : Simplifies building advanced RAG systems to nearly a single line of code, offering techniques like Hybrid Fusion and Auto-merging Retriever. [ Tweet ](https://x.com/llama_index/status/1729303619760259463?s=20) . \n  2. **Introduction of the OpenAI Cookbook** : A comprehensive guide for evaluating RAG systems with LlamaIndex, covering system understanding, building, and performance evaluation. [ Blog ](/openai-cookbook-evaluating-rag-systems-fe393c61fb93) , [ Notebook ](https://github.com/openai/openai-cookbook/blob/main/examples/evaluation/Evaluate_RAG_with_LlamaIndex.ipynb)\n  3. **Speed Enhancement in Structured Metadata Extraction** : Achieved 2x to 10x faster processing in extracting structured metadata from text, boosting RAG performance. [ Docs ](https://t.co/sBVWeO8jKo) , [ Tweet ](https://x.com/llama_index/status/1730400634757939691?s=20) . \n  4. We launched versions 3 of [ RAGs ](https://github.com/run-llama/rags) , our project that lets you use natural language to generate a RAG bot customized to your needs. This version incorporates web search, so your bot can incorporate answers fresh from the web. [ Tweet ](https://x.com/llama_index/status/1730320635279331524?s=20) . \n  5. **Core** [ **guide** ](https://docs.llamaindex.ai/en/latest/community/full_stack_projects.html#) **for Full-Stack LLM App Development** : Simplifies complex app development with tools like \u2018create-llama\u2019 for full-stack apps, \u2018SEC Insights\u2019 for multi-document processing, and \u2018LlamaIndex Chat\u2019 for chatbot customization. \n\n**Feature Releases and Enhancements:**\n\n  * We\u2019ve launched seven advanced retrieval LlamaPacks, serving as templates to easily build advanced RAG systems. These packs simplify the process to almost a single line of code, moving away from the traditional notebook approach. The techniques include Hybrid Fusion, Query Rewriting + Fusion, Retrieval with Embedded Tables, Auto-merging Retriever, Sentence Window Retriever, Node Reference Retriever, and Multi-Document Agents for handling complex queries. [ Tweet ](https://x.com/llama_index/status/1729303619760259463?s=20) . \n  * We introduce new abstractions for structured output extraction in multi-modal settings, enabling the transformation of images into structured Pydantic objects. This enhancement is particularly useful for applications like product reviews, restaurant listings, and OCR. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_pydantic.ipynb) , [ Tweet ](https://x.com/llama_index/status/1729535952912290050?s=20) . \n  * We introduce the [ OpenAI Cookbook ](https://github.com/openai/openai-cookbook/blob/main/examples/evaluation/Evaluate_RAG_with_LlamaIndex.ipynb) , a guide focused on evaluating RAG systems using LlamaIndex. It encompasses understanding RAG systems, building them with LlamaIndex, and evaluating their performance in retrieval and response generation. [ Blog ](/openai-cookbook-evaluating-rag-systems-fe393c61fb93) , [ Notebook ](https://github.com/openai/openai-cookbook/blob/main/examples/evaluation/Evaluate_RAG_with_LlamaIndex.ipynb) , [ Tweet ](https://x.com/llama_index/status/1729587400240967761?s=20) . \n  * We launched RAGs v3 \u2014 a bot that transcends traditional limits by incorporating web search capabilities. This bot, designed to operate in natural language rather than code, offers an enhanced experience compared to the combination of ChatGPT and Bing. Leveraging our integration with Metaphor Systems \u2014 a search engine tailored for Large Language Models (LLMs) \u2014 the bot can retrieve relevant text from the internet to provide answers beyond its internal corpus. Additionally, users can now view the tools the agent uses, with the web search feature exclusively accessible to our OpenAI agent. [ Repo ](https://t.co/838BDVOEbA) , [ Tweet ](https://x.com/llama_index/status/1730320635279331524?s=20) . \n  * We have significantly improved the speed of extracting structured metadata (like titles and summaries) from text to enhance RAG performance. Our new implementation offers 2x to 10x faster processing, overcoming the limitations of previous slower methods. [ Docs ](https://t.co/sBVWeO8jKo) , [ Tweet ](https://x.com/llama_index/status/1730400634757939691?s=20) . \n  * We have made it incredibly easy to set up a RAG + Streamlit app, now possible with just a single line of code using our ` **StreamlitChatPack** ` . This pack provides a ready-to-use RAG pipeline and a Streamlit chat interface, customizable in terms of data sources and retrieval algorithms. [ Docs ](https://llamahub.ai/l/llama_packs-streamlit_chatbot) , [ Tweet ](https://x.com/llama_index/status/1731121252142878982?s=20) . \n\n**Demo:**\n\nAInimal Go \u2014 an innovative multi-modal app inspired by Pokemon-Go. This\ninteractive application, developed by [ Harshad Suryawanshi\n](https://harshadsuryawanshi.medium.com/) , lets users capture or upload\nimages of animals, classify them using the ResNet-18 model, and engage in\nconversations with the animals, augmented by a knowledge base of over 200\nWikipedia articles. Notably, the app employs a targeted ResNet model for\nclassification, offering enhanced speed and cost efficiency, instead of using\nGPT-4V.\n\n[ Blog ](/multimodal-rag-building-ainimal-go-fecf8404ed97) , [ Repo\n](https://github.com/AI-ANK/AInimalGo-Chat-with-Animals) , [ HuggingFace Space\n](https://huggingface.co/spaces/AI-ANK/AInimal_Go) , [ Tweet\n](https://x.com/llama_index/status/1729246724911477165?s=20) .\n\n**Guides:**\n\n  * We introduce a core [ guide ](https://docs.llamaindex.ai/en/latest/community/full_stack_projects.html#) within the LlamaIndex ecosystem, designed to simplify \u201cfull-stack\u201d app development, which is notably more complex than notebook development. This includes \u2018create-llama\u2019 for building full-stack apps with advanced templates, \u2018SEC Insights\u2019 for multi-document handling of over 10,000 filings, and \u2018LlamaIndex Chat\u2019 for a customizable chatbot experience. All tools are open-source with full guides and tutorials available. \n  * [ Guide ](https://t.co/2Ygxs6bPoX) on using the Table Transformer model with GPT-4V for advanced RAG applications in parsing tables from PDFs: Our method involves CLIP for page retrieval, Table Transforms for table image extraction, and GPT-4V for answer synthesis. This approach is compared with three other multi-modal table understanding techniques, including using CLIP for whole page retrieval, text extraction and indexing with GPT-4V, and OCR on table images for context. \n  * [ Guide ](https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_pydantic.ipynb) on analyzing various multi-modal models for their ability to extract structured data from complex product images on an Amazon page. The models compared include GPT-4V, Fuyu-8B, MiniGPT4, CogVLM-4, and LLaVa-13B. Key findings reveal that all models incorrectly identified the number of reviews (correct answer: 5685), only GPT-4V and Fuyu accurately determined the price, each model\u2019s product description varied from the original, and Mini-GPT4 incorrectly assessed the product rating. \n\n**Tutorials:**\n\n  * [ Jo Kristian Bergum ](https://www.linkedin.com/in/jo-bergum/) [ blog post ](https://blog.vespa.ai/scaling-personal-ai-assistants-with-streaming-mode/) on Hands-On RAG guide for personal data with Vespa and LLamaIndex. \n  * [ Wenqi Glantz ](https://twitter.com/wenqi_glantz) made a [ tutorial ](https://levelup.gitconnected.com/llama-packs-the-low-code-solution-to-building-your-llm-apps-269eec05557b) on Llama Packs: The Low-Code Solution to Building Your LLM Apps. \n  * [ Liza Shulyayeva ](https://twitter.com/Lazer) \u2019s in-depth [ tutorial ](https://www.daily.co/blog/search-your-video-content-library-with-llamaindex-and-chroma/) on building and deploying a retrieval-augmented generation (RAG) app to conversationally query the contents of your video library \n\n**Webinars:**\n\n  * [ Webinar ](https://www.youtube.com/watch?v=0zGHrcE-Zy4) on PrivateGPT \u2014 Production RAG with Local Models. \n\n**Hackathons:**\n\n  * Your reminder that there\u2019s still time to join [ the TruEra Challenge ](https://lablab.ai/event/truera-challenge-build-llm-applications?utm_medium=post&utm_source=twitter&utm_campaign=truera_challenge_hackathon&utm_term=hackathon_page&utm_content=event_promo) , an online hackathon from Dec 1st to 8th, and explore AI observability with technology from TruEra AI and Google Vertex AI. Use the LlamaIndex framework to enhance your LLM-based app. Participants receive $30 in Google Cloud credits, plus an additional $100 upon solution submission. Winners share a $9,000 cash prize pool and $14,000 in Google Cloud credits. \n  * We partnered with Zilliz Universe to participate in their [ Advent of Code ](https://t.co/hGzBA1acf6) event. This December, explore 25 open-source projects, with daily challenges to build something in 30 minutes or less. It\u2019s a great opportunity to learn new skills and have winter fun. For tips, tutorials, and resources, visit the Advent of Code channel in Discord each day.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 10068, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"02724515-7eb1-4490-9400-228d88ac6885": {"doc_hash": "5a770d6ef4dc053c309d84d2804b2e5da58eae8c3fb39df0f933726118e343b8", "ref_doc_id": "646a8dfd-94e9-473b-9050-454993214e1e"}}, "docstore/ref_doc_info": {"646a8dfd-94e9-473b-9050-454993214e1e": {"node_ids": ["02724515-7eb1-4490-9400-228d88ac6885"], "metadata": {"filename": "llamaindex-newsletter-2023-12-05-faf5ab930264.md", "extension": ".md", "title": "LlamaIndex Newsletter 2023\u201312\u201305", "date": "Dec 5, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2023-12-05-faf5ab930264"}}}}