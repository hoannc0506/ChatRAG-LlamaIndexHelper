{"docstore/data": {"77decfb2-be90-4887-a6a3-55d3bba5dced": {"__data__": {"id_": "77decfb2-be90-4887-a6a3-55d3bba5dced", "embedding": null, "metadata": {"filename": "llamaindex-newsletter-2024-01-02-f349db8c1842.md", "extension": ".md", "title": "LlamaIndex Newsletter 2024\u201301\u201302", "date": "Jan 2, 2024", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-02-f349db8c1842"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aae99bae-74b1-42f9-b928-d3ebff189ed8", "node_type": "4", "metadata": {"filename": "llamaindex-newsletter-2024-01-02-f349db8c1842.md", "extension": ".md", "title": "LlamaIndex Newsletter 2024\u201301\u201302", "date": "Jan 2, 2024", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-02-f349db8c1842"}, "hash": "e5739314b5ad4c4779c8479561babb94aa9da824bb3842722b56f412672f3688", "class_name": "RelatedNodeInfo"}}, "text": "Hello, Llama Lovers ,\n\nHappy New Year! As we step into 2024, we\u2019re thrilled to bring you a special\nedition of our newsletter, packed with updates from the last two weeks of\n2023. This edition is brimming with the latest features, community demos,\ncourses, insightful tutorials, guides, and webinars that we\u2019ve curated for\nyou.\n\nHave you been working on an interesting project, written an engaging article,\nor created a video? We can\u2019t wait to hear about it! Please share your work\nwith us at [ news@llamaindex.ai ](mailto:news@llamaindex.ai) . Don\u2019t forget to\nsubscribe to our newsletter via our [ website ](https://www.llamaindex.ai/) to\nreceive all these exciting updates directly in your inbox.\n\n**First, the highlights:**\n\n  1. **LLMCompiler Implementation:** A SOTA agent implementation for faster, efficient handling of complex queries. [ Notebook ](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb) , [ Tweet ](https://x.com/llama_index/status/1740778394856648843?s=20) . \n  2. **MultiDocAutoRetrieverPack:** A RAG template for structured retrieval and dynamic responses to large documents and metadata. [ Tweet ](https://x.com/llama_index/status/1739307699773518201?s=20) , [ LlamaPack ](https://llamahub.ai/l/llama_packs-multidoc_autoretrieval?from=llama_packs) . \n  3. **Structured Hierarchical RAG:** New RAG technique for optimized retrieval over multiple documents, ensuring precise, relevant responses. [ Docs ](https://docs.llamaindex.ai/en/latest/examples/query_engine/multi_doc_auto_retrieval/multi_doc_auto_retrieval.html) , [ Tweet ](https://x.com/llama_index/status/1737515390664872040?s=20) . \n  4. **Custom Agents:** A simple abstraction for custom agent reasoning loops, enabling easy integration with RAG, SQL, and other systems, and enhancing response refinement for complex queries. [ Docs ](https://docs.llamaindex.ai/en/latest/examples/agent/custom_agent.html) , [ Tweet ](https://x.com/llama_index/status/1741141394558001414?s=20) . \n  5. **New lower-level agent API:** For enhanced transparency, debuggability, and control, supporting step-wise execution and task modification. [ Docs ](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner.html) , [ Tweet ](https://x.com/llama_index/status/1736809248947155076?s=20) . \n\n**Feature Releases and Enhancements:**\n\n  * We have introduced a simple abstraction for building custom agent reasoning loops, surpassing prepackaged frameworks like ReAct. This tool allows for easy integration with RAG, SQL, or other systems, and we demonstrated how to build an agent with retry logic for routers, enhancing its ability to manage complex, multi-part questions and refine query responses. [ Docs ](https://docs.llamaindex.ai/en/latest/examples/agent/custom_agent.html) , [ Tweet ](https://x.com/llama_index/status/1741141394558001414?s=20) . \n  * We have implemented the LLMCompiler project, a SOTA agent framework enabling DAG-based planning and parallel function execution. This surpasses traditional sequential methods in speed, allowing for quicker and more efficient handling of complex queries in any LLM and data pipeline. [ Notebook ](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb) , [ Tweet ](https://x.com/llama_index/status/1740778394856648843?s=20) . \n  * We have introduced MultiDocAutoRetrieverPack, a RAG template for efficiently handling large documents and metadata, offering structured retrieval and dynamic responses tailored to specific queries. [ Tweet ](https://x.com/llama_index/status/1739307699773518201?s=20) , [ LlamaPack ](https://llamahub.ai/l/llama_packs-multidoc_autoretrieval?from=llama_packs) . \n  * We have introduced a Structured Hierarchical RAG technique, optimizing RAG over multiple documents. It involves modeling documents as structured metadata for auto-retrieval, indexed in a vector database. This method dynamically selects documents based on inferred properties and performs recursive retrieval within each document for precise, relevant responses in your RAG pipeline. [ Docs ](https://docs.llamaindex.ai/en/latest/examples/query_engine/multi_doc_auto_retrieval/multi_doc_auto_retrieval.html) , [ Tweet ](https://x.com/llama_index/status/1737515390664872040?s=20) . \n  * We have launched a new feature for advanced RAG that allows step-wise feedback for complex query executions, improving interpretability and control. This is particularly beneficial for weaker models that struggle with multi-part tasks. We also introduced a step-by-step chat interface for enhanced user interaction and control. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner_rag_controllable.ipynb) , [ Tweet ](https://x.com/llama_index/status/1737161312944468412?s=20) . \n  * We have integrated with OpenRouterAI, offering a unified API for easy LLM access, cost efficiency, and reliable fallback options. OpenRouterAI allows users to compare costs, latency, and throughput for various models, like mixtral-8x7b, directly on their platform. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/openrouter.ipynb) , [ Tweet ](https://x.com/llama_index/status/1737176999712731349?s=20) . \n  * We have introduced a new lower-level agent API that enhances transparency, debuggability, and control. This API allows for granular control over agents, decouples task creation from execution, and supports step-wise execution. It also enables viewing each step, upcoming steps, and soon, modifying intermediate steps with human feedback. [ Docs ](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner.html) , [ Tweet ](https://x.com/llama_index/status/1736809248947155076?s=20) . \n\n**Community Demos** :\n\n  * **Automated LeetCode Crash Course:** The Project integrates advanced ML with traditional algorithms to streamline LeetCode study for technical interviews. It involves extracting and summarizing LeetCode problems using an LLM, organizing these summaries in a vector store, and employing scikit-learn for clustering. [ Blog ](https://medium.com/@kevinchwong/from-machine-learning-to-learning-machine-483eaa4b2855) , [ Code ](https://github.com/kevinchwong/leetcode-intensive/) . \n  * **RAG Assisted Auto Developer** : A project by [ **Ocean Li** ](https://twitter.com/quantoceanli) for building a devbot that understands and writes code. It integrates various tools: LlamaIndex for indexing codebases, Autogen / OpenAI Code Interpreter for code writing and testing, and [ lionagi.ai ](http://lionagi.ai/) for orchestration. [ Notebook ](https://github.com/lion-agi/lionagi/blob/main/notebooks/AutoDev_with_llama_autogen_assistant.ipynb) . \n\n**Courses:**\n\n  * We\u2019ve partnered with [ ActiveLoop AI ](https://twitter.com/activeloopai) to provide a [ free course ](https://learn.activeloop.ai/courses/rag) on retrieval-augmented generation for production, featuring 33 lessons, 7 hands-on assignments, and a certification upon completion. \n  * Beginner-friendly [ course ](https://cognitiveclass.ai/courses/course-v1:IBMSkillsNetwork+GPXX0OLGEN+v1#about-course) from [ IBM Skills Network ](https://twitter.com/skillsnetworkhq) on using LlamaIndex with IBM Watsonx to create effective product recommendations. \n\n**Guides:**\n\n  * [ Guide ](https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/structured_image_retrieval.ipynb) to Semi-Structured Image QA with Gemini: Learn to extract data from unlabeled images and query it, using multi-modal models and advanced retrieval techniques, as demonstrated with the SROIE v2 dataset which contains images of receipts/invoices. \n  * [ Guide ](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6) to Advanced RAG Concepts: A comprehensive survey by [ Ivan Ilin ](https://twitter.com/ivanilin9) , covering twelve core concepts including chunking, hierarchical indexing, query rewriting, and more. Each section provides resources and guides from our system for deeper understanding and practical application. \n  * [ Guide ](https://github.com/run-llama/llama_index/blob/main/docs/examples/vector_stores/qdrant_hybrid.ipynb) to Building Hybrid Search: Learn to create a hybrid search for RAG from scratch. The process involves generating sparse vectors, fusing sparse and dense queries, and implementing this in a Qdrant engine database for effective RAG integration. \n  * [ Guide ](https://github.com/run-llama/llama_index/blob/main/docs/examples/vector_stores/pinecone_auto_retriever.ipynb) to Building Structured Retrieval with LLMs: Set up auto-retrieval in Pinecone vector database, monitor prompts with Arize AI Phoenix, and tailor prompts for specific queries to enhance your document handling and structured data analysis. \n  * [ Guide ](/two-new-llama-datasets-and-a-gemini-vs-gpt-showdown-9770302c91a5) on Evaluating LLM Evaluators: our new evaluation method and dataset bundle, are designed to benchmark LLMs as evaluators against human annotations. This involves comparing LLM judge predictions (1\u20135 score) with ground-truth judgments, using metrics like Correlation, Hamming Distance, and Agreement Rate. \n\n**Tutorials:**\n\n  * [ Ryan Nguyen ](https://medium.com/@ryanntk) [ tutorial ](https://levelup.gitconnected.com/a-guide-to-processing-tables-in-rag-pipelines-with-llamaindex-and-unstructuredio-3500c8f917a7) on Processing Tables in RAG Pipelines with LlamaIndex and UnstructuredIO. \n  * [ Wenqi Glantz ](https://www.linkedin.com/in/wenqi-glantz-b5448a5a/) [ tutorial ](https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756) on Safeguarding RAG Pipelines: A Step-by-Step Guide to Implementing Llama Guard with LlamaIndex. \n  * [ Wenqi Glantz ](https://www.linkedin.com/in/wenqi-glantz-b5448a5a/) [ tutorial ](https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756) on 10+ Ways to Run Open-Source Models with LlamaIndex. \n  * Jina AI [ tutorial ](https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex/) on enhancing RAG applications by integrating Jina v2 embeddings with LlamaIndex and Mixtral LLM via Hugging Face. \n  * [ Ankush Singal ](https://medium.com/@andysingal) [ tutorial ](https://ai.gopubby.com/benchmarking-rag-pipelines-with-a-evaluation-pack-in-forward-looking-active-retrieval-augmented-a8bd057c856b) on Benchmarking RAG Pipelines With A Evaluation Pack in Forward-Looking Active Retrieval Augmented Generation (FLARE). \n  * [ Laurie\u2019s ](https://twitter.com/seldo) [ tutorial ](/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab) on Effortlessly Running Mistral AI\u2019s Mixtral 8x7b: Learn to use OLLAMA with LlamaIndex for a one-line setup of a local, open-source retrieval-augmented generation app with API, featuring Qdrant engine integration for vector storage. \n  * [ Tomaz Bratanic ](https://twitter.com/tb_tomaz) [ tutorial ](/multimodal-rag-pipeline-with-llamaindex-and-neo4j-a2c542eb0206) on Multimodal RAG pipeline with LlamaIndex and Neo4j. \n  * [ Sudarshan Koirala ](https://twitter.com/mesudarshan) video [ tutorial ](https://www.youtube.com/watch?v=N8is20i2tqA) on using Mistral API with LlamaIndex. \n  * [ Chia Jeng Yang ](https://chiajy.medium.com/) [ tutorial ](https://medium.com/enterprise-rag/a-first-intro-to-complex-rag-retrieval-augmented-generation-a8624d70090f) on Technical Considerations for Complex RAG. \n\n**Webinars:**\n\n  * [ Webinar ](https://www.youtube.com/watch?v=fdpaHJlN0PQ) with Google Developers on advanced RAG applications and multi-modal settings with Google Gemini. \n  * [ Webinar ](https://www.youtube.com/watch?v=kZxl4gpe3OM) of Jerry Liu with Louis-Fran\u00e7ois on the Future of AI: LlamaIndex, LLMs, RAG, Prompting, and more. \n\n**Calling all enterprises:**\n\nAre you building with LlamaIndex? We are working hard to make LlamaIndex even\nmore Enterprise-ready and have sneak peeks at our upcoming products available\nfor partners. Interested? [ Get in touch.\n](https://docs.google.com/forms/d/e/1FAIpQLScBNdM2a_fn8UZOKmFQt6lBsrd1o6FflvsdPH-\nPn3JkdlN_Rg/viewform)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 12280, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"77decfb2-be90-4887-a6a3-55d3bba5dced": {"doc_hash": "89cc7dafb750f2ad2a5812c6a15047541b15939c7981de2e198980cd9db53bf9", "ref_doc_id": "aae99bae-74b1-42f9-b928-d3ebff189ed8"}}, "docstore/ref_doc_info": {"aae99bae-74b1-42f9-b928-d3ebff189ed8": {"node_ids": ["77decfb2-be90-4887-a6a3-55d3bba5dced"], "metadata": {"filename": "llamaindex-newsletter-2024-01-02-f349db8c1842.md", "extension": ".md", "title": "LlamaIndex Newsletter 2024\u201301\u201302", "date": "Jan 2, 2024", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-02-f349db8c1842"}}}}