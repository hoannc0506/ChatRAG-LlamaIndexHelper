{"docstore/data": {"9515ba56-7d1a-4cac-9094-2fc6ecf9dd9e": {"__data__": {"id_": "9515ba56-7d1a-4cac-9094-2fc6ecf9dd9e", "embedding": null, "metadata": {"filename": "llamaindex-newsletter-2024-01-09-6209000da2e6.md", "extension": ".md", "title": "LlamaIndex Newsletter 2024\u201301\u201309", "date": "Jan 9, 2024", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-09-6209000da2e6"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "94fdfb07-21e6-48eb-88a2-c7fac544581d", "node_type": "4", "metadata": {"filename": "llamaindex-newsletter-2024-01-09-6209000da2e6.md", "extension": ".md", "title": "LlamaIndex Newsletter 2024\u201301\u201309", "date": "Jan 9, 2024", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-09-6209000da2e6"}, "hash": "74923dd63e9c21f60555ae9e8714df0037dfcdb08304e08a4c725457ea16d830", "class_name": "RelatedNodeInfo"}}, "text": "Hola, LlamaIndex Lovers ,\n\nWelcome to another thrilling week at LlamaIndex, filled with vibrant community\ncontributions and enriching educational content. Immerse yourself in our\nengaging tutorials, guides, community demos, and webinars, all crafted to\namplify your LlamaIndex experience. Before we jump into our latest updates,\nwe\u2019re thrilled to share two major announcements:\n\n\u200d **Join Our LlamaIndex Community Office Hours** : Struggling with complex\nLLM/RAG queries or have feedback that our documentation doesn\u2019t cover? [\nRegister ](https://t.co/A16nitoIgV) for our community office hours for a\nchance to have an enlightening conversation and get your questions answered!\n\n[ **Explore Our Open-Source Roadmap for 2024** : ](https://github.com/run-\nllama/llama_index/discussions/9888) We\u2019re excited to unveil our ambitious\nroadmap for the LlamaIndex ecosystem. Over the next 3\u20136 months, we aim to\nenhance LlamaIndex\u2019s production readiness, accessibility, and its advanced\nfeatures, including RAG, agents, and more. This [ living document\n](https://github.com/run-llama/llama_index/discussions/9888) is available on\nour GitHub discussions page \u2014 a must-visit to be part of our exciting journey!\n\nAdditionally, if you\u2019ve been working on an interesting project, written an\ninsightful article, or created a captivating video, we\u2019d love to hear about\nit! Please share your work with us at [ news@llamaindex.ai\n](mailto:news@llamaindex.ai) . And remember to subscribe to our newsletter\nthrough our [ website ](https://www.llamaindex.ai/) to get all these exciting\nupdates straight to your inbox\n\n**The highlights:**\n\n  1. **Query Pipelines** : Introducing a new declarative API for effortless orchestration of simple to complex RAG query workflows. [ Docs ](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/root.html#) , [ Blogpost ](/introducing-query-pipelines-025dc2bb0537) , [ Tweet ](https://x.com/llama_index/status/1744406288724017278?s=20) . \n  2. **ETL Pipeline Launch** : New repository for setting up production ETL pipelines in RAG/LLM apps, boasting a 4x speed boost and integrating Hugging Face, RabbitMQ, and AWS EKS. [ Github Repo ](https://github.com/run-llama/llamaindex_aws_ingestion) , [ Blogpost ](/scaling-llamaindex-with-aws-and-hugging-face-e2c71aa64716) , [ Tweet ](https://x.com/llama_index/status/1742226327900721168?s=20) . \n  3. **Multimodal ReAct Agent** : Launch of an agent capable of processing text and images, enhancing RAG pipeline and web search functionalities using GPT-4V. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/mm_agent.ipynb) , [ Tweet ](https://x.com/llama_index/status/1742588989884989477?s=20) . \n  4. **RAGatouille LlamaPack** : Introduction of an easy-to-use pack for ColBERT retrieval, enabling one-line code integration in LlamaIndex RAG pipelines. [ Docs ](https://llamahub.ai/l/llama_packs-ragatouille_retriever?from=llama_packs) , [ Tweet ](https://x.com/llama_index/status/1743076579302105338?s=20) . \n  5. [ **Advanced RAG Cheat Sheet** ](/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b) : A comprehensive cheat sheet with techniques for RAG enhancement, perfect for both new and experienced LLM users. \n\n**Feature Releases and Enhancements:**\n\n  * We have introduced Query Pipelines, a declarative API designed to simplify the creation and customization of advanced RAG workflows. This tool enables the orchestration of query workflows, ranging from basic sequential chains to complex DAGs, tailored to specific use cases. [ Docs ](https://docs.llamaindex.ai/en/latest/module_guides/querying/pipeline/root.html#) , [ Blogpost ](/introducing-query-pipelines-025dc2bb0537) , [ Tweet ](https://x.com/llama_index/status/1744406288724017278?s=20) . \n  * We have launched a repository for easily setting up a production ETL pipeline for RAG/LLM apps, offering a 4x speed increase over laptop-based operations. This solution integrates Hugging Face, RabbitMQ, Llama Index, and AWS EKS, providing fast document indexing and efficient data handling, complete with an AWS Lambda API endpoint. Ideal for RAG apps transitioning to production, especially on AWS. [ Github Repo ](https://github.com/run-llama/llamaindex_aws_ingestion) , [ Blogpost ](/scaling-llamaindex-with-aws-and-hugging-face-e2c71aa64716) , [ Tweet ](https://x.com/llama_index/status/1742226327900721168?s=20) . \n  * We have launched the Multimodal ReAct Agent, combining GPT-4V with the ability to process both text and images. This agent can perform tasks like querying a RAG pipeline or conducting web searches based on visual and textual inputs. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/mm_agent.ipynb) , [ Tweet ](https://x.com/llama_index/status/1742588989884989477?s=20) . \n  * RAGatouille LlamaPack: RAGatouille simplifies the use of ColBERT, a more advanced retrieval model compared to dense embedding-based retrieval techniques. This pack allows you to build an end-to-end LlamaIndex RAG pipeline with just one line of code by ingesting documents using any of our 150+ data loaders, combined with your preferred LLM for response synthesis. [ Docs ](https://llamahub.ai/l/llama_packs-ragatouille_retriever?from=llama_packs) , [ Tweet ](https://x.com/llama_index/status/1743076579302105338?s=20) . \n  * We have integrated with Pathway\u2019s open data processing framework which enables us to handle dynamic data sources in production, automatically updating indexes based on real-time changes, ensuring up-to-date and accurate query responses. [ Docs ](https://docs.llamaindex.ai/en/stable/examples/data_connectors/PathwayReaderDemo.html) , [ Tweet ](https://x.com/llama_index/status/1741862685103579476?s=20) . \n  * [ **Ian McCrystal** ](https://twitter.com/ianmst) has added the StripeDocsLoader to LlamaHub, enabling a quick setup of RAG over Stripe\u2019s documentation using Llama Index. [ Docs ](https://llamahub.ai/l/stripe_docs) . \n  * [ Jeremy Dyer ](https://twitter.com/mightyjeremy) has integrated NVIDIA\u2019s Triton Inference Server which allows you to run optimized inference on any AI framework. It supports the TensorRT-LLM backend, enhancing LLM performance on Nvidia GPUs. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/nvidia_triton.ipynb) , [ Tweet ](https://x.com/llama_index/status/1744044446029901943?s=20) . \n\n**Community Demos** :\n\n  * Context-Augmented Agent for Food Delivery: A full-stack application guide by lucastonon for creating an RAG agent. This tool performs in-browser tasks like opening restaurant pages and adding food to carts, purely via voice commands, integrating with Llama Index, Pinecone, OpenAI\u2019s Whisper, LLMs, Function Calling, vue.js, and FastAPI. [ Github Repo ](https://github.com/lucastononro/llm-food-delivery) , [ Tweet ](https://x.com/llama_index/status/1741987664272986534?s=20) . \n  * [ GRDN.AI ](https://medium.com/@dheymann314/ai-infused-optimization-in-the-wild-developing-a-companion-planting-app-357e5da29d10) : A fascinating side project from Danielle Heymann, using a genetic algorithm and LLM to optimize plant placement based on compatibility. This project harnesses local models from HuggingFace, accessed through LlamaIndex for the LLM part, combining traditional mathematical strategies with LLMs. [ Blogpost ](https://medium.com/@dheymann314/ai-infused-optimization-in-the-wild-developing-a-companion-planting-app-357e5da29d10) , [ Tweet ](https://x.com/llama_index/status/1742703399081271555?s=20) . \n  * [ Build an AI Shopping Assistant with RAG and Agents ](https://www.activeloop.ai/resources/use-llama-index-to-build-an-ai-shopping-assistant-with-rag-and-agents/) : This assistant can analyze a picture of an item and suggest weather-appropriate accessories. The work by D. Kiedanski and Lucas Micol from Tryolabs explains how to transform APIs into problem-solving tools for a LlamaIndex agent. \n\n**Guides:**\n\n  * [ Guide ](/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b) to Advanced RAG: Our comprehensive cheat sheet offers insights into improving RAG with techniques like optimized retrieval, effective document use in generation, and interleaving generation with retrieval. Ideal for both new and seasoned LLM users, it\u2019s a must-have resource, complete with LlamaIndex links. \n  * [ Guide ](https://github.com/NVIDIA/GenerativeAIExamples/blob/main/notebooks/04_llamaindex_hier_node_parser.ipynb) to building advanced RAG CHATBOT with NVIDIA\u2019S TensorRT-LLM: This chatbot is designed to maintain contiguous document or code blocks, avoiding awkward chunking. It features a stack combining Llama Index\u2019s auto-merging retriever with NVIDIA\u2019s TensorRT-LLM and a custom postprocessor, optimized for RAG using open-source models. \n\n**Tutorials:**\n\n  * BentoML [ tutorial ](https://www.bentoml.com/blog/building-an-intelligent-query-response-system-with-llamaindex-and-openllm) on Building An Intelligent Query-Response System with LlamaIndex and OpenLLM. \n  * [ Akash Mathur ](https://www.linkedin.com/in/akashmathur22/) [ tutorial ](https://akash-mathur.medium.com/advanced-rag-optimizing-retrieval-with-additional-context-metadata-using-llamaindex-aeaa32d7aa2f) on Advanced RAG: Optimizing Retrieval with Additional Context & MetaData using LlamaIndex. \n\n**Webinars:**\n\n  * Weights & Biases [ podcast ](https://www.youtube.com/watch?v=xejCaLsYzV4) with Jerry Liu on Revolutionizing AI Data Management. \n\n**Calling all enterprises:**\n\nAre you building with LlamaIndex? We are working hard to make LlamaIndex, even\nmore, Enterprise-ready and have sneak peeks at our upcoming products available\nfor partners. Interested? [ Get in touch.\n](https://docs.google.com/forms/d/e/1FAIpQLScBNdM2a_fn8UZOKmFQt6lBsrd1o6FflvsdPH-\nPn3JkdlN_Rg/viewform)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 9820, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"9515ba56-7d1a-4cac-9094-2fc6ecf9dd9e": {"doc_hash": "6fe094ce18e2c13c9a3a2b6d5500e135ca3f12de9efb36fbbd64a2a9ca1c842e", "ref_doc_id": "94fdfb07-21e6-48eb-88a2-c7fac544581d"}}, "docstore/ref_doc_info": {"94fdfb07-21e6-48eb-88a2-c7fac544581d": {"node_ids": ["9515ba56-7d1a-4cac-9094-2fc6ecf9dd9e"], "metadata": {"filename": "llamaindex-newsletter-2024-01-09-6209000da2e6.md", "extension": ".md", "title": "LlamaIndex Newsletter 2024\u201301\u201309", "date": "Jan 9, 2024", "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2024-01-09-6209000da2e6"}}}}