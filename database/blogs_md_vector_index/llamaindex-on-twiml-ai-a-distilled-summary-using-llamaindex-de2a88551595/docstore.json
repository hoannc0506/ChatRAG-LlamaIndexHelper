{"docstore/data": {"37e9cef9-9fca-4cde-ab33-1d70e75bbb1e": {"__data__": {"id_": "37e9cef9-9fca-4cde-ab33-1d70e75bbb1e", "embedding": null, "metadata": {"Header_1": " Overview", "filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9e4f8de8-ece1-4ea4-b3fd-66aaef5f0629", "node_type": "4", "metadata": {"filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "hash": "adde2250c4c6b4a98d2a892874c0b3f884cfead5097dcace098c9991e2212113", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2e804da9-3a80-4079-a8a1-cdfce1862615", "node_type": "1", "metadata": {"Header_1": " Distilled Highlights"}, "hash": "fd2772776a76f246c3c6a273e08ff2f1fd6ba093a1a040ee00e5c7e9e2928610", "class_name": "RelatedNodeInfo"}}, "text": "Overview\n\nI had the pleasure of speaking with Sam Charrington on the [ TWIML AI podcast\n](https://twimlai.com/) about LlamaIndex, and the episode was just released\nthis past Monday (5/8/23).\n\nI thought it would be a fun experiment to distill some highlights from the\npodcast! And what better way to do this than using LlamaIndex itself (plus\nOpenAI Whisper for transcription)?\n\nI did the following:\n\n  1. Ran the podcast through [ whisper.cpp ](https://github.com/ggerganov/whisper.cpp)\n  2. Did some light manual cleaning of the text, and uploaded it as a [ Dropbox file ](https://www.dropbox.com/s/gn2rpfvkjkygemb/twiml.txt?dl=0) . \n  3. Get a high-level summary + ask some more targeted questions over the podcast transcript. Uses LlamaIndex . [ Colab notebook here ](https://colab.research.google.com/drive/1sAHWbyQRjtp_w-r-HOMpL0gkkhigkdGR?usp=sharing) ! \n\nWe used the our list index to get an overall summary of the podcast, and also\nour vector index to ask more specific questions. We ask some basic questions\nourselves, but also directly ask questions that Sam asked during the podcast\nin order to extract more concise versions of the responses that I gave\n(including removing a bunch of filler \u201cyou know\u201d words).\n\nAll the distilled highlights using LlamaIndex are showcased below. Let us know\nwhat you think!", "mimetype": "text/plain", "start_char_idx": 3, "end_char_idx": 1320, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2e804da9-3a80-4079-a8a1-cdfce1862615": {"__data__": {"id_": "2e804da9-3a80-4079-a8a1-cdfce1862615", "embedding": null, "metadata": {"Header_1": " Distilled Highlights", "filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9e4f8de8-ece1-4ea4-b3fd-66aaef5f0629", "node_type": "4", "metadata": {"filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "hash": "adde2250c4c6b4a98d2a892874c0b3f884cfead5097dcace098c9991e2212113", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37e9cef9-9fca-4cde-ab33-1d70e75bbb1e", "node_type": "1", "metadata": {"Header_1": " Overview", "filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "hash": "313c47debe4559819a1ea3aec052cd513fe3677354e26af5b0b9765bea49a8f3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70d78f92-1bff-4525-9d4d-b3bc40ac78b7", "node_type": "1", "metadata": {"Header_1": " Want to ask your own questions over the podcast?"}, "hash": "8e1257e0ee86abc933edb9a1211c7a2a4c0f1bae6744c15c405097312696ba81", "class_name": "RelatedNodeInfo"}}, "text": "Distilled Highlights\n\n**What are three key points described in this podcast? Give a followup of each\nkey point with an explanation.**\n\n  1. _LlamaIndex is a toolkit for connecting language models to data._ It was initially designed as a fun tool to play around with and solve a specific problem, but has since evolved into a set of useful tools and instructions that people can use to build applications on top of. The technique people were playing around with at the time was the idea of prompting and context learning, which is providing the right conditioning variable for the input and using that to send some sort of input prompt to the language model and get back a response. Additionally, LlamaIndex offers more advanced primitives such as decision-making at the top level to route queries to the right sub-data structure, and the ability to synthesize an answer from multiple data sources. It also provides an outer abstraction layer that can automatically reason which structure to use given an outer query request, and can be used as a drop-in module on top of existing data systems without having to worry about complexity. Examples of applications that can be built on top of LlamaIndex include ingesting video and structured data to parse into an audio transcript, running image captioning models, and creating augmented chatbot experiences on top of web scrapers. \n  2. _LlamaIndex is also exploring the idea of automation and unifying everything under a single query interface,_ so that users don\u2019t have to specify a different parameter for every use case. This includes optimizing token usage, making queries faster, and reducing costs for the user. Additionally, LlamaIndex is looking into applying automation to the data system world, such as teaching Oracle databases how to spit out natural language prompt responses, and making the data stack more efficient. This includes simplifying the data stack over time, especially as language models take off, and leveraging capabilities of LLM\u2019s and various components of the data landscape to simplify the number of steps it takes from raw data to insight for the user. They are also exploring the idea of inferring the right schemas and writing structured data from unstructured data, as well as automatically building a natural language query interface with a view of the data within the data system. \n  3. _LlamaIndex is also exploring the idea of agents as a layer of automation for decision making over any sort of function that you want to run._ This includes taking in some input and doing reasoning under the hood to decide, make a decision over some input, as well as some access to some context, for instance, over your data or over the set of tools that is able to have access to. Additionally, LlamaIndex is looking into ways to reduce cost and latency, such as using more fine-tuned distilled models that are a bit smaller, and making sure that the more decisions that are chained together, the less errors propagate over time. They are also exploring the idea of observability and evidence across a chain of relatively independent decisions that individual agents are making, as well as the interfaces that these agents might use, such as traditional software and agent worlds. \n\n**What is the origin story of LlamaIndex?**\n\nThe origin story of LlamaIndex is that it was founded in November by Jerry,\nwho was trying to build a sales bot. He was playing around with GPT-3 and\nwanted to use it on his internal company data. He wanted to use it to\nsynthesize a to do list for him for the next customer meeting, as he had to\nspend 20\u201330 minutes reviewing notes from the previous call transcripts. This\nled to the idea of stuffing data from Notions, Slack, Salesforce, data lakes,\nvector databases, and structure databases into language models. This was the\nimpetus for LlamaIndex, which is focused on connecting data to language models\nand tapping into the capabilities of language models to utilize them on top of\nprivate sources of data.\n\n**What is LlamaIndex doing beyond top-k retrieval?**\n\nLlamaIndex is offering more advanced primitives on top of basic top-k\nretrieval in order to provide responses to more complicated questions. These\nprimitives include decision-making at the top level to route queries to the\nright sub-data structure, synthesizing information from multiple data systems,\nand providing trade-offs between different approaches.\n\nAdditionally, LlamaIndex is working on building tooling to help users create\ncustomizable indexes and views of their data to allow them to execute\ndifferent types of queries. This includes connecting to existing data systems,\ndefining metadata on top of each unit of data, providing the building blocks\nto create different types of indexes, and abstracting away complexity with an\nouter agent layer that can automatically reason which structure to use given a\nquery request. This allows users to get the best results for a query, while\nalso providing an alternative to something like a langchain or using it as\npart of building a broader solution.\n\n**[Sam] It sounds like we\u2019re starting to identify a higher level of\nabstraction that different use cases will fall under. Is it more the case that\nthere\u2019s some manageable number of these primitives, like 10, 20, or is it that\nevery use case is going to be a little bit different, and there are hundreds\nof thousands of kind of fundamental ways that people want to work with their\ndocuments, and so you need to just give them a very open capability?**\n\nJerry\u2019s response is that there are probably a few different use cases that\npeople tend to want to get answers from over their data, and it is possible\nthere is a giant long tail of different tasks. He believes that the complexity\nof the task scales with the number of steps it requires to execute, and that\nusers need to be given customizable building blocks in order to get the\nresults they want. He also believes that the next natural step is to automate\nthe process and unify everything under a single query interface, so that users\ndon\u2019t have to specify different parameters for every use case.\n\nHe also believes that this paradigm is displacing more static paradigms like\nETL, and that it is applicable to a wide range of applications. He sees this\nagent type environment becoming fundamental infrastructure that reimagines the\nentire existing enterprise data stack, and that it can be used to parse\nunstructured data into structured data, as well as to automatically reason how\nto best transform data from one place to another. He also believes that this\nwill make the job of the data engineer and data scientist much more efficient,\nand that it will enable the creation of natural language query interfaces that\nhave a view of the data within the data system.\n\n**[Sam] When you think about the interface between LLM-based data processing\nsystem and the data sources of record, what does that interface evolve to look\nlike? For example, does it evolve to look like the chat GPT plugin model,\nwhere we\u2019re going to teach our Oracle databases how to spit out natural\nlanguage prompt responses, that kind of thing, or do you think that there\u2019s\nsome more efficient way of doing that or is that more efficient? Like, what\u2019s\nyour view of the way these things evolve?**\n\nI think the way this interface will evolve is that it will become more\nautomated and efficient. We will be able to use language models to understand\nraw text and extract the relevant information from it, without having to\nmanually enter data into a structured format. We will also be able to use\nagents to automate decision making and provide a unified query interface, so\nthat users don\u2019t have to specify different parameters for every use case.\n\nAdditionally, we can use LlamaIndex to structure data in a way that allows us\nto make use of the limited prompt size of GPT-3, while still being able to\nachieve the task. We can also use this data stack to infer the right schemas\nand further write structured data from unstructured data, as well as\nautomatically build a natural language query interface that has a view of the\ndata within the data system. This will enable us to make the job of the data\nengineer and data scientist much more efficient by having automated reasoning\nagents over deciding, making decisions at every stage of the data\ninfrastructure stack.", "mimetype": "text/plain", "start_char_idx": 1325, "end_char_idx": 9689, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "70d78f92-1bff-4525-9d4d-b3bc40ac78b7": {"__data__": {"id_": "70d78f92-1bff-4525-9d4d-b3bc40ac78b7", "embedding": null, "metadata": {"Header_1": " Want to ask your own questions over the podcast?", "filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9e4f8de8-ece1-4ea4-b3fd-66aaef5f0629", "node_type": "4", "metadata": {"filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "hash": "adde2250c4c6b4a98d2a892874c0b3f884cfead5097dcace098c9991e2212113", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2e804da9-3a80-4079-a8a1-cdfce1862615", "node_type": "1", "metadata": {"Header_1": " Distilled Highlights", "filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}, "hash": "a5a53311df2bb1683e96f0a8add92ea580a4a654efbec891d350f468e845a0df", "class_name": "RelatedNodeInfo"}}, "text": "Want to ask your own questions over the podcast?\n\nIf you want to build your own LLM-powered chatbot over our TWIML podcast,\ncheck out the resources below!\n\n[ Colab notebook ](https://colab.research.google.com/drive/1sAHWbyQRjtp_w-r-\nHOMpL0gkkhigkdGR?usp=sharing)\n\n[ Raw Transcript ](https://www.dropbox.com/s/gn2rpfvkjkygemb/twiml.txt?dl=0)\n\n[ Podcast on Spotify\n](https://open.spotify.com/episode/2vEO6dkzfEw5e7eZqngsGz?si=397cc8d7496a479c)", "mimetype": "text/plain", "start_char_idx": 9694, "end_char_idx": 10135, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"37e9cef9-9fca-4cde-ab33-1d70e75bbb1e": {"doc_hash": "313c47debe4559819a1ea3aec052cd513fe3677354e26af5b0b9765bea49a8f3", "ref_doc_id": "9e4f8de8-ece1-4ea4-b3fd-66aaef5f0629"}, "2e804da9-3a80-4079-a8a1-cdfce1862615": {"doc_hash": "a5a53311df2bb1683e96f0a8add92ea580a4a654efbec891d350f468e845a0df", "ref_doc_id": "9e4f8de8-ece1-4ea4-b3fd-66aaef5f0629"}, "70d78f92-1bff-4525-9d4d-b3bc40ac78b7": {"doc_hash": "0ff79fb1411c1dc5ffe15b918710cd711fce0811f3e3e2bdfdc2a4800994f494", "ref_doc_id": "9e4f8de8-ece1-4ea4-b3fd-66aaef5f0629"}}, "docstore/ref_doc_info": {"9e4f8de8-ece1-4ea4-b3fd-66aaef5f0629": {"node_ids": ["37e9cef9-9fca-4cde-ab33-1d70e75bbb1e", "2e804da9-3a80-4079-a8a1-cdfce1862615", "70d78f92-1bff-4525-9d4d-b3bc40ac78b7"], "metadata": {"Header_1": " Overview", "filename": "llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595.md", "extension": ".md", "title": "LlamaIndex on TWIML AI: A Distilled Summary (using LlamaIndex)", "date": "May 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-on-twiml-ai-a-distilled-summary-using-llamaindex-de2a88551595"}}}}