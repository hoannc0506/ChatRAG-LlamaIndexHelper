{"docstore/data": {"b84e38e4-c4ab-4151-a263-91d2d5d2ef4b": {"__data__": {"id_": "b84e38e4-c4ab-4151-a263-91d2d5d2ef4b", "embedding": null, "metadata": {"Header_1": " Introduction", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eed95434-8284-4c65-bff8-7774db477889", "node_type": "1", "metadata": {"Header_1": " Outline:"}, "hash": "e9a469c30b6b800695fdd724a783fda067d6f3d8e3ef80d834f8512d9f707e07", "class_name": "RelatedNodeInfo"}}, "text": "Introduction\n\nEvaluation is a critical component in enhancing your Retrieval-Augmented\nGeneration (RAG) pipeline, traditionally reliant on GPT-4. However, the open-\nsource [ Prometheus model ](https://huggingface.co/kaist-\nai/prometheus-13b-v1.0) has recently emerged as a notable alternative for such\nevaluation tasks.\n\nIn this blog post, we will demonstrate how to effectively use the Prometheus\nmodel for evaluation purposes, integrating it smoothly with the LlamaIndex\nframework by comparing it with GPT-4 evaluation. Our primary focus will be on\nassessing RAG using our standard metrics: Correctness, Faithfulness, and\nContext Relevancy. To provide a clearer understanding, here\u2019s what each metric\nentails:\n\n  1. **Correctness** : Assesses whether the generated answer aligns with the reference answer, given the query (this necessitates labeled data). \n  2. **Faithfulness** : Measures if the answer remains true to the retrieved contexts, essentially checking for the absence of hallucinations. \n  3. **Context Relevancy** : Evaluate the relevance of both the retrieved context and the answer to the query. \n\nFor an in-depth exploration, our documentation is available [ here\n](https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html) .\n\nFor those who are exploring the Prometheus model for the first time, the paper\nsummary by [ Andrei ](https://www.linkedin.com/in/nerdai/) is an excellent\nresource to gain a better understanding.\n\nA crucial aspect to remember when using the Prometheus model is its dependence\non rubric scores within the prompt for effective evaluation. An example of\nsuch Rubric scores in the context of ` Correctness Evaluation ` is as follows:\n\n> ###Score Rubrics: Score 1: If the generated answer is not relevant to the\n> user query and reference answer. Score 2: If the generated answer is\n> according to reference answer but not relevant to user query. Score 3: If\n> the generated answer is relevant to the user query and reference answer but\n> contains mistakes. Score 4: If the generated answer is relevant to the user\n> query and has the exact same metrics as the reference answer, but it is not\n> as concise. Score 5: If the generated answer is relevant to the user query\n> and fully correct according to the reference answer.\n\nYou\u2019ll find comprehensive details on this in the prompts section of this\ntutorial.\n\nFor a detailed walkthrough of the code, feel free to follow along with our [\nGoogle Colab Notebook ](https://colab.research.google.com/github/run-\nllama/llama_index/blob/main/docs/examples/evaluation/prometheus_evaluation.ipynb)\naccompanying this blog post. In the notebook, we conducted evaluations on both\nthe ` Paul Graham Essay Text ` and the ` Llama2 Paper ` . However, for this\nblog post, we\u2019ll focus exclusively on the Llama2 Paper, as it revealed some\nparticularly interesting insights.", "mimetype": "text/plain", "start_char_idx": 3, "end_char_idx": 2862, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eed95434-8284-4c65-bff8-7774db477889": {"__data__": {"id_": "eed95434-8284-4c65-bff8-7774db477889", "embedding": null, "metadata": {"Header_1": " Outline:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b84e38e4-c4ab-4151-a263-91d2d5d2ef4b", "node_type": "1", "metadata": {"Header_1": " Introduction", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "922bb1e59b0d44c47acf7d7d1dd0dae58fa6ca298ab1aba9c3b0ab619599d60a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8769012e-5814-4fba-b0a7-531d15ce2cfe", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline"}, "hash": "18991424316214398532f47773e0d995fc58da98790184a3d93295fe40def288", "class_name": "RelatedNodeInfo"}}, "text": "Outline:\n\n  1. Setup Evaluation Pipeline. \n\n  * Download Dataset. \n  * Define LLMs (Prometheus, GPT-4) needed for evaluation. \n  * Define Correctness, Faithfulness, and Relevancy prompt templates. \n  * Define Prometheus, GPT-4 Evaluators, and Batch Eval Runner. \n  * Run the Correctness, Faithfulness, and Relevancy Evaluation over the Llama2 dataset. \n\n2\\. Results\n\n  * Correctness Evaluation score distribution between Prometheus and GPT-4. \n  * Feedback comparison between Prometheus and GPT-4 for correctness evaluation. \n  * Faithfulness and Relevancy Evaluation scores with Prometheus and GPT-4. \n  * Hamming Distance comparison between Prometheus and GPT-4. \n  * Feedback comparison between Prometheus and GPT-4 for Faithfulness and Relevancy \n\n3\\. Summary with Cost Analysis.", "mimetype": "text/plain", "start_char_idx": 2867, "end_char_idx": 3650, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8769012e-5814-4fba-b0a7-531d15ce2cfe": {"__data__": {"id_": "8769012e-5814-4fba-b0a7-531d15ce2cfe", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eed95434-8284-4c65-bff8-7774db477889", "node_type": "1", "metadata": {"Header_1": " Outline:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "b4f89a61f20659c891a50e2ca2d4c8c8c540be51109daa2440bccc540d4d513c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a49c56df-30ba-4a95-bc6b-ab13bee29260", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Download Dataset"}, "hash": "da1999cf16f6b723dbd19601df65d997c2689e5872703c882a882af0ffc1cc21", "class_name": "RelatedNodeInfo"}}, "text": "Setup Evaluation Pipeline\n\nPlease be aware that certain functions mentioned here are not defined in\ndetail within the blog post. We have showcased only the essential parts of the\npipeline to provide an overview of its setup. For a comprehensive code\nwalkthrough, we recommend visiting our [ Google Colab Notebook\n](https://colab.research.google.com/github/run-\nllama/llama_index/blob/main/docs/examples/evaluation/prometheus_evaluation.ipynb)\n.", "mimetype": "text/plain", "start_char_idx": 3655, "end_char_idx": 4099, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a49c56df-30ba-4a95-bc6b-ab13bee29260": {"__data__": {"id_": "a49c56df-30ba-4a95-bc6b-ab13bee29260", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Download Dataset", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8769012e-5814-4fba-b0a7-531d15ce2cfe", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "827add6eae2409c1b6ded7627540fe75ef65bd3ab73a5b2bb989872a0e941b5b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c731b1e-271e-4c6c-9f77-0faad01d45bc", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Define Prometheus LLM hosted on HuggingFace And OpenAI for creating an"}, "hash": "fe7cfbf46eadb07dc21b2fe3e5d4bfd80835452aadf5d6ea8e8bbfe56a61013e", "class_name": "RelatedNodeInfo"}}, "text": "Download Dataset\n\nWe will use the Llama2 paper dataset from Llama Datasets which contains 100\nquestions and their reference answers.\n\n    \n    \n    from llama_index.llama_dataset import download_llama_dataset\n    \n    llama2_rag_dataset, llama2_documents = download_llama_dataset(\n        \"Llama2PaperDataset\", \"./data/llama2\"\n    )", "mimetype": "text/plain", "start_char_idx": 4105, "end_char_idx": 4437, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2c731b1e-271e-4c6c-9f77-0faad01d45bc": {"__data__": {"id_": "2c731b1e-271e-4c6c-9f77-0faad01d45bc", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Define Prometheus LLM hosted on HuggingFace And OpenAI for creating an", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a49c56df-30ba-4a95-bc6b-ab13bee29260", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Download Dataset", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "39c75c91b09a0f2f138d5616725bd8656a348b3d5d6f3aee62f6f4b11a1d4f51", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ac19fff-183b-4293-99f0-03b20f110cc5", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Prompt templates."}, "hash": "17c1a4d3563c50a471a1bf2c068da6474dcbe5d4952e4586d16c768739528fcb", "class_name": "RelatedNodeInfo"}}, "text": "Define Prometheus LLM hosted on HuggingFace And OpenAI for creating an\nIndex (RAG) pipeline\n\nWe need to host the model on HF Inference endpoint using Nvidia A100 GPU, 80\nGB RAM.\n\n    \n    \n    from llama_index.llms import HuggingFaceInferenceAPI\n    import os\n    \n    HF_TOKEN = \"YOUR HF TOKEN\"\n    HF_ENDPOINT_URL = \"HF END POINT URL\"\n    \n    prometheus_llm = HuggingFaceInferenceAPI(\n        model_name=HF_ENDPOINT_URL,\n        token=HF_TOKEN,\n        temperature=0.1,\n        do_sample=True,\n        top_p=0.95,\n        top_k=40,\n        repetition_penalty=1.1,\n    )\n    \n    os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\"\n    \n    from llama_index.llms import OpenAI\n    \n    gpt4_llm = OpenAI(\"gpt-4\")", "mimetype": "text/plain", "start_char_idx": 4443, "end_char_idx": 5158, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4ac19fff-183b-4293-99f0-03b20f110cc5": {"__data__": {"id_": "4ac19fff-183b-4293-99f0-03b20f110cc5", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Prompt templates.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c731b1e-271e-4c6c-9f77-0faad01d45bc", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Define Prometheus LLM hosted on HuggingFace And OpenAI for creating an", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "b9ad562479f8d6423a50d0b10bf3f5a814e52a482a6b83cf0ed4f618df1e7395", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3cb1da35-5643-4926-ba81-834b16f27077", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Define Correctness, FaithFulness, Relevancy Evaluators"}, "hash": "bdaca83e04c058d9e0b19f9c066cdc07432b5bcea12e40edd0682179b087ead5", "class_name": "RelatedNodeInfo"}}, "text": "Prompt templates.\n\nWe will use the same prompts for the Prometheus model and GPT-4 to make\nconsistent performance comparisons.\n\n**Correctness Evaluation Prompt:**\n\n    \n    \n    prometheus_correctness_eval_prompt_template = \"\"\"###Task Description: An instruction (might include an Input inside it), a query, a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given. \n       1. Write a detailed feedback that assesses the quality of the response strictly based on the given score rubric, not evaluating in general. \n       2. After writing a feedback, write a score that is either 1 or 2 or 3 or 4 or 5. You should refer to the score rubric. \n       3. The output format should look as follows: 'Feedback: (write a feedback for criteria) [RESULT] (1 or 2 or 3 or 4 or 5)'\n       4. Please do not generate any other opening, closing, and explanations. \n       5. Only evaluate on common things between generated answer and reference answer. Don't evaluate on things which are present in reference answer but not in generated answer.\n    \n       ###The instruction to evaluate: Your task is to evaluate the generated answer and reference answer for the query: {query}\n       \n       ###Generate answer to evaluate: {generated_answer} \n    \n       ###Reference Answer (Score 5): {reference_answer}\n                \n       ###Score Rubrics: \n       Score 1: If the generated answer is not relevant to the user query and reference answer.\n       Score 2: If the generated answer is according to reference answer but not relevant to user query.\n       Score 3: If the generated answer is relevant to the user query and reference answer but contains mistakes.\n       Score 4: If the generated answer is relevant to the user query and has the exact same metrics as the reference answer, but it is not as concise.\n       Score 5: If the generated answer is relevant to the user query and fully correct according to the reference answer.\n        \n       ###Feedback:\"\"\"\n    \n\n**Faithfulness Evaluation Prompt:**\n\n    \n    \n    prometheus_faithfulness_eval_prompt_template= \"\"\"###Task Description: An instruction (might include an Input inside it), an information, a context, and a score rubric representing evaluation criteria are given.\n    1. You are provided with evaluation task with the help of information, context information to give result based on score rubrics.\n    2. Write a detailed feedback based on evaluation task and the given score rubric, not evaluating in general.\n    3. After writing a feedback, write a score that is YES or NO. You should refer to the score rubric.\n    4. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (YES or NO)\u201d\n    5. Please do not generate any other opening, closing, and explanations.\n    \n    ###The instruction to evaluate: Your task is to evaluate if the given piece of information is supported by context.\n    \n    ###Information: {query_str}\n    \n    ###Context: {context_str}\n    \n    ###Score Rubrics:\n    Score YES: If the given piece of information is supported by context.\n    Score NO: If the given piece of information is not supported by context\n    \n    ###Feedback: \"\"\"\n    \n    prometheus_faithfulness_refine_prompt_template= \"\"\"###Task Description: An instruction (might include an Input inside it), a information, a context information, an existing answer, and a score rubric representing a evaluation criteria are given.\n    1. You are provided with evaluation task with the help of information, context information and an existing answer.\n    2. Write a detailed feedback based on evaluation task and the given score rubric, not evaluating in general.\n    3. After writing a feedback, write a score that is YES or NO. You should refer to the score rubric.\n    4. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (YES or NO)\"\n    5. Please do not generate any other opening, closing, and explanations.\n    \n    ###The instruction to evaluate: If the information is present in the context and also provided with an existing answer.\n    \n    ###Existing answer: {existing_answer}\n    \n    ###Information: {query_str}\n    \n    ###Context: {context_msg}\n    \n    ###Score Rubrics:\n    Score YES: If the existing answer is already YES or If the Information is present in the context.\n    Score NO: If the existing answer is NO and If the Information is not present in the context.\n    \n    ###Feedback: \"\"\"\n\n**Relevancy Evaluation Prompt:**\n\n    \n    \n    prometheus_relevancy_eval_prompt_template = \"\"\"###Task Description: An instruction (might include an Input inside it), a query with response, context, and a score rubric representing evaluation criteria are given. \n           1. You are provided with evaluation task with the help of a query with response and context.\n           2. Write a detailed feedback based on evaluation task and the given score rubric, not evaluating in general. \n           3. After writing a feedback, write a score that is YES or NO. You should refer to the score rubric. \n           4. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (YES or NO)\u201d \n           5. Please do not generate any other opening, closing, and explanations. \n    \n            ###The instruction to evaluate: Your task is to evaluate if the response for the query is in line with the context information provided.\n    \n            ###Query and Response: {query_str} \n    \n            ###Context: {context_str}\n                \n            ###Score Rubrics: \n            Score YES: If the response for the query is in line with the context information provided.\n            Score NO: If the response for the query is not in line with the context information provided.\n        \n            ###Feedback: \"\"\"\n    \n    prometheus_relevancy_refine_prompt_template = \"\"\"###Task Description: An instruction (might include an Input inside it), a query with response, context, an existing answer, and a score rubric representing a evaluation criteria are given. \n       1. You are provided with evaluation task with the help of a query with response and context and an existing answer.\n       2. Write a detailed feedback based on evaluation task and the given score rubric, not evaluating in general. \n       3. After writing a feedback, write a score that is YES or NO. You should refer to the score rubric. \n       4. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (YES or NO)\" \n       5. Please do not generate any other opening, closing, and explanations. \n    \n       ###The instruction to evaluate: Your task is to evaluate if the response for the query is in line with the context information provided.\n    \n       ###Query and Response: {query_str} \n    \n       ###Context: {context_str}\n                \n       ###Score Rubrics: \n       Score YES: If the existing answer is already YES or If the response for the query is in line with the context information provided.\n       Score NO: If the existing answer is NO and If the response for the query is in line with the context information provided.\n        \n       ###Feedback: \"\"\"", "mimetype": "text/plain", "start_char_idx": 5164, "end_char_idx": 12412, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3cb1da35-5643-4926-ba81-834b16f27077": {"__data__": {"id_": "3cb1da35-5643-4926-ba81-834b16f27077", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Define Correctness, FaithFulness, Relevancy Evaluators", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ac19fff-183b-4293-99f0-03b20f110cc5", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Prompt templates.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "1d37cef87d4319e96267930009a9897fe173dda1ee17996eb14eb62e09066302", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e4b6c7cb-1d8c-4ec7-8a83-c33dab06f6f1", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Function to run batch evaluations on defined evaluators"}, "hash": "76771e858959ccb2be0887765e9289daeeae3d33f23911378dc94eadad32b44a", "class_name": "RelatedNodeInfo"}}, "text": "Define Correctness, FaithFulness, Relevancy Evaluators\n\n    \n    \n    from llama_index import ServiceContext\n    from llama_index.evaluation import (\n        CorrectnessEvaluator,\n        FaithfulnessEvaluator,\n        RelevancyEvaluator,\n    )\n    from llama_index.callbacks import CallbackManager, TokenCountingHandler\n    import tiktoken\n    \n    # Provide Prometheus model in service_context\n    prometheus_service_context = ServiceContext.from_defaults(llm=prometheus_llm)\n    \n    # CorrectnessEvaluator with Prometheus model\n    prometheus_correctness_evaluator = CorrectnessEvaluator(\n        service_context=prometheus_service_context,\n        parser_function=parser_function,\n        eval_template=prometheus_correctness_eval_prompt_template,\n    )\n    \n    # FaithfulnessEvaluator with Prometheus model\n    prometheus_faithfulness_evaluator = FaithfulnessEvaluator(\n        service_context=prometheus_service_context,\n        eval_template=prometheus_faithfulness_eval_prompt_template,\n        refine_template=prometheus_faithfulness_refine_prompt_template,\n    )\n    \n    # RelevancyEvaluator with Prometheus model\n    prometheus_relevancy_evaluator = RelevancyEvaluator(\n        service_context=prometheus_service_context,\n        eval_template=prometheus_relevancy_eval_prompt_template,\n        refine_template=prometheus_relevancy_refine_prompt_template,\n    )\n    \n    # Set the encoding model to `gpt-4` for token counting.\n    token_counter = TokenCountingHandler(\n        tokenizer=tiktoken.encoding_for_model(\"gpt-4\").encode\n    )\n    \n    callback_manager = CallbackManager([token_counter])\n    \n    # Provide GPT-4 model in service_context\n    gpt4_service_context = ServiceContext.from_defaults(\n        llm=gpt4_llm, callback_manager=callback_manager\n    )\n    \n    # CorrectnessEvaluator with GPT-4 model\n    gpt4_correctness_evaluator = CorrectnessEvaluator(\n        service_context=gpt4_service_context,\n        # parser_function=parser_function,\n    )\n    \n    # FaithfulnessEvaluator with GPT-4 model\n    gpt4_faithfulness_evaluator = FaithfulnessEvaluator(\n        service_context=gpt4_service_context,\n        eval_template=prometheus_faithfulness_eval_prompt_template,\n        refine_template=prometheus_faithfulness_refine_prompt_template,\n    )\n    \n    # RelevancyEvaluator with GPT-4 model\n    gpt4_relevancy_evaluator = RelevancyEvaluator(\n        service_context=gpt4_service_context,\n        eval_template=prometheus_relevancy_eval_prompt_template,\n        refine_template=prometheus_relevancy_refine_prompt_template,\n    )\n    \n    # create a dictionary of evaluators\n    prometheus_evaluators = {\n        \"correctness\": prometheus_correctness_evaluator,\n        \"faithfulness\": prometheus_faithfulness_evaluator,\n        \"relevancy\": prometheus_relevancy_evaluator,\n    }\n    \n    gpt4_evaluators = {\n        \"correctness\": gpt4_correctness_evaluator,\n        \"faithfulness\": gpt4_faithfulness_evaluator,\n        \"relevancy\": gpt4_relevancy_evaluator,\n    }", "mimetype": "text/plain", "start_char_idx": 12418, "end_char_idx": 15416, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e4b6c7cb-1d8c-4ec7-8a83-c33dab06f6f1": {"__data__": {"id_": "e4b6c7cb-1d8c-4ec7-8a83-c33dab06f6f1", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Function to run batch evaluations on defined evaluators", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3cb1da35-5643-4926-ba81-834b16f27077", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Define Correctness, FaithFulness, Relevancy Evaluators", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "3d81a0ee8647dba2ed848ca24bb630d121c0b43552bc655689d002abac06c46b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7372e50-7a82-437f-a2ec-c18fc4473551", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Get Query Engine, Questions, and References."}, "hash": "db40310e90f6556f2e28893f94dc440a41e8e7da8baf1ff766938c051a30e719", "class_name": "RelatedNodeInfo"}}, "text": "Function to run batch evaluations on defined evaluators\n\n    \n    \n    from llama_index.evaluation import BatchEvalRunner\n    \n    \n    async def batch_eval_runner(\n        evaluators, query_engine, questions, reference=None, num_workers=8\n    ):\n        batch_runner = BatchEvalRunner(\n            evaluators, workers=num_workers, show_progress=True\n        )\n    \n        eval_results = await batch_runner.aevaluate_queries(\n            query_engine, queries=questions, reference=reference\n        )\n    \n        return eval_results", "mimetype": "text/plain", "start_char_idx": 15422, "end_char_idx": 15956, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7372e50-7a82-437f-a2ec-c18fc4473551": {"__data__": {"id_": "b7372e50-7a82-437f-a2ec-c18fc4473551", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Get Query Engine, Questions, and References.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e4b6c7cb-1d8c-4ec7-8a83-c33dab06f6f1", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Function to run batch evaluations on defined evaluators", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "0dd0d499d46d5a25433b2b0d778429e8a52fad6052aaca00235d596b7b1f46fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a35ef7b3-089a-473d-b287-637a69f754f5", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Compute Correctness, Faithfulness, and Relevancy Evaluation."}, "hash": "b471be3292d6c24beb3c015753a6fc4a79a093f75fc44bf9e9d2f1dfad93afca", "class_name": "RelatedNodeInfo"}}, "text": "Get Query Engine, Questions, and References.\n\n    \n    \n    query_engine, rag_dataset = create_query_engine_rag_dataset(\"./data/llama2\")\n    \n    questions = [example.query for example in rag_dataset.examples]\n    \n    reference = [[example.reference_answer] for example in rag_dataset.examples]", "mimetype": "text/plain", "start_char_idx": 15962, "end_char_idx": 16257, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a35ef7b3-089a-473d-b287-637a69f754f5": {"__data__": {"id_": "a35ef7b3-089a-473d-b287-637a69f754f5", "embedding": null, "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Compute Correctness, Faithfulness, and Relevancy Evaluation.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7372e50-7a82-437f-a2ec-c18fc4473551", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Get Query Engine, Questions, and References.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "fa88e5fd43c043e266e327bfce301ee0dd341e88c3e2343d5e8473d4b961b39b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8d92bafc-a7c2-4276-ac00-fcaa5308df64", "node_type": "1", "metadata": {"Header_1": " Results"}, "hash": "1969697ad88fe93fc8593723a245f82babc86eb0a7d139295b18623405b3ac8b", "class_name": "RelatedNodeInfo"}}, "text": "Compute Correctness, Faithfulness, and Relevancy Evaluation.\n\n    \n    \n    prometheus_eval_results = await batch_eval_runner(\n        prometheus_evaluators, query_engine, questions, reference\n    )\n    \n    gpt4_eval_results = await batch_eval_runner(\n        gpt4_evaluators, query_engine, questions, reference\n    )", "mimetype": "text/plain", "start_char_idx": 16263, "end_char_idx": 16581, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8d92bafc-a7c2-4276-ac00-fcaa5308df64": {"__data__": {"id_": "8d92bafc-a7c2-4276-ac00-fcaa5308df64", "embedding": null, "metadata": {"Header_1": " Results", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a35ef7b3-089a-473d-b287-637a69f754f5", "node_type": "1", "metadata": {"Header_1": " Setup Evaluation Pipeline", "Header_2": " Compute Correctness, Faithfulness, and Relevancy Evaluation.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "755b7f01df06131196d45f975e0a10fd8dff43db68951159b074ab763b6529e9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b41844ed-3b16-4fc1-bc20-c5a994bb7a1a", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Correctness Evaluation score distribution."}, "hash": "06fb2bca620e8bd1339604f756f2e3927f96e38e559d41d5af469145f206820d", "class_name": "RelatedNodeInfo"}}, "text": "Results", "mimetype": "text/plain", "start_char_idx": 3225, "end_char_idx": 3232, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b41844ed-3b16-4fc1-bc20-c5a994bb7a1a": {"__data__": {"id_": "b41844ed-3b16-4fc1-bc20-c5a994bb7a1a", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " Correctness Evaluation score distribution.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8d92bafc-a7c2-4276-ac00-fcaa5308df64", "node_type": "1", "metadata": {"Header_1": " Results", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "3b2941def5f36062eeb354b11d6b4b9f3a4f294d60944ed1cb20860d51bdcf84", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca6454a4-f970-40a0-80a5-39c43b31f6a6", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With the Prometheus Model:"}, "hash": "063905330b1dc57fdf59357ba22b7aefc4bd385da0881723a47eaafa8fa1186c", "class_name": "RelatedNodeInfo"}}, "text": "Correctness Evaluation score distribution.", "mimetype": "text/plain", "start_char_idx": 16599, "end_char_idx": 16641, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ca6454a4-f970-40a0-80a5-39c43b31f6a6": {"__data__": {"id_": "ca6454a4-f970-40a0-80a5-39c43b31f6a6", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " With the Prometheus Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b41844ed-3b16-4fc1-bc20-c5a994bb7a1a", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Correctness Evaluation score distribution.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "7f88cc167fe40fdbb8371cd84f271856199f8a5355aea6ce93ae4e0459d92a23", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7ee29d0a-818b-4958-b521-9b13a8b9110b", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With GPT-4 Model:"}, "hash": "967f5c2f95d1c2e66eb4c86a64974abac89efb37eaa40e682d043f1f0a831ec7", "class_name": "RelatedNodeInfo"}}, "text": "With the Prometheus Model:\n\n> 3.0: 56.0, 1.0: 26.0, 5.0: 9.0, 4.0: 8.0, 2.0: 1.0", "mimetype": "text/plain", "start_char_idx": 16647, "end_char_idx": 16727, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7ee29d0a-818b-4958-b521-9b13a8b9110b": {"__data__": {"id_": "7ee29d0a-818b-4958-b521-9b13a8b9110b", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " With GPT-4 Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca6454a4-f970-40a0-80a5-39c43b31f6a6", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With the Prometheus Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "71843df04d8ec44c9179a30d9356ddbdd2db2ed8e6af016e3e172e752c045849", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9461b219-4fa0-4915-a1db-d0e5844de403", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " **Observation:**"}, "hash": "a5cc4776bfb3a6fc5b68d0bae3b06e310569fb6e15c655b80382e3c6fee25f4b", "class_name": "RelatedNodeInfo"}}, "text": "With GPT-4 Model:\n\n> 4.5: 57.99, 1.0: 6.0, 4.0: 12.0, 5.0: 10.0, 2.0: 5.0, 3.5: 5.0, 2.5: 3.0,\n> 3.0: 1.0", "mimetype": "text/plain", "start_char_idx": 16733, "end_char_idx": 16838, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9461b219-4fa0-4915-a1db-d0e5844de403": {"__data__": {"id_": "9461b219-4fa0-4915-a1db-d0e5844de403", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " **Observation:**", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ee29d0a-818b-4958-b521-9b13a8b9110b", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With GPT-4 Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "879547fdc39c8548bd8d5d731fcbcb0ef6dc418200f3f3a18d3511f342b7f870", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "83dad89d-f9c8-4ab6-b894-9a0383c86706", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Feedback comparison between Prometheus and GPT-4 for correctness."}, "hash": "9edc0bf4b96575d8ac2e6d3809840029ab492ce5a86bf763b27fb6f742eadc11", "class_name": "RelatedNodeInfo"}}, "text": "**Observation:**\n\nPrometheus Evaluator gives more ` 3.0 ` scores compared to GPT-4 which gives `\n4.5 ` . Let\u2019s investigate it with the help of feedback.", "mimetype": "text/plain", "start_char_idx": 16844, "end_char_idx": 16996, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "83dad89d-f9c8-4ab6-b894-9a0383c86706": {"__data__": {"id_": "83dad89d-f9c8-4ab6-b894-9a0383c86706", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " Feedback comparison between Prometheus and GPT-4 for correctness.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9461b219-4fa0-4915-a1db-d0e5844de403", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " **Observation:**", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "3e7abb732edbde7d68113320227ee76317b233c9668bda5087627a1cfdd9e4f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cc87d010-a35f-4a7b-9390-d556a2dc93b7", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Faithfulness and Relevancy Evaluation scores."}, "hash": "3f7a360578941f2cadbc071d1406c48183f6244234d2a17adf19a2bb6430a741", "class_name": "RelatedNodeInfo"}}, "text": "Feedback comparison between Prometheus and GPT-4 for correctness.\n\n> **_Query:_ ** _Based on the abstract of \u201cLlama 2: Open Foundation and Fine-\n> Tuned Chat Models,\u201d what are the two primary objectives achieved in this\n> work, and what is the range of parameters for the large language models\n> developed?_\n>\n> **_Generated Answer:_ ** _The two primary objectives achieved in this work\n> are the development and release of Llama 2, a collection of pretrained and\n> fine-tuned large language models (LLMs), and the optimization of these\n> models for dialogue use cases. The range of parameters for the large\n> language models developed is from 7 billion to 70 billion._\n>\n> **_Reference Answer:_ ** _The two primary objectives achieved in the work\n> described in the abstract of \u201cLlama 2: Open Foundation and Fine-Tuned Chat\n> Models\u201d are: 1. The development and release of a collection of pretrained\n> and fine-tuned large language models (LLMs) specifically optimized for\n> dialogue use cases. 2. The demonstration that these fine-tuned LLMs,\n> referred to as Llama 2-Chat, outperform open-source chat models on most\n> benchmarks tested and may be a suitable substitute for closed-source models,\n> particularly in terms of helpfulness and safety based on human evaluations.\n> The range of parameters for the large language models developed in this work\n> is from 7 billion to 70 billion parameters._\n>\n> **_Prometheus Feedback:_ ** _The generated response is relevant to the user\n> query and correctly identifies the two primary objectives of the work\n> described in the abstract of \u201cLlama 2: Open Foundation and Fine-Tuned Chat\n> Models.\u201d However, it does not mention the demonstration of the fine-tuned\n> LLMs outperforming open-source chat models on most benchmarks tested, which\n> is a key point in the reference response. The range of parameters for the\n> large language models developed is correctly identified, but the response\n> does not mention the specific models referred to as Llama 2-Chat. So the\n> overall score is 3._\n>\n> **_Prometheus Score:_ ** _3.0_\n>\n> **_GPT-4 Feedback:_ ** _The generated answer is relevant and almost fully\n> correct. It correctly identifies the two primary objectives and the range of\n> parameters for the large language models. However, it misses the detail\n> about Llama 2-Chat outperforming other models on most benchmarks and\n> potentially being a suitable substitute for closed-source models._\n>\n> **_GPT-4 Score:_ ** _4.5_\n\n**Observation:**\n\nThe feedback from Prometheus is a little more precise compared to GPT-4 and it\npenalizes and gives a score of ` 3.0 ` but GPT-4 gives a score of ` 4.5 ` .\nPrometheus penalizes more even if some of the text in the reference answer is\nmissed in the generated answer.", "mimetype": "text/plain", "start_char_idx": 17002, "end_char_idx": 19756, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cc87d010-a35f-4a7b-9390-d556a2dc93b7": {"__data__": {"id_": "cc87d010-a35f-4a7b-9390-d556a2dc93b7", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " Faithfulness and Relevancy Evaluation scores.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "83dad89d-f9c8-4ab6-b894-9a0383c86706", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Feedback comparison between Prometheus and GPT-4 for correctness.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "d11e03fbe76829f85850394afacd31f9c80c417411ba52d080d187dc986b4961", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a0cdc8a2-4875-48cb-a968-60fc9bc3bf1b", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With the Prometheus Model:"}, "hash": "c3ab72c7f0553df99e67a52554dbe8c953af796f3834f89462a0eaa2ef1ea304", "class_name": "RelatedNodeInfo"}}, "text": "Faithfulness and Relevancy Evaluation scores.", "mimetype": "text/plain", "start_char_idx": 19762, "end_char_idx": 19807, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a0cdc8a2-4875-48cb-a968-60fc9bc3bf1b": {"__data__": {"id_": "a0cdc8a2-4875-48cb-a968-60fc9bc3bf1b", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " With the Prometheus Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc87d010-a35f-4a7b-9390-d556a2dc93b7", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Faithfulness and Relevancy Evaluation scores.", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "67bcefda6b05ab816953fb3847801ca47c1e031c6ee587a7fdf810745070ee02", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f55fd630-559b-473e-9f28-34ac16d2eb1c", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With GPT-4 Model:"}, "hash": "c9a9aab6f2992a4f6471dee57f8bf4d3fb984cb0994f27486a6957f4d0807e4a", "class_name": "RelatedNodeInfo"}}, "text": "With the Prometheus Model:\n\n> faithfulness Score: 0.39 relevancy Score: 0.57", "mimetype": "text/plain", "start_char_idx": 19813, "end_char_idx": 19889, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f55fd630-559b-473e-9f28-34ac16d2eb1c": {"__data__": {"id_": "f55fd630-559b-473e-9f28-34ac16d2eb1c", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " With GPT-4 Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a0cdc8a2-4875-48cb-a968-60fc9bc3bf1b", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With the Prometheus Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "800ab20d311a7ff7e1bb9f555e8d934e294afa0d4a05ecc4115461cb2c2c7aee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6cd8ce7c-94bf-4c40-805a-17aed60e0022", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Hamming Distance comparison between Prometheus and GPT-4:"}, "hash": "fc22c9753f67d97f9a59e71c28b6a827857a7227be2eba8fd7c352d078ab6511", "class_name": "RelatedNodeInfo"}}, "text": "With GPT-4 Model:\n\n> faithfulness Score: 0.93 relevancy Score: 0.98\n\n**Observation:**\n\nWe see a higher faithfulness and relevancy score with GPT-4 compared to the\nPrometheus model. Let\u2019s investigate it through feedback.", "mimetype": "text/plain", "start_char_idx": 19895, "end_char_idx": 20114, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6cd8ce7c-94bf-4c40-805a-17aed60e0022": {"__data__": {"id_": "6cd8ce7c-94bf-4c40-805a-17aed60e0022", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " Hamming Distance comparison between Prometheus and GPT-4:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f55fd630-559b-473e-9f28-34ac16d2eb1c", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " With GPT-4 Model:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "9fab60143c76be8dc6c455dd991b7c82b3e6ea558b621415d48aab1e78b4bc31", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "09b905d1-2777-4afc-b394-fb7c712b1afa", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Observation:"}, "hash": "888d3803fa6a5b78ff7df689368f866247a861a9e4e7c74c8504973f5f8c496e", "class_name": "RelatedNodeInfo"}}, "text": "Hamming Distance comparison between Prometheus and GPT-4:\n\n> Faithfulness Hamming Distance: 58 Relevancy Hamming Distance: 41", "mimetype": "text/plain", "start_char_idx": 20120, "end_char_idx": 20245, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "09b905d1-2777-4afc-b394-fb7c712b1afa": {"__data__": {"id_": "09b905d1-2777-4afc-b394-fb7c712b1afa", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " Observation:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6cd8ce7c-94bf-4c40-805a-17aed60e0022", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Hamming Distance comparison between Prometheus and GPT-4:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "cc9edf7faa7e464c3c30ae9b3b21884a909d7e6b31150c9c53ed0a9bfa2dd61e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f03cc287-f8d0-4bea-9838-123d13141c98", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Feedback comparison between Prometheus and GPT-4 for Faithfulness and"}, "hash": "a3819a3a8f57aeb9c97b80839562faf2022f50b640d44aa366c316d2f40b7618", "class_name": "RelatedNodeInfo"}}, "text": "Observation:\n\nThe comparison reveals that approximately ` 42% ` of the scores in case of `\nFaithfulness ` and ` 59% ` in case of ` Relevancy ` are common between\nPrometheus and GPT-4 evaluations. This indicates a decent amount of\ncorrelation in terms of faithfulness and relevance scoring between the\nPrometheus and GPT-4 models.", "mimetype": "text/plain", "start_char_idx": 20251, "end_char_idx": 20580, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f03cc287-f8d0-4bea-9838-123d13141c98": {"__data__": {"id_": "f03cc287-f8d0-4bea-9838-123d13141c98", "embedding": null, "metadata": {"Header_1": " Results", "Header_2": " Feedback comparison between Prometheus and GPT-4 for Faithfulness and", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09b905d1-2777-4afc-b394-fb7c712b1afa", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Observation:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "ee25f33ad3e6b8a536b2d40e75060b0162ad6a6c020bb41cb1daf4c6427f19b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aa1db30a-d5fe-449e-9378-e5592630aa50", "node_type": "1", "metadata": {"Header_1": " Observation:"}, "hash": "0d2f8bdee0aa72aba9799ac8c3be3f05116d0e7e865adff0eb21319592ce70cf", "class_name": "RelatedNodeInfo"}}, "text": "Feedback comparison between Prometheus and GPT-4 for Faithfulness and\nRelevancy\n\n> **Query:** Based on the abstract of \u201cLlama 2: Open Foundation and Fine-Tuned\n> Chat Models,\u201d what are the two primary objectives achieved in this work, and\n> what is the range of parameters for the large language models developed?\n> Generated Answer: The two primary objectives achieved in this work are the\n> development and release of Llama 2, a collection of pretrained and fine-\n> tuned large language models (LLMs), and the optimization of these models for\n> dialogue use cases. The range of parameters for the large language models\n> developed is from 7 billion to 70 billion.\n>\n> **Context-1:** Llama 2 : Open Foundation and Fine-Tuned Chat Models Hugo\n> Touvron\u2217Louis Martin\u2020Kevin Stone\u2020 Peter Albert Amjad Almahairi Yasmine\n> Babaei Nikolay Bashlykov Soumya Batra Prajjwal Bhargava Shruti Bhosale Dan\n> Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen Guillem Cucurull David\n> Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller Cynthia Gao Vedanuj\n> Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou Hakan Inan\n> Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n> Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana\n> Liskovich Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar\n> Mishra Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta\n> Kalyan Saladi Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian\n> Xiaoqing Ellen Tan Binh Tang Ross Taylor Adina Williams Jian Xiang Kuan\n> Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang Angela Fan Melanie Kambadur\n> Sharan Narang Aurelien Rodriguez Robert Stojnic Sergey Edunov Thomas\n> Scialom\u2217 GenAI, Meta Abstract In this work, we develop and release Llama 2,\n> a collection of pretrained and fine-tuned large language models (LLMs)\n> ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned\n> LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our models\n> outperform open-source chat models on most benchmarks we tested, and based\n> on\n> ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\n> source models. We provide a detailed description of our approach to fine-\n> tuning and safety improvements of Llama 2-Chat in order to enable the\n> community to build on our work and contribute to the responsible development\n> of LLMs. \u2217Equal contribution, corresponding authors: {tscialom,\n> htouvron}@meta.com \u2020Second author Contributions for all the authors can be\n> found in Section A.1.arXiv:2307.09288v2 [cs.CL] 19 Jul 2023\n>\n> **Context-2:** (2021)alsoilluminatesthedifficultiestiedtochatbot-oriented\n> LLMs, with concerns ranging from privacy to misleading expertise claims.\n> Deng et al. (2023) proposes a taxonomic framework to tackle these issues,\n> and Bergman et al. (2022) delves into the balance between potential positive\n> and negative impacts from releasing dialogue models.\n> InvestigationsintoredteamingrevealspecificchallengesintunedLLMs,withstudiesbyGangulietal.(2022)\n> and Zhuoet al. (2023) showcasing a variety ofsuccessful attack typesand\n> their effects onthe generation of harmful content. National security\n> agencies and various researchers, such as (Mialon et al., 2023), have also\n> raisedredflagsaroundadvancedemergentmodelbehaviors,cyberthreats,andpotentialmisuseinareaslike\n> biological warfare. Lastly, broader societal issues like job displacement\n> due to accelerated AI research and an over-reliance on LLMs leading to\n> training data degradation are also pertinent considerations (Acemoglu\n> andRestrepo,2018;AutorandSalomons,2018;Webb,2019;Shumailovetal.,2023).\n> Wearecommittedto continuing our work engaging with the broader policy,\n> academic, and industry community on these issues. 7 Conclusion\n> Inthisstudy,wehaveintroduced Llama 2,anewfamilyofpretrainedandfine-\n> tunedmodelswithscales of7billionto70billionparameters.\n> Thesemodelshavedemonstratedtheircompetitivenesswithexisting open-source chat\n> models, as well as competency that is equivalent to some proprietary models\n> on evaluation setsweexamined,althoughtheystilllagbehindothermodelslikeGPT-4.\n> Wemeticulouslyelaboratedonthe\n> methodsandtechniquesappliedinachievingourmodels,withaheavyemphasisontheiralignmentwiththe\n> principlesofhelpfulnessandsafety.\n> Tocontributemoresignificantlytosocietyandfosterthepaceofresearch,\n> wehaveresponsiblyopenedaccessto Llama 2 andLlama 2-Chat .\n> Aspartofourongoingcommitmentto transparency and safety, we plan to make\n> further improvements to Llama 2-Chat in future work. 36\n>\n> **Prometheus Faithfulness Feedback:** The information provided in the\n> context is not supported by the given information. The context is about the\n> development and release of Llama 2, a collection of pretrained and fine-\n> tuned large language models (LLMs), and the optimization of these models for\n> dialogue use cases. However, the information provided in the context does\n> not align with the given information. The context does not mention the range\n> of parameters for the large language models developed, which is the primary\n> objective mentioned in the information. The context only talks about the\n> development and release of Llama 2 and its optimization for dialogue use\n> cases, but it does not provide any information about the range of parameters\n> for the large language models developed. So the overall score is NO.\n> [RESULT] NO\n>\n> **Prometheus Faithfulness Score:** 0.0\n>\n> **Prometheus Relevancy Feedback:** The response is not in line with the\n> context information provided. The query asked for the two primary objectives\n> achieved in the work and the range of parameters for the large language\n> models developed. However, the response provided the abstract of the paper\n> and mentioned the authors, which is not relevant to the query. The response\n> also did not mention the two primary objectives achieved in the work or the\n> range of parameters for the large language models developed. So the overall\n> score is NO. [RESULT] NO\n>\n> **Prometheus Relevancy Score:** 0.0\n>\n> **GPT-4 Faithfulness Feedback:** The given piece of information is well\n> supported by the context. The context clearly states that Llama 2, a\n> collection of pretrained and fine-tuned large language models (LLMs), was\n> developed and released. It also mentions that these models range in scale\n> from 7 billion to 70 billion parameters. Furthermore, the context confirms\n> that these models are optimized for dialogue use cases. Therefore, the\n> information provided is accurate and is corroborated by the context.\n> [RESULT] YES\n>\n> **GPT-4 Faithfulness Score:** 1.0\n>\n> **GPT-4 Relevancy Feedback:** The response accurately reflects the context\n> provided. The response correctly identifies the two primary objectives of\n> the work as the development and release of Llama 2, a collection of\n> pretrained and fine-tuned large language models (LLMs), and the optimization\n> of these models for dialogue use cases. This is in line with the information\n> provided in the abstract of the context. The response also correctly states\n> the range of parameters for the large language models developed as being\n> from 7 billion to 70 billion, which is also confirmed in the context.\n> Therefore, the response is in line with the context information provided.\n> [RESULT] YES\n>\n> **GPT-4 Relevancy Score:** 1.0", "mimetype": "text/plain", "start_char_idx": 20586, "end_char_idx": 28006, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa1db30a-d5fe-449e-9378-e5592630aa50": {"__data__": {"id_": "aa1db30a-d5fe-449e-9378-e5592630aa50", "embedding": null, "metadata": {"Header_1": " Observation:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f03cc287-f8d0-4bea-9838-123d13141c98", "node_type": "1", "metadata": {"Header_1": " Results", "Header_2": " Feedback comparison between Prometheus and GPT-4 for Faithfulness and", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "72975a52ee8bf4065a36bf6e8ca0bc72de39b4e014343b68653a44f4389533f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b4d8f57a-c91e-4c8e-8ec6-95c8a5a3b8f4", "node_type": "1", "metadata": {"Header_1": " Summary"}, "hash": "c0857a23387e00fc0cab10e916b7e465ca706a8a1d6d4715bea3c8759bf1dfa5", "class_name": "RelatedNodeInfo"}}, "text": "Observation:\n\n  1. Prometheus: If you compare the feedback and contexts, there is mention of a range of parameters in the context and response but the feedback says the model could not find such information. \n  2. GPT-4: Evaluates it correctly, unlike the Prometheus model.", "mimetype": "text/plain", "start_char_idx": 28011, "end_char_idx": 28284, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4d8f57a-c91e-4c8e-8ec6-95c8a5a3b8f4": {"__data__": {"id_": "b4d8f57a-c91e-4c8e-8ec6-95c8a5a3b8f4", "embedding": null, "metadata": {"Header_1": " Summary", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aa1db30a-d5fe-449e-9378-e5592630aa50", "node_type": "1", "metadata": {"Header_1": " Observation:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "f01273d2fb4cf0877b934c98f56c547d4f2642203fd2660c2306d4da74c0281b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8fc60770-165a-45a5-b938-baa06d812dd1", "node_type": "1", "metadata": {"Header_1": " **Note:**"}, "hash": "1dfa44875009545c4ada7bb2ed1b67c754778944f0575c374c5d3ec89fd328ab", "class_name": "RelatedNodeInfo"}}, "text": "Summary\n\n  1. The cost for evaluation (approx.): ` $1.5 ` for Prometheus Model and ` $15 ` for GPT4. \n  2. The Prometheus model, though offering more detailed feedback than GPT-4, occasionally provides incorrect feedback, necessitating cautious application. \n  3. If a generated answer lacks certain facts present in the reference answer, the Prometheus model applies stricter penalties to scores than GPT-4. \n  4. The faithfulness and relevancy feedback of Prometheus shows more hallucinations/ wrong interpretations in the feedback compared to GPT-4.", "mimetype": "text/plain", "start_char_idx": 28290, "end_char_idx": 28842, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8fc60770-165a-45a5-b938-baa06d812dd1": {"__data__": {"id_": "8fc60770-165a-45a5-b938-baa06d812dd1", "embedding": null, "metadata": {"Header_1": " **Note:**", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b4d8f57a-c91e-4c8e-8ec6-95c8a5a3b8f4", "node_type": "1", "metadata": {"Header_1": " Summary", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "134b8ec10f52b07e52246e34a05417eabd4d0cd1b5bfce7e30c964173c06b7ef", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "22e677b5-079f-4e41-9a3c-6d8eb9993dd6", "node_type": "1", "metadata": {"Header_1": " References:"}, "hash": "d7cfb8ff466f24b02a8eb828c61219e8c57c84d4d27bffad071c473259dff788", "class_name": "RelatedNodeInfo"}}, "text": "**Note:**\n\n  * You can check detailed analysis with code on [ Google Colab Notebook ](https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/evaluation/prometheus_evaluation.ipynb) . \n  * The endpoint on HF is served on AWS Nvidia A100G \u00b7 1x GPU \u00b7 80 GB which costs $6.5/h. (We extend our gratitude to the Hugging Face team for their assistance whenever we encounter issues.) \n  * We used the [ Prometheus model ](https://huggingface.co/kaist-ai/prometheus-13b-v1.0) for the analysis here. We also made a similar analysis with the [ GPTQ Quantized version ](https://huggingface.co/TheBloke/prometheus-13B-v1.0-GPTQ) of the [ Prometheus model ](https://huggingface.co/kaist-ai/prometheus-13b-v1.0) and observed a bit more hallucinations in feedback compared to the original unquantized model. Thanks to the authors of the paper for open-sourcing the model and [ Tom Jobbins ](https://twitter.com/TheBlokeAI) for the quantized version of the model.", "mimetype": "text/plain", "start_char_idx": 28848, "end_char_idx": 29826, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "22e677b5-079f-4e41-9a3c-6d8eb9993dd6": {"__data__": {"id_": "22e677b5-079f-4e41-9a3c-6d8eb9993dd6", "embedding": null, "metadata": {"Header_1": " References:", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f", "node_type": "4", "metadata": {"filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "40ab5d3b57a9f84bc51dc27ed0ea7afb6cdedd3504ce981ef4b8756ec50cb055", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8fc60770-165a-45a5-b938-baa06d812dd1", "node_type": "1", "metadata": {"Header_1": " **Note:**", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}, "hash": "3f4c464c7064bdc27fa1a5278fc7f059c9b98dbb1d8e31ef5073e35794c44fb4", "class_name": "RelatedNodeInfo"}}, "text": "References:\n\n  * [ Prometheus paper ](https://arxiv.org/abs/2310.08491) . \n  * [ Prometheus model on HuggingFace. ](https://huggingface.co/kaist-ai/prometheus-13b-v1.0)", "mimetype": "text/plain", "start_char_idx": 29832, "end_char_idx": 30000, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"b84e38e4-c4ab-4151-a263-91d2d5d2ef4b": {"doc_hash": "922bb1e59b0d44c47acf7d7d1dd0dae58fa6ca298ab1aba9c3b0ab619599d60a", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "eed95434-8284-4c65-bff8-7774db477889": {"doc_hash": "b4f89a61f20659c891a50e2ca2d4c8c8c540be51109daa2440bccc540d4d513c", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "8769012e-5814-4fba-b0a7-531d15ce2cfe": {"doc_hash": "827add6eae2409c1b6ded7627540fe75ef65bd3ab73a5b2bb989872a0e941b5b", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "a49c56df-30ba-4a95-bc6b-ab13bee29260": {"doc_hash": "39c75c91b09a0f2f138d5616725bd8656a348b3d5d6f3aee62f6f4b11a1d4f51", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "2c731b1e-271e-4c6c-9f77-0faad01d45bc": {"doc_hash": "b9ad562479f8d6423a50d0b10bf3f5a814e52a482a6b83cf0ed4f618df1e7395", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "4ac19fff-183b-4293-99f0-03b20f110cc5": {"doc_hash": "1d37cef87d4319e96267930009a9897fe173dda1ee17996eb14eb62e09066302", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "3cb1da35-5643-4926-ba81-834b16f27077": {"doc_hash": "3d81a0ee8647dba2ed848ca24bb630d121c0b43552bc655689d002abac06c46b", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "e4b6c7cb-1d8c-4ec7-8a83-c33dab06f6f1": {"doc_hash": "0dd0d499d46d5a25433b2b0d778429e8a52fad6052aaca00235d596b7b1f46fd", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "b7372e50-7a82-437f-a2ec-c18fc4473551": {"doc_hash": "fa88e5fd43c043e266e327bfce301ee0dd341e88c3e2343d5e8473d4b961b39b", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "a35ef7b3-089a-473d-b287-637a69f754f5": {"doc_hash": "755b7f01df06131196d45f975e0a10fd8dff43db68951159b074ab763b6529e9", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "8d92bafc-a7c2-4276-ac00-fcaa5308df64": {"doc_hash": "3b2941def5f36062eeb354b11d6b4b9f3a4f294d60944ed1cb20860d51bdcf84", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "b41844ed-3b16-4fc1-bc20-c5a994bb7a1a": {"doc_hash": "7f88cc167fe40fdbb8371cd84f271856199f8a5355aea6ce93ae4e0459d92a23", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "ca6454a4-f970-40a0-80a5-39c43b31f6a6": {"doc_hash": "71843df04d8ec44c9179a30d9356ddbdd2db2ed8e6af016e3e172e752c045849", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "7ee29d0a-818b-4958-b521-9b13a8b9110b": {"doc_hash": "879547fdc39c8548bd8d5d731fcbcb0ef6dc418200f3f3a18d3511f342b7f870", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "9461b219-4fa0-4915-a1db-d0e5844de403": {"doc_hash": "3e7abb732edbde7d68113320227ee76317b233c9668bda5087627a1cfdd9e4f1", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "83dad89d-f9c8-4ab6-b894-9a0383c86706": {"doc_hash": "d11e03fbe76829f85850394afacd31f9c80c417411ba52d080d187dc986b4961", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "cc87d010-a35f-4a7b-9390-d556a2dc93b7": {"doc_hash": "67bcefda6b05ab816953fb3847801ca47c1e031c6ee587a7fdf810745070ee02", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "a0cdc8a2-4875-48cb-a968-60fc9bc3bf1b": {"doc_hash": "800ab20d311a7ff7e1bb9f555e8d934e294afa0d4a05ecc4115461cb2c2c7aee", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "f55fd630-559b-473e-9f28-34ac16d2eb1c": {"doc_hash": "9fab60143c76be8dc6c455dd991b7c82b3e6ea558b621415d48aab1e78b4bc31", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "6cd8ce7c-94bf-4c40-805a-17aed60e0022": {"doc_hash": "cc9edf7faa7e464c3c30ae9b3b21884a909d7e6b31150c9c53ed0a9bfa2dd61e", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "09b905d1-2777-4afc-b394-fb7c712b1afa": {"doc_hash": "ee25f33ad3e6b8a536b2d40e75060b0162ad6a6c020bb41cb1daf4c6427f19b3", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "f03cc287-f8d0-4bea-9838-123d13141c98": {"doc_hash": "72975a52ee8bf4065a36bf6e8ca0bc72de39b4e014343b68653a44f4389533f6", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "aa1db30a-d5fe-449e-9378-e5592630aa50": {"doc_hash": "f01273d2fb4cf0877b934c98f56c547d4f2642203fd2660c2306d4da74c0281b", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "b4d8f57a-c91e-4c8e-8ec6-95c8a5a3b8f4": {"doc_hash": "134b8ec10f52b07e52246e34a05417eabd4d0cd1b5bfce7e30c964173c06b7ef", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "8fc60770-165a-45a5-b938-baa06d812dd1": {"doc_hash": "3f4c464c7064bdc27fa1a5278fc7f059c9b98dbb1d8e31ef5073e35794c44fb4", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}, "22e677b5-079f-4e41-9a3c-6d8eb9993dd6": {"doc_hash": "8717e71067cfbc610136deb143d4840fee95526dcd21626e1c735f1fb8bed91c", "ref_doc_id": "076ef03e-e5ff-470c-a85d-ed801c460a4f"}}, "docstore/ref_doc_info": {"076ef03e-e5ff-470c-a85d-ed801c460a4f": {"node_ids": ["b84e38e4-c4ab-4151-a263-91d2d5d2ef4b", "eed95434-8284-4c65-bff8-7774db477889", "8769012e-5814-4fba-b0a7-531d15ce2cfe", "a49c56df-30ba-4a95-bc6b-ab13bee29260", "2c731b1e-271e-4c6c-9f77-0faad01d45bc", "4ac19fff-183b-4293-99f0-03b20f110cc5", "3cb1da35-5643-4926-ba81-834b16f27077", "e4b6c7cb-1d8c-4ec7-8a83-c33dab06f6f1", "b7372e50-7a82-437f-a2ec-c18fc4473551", "a35ef7b3-089a-473d-b287-637a69f754f5", "8d92bafc-a7c2-4276-ac00-fcaa5308df64", "b41844ed-3b16-4fc1-bc20-c5a994bb7a1a", "ca6454a4-f970-40a0-80a5-39c43b31f6a6", "7ee29d0a-818b-4958-b521-9b13a8b9110b", "9461b219-4fa0-4915-a1db-d0e5844de403", "83dad89d-f9c8-4ab6-b894-9a0383c86706", "cc87d010-a35f-4a7b-9390-d556a2dc93b7", "a0cdc8a2-4875-48cb-a968-60fc9bc3bf1b", "f55fd630-559b-473e-9f28-34ac16d2eb1c", "6cd8ce7c-94bf-4c40-805a-17aed60e0022", "09b905d1-2777-4afc-b394-fb7c712b1afa", "f03cc287-f8d0-4bea-9838-123d13141c98", "aa1db30a-d5fe-449e-9378-e5592630aa50", "b4d8f57a-c91e-4c8e-8ec6-95c8a5a3b8f4", "8fc60770-165a-45a5-b938-baa06d812dd1", "22e677b5-079f-4e41-9a3c-6d8eb9993dd6"], "metadata": {"Header_1": " Introduction", "filename": "llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277.md", "extension": ".md", "title": "LlamaIndex: RAG Evaluation Showdown with GPT-4 vs. Open-Source Prometheus Model", "date": "Dec 15, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-rag-evaluation-showdown-with-gpt-4-vs-open-source-prometheus-model-14cdca608277"}}}}