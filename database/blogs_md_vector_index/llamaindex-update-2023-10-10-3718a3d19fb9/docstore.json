{"docstore/data": {"bfefcf24-b56e-4cf3-9fb2-75f5280a9d22": {"__data__": {"id_": "bfefcf24-b56e-4cf3-9fb2-75f5280a9d22", "embedding": null, "metadata": {"filename": "llamaindex-update-2023-10-10-3718a3d19fb9.md", "extension": ".md", "title": "LlamaIndex update 2023\u201310\u201310", "date": "Oct 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-update-2023-10-10-3718a3d19fb9"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dff93b2c-eb0b-4f68-bc11-3abd4593bce7", "node_type": "4", "metadata": {"filename": "llamaindex-update-2023-10-10-3718a3d19fb9.md", "extension": ".md", "title": "LlamaIndex update 2023\u201310\u201310", "date": "Oct 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-update-2023-10-10-3718a3d19fb9"}, "hash": "89a0de0998b55c732e8bb4755211bcd7011c79db3fbf5ce275a89c1f423169c9", "class_name": "RelatedNodeInfo"}}, "text": "Here\u2019s our weekly look at developments across the LLM space and RAG (Retrieval\nAugmented Generation) in particular, as well as the latest news and features\nfrom your favorite open source library. If you\u2019ve got a project (or a blog\npost, or a video) that you think people should hear about, we\u2019re happy to\nfeature it in here! Drop us a line at [ news@llamaindex.ai\n](mailto:news@llamaindex.ai) .\n\nThis update is now available in handy email form! Just head to our [ home page\n](https://llamaindex.ai) and enter your email to sign up.\n\n**First, the highlights:**\n\n  1. **Full observability with Arize AI Phoenix** : we launched a one-code-line integration with Arize AI for comprehensive tracing and observability in all RAG/agent pipelines. Enjoy local data storage, track LLM input/output prompts, monitor token usage, timing, retrieval visualizations, and agent loops. Additionally, export traces for evaluations and data analysis. All while ensuring your data stays local. [ Notebook ](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/llama_index_tracing_tutorial.ipynb) , [ Tweet ](https://twitter.com/llama_index/status/1708866998149816540?s=20) . \n  2. **RetrieverEvaluator** : new in the library, \u201cRetrieverEvaluator\u201d allows enhanced retrieval evaluations, complementing LLM generation tests. The module supports benchmarking, standard ranking metrics, and synthetic dataset creation for comprehensive retrieval assessments. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/evaluation/retrieval/retriever_eval.html) , [ Tweet ](https://twitter.com/llama_index/status/1704884477552660612?s=20) . \n  3. **HuggingFace Embeddings** : we added native support for three more Hugging Face embedding models, including the base embeddings wrapper, instructor embeddings, and optimum embeddings in ONNX format. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/embeddings/huggingface.html) , [ Tweet ](https://x.com/llama_index/status/1706096762933653962?s=20) . \n  4. **Multi-Document Agents** : we\u2019ve introduced v0 experimental support for multi-document agents for advanced QA, beyond typical top-k RAG. It supports diverse queries from single to multiple docs. This foundational version sets the stage for future enhancements like parallel query planning and reduced latency. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/agent/multi_document_agents.html) , [ Tweet ](https://twitter.com/jerryjliu0/status/1708523212366393403?s=20) . \n\n**Congratulations to our Streamlit Hackathon Winners!**\n\nWe love seeing people build amazing things with LlamaIndex!\n\n  1. NewsGPT by Kang-Chi Ho: [ https://buff.ly/46jkutx ](https://buff.ly/46jkutx)\n  2. FinSight by Vishwas Gowda: [ https://buff.ly/3PzOnyC ](https://buff.ly/3PzOnyC)\n\n**Feature Releases** **and Enhancements:**\n\n  1. **Multi-Document Agents** : we introduced multi-document agents (V0) for advanced QA, beyond typical top-k RAG. They support diverse queries from single to multiple docs. This foundational version sets the stage for future enhancements like parallel query planning and reduced latency. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/agent/multi_document_agents.html) , [ Tweet ](https://twitter.com/jerryjliu0/status/1708523212366393403?s=20) . \n  2. **Ensemble Retriever:** we\u2019re addressing the RAG challenge of determining chunk size by experimenting with diverse document chunking and ensembling for retrieval. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/retrievers/ensemble_retrieval.html) , [ Tweet ](https://twitter.com/jerryjliu0/status/1707541270934212737?s=20) . \n  3. **HuggingFace Embeddings** : we added native support for three more Hugging Face embedding models, including the base embeddings wrapper, instructor embeddings, and optimum embeddings in ONNX format. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/embeddings/huggingface.html) , [ Tweet ](https://x.com/llama_index/status/1706096762933653962?s=20) . \n  4. **OpenAI Function Calling fine-tuning:** we\u2019re using OpenAI\u2019s latest function calling fine-tuning which enhanced structured data extraction, optimizing gpt-3.5-turbo for improved extraction in RAG. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/finetuning/openai_fine_tuning_functions.html) , [ Tweet ](https://twitter.com/llama_index/status/1709986951661818185?s=20) . \n  5. **Metadata Extraction** : we\u2019re making metadata extraction efficient by extracting a complete Pydantic object from a document with just one LLM call. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/PydanticExtractor.html) , [ Tweet ](https://twitter.com/llama_index/status/1705302359038202101?s=20) . \n  6. **Structured RAG Outputs** : we now efficiently structure RAG pipeline outputs with native Pydantic outputs from all queries without the need for an additional LLM parsing call. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/query_engine/pydantic_query_engine.html) , [ Tweet ](https://twitter.com/llama_index/status/1709229624709025972?s=20) . \n  7. **Streamlined** [ **secinsights.ai** ](http://secinsights.ai) **deployment** : Our open-sourced [ secinsights.ai ](https://secinsights.ai) offers a RAG app template, now enhanced with GitHub Codespaces and Docker for swift cloud deployment without setup hassles. [ Tweet ](https://twitter.com/llama_index/status/1707773681605419296?s=20) . \n  8. **LongContextReorder:** We introduced LongContextReorder****,**** Zeneto\u2019s approach to reposition vital context in RAG systems, addressing the challenge of over-retrieving which can obscure essential details. [ Docs ](https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/node_postprocessors/modules.html#longcontextreorder) , [ Tweet ](https://twitter.com/llama_index/status/1705009024050270456?s=20) . \n  9. **RA-DIT:** We drew inspiration from the RA-DIT paper, which introduced LLM fine-tuning for retrieval-augmented input prompts to improve RAG systems. This method fosters enhanced utilization of context and more effective answer synthesis, even in the presence of suboptimal context. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/finetuning/knowledge/finetune_retrieval_aug.html) , [ Tweet ](https://twitter.com/jerryjliu0/status/1709646787076935818?s=20) . \n  10. **Blockchain:** LlamaIndex data agents can be now used to analyze any blockchain subgraph using natural language queries. [ Tweet ](https://twitter.com/llama_index/status/1707417880420294741?s=20) . \n\n**RAG Evaluation Enhancements:**\n\n  1. **RetrieverEvaluator** : We introduced \u201cRetrieverEvaluator\u201d for enhanced retrieval evaluations, complementing LLM generation tests. The module supports benchmarking, standard ranking metrics, and synthetic dataset creation for comprehensive retrieval assessments. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/evaluation/retrieval/retriever_eval.html) , [ Tweet ](https://twitter.com/llama_index/status/1704884477552660612?s=20) . \n  2. **SemanticSimilarityEvaluator** : We introduced a new semantic similarity evaluator \u2014 SemanticSimilarityEvaluator for LLM/RAG outputs, comparing embedding similarity between reference and generated answers. [ Docs ](https://gpt-index.readthedocs.io/en/latest/examples/evaluation/semantic_similarity_eval.html) , [ Tweet ](https://twitter.com/llama_index/status/1705614101601509630?s=20) . \n\n**Tutorials:**\n\n  1. [ Guide ](https://gpt-index.readthedocs.io/en/latest/examples/low_level/oss_ingestion_retrieval.html) on building RAG from scratch with open-source modules. \n  2. [ Dstack ](https://twitter.com/dstackai) [ tutorial ](https://dstack.ai/examples/llama-index-weaviate/) on implementing RAG with OSS LLMs using LlamaIndex and Weaviate. \n  3. [ Wenqi Glantz ](https://twitter.com/wenqi_glantz) [ turorial ](https://betterprogramming.pub/exploring-react-agent-for-better-prompting-in-rag-pipeline-b231aae0ca7c) on Exploring ReAct Agent for Better Prompting in RAG Pipeline. \n  4. [ Javier Torres ](https://twitter.com/Javtorr_) [ tutorial ](https://gpt-index.readthedocs.io/en/stable/end_to_end_tutorials/chatbots/building_a_chatbot.html) on building a multi-document chatbot. \n  5. [ Erika Cardenas ](https://twitter.com/ecardenas300) [ tutorial ](https://www.youtube.com/watch?v=Su-ROQMaiaw) on RAG techniques in LlamaIndex covering SQL Router Query Engine, Sub Question Query Engine, Recursive Retriever Query Engine, Self-Correcting Query Engine. \n  6. [ Wenqi Glantz ](https://twitter.com/wenqi_glantz) [ tutorial ](https://betterprogramming.pub/7-query-strategies-for-navigating-knowledge-graphs-with-llamaindex-ed551863d416) on 7 Query Strategies for Navigating Knowledge Graphs With LlamaIndex. \n  7. [ Ravi Theja ](https://twitter.com/ravithejads) [ tutorial ](/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5) on Evaluating the Ideal Chunk Size for RAG using LlamaIndex. \n\n**Integrations & Collaborations: **\n\n  1. **Arize AI Phoenix** : We launched a one-code-line integration with Arize AI for comprehensive tracing and observability in all RAG/agent pipelines. Enjoy local data storage, track LLM input/output prompts, monitor token usage, timing, retrieval visualizations, and agent loops. Additionally, export traces for evaluations and data analysis. All while ensuring your data stays local. [ Notebook ](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/llama_index_tracing_tutorial.ipynb) , [ Tweet ](https://twitter.com/llama_index/status/1708866998149816540?s=20) . \n  2. **Neo4j** : We introduced an API spec for LLM-agent interaction with Neo4j, offering beyond just \u201ctext-to-cypher\u201d with full agent reasoning. [ Docs ](https://llamahub.ai/l/tools-neo4j_db) , [ Tweet ](https://twitter.com/llama_index/status/1706049423644774910?s=20) . \n  3. **TimescaleDB** : We integrated with TimescaleDB for enhanced time-based retrieval in RAG systems, offering time filters and cost-effective storage solutions. [ Blogpost ](/timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0) , [ Tweet ](https://twitter.com/llama_index/status/1707057039950991798?s=20) . \n  4. **BraintrustData** : We integrated with BraintrustData, enabling seamless RAG pipeline construction, evaluations, and easy public URL sharing for results. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/retrievers/recurisve_retriever_nodes_braintrust.ipynb) , [ Tweet ](https://twitter.com/llama_index/status/1707485040018632776?s=20) . \n  5. **LocalAI** : We integrated LocalAI_API LLM support for on-prem runs or as an alternative to OpenAI LLM. [ Tweet ](https://x.com/llama_index/status/1708227476684734555?s=20) . \n  6. **HoneyHiveAI** : We integrated with HoneyHiveAI for enhanced multi-step RAG/agent pipeline monitoring. Log traces, gather user feedback, and utilize it for precise fine-tuning and evaluations. [ Docs ](https://docs.honeyhive.ai/quickstart/llamaindex) , [ Tweet ](https://x.com/llama_index/status/1709311769947357425?s=20) . \n  7. **UnstructuredIO** : We integrated with UnstructuredIO to tackle the RAG challenge of querying embedded tables in 10-K filings. Now, seamlessly query any tabular data or text within a 10-K document. [ Notebook ](https://github.com/run-llama/llama_index/blob/main/docs/examples/query_engine/sec_tables/tesla_10q_table.ipynb) , [ Tweet ](https://twitter.com/jerryjliu0/status/1709352476456132702?s=20) . \n  8. **Clarifai** : We integrated with Clarifai, offering access to 40+ LLMs and various embedding models. [ Tweet ](https://twitter.com/llama_index/status/1710065802672476342?s=20) . \n\n**Webinars:**\n\n  1. [ Webinar ](https://www.singlestore.com/resources/webinar-how-to-build-a-genai-app-with-llama-index/?utm_source=kunal-kushwaha&utm_medium=influencer&utm_campaign=How-to-Build-a-GenAI-App-with-LlamaIndex&campaignid=7014X0000029YtwQAE) by SingleStoreDB on How to Build a GenAI App with LlamaIndex. \n  2. [ Webinar ](https://www.youtube.com/watch?v=C5NhoMBkaQU) on projects built during the SuperAGI Autonomous Agents Hackathon featuring evo.ninja, RicAI, Atlas and MunichAI. \n\n**Events:**\n\n  1. Jerry Liu and Simon [ conducted ](https://github.com/anyscale/ray-summit-2023-training/tree/main/Ray-LlamaIndex/notebooks) a workshop on RAG + Evaluation at RaySummit. \n  2. [ Yi Ding ](https://twitter.com/yi_ding) spoke on \u2018LLM Quirks Mode\u2019 at MLOps community event. \n  3. Jerry Liu spoke on Evals/ Benchmarking [ and Advanced RAG techniques ](https://docs.google.com/presentation/d/1v7T6ejrSo87ndGeGC7tt6zeq-cftu03WWw7WL8Jskug/edit?usp=sharing) at AIConf 2023. \n  4. [ Ravi Theja ](https://twitter.com/ravithejads) conducted a workshop on Mastering RAG with LlamaIndex at PyCon India, 2023. \n  5. [ Ravi Theja ](https://twitter.com/ravithejads) presented a [ poster ](https://x.com/ravithejads/status/1709431323989856348?s=20) on Automatic Knowledge Transfer(KT) Video generation on code bases using LlamaIndex at PyCon India, 2023.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 13087, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"bfefcf24-b56e-4cf3-9fb2-75f5280a9d22": {"doc_hash": "65bee46d62d1e252ed52d5b86cd60529b2e8f0ee99fc01c7023e7de98fd02bb0", "ref_doc_id": "dff93b2c-eb0b-4f68-bc11-3abd4593bce7"}}, "docstore/ref_doc_info": {"dff93b2c-eb0b-4f68-bc11-3abd4593bce7": {"node_ids": ["bfefcf24-b56e-4cf3-9fb2-75f5280a9d22"], "metadata": {"filename": "llamaindex-update-2023-10-10-3718a3d19fb9.md", "extension": ".md", "title": "LlamaIndex update 2023\u201310\u201310", "date": "Oct 10, 2023", "url": "https://www.llamaindex.ai/blog/llamaindex-update-2023-10-10-3718a3d19fb9"}}}}