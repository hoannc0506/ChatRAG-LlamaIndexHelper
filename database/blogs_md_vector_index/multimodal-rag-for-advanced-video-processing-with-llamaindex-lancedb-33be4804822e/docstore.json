{"docstore/data": {"ffb4b8bb-b397-4ae4-a67e-0a16a6d6632f": {"__data__": {"id_": "ffb4b8bb-b397-4ae4-a67e-0a16a6d6632f", "embedding": null, "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1426ebeb-c615-4012-8949-d4461a702bc0", "node_type": "1", "metadata": {"Header_1": " Core Concept of RAG"}, "hash": "c1844d87971b3a033ced4fb4962bf0f5be886ba7d4ba84f468b00b80ac333798", "class_name": "RelatedNodeInfo"}}, "text": "The widespread consumption of videos on platforms like YouTube, Instagram, and\nothers highlights the importance of efficiently processing and analyzing video\ncontent. This capability unlocks vast opportunities across various sectors,\nincluding media and entertainment, security, and education. However, the main\nchallenge is effectively extracting meaningful information from videos, which\nare inherently complex and multimodal data streams.\n\nThis blog post introduces a solution that leverages the LlamaIndex [ Python\nAPI ](https://docs.llamaindex.ai/en/latest/index.html#) for using the advanced\ncapabilities of OpenAI\u2019s [ GPT4V\n](https://help.openai.com/en/articles/8555496-gpt-4v-api) , combined with the\nefficient data management by [ LanceDB ](https://lancedb.github.io/lancedb/)\nacross all data formats, to process videos.\n\n\u2026But what does \u2018RAG\u2019 even mean?\n\nRetrieval-augmented generation (RAG) is a technique that merges information\nretrieval with generative AI to produce systems capable of generating precise\nand contextually relevant responses by tapping into large data repositories.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1094, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1426ebeb-c615-4012-8949-d4461a702bc0": {"__data__": {"id_": "1426ebeb-c615-4012-8949-d4461a702bc0", "embedding": null, "metadata": {"Header_1": " Core Concept of RAG", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ffb4b8bb-b397-4ae4-a67e-0a16a6d6632f", "node_type": "1", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "fb86bbf21c94bf14cd30e007df26e4fbf7421ff6705529e87f946e2393e44bd4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0c1d2b8a-a1d5-43a0-bfce-8fd76630a698", "node_type": "1", "metadata": {"Header_1": " RAG Architecture"}, "hash": "4c0d369d914c0682f051a7ed2dddf4f633ab35eff83430304db8ba0213925caf", "class_name": "RelatedNodeInfo"}}, "text": "Core Concept of RAG\n\nRAG operates in two stages:\n\n  1. **Retrieval** : Utilizes semantic search to find documents related to a query, leveraging the context and meaning beyond mere keywords. \n  2. **Generation** : Integrates retrieved information to produce coherent responses, allowing the AI to \u201clearn\u201d from a wide range of content dynamically.", "mimetype": "text/plain", "start_char_idx": 1099, "end_char_idx": 1445, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0c1d2b8a-a1d5-43a0-bfce-8fd76630a698": {"__data__": {"id_": "0c1d2b8a-a1d5-43a0-bfce-8fd76630a698", "embedding": null, "metadata": {"Header_1": " RAG Architecture", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1426ebeb-c615-4012-8949-d4461a702bc0", "node_type": "1", "metadata": {"Header_1": " Core Concept of RAG", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "5ed8a3c4729978fd6ff6a77e1674f8ca58e6cf119e7dee7231a147a9acf23d9b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8428a665-a795-4af0-a25c-d8b5de57299f", "node_type": "1", "metadata": {"Header_1": " Extending to Multimodality"}, "hash": "663ac14e90d2831f09e5fa6549cc68f7147c0353a99cefaa0502cc1e660f0d33", "class_name": "RelatedNodeInfo"}}, "text": "RAG Architecture\n\nThe architecture typically involves a dense vector search engine for retrieval\nand a transformer model for generation. The process:\n\n  * Performs a semantic search to fetch relevant documents. \n  * Processes these documents with the query to create a comprehensive context. \n  * The generative model then crafts a detailed response based on this enriched context.", "mimetype": "text/plain", "start_char_idx": 1451, "end_char_idx": 1832, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8428a665-a795-4af0-a25c-d8b5de57299f": {"__data__": {"id_": "8428a665-a795-4af0-a25c-d8b5de57299f", "embedding": null, "metadata": {"Header_1": " Extending to Multimodality", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0c1d2b8a-a1d5-43a0-bfce-8fd76630a698", "node_type": "1", "metadata": {"Header_1": " RAG Architecture", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "0bb5d9bcf3ef17819544626e04ebb6480f1793741046ad39dd4d9701a3664c8d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "86a0d7d6-372e-449f-8322-2c373dfa69d7", "node_type": "1", "metadata": {"Header_1": " 1\\. Video Downloading"}, "hash": "d0f1f9ee557b667d7da92876b2af737f8818c33eb13ac126a2b2d766a8729bde", "class_name": "RelatedNodeInfo"}}, "text": "Extending to Multimodality\n\nMultimodal RAG integrates various data types (text, images, audio, video) in\nboth retrieval and generation phases, enabling richer information sourcing.\nFor example, responding to queries about \u201cclimate change impacts on polar\nbears\u201d might involve retrieving scientific texts, images, and videos to\nproduce an enriched, multi-format response.\n\nLet\u2019s return to our use case and dive into how it\u2019s all done. Moving forward,\nyou can access the full code on [ Google Colab ](https://github.com/run-\nllama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_video_RAG.ipynb)\n.\n\nThe solution is divided into the following sections. Click on the topic to\nskip to a specific part:\n\n  1. Video Downloading \n  2. Video Processing \n  3. Building the Multi-Modal Index and Vector Store \n  4. Retrieving Relevant Images and Context \n  5. Reasoning and Response Generation", "mimetype": "text/plain", "start_char_idx": 1838, "end_char_idx": 2732, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "86a0d7d6-372e-449f-8322-2c373dfa69d7": {"__data__": {"id_": "86a0d7d6-372e-449f-8322-2c373dfa69d7", "embedding": null, "metadata": {"Header_1": " 1\\. Video Downloading", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8428a665-a795-4af0-a25c-d8b5de57299f", "node_type": "1", "metadata": {"Header_1": " Extending to Multimodality", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "05b517c31447aa2cda56c4ad1cb62f16c3ecd92f83447d8ccc5428788a6ab2f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2fddbf19-3ecd-4347-877f-9146a97dd111", "node_type": "1", "metadata": {"Header_1": " _2\\. Video Processing_"}, "hash": "d87476cb5bd3bd513f3b16791add91c68f20622c91bd1464a90952a4e9dcd10d", "class_name": "RelatedNodeInfo"}}, "text": "1\\. Video Downloading\n\nTo begin, we need to locally download multimodal content from a publicly\navailable source, I used pytube to download a YouTube video by 3Blue1Brown on\nthe Gaussian function.\n\n    \n    \n    # SET CONFIG\n    video_url = \"https://www.youtube.com/watch?v=d_qvLDhkg00\"\n    output_video_path = \"./video_data/\"\n    output_folder = \"./mixed_data/\"\n    output_audio_path = \"./mixed_data/output_audio.wav\"\n    \n    filepath = output_video_path + \"input_vid.mp4\"\n    Path(output_folder).mkdir(parents=True, exist_ok=True)\n    \n    \n    def download_video(url, output_path):\n        \"\"\"\n        Download a video from a given url and save it to the output path.\n    \n        Parameters:\n        url (str): The url of the video to download.\n        output_path (str): The path to save the video to.\n    \n        Returns:\n        dict: A dictionary containing the metadata of the video.\n        \"\"\"\n      from pytube import YouTube\n    \n        yt = YouTube(url)\n        metadata = {\"Author\": yt.author, \"Title\": yt.title, \"Views\": yt.views}\n        yt.streams.get_highest_resolution().download(\n            output_path=output_path, filename=\"input_vid.mp4\"\n        )\n        return metadata\n    \n\nRun ` **metadata_vid = download_video(video_url, output_video_path)** ` to\ninvoke the function and store the video locally.", "mimetype": "text/plain", "start_char_idx": 2738, "end_char_idx": 4067, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2fddbf19-3ecd-4347-877f-9146a97dd111": {"__data__": {"id_": "2fddbf19-3ecd-4347-877f-9146a97dd111", "embedding": null, "metadata": {"Header_1": " _2\\. Video Processing_", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "86a0d7d6-372e-449f-8322-2c373dfa69d7", "node_type": "1", "metadata": {"Header_1": " 1\\. Video Downloading", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "0591e272cd0380a22af5af469d459303595f775c7140874a02bb213aa41e40e1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "25eb1674-e8e2-4173-af8d-10d1d61f01ff", "node_type": "1", "metadata": {"Header_1": " 3\\. Building the Multi-Modal Index and Vector Store"}, "hash": "fe017fe92b1a3a8fc85e8b90273f01bd0e35b1f8f507c26646cd16293c493ef5", "class_name": "RelatedNodeInfo"}}, "text": "_2\\. Video Processing_\n\nWe need to now extract multimodal content \u2014 Images, Text(via Audio). I\nextracted 1 frame every 5 seconds of the video (~160 frames) using ` moviepy `\n.\n\n    \n    \n    def video_to_images(video_path, output_folder):\n        \"\"\"\n        Convert a video to a sequence of images and save them to the output folder.\n    \n        Parameters:\n        video_path (str): The path to the video file.\n        output_folder (str): The path to the folder to save the images to.\n    \n        \"\"\"\n        clip = VideoFileClip(video_path)\n        clip.write_images_sequence(\n            os.path.join(output_folder, \"frame%04d.png\"), fps=0.2 #configure this for controlling frame rate.\n        )\n\nFollowing this, we extract the audio component:\n\n    \n    \n    def video_to_audio(video_path, output_audio_path):\n        \"\"\"\n        Convert a video to audio and save it to the output path.\n    \n        Parameters:\n        video_path (str): The path to the video file.\n        output_audio_path (str): The path to save the audio to.\n    \n        \"\"\"\n        clip = VideoFileClip(video_path)\n        audio = clip.audio\n        audio.write_audiofile(output_audio_path)\n\nNext, let\u2019s extract text from the audio using the SpeechRecognition library:\n\n    \n    \n    def audio_to_text(audio_path):\n        \"\"\"\n        Convert an audio file to text.\n    \n        Parameters:\n        audio_path (str): The path to the audio file.\n    \n        Returns:\n        test (str): The text recognized from the audio.\n    \n        \"\"\"\n        recognizer = sr.Recognizer()\n        audio = sr.AudioFile(audio_path)\n    \n        with audio as source:\n            # Record the audio data\n            audio_data = recognizer.record(source)\n    \n            try:\n                # Recognize the speech\n                text = recognizer.recognize_whisper(audio_data)\n            except sr.UnknownValueError:\n                print(\"Speech recognition could not understand the audio.\")\n            except sr.RequestError as e:\n                print(f\"Could not request results from service; {e}\")\n    \n        return text\n\nRun the below chunk to complete the extraction and storage process:\n\n    \n    \n    video_to_images(filepath, output_folder)\n    video_to_audio(filepath, output_audio_path)\n    text_data = audio_to_text(output_audio_path)\n    \n    with open(output_folder + \"output_text.txt\", \"w\") as file:\n        file.write(text_data)\n    print(\"Text data saved to file\")\n    file.close()\n    os.remove(output_audio_path)\n    print(\"Audio file removed\")", "mimetype": "text/plain", "start_char_idx": 4072, "end_char_idx": 6609, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "25eb1674-e8e2-4173-af8d-10d1d61f01ff": {"__data__": {"id_": "25eb1674-e8e2-4173-af8d-10d1d61f01ff", "embedding": null, "metadata": {"Header_1": " 3\\. Building the Multi-Modal Index and Vector Store", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2fddbf19-3ecd-4347-877f-9146a97dd111", "node_type": "1", "metadata": {"Header_1": " _2\\. Video Processing_", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "338b5edb61bb53b1c9666f5c872f8b2a7fb72682a816f02f0802a2413b07230b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aaf3a09b-d2af-4e21-9bcc-02e49361fa47", "node_type": "1", "metadata": {"Header_1": " 4\\. Retrieving Relevant Images and Context"}, "hash": "8bf113d188df105e066fe2566b78a26180d6d6eb3c8d7828b3128b1c594aca4e", "class_name": "RelatedNodeInfo"}}, "text": "3\\. Building the Multi-Modal Index and Vector Store\n\nAfter processing the video, we proceed to construct a multi-modal index and\nvector store. This entails generating embeddings for both textual and visual\ndata using OpenAI\u2019s CLIP model, subsequently storing and managing these\nembeddings in LanceDB VectorStore via the ` **LanceDBVectorStore** ` class.\n\n    \n    \n    from llama_index.indices.multi_modal.base import MultiModalVectorStoreIndex\n    from llama_index import SimpleDirectoryReader, StorageContext\n    \n    from llama_index import SimpleDirectoryReader, StorageContext\n    from llama_index.vector_stores import LanceDBVectorStore\n    \n    \n    from llama_index import (\n        SimpleDirectoryReader,\n    )\n    \n    text_store = LanceDBVectorStore(uri=\"lancedb\", table_name=\"text_collection\")\n    image_store = LanceDBVectorStore(uri=\"lancedb\", table_name=\"image_collection\")\n    storage_context = StorageContext.from_defaults(\n        vector_store=text_store, image_store=image_store\n    )\n    \n    # Create the MultiModal index\n    documents = SimpleDirectoryReader(output_folder).load_data()\n    \n    index = MultiModalVectorStoreIndex.from_documents(\n        documents,\n        storage_context=storage_context,\n    )", "mimetype": "text/plain", "start_char_idx": 6614, "end_char_idx": 7847, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aaf3a09b-d2af-4e21-9bcc-02e49361fa47": {"__data__": {"id_": "aaf3a09b-d2af-4e21-9bcc-02e49361fa47", "embedding": null, "metadata": {"Header_1": " 4\\. Retrieving Relevant Images and Context", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "25eb1674-e8e2-4173-af8d-10d1d61f01ff", "node_type": "1", "metadata": {"Header_1": " 3\\. Building the Multi-Modal Index and Vector Store", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "0ea4d8873a5bb234533ea54da78435117d05fa87f8a84a561aa34d43054fc770", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e81391dc-ac22-426f-8313-33554c707edd", "node_type": "1", "metadata": {"Header_1": " 5\\. Reasoning and Response Generation"}, "hash": "e51b30b4e03e1b464f28011e679529f489b744e5c4356a6c258cafef00e99141", "class_name": "RelatedNodeInfo"}}, "text": "4\\. Retrieving Relevant Images and Context\n\nWith the index in place, the system can then retrieve pertinent images and\ncontextual information based on input queries. This enhances the prompt with\nprecise and relevant multimodal data, anchoring the analysis in the video\u2019s\ncontent.\n\nLets set up the engine for retrieving, I am fetching top 5 most relevant `\nNodes ` from the vectordb based on the similarity score:\n\n    \n    \n    retriever_engine = index.as_retriever(\n        similarity_top_k=5, image_similarity_top_k=5\n    )\n\n> _A_ ` _Node_ ` _object is a \u201cchunk\u201d of any source Document, whether it\u2019s\n> text, an image, or other. It contains embeddings as well as meta information\n> of the chunk of data._\n>\n> By default, LanceDB uses ` l2 ` as metric type for evaluating similarity.\n> You can specify the metric type as ` cosine ` or ` dot ` if required.\n\nNext, we create a helper function for executing the retrieval logic:\n\n    \n    \n    from llama_index.response.notebook_utils import display_source_node\n    from llama_index.schema import ImageNode\n    \n    \n    def retrieve(retriever_engine, query_str):\n        retrieval_results = retriever_engine.retrieve(query_str)\n    \n        retrieved_image = []\n        retrieved_text = []\n        for res_node in retrieval_results:\n            if isinstance(res_node.node, ImageNode):\n                retrieved_image.append(res_node.node.metadata[\"file_path\"])\n            else:\n                display_source_node(res_node, source_length=200)\n                retrieved_text.append(res_node.text)\n    \n        return retrieved_image, retrieved_textdef retrieve(retriever_engine, query_str):\n        retrieval_results = retriever_engine.retrieve(query_str)\n\nLets input the query now and then move on to complete the process by\nretrieving and visualizing the data :\n\n    \n    \n    query_str = \"\"\"\n    Using examples from the video, explain all things covered regarding\n    the Gaussian function\n    \"\"\"\n    \n    \n    img, txt = retrieve(retriever_engine=retriever_engine, query_str=query_str)\n    image_documents = SimpleDirectoryReader(\n        input_dir=output_folder, input_files=img\n    ).load_data()\n    context_str = \"\".join(txt)\n    plot_images(img)\n\nYou should see something similar to the example below (note that the output\nwill vary depending on your query):\n\nDisplaying the similar Text objects (nodes)  Retrieved Images\n\nObserve that the ` node ` object displayed shows the ` Id ` of the data chunk\n, its similarity score and the source text of the chunk that was matched (for\nimages we get the filepath instead of text).", "mimetype": "text/plain", "start_char_idx": 7852, "end_char_idx": 10434, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e81391dc-ac22-426f-8313-33554c707edd": {"__data__": {"id_": "e81391dc-ac22-426f-8313-33554c707edd", "embedding": null, "metadata": {"Header_1": " 5\\. Reasoning and Response Generation", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aaf3a09b-d2af-4e21-9bcc-02e49361fa47", "node_type": "1", "metadata": {"Header_1": " 4\\. Retrieving Relevant Images and Context", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "748bc721b2dfc0560442ee2688dca0c217c238745530be7878f43dff5b45ae67", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fff743ae-0f99-4dae-9f9f-655d60683018", "node_type": "1", "metadata": {"Header_1": " Conclusion"}, "hash": "bdc1c0f10e513a565fd8ab1e802fb2fad35e1f3e0f326838c734307e5fc7d27a", "class_name": "RelatedNodeInfo"}}, "text": "5\\. Reasoning and Response Generation\n\nThe final step leverages GPT4V to reason about the correlations between the\ninput query and the augmented data. Below is the prompt template :\n\n    \n    \n    qa_tmpl_str = (\n        \"\"\"\n     Given the provided information, including relevant images and retrieved context from the video, \\\n     accurately and precisely answer the query without any additional prior knowledge.\\n\"\n        \"Please ensure honesty and responsibility, refraining from any racist or sexist remarks.\\n\"\n        \"---------------------\\n\"\n        \"Context: {context_str}\\n\"\n        \"Metadata for video: {metadata_str} \\n\"\n        \"---------------------\\n\"\n        \"Query: {query_str}\\n\"\n        \"Answer: \"\n    \"\"\"\n    )\n\nThe ` OpenAIMultiModal ` class from LlamaIndex enables us to incorporate image\ndata directly into our prompt object. Thus, in the final step, we enhance the\nquery and contextual elements within the template to produce the response as\nfollows:\n\n    \n    \n    from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n    \n    openai_mm_llm = OpenAIMultiModal(\n        model=\"gpt-4-vision-preview\", api_key=OPENAI_API_TOKEN, max_new_tokens=1500\n    )\n    \n    \n    response_1 = openai_mm_llm.complete(\n        prompt=qa_tmpl_str.format(\n            context_str=context_str, query_str=query_str, metadata_str=metadata_str\n        ),\n        image_documents=image_documents,\n    )\n    \n    pprint(response_1.text)\n\n> _The generated response captures the context pretty well and structures the\n> answer correctly :_\n>\n> The video \u201cA pretty reason why Gaussian + Gaussian = Gaussian\u201d by\n> 3Blue1Brown delves into the Gaussian function or normal distribution,\n> highlighting several critical aspects:\n>\n> **Central Limit Theorem:** It starts with the central limit theorem,\n> illustrating how the sum of multiple random variable copies tends toward a\n> normal distribution, improving with more variables.\n>\n> **Convolution of Random Variables:** Explains the addition of two random\n> variables as their distributions\u2019 convolution, focusing on visualizing this\n> through diagonal slices.\n>\n> **Gaussian Function:** Details the Gaussian function, emphasizing the\n> normalization factor for a valid probability distribution, and describes the\n> distribution\u2019s spread and center with standard deviation (\u03c3) and mean (\u03bc).\n>\n> **Convolution of Two Gaussians:** Discusses adding two normally distributed\n> variables, equivalent to convolving two Gaussian functions, and visualizes\n> this using the graph\u2019s rotational symmetry.\n>\n> **Rotational Symmetry and Slices:** Shows the rotational symmetry of e^(-x\u00b2)\n> * e^(-y\u00b2) around the origin, a unique Gaussian function property. It\n> explains computing the area under diagonal slices, equating to the\n> functions\u2019 convolution.\n>\n> **Resulting Distribution:** Demonstrates the convolution of two Gaussian\n> functions yielding another Gaussian, a notable exception in convolutions\n> usually resulting in a different function type.\n>\n> **Standard Deviation of the Result:** Concludes that convolving two normal\n> distributions with mean 0 and standard deviation (\u03c3) produces a normal\n> distribution with a standard deviation of sqrt(2) * \u03c3.\n>\n> **Implications for the Central Limit Theorem:** Highlights the convolution\n> of two Gaussians\u2019 role in the central limit theorem, positioning the\n> Gaussian distribution as a distribution space fixed point.\n>\n> The author uses visual examples and explanations throughout to clarify the\n> mathematical concepts related to the Gaussian function and its significance\n> in probability and statistics.", "mimetype": "text/plain", "start_char_idx": 10439, "end_char_idx": 14051, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fff743ae-0f99-4dae-9f9f-655d60683018": {"__data__": {"id_": "fff743ae-0f99-4dae-9f9f-655d60683018", "embedding": null, "metadata": {"Header_1": " Conclusion", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17", "node_type": "4", "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "1d0cb5e3c9e00cae96958510d2fb59f2efee2da8e89212d08150050c675aea97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e81391dc-ac22-426f-8313-33554c707edd", "node_type": "1", "metadata": {"Header_1": " 5\\. Reasoning and Response Generation", "filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}, "hash": "b14da141e858bfa99c5bf99286462df7574f72740e3cec5262206a7fe5ef3a52", "class_name": "RelatedNodeInfo"}}, "text": "Conclusion\n\nThe Multimodal RAG architecture offers a powerful and efficient solution for\nprocessing and analyzing video content. By leveraging the capabilities of\nOpenAI\u2019s GPT4V and LanceDB, this approach not only simplifies the video\nanalysis process but also enhances its accuracy and relevance. Whether for\ncontent creation, security surveillance, or educational purposes, the\npotential applications of this technology are vast and varied. As we continue\nto explore and refine these tools, the future of video analysis looks\npromising, with AI-driven solutions leading the way towards more insightful\nand actionable interpretations of video data.\n\nStay tuned for upcoming projects !", "mimetype": "text/plain", "start_char_idx": 14056, "end_char_idx": 14741, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"ffb4b8bb-b397-4ae4-a67e-0a16a6d6632f": {"doc_hash": "fb86bbf21c94bf14cd30e007df26e4fbf7421ff6705529e87f946e2393e44bd4", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "1426ebeb-c615-4012-8949-d4461a702bc0": {"doc_hash": "5ed8a3c4729978fd6ff6a77e1674f8ca58e6cf119e7dee7231a147a9acf23d9b", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "0c1d2b8a-a1d5-43a0-bfce-8fd76630a698": {"doc_hash": "0bb5d9bcf3ef17819544626e04ebb6480f1793741046ad39dd4d9701a3664c8d", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "8428a665-a795-4af0-a25c-d8b5de57299f": {"doc_hash": "05b517c31447aa2cda56c4ad1cb62f16c3ecd92f83447d8ccc5428788a6ab2f1", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "86a0d7d6-372e-449f-8322-2c373dfa69d7": {"doc_hash": "0591e272cd0380a22af5af469d459303595f775c7140874a02bb213aa41e40e1", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "2fddbf19-3ecd-4347-877f-9146a97dd111": {"doc_hash": "338b5edb61bb53b1c9666f5c872f8b2a7fb72682a816f02f0802a2413b07230b", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "25eb1674-e8e2-4173-af8d-10d1d61f01ff": {"doc_hash": "0ea4d8873a5bb234533ea54da78435117d05fa87f8a84a561aa34d43054fc770", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "aaf3a09b-d2af-4e21-9bcc-02e49361fa47": {"doc_hash": "748bc721b2dfc0560442ee2688dca0c217c238745530be7878f43dff5b45ae67", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "e81391dc-ac22-426f-8313-33554c707edd": {"doc_hash": "b14da141e858bfa99c5bf99286462df7574f72740e3cec5262206a7fe5ef3a52", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}, "fff743ae-0f99-4dae-9f9f-655d60683018": {"doc_hash": "922cfafe3023a7702e30f7532d0f1e948f7c29292f66887b5fc53487ca3ae1b5", "ref_doc_id": "62deb52f-c1e8-4b24-add9-4fe9fce11e17"}}, "docstore/ref_doc_info": {"62deb52f-c1e8-4b24-add9-4fe9fce11e17": {"node_ids": ["ffb4b8bb-b397-4ae4-a67e-0a16a6d6632f", "1426ebeb-c615-4012-8949-d4461a702bc0", "0c1d2b8a-a1d5-43a0-bfce-8fd76630a698", "8428a665-a795-4af0-a25c-d8b5de57299f", "86a0d7d6-372e-449f-8322-2c373dfa69d7", "2fddbf19-3ecd-4347-877f-9146a97dd111", "25eb1674-e8e2-4173-af8d-10d1d61f01ff", "aaf3a09b-d2af-4e21-9bcc-02e49361fa47", "e81391dc-ac22-426f-8313-33554c707edd", "fff743ae-0f99-4dae-9f9f-655d60683018"], "metadata": {"filename": "multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e.md", "extension": ".md", "title": "MultiModal RAG for Advanced Video Processing with LlamaIndex & LanceDB", "date": "Feb 17, 2024", "url": "https://www.llamaindex.ai/blog/multimodal-rag-for-advanced-video-processing-with-llamaindex-lancedb-33be4804822e"}}}}