{"docstore/data": {"a6e57745-82e3-497a-9bd6-40c8b9a08248": {"__data__": {"id_": "a6e57745-82e3-497a-9bd6-40c8b9a08248", "embedding": null, "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644", "node_type": "4", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b2448a6d51f64d46aaf01da26cdbbbfbca0f16cb4dc6d3b9cc74802795c36aab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e3bf1309-ad93-44f2-8dc5-10ff88973ef3", "node_type": "1", "metadata": {"Header_2": " The challenge"}, "hash": "20a8ae8847e925ceaa514095e79f14951d0298215d75c04e21a2c00fd13d85a4", "class_name": "RelatedNodeInfo"}}, "text": "_This is a guest post from the team at Langfuse_\n\nThere are so many different ways to make RAG work for a use case. What vector\nstore to use? What retrieval strategy to use? LlamaIndex makes it easy to try\nmany of them without having to deal with the complexity of integrations,\nprompts and memory all at once.\n\nInitially, we at Langfuse worked on complex RAG/agent applications and quickly\nrealized that there is a new need for observability and experimentation to\ntweak and iterate on the details. In the end, these details matter to get from\nsomething cool to an actually reliable RAG application that is safe for users\nand customers. Think of this: if there is a user session of interest in your\n_production_ RAG application, how can you quickly see whether the retrieved\ncontext for that session was actually relevant or the LLM response was on\npoint?\n\nThus, we started working on [ Langfuse.com ](http://langfuse.com) ( [ GitHub\n](https://github.com/langfuse/langfuse) ) to establish an open source LLM\nengineering platform with tightly integrated features for tracing, prompt\nmanagement, and evaluation. In the beginning we just solved our own and our\nfriends\u2019 problems. Today we are at over 1000 projects which rely on Langfuse,\nand 2.3k stars on GitHub. You can either [ self-host\n](https://langfuse.com/docs/deployment/self-host) Langfuse or use the [ cloud\ninstance ](https://cloud.langfuse.com) maintained by us.\n\nWe are thrilled to announce our new integration with LlamaIndex today. This\nfeature was [ highly requested\n](https://github.com/orgs/langfuse/discussions/828) by our community and\naligns with our project's focus on native integration with major application\nframeworks. Thank you to everyone who contributed and tested it during the\nbeta phase!", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1769, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e3bf1309-ad93-44f2-8dc5-10ff88973ef3": {"__data__": {"id_": "e3bf1309-ad93-44f2-8dc5-10ff88973ef3", "embedding": null, "metadata": {"Header_2": " The challenge", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644", "node_type": "4", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b2448a6d51f64d46aaf01da26cdbbbfbca0f16cb4dc6d3b9cc74802795c36aab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a6e57745-82e3-497a-9bd6-40c8b9a08248", "node_type": "1", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "2ae1c8ceda2132c544da0acc35f3a87f350ac99a3973369515a48dd22e5b349d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "957502dd-c483-4617-a1b3-47c02037bd01", "node_type": "1", "metadata": {"Header_2": " One-click OSS observability to the rescue"}, "hash": "e9b2727ff827bce6b85e0d102177edc39c218ded50c1f7bbe24d7e0937ab95fb", "class_name": "RelatedNodeInfo"}}, "text": "The challenge\n\nWe love LlamaIndex, since the clean and standardized interface abstracts a lot\nof complexity away. Let\u2019s take this simple example of a VectorStoreIndex and a\nChatEngine.\n\n    \n    \n    from llama_index.core import SimpleDirectoryReader\n    from llama_index.core import VectorStoreIndex\n    \n    documents = SimpleDirectoryReader(\"./data\").load_data()\n    \n    index = VectorStoreIndex.from_documents(documents)\n    \n    chat_engine = index.as_chat_engine()\n    \n    print(chat_engine.chat(\"What problems can I solve with RAG?\"))\n    print(chat_engine.chat(\"How do I optimize my RAG application?\"))\n\nIn just 3 lines we loaded our local documents, added them to an index and\ninitialized a ChatEngine with memory. Subsequently we had a stateful\nconversation with the chat_engine.\n\nThis is awesome to get started, but we quickly run into questions like:\n\n  * _\u201cWhat context is actually retrieved from the index to answer the questions?\u201d_\n  * _\u201cHow is chat memory managed?\u201d_\n  * _\u201cWhich steps add the most latency to the overall execution? How to optimize it?\u201d_", "mimetype": "text/plain", "start_char_idx": 1775, "end_char_idx": 2846, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "957502dd-c483-4617-a1b3-47c02037bd01": {"__data__": {"id_": "957502dd-c483-4617-a1b3-47c02037bd01", "embedding": null, "metadata": {"Header_2": " One-click OSS observability to the rescue", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644", "node_type": "4", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b2448a6d51f64d46aaf01da26cdbbbfbca0f16cb4dc6d3b9cc74802795c36aab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e3bf1309-ad93-44f2-8dc5-10ff88973ef3", "node_type": "1", "metadata": {"Header_2": " The challenge", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "c6551896c5c72352eeacb97a9aff3b61575e31e299fcb7b4120a1c1765f78ad4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "40c87a06-7e54-4251-96d8-6324b6418155", "node_type": "1", "metadata": {"Header_2": " Group multiple chat threads into a session"}, "hash": "4b102097748e01cfae7e5eb25ef805d6bf33ab08f00e947e07aeb8af5b610200", "class_name": "RelatedNodeInfo"}}, "text": "One-click OSS observability to the rescue\n\nWe integrated Langfuse to be a one-click integration with LlamaIndex using the\nglobal callback manager.\n\nPreparation\n\n  1. Install the community package (pip install llama-index-callbacks-langfuse) \n  2. Copy/paste the environment variables from the Langfuse project settings to your Python project: 'LANGFUSE_SECRET_KEY', 'LANGFUSE_PUBLIC_KEY' and 'LANGFUSE_HOST' \n\nNow, you only need to set the global langfuse handler:\n\n    \n    \n    from llama_index.core import set_global_handler\n    \n    set_global_handler(\"langfuse\")\n\nAnd voil\u00e1, with just two lines of code you get detailed traces for all aspects\nof your RAG application in Langfuse. They automatically include latency and\nusage/cost breakdowns.", "mimetype": "text/plain", "start_char_idx": 2852, "end_char_idx": 3598, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40c87a06-7e54-4251-96d8-6324b6418155": {"__data__": {"id_": "40c87a06-7e54-4251-96d8-6324b6418155", "embedding": null, "metadata": {"Header_2": " Group multiple chat threads into a session", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644", "node_type": "4", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b2448a6d51f64d46aaf01da26cdbbbfbca0f16cb4dc6d3b9cc74802795c36aab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "957502dd-c483-4617-a1b3-47c02037bd01", "node_type": "1", "metadata": {"Header_2": " One-click OSS observability to the rescue", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "a594c373d5a21bd51d52ca8f3d5838d128cdc18acaac99fac679c59d1455acc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48a5084b-36f5-4a24-8d3f-fd3c871c8c20", "node_type": "1", "metadata": {"Header_2": " Trace more complex applications and use other Langfuse features for prompt"}, "hash": "5ef386e0825c655dbbcfef1b232c6c5f485e1c0a6df25cad3ad6a446219f9c06", "class_name": "RelatedNodeInfo"}}, "text": "Group multiple chat threads into a session\n\nWorking with lots of teams building GenAI/LLM/RAG applications, we\u2019ve\ncontinuously added more features that are useful to debug and improve these\napplications. One example is [ session tracking\n](https://langfuse.com/docs/tracing/sessions) for conversational applications\nto see the traces in context of a full message thread.\n\nTo activate it, just add an id that identifies the session as a trace param\nbefore calling the chat_engine.\n\n    \n    \n    from llama_index.core import global_handler\n    \n    global_handler.set_trace_params(\n      session_id=\"your-session-id\"\n    )\n    \n    chat_engine.chat(\"What did he do growing up?\")\n    chat_engine.chat(\"What did he do at USC?\")\n    chat_engine.chat(\"How old is he?\")\n\nThereby you can see all these chat invocations grouped into a session view in\nLangfuse Tracing:\n\nNext to sessions, you can also track individual users or add tags and metadata\nto your Langfuse traces.", "mimetype": "text/plain", "start_char_idx": 3604, "end_char_idx": 4569, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "48a5084b-36f5-4a24-8d3f-fd3c871c8c20": {"__data__": {"id_": "48a5084b-36f5-4a24-8d3f-fd3c871c8c20", "embedding": null, "metadata": {"Header_2": " Trace more complex applications and use other Langfuse features for prompt", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644", "node_type": "4", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b2448a6d51f64d46aaf01da26cdbbbfbca0f16cb4dc6d3b9cc74802795c36aab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "40c87a06-7e54-4251-96d8-6324b6418155", "node_type": "1", "metadata": {"Header_2": " Group multiple chat threads into a session", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "00e956a50677423ecd9b0fb0e01e3d82bd31701543733c7edb54fe9107257f70", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d35ad1c5-b69e-4246-aa7d-c5877f493a2a", "node_type": "1", "metadata": {"Header_2": " Get started"}, "hash": "6c529343ebe4a43cc083bdfdea92ab5b2e36542c179d922dcd50cbf93954b4dc", "class_name": "RelatedNodeInfo"}}, "text": "Trace more complex applications and use other Langfuse features for prompt\nmanagement and evaluation\n\nThis integration makes it easy to get started with Tracing. If your\napplication ends up growing into using custom logic or other\nframeworks/packages, all Langfuse integrations are fully interoperable.\n\nWe have also built additional features to version control and collaborate on\nprompts (langfuse [ prompt management ](https://langfuse.com/docs/prompts/get-\nstarted) ), track [ experiments ](https://langfuse.com/docs/experimentation) ,\nand [ evaluate ](https://langfuse.com/docs/scores/overview) production traces.\nFor RAG specifically, we collaborated with the RAGAS team and it\u2019s easy to run\ntheir popular eval suite on traces captured with Langfuse (see [ cookbook\n](https://langfuse.com/docs/scores/model-based-evals/ragas) ).", "mimetype": "text/plain", "start_char_idx": 4575, "end_char_idx": 5408, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d35ad1c5-b69e-4246-aa7d-c5877f493a2a": {"__data__": {"id_": "d35ad1c5-b69e-4246-aa7d-c5877f493a2a", "embedding": null, "metadata": {"Header_2": " Get started", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644", "node_type": "4", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b2448a6d51f64d46aaf01da26cdbbbfbca0f16cb4dc6d3b9cc74802795c36aab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48a5084b-36f5-4a24-8d3f-fd3c871c8c20", "node_type": "1", "metadata": {"Header_2": " Trace more complex applications and use other Langfuse features for prompt", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b68789b5f7b420149975f580a298604c0bf6bb0610a449b42823f5f624ba2cdc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1a99d728-3543-4f9b-bb97-a90266bfeacd", "node_type": "1", "metadata": {"Header_2": " Feedback? Ping us"}, "hash": "2a65aacf41301f03900835fe2f899b94ec64acc7f57cce2fa0bce58d4f72eff8", "class_name": "RelatedNodeInfo"}}, "text": "Get started\n\nThe easiest way to get started is to follow the [ cookbook\n](https://docs.llamaindex.ai/en/stable/examples/callbacks/LangfuseCallbackHandler.html)\nand check out the [ docs ](https://langfuse.com/docs/integrations/llama-\nindex/get-started) .", "mimetype": "text/plain", "start_char_idx": 5414, "end_char_idx": 5667, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a99d728-3543-4f9b-bb97-a90266bfeacd": {"__data__": {"id_": "1a99d728-3543-4f9b-bb97-a90266bfeacd", "embedding": null, "metadata": {"Header_2": " Feedback? Ping us", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644", "node_type": "4", "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "b2448a6d51f64d46aaf01da26cdbbbfbca0f16cb4dc6d3b9cc74802795c36aab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d35ad1c5-b69e-4246-aa7d-c5877f493a2a", "node_type": "1", "metadata": {"Header_2": " Get started", "filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}, "hash": "8d419df469ff6d424d6ac24d74e753b06c18bfd85a52fe57ac3d13f6034a5907", "class_name": "RelatedNodeInfo"}}, "text": "Feedback? Ping us\n\nWe\u2019d love to hear any feedback. Come join us on our [ community discord\n](https://langfuse.com/discord) or add your thoughts to this [ GitHub thread\n](https://github.com/orgs/langfuse/discussions/828) .", "mimetype": "text/plain", "start_char_idx": 5673, "end_char_idx": 5894, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"a6e57745-82e3-497a-9bd6-40c8b9a08248": {"doc_hash": "2ae1c8ceda2132c544da0acc35f3a87f350ac99a3973369515a48dd22e5b349d", "ref_doc_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644"}, "e3bf1309-ad93-44f2-8dc5-10ff88973ef3": {"doc_hash": "c6551896c5c72352eeacb97a9aff3b61575e31e299fcb7b4120a1c1765f78ad4", "ref_doc_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644"}, "957502dd-c483-4617-a1b3-47c02037bd01": {"doc_hash": "a594c373d5a21bd51d52ca8f3d5838d128cdc18acaac99fac679c59d1455acc0", "ref_doc_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644"}, "40c87a06-7e54-4251-96d8-6324b6418155": {"doc_hash": "00e956a50677423ecd9b0fb0e01e3d82bd31701543733c7edb54fe9107257f70", "ref_doc_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644"}, "48a5084b-36f5-4a24-8d3f-fd3c871c8c20": {"doc_hash": "b68789b5f7b420149975f580a298604c0bf6bb0610a449b42823f5f624ba2cdc", "ref_doc_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644"}, "d35ad1c5-b69e-4246-aa7d-c5877f493a2a": {"doc_hash": "8d419df469ff6d424d6ac24d74e753b06c18bfd85a52fe57ac3d13f6034a5907", "ref_doc_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644"}, "1a99d728-3543-4f9b-bb97-a90266bfeacd": {"doc_hash": "696519ef6a302a70fcf7871554201c1ce39d5b34661714256365ca9b0953ef04", "ref_doc_id": "e9dcce0e-d039-4e07-89b8-a16086ef2644"}}, "docstore/ref_doc_info": {"e9dcce0e-d039-4e07-89b8-a16086ef2644": {"node_ids": ["a6e57745-82e3-497a-9bd6-40c8b9a08248", "e3bf1309-ad93-44f2-8dc5-10ff88973ef3", "957502dd-c483-4617-a1b3-47c02037bd01", "40c87a06-7e54-4251-96d8-6324b6418155", "48a5084b-36f5-4a24-8d3f-fd3c871c8c20", "d35ad1c5-b69e-4246-aa7d-c5877f493a2a", "1a99d728-3543-4f9b-bb97-a90266bfeacd"], "metadata": {"filename": "one-click-open-source-rag-observability-with-langfuse.md", "extension": ".md", "title": "One-click Open Source RAG Observability with Langfuse", "date": "Mar 18, 2024", "url": "https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse"}}}}