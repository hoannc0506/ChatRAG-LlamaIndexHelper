{"docstore/data": {"2e2c896a-f56c-4fb3-b14f-4baf92cdf924": {"__data__": {"id_": "2e2c896a-f56c-4fb3-b14f-4baf92cdf924", "embedding": null, "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da", "node_type": "4", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "9499fc1f51d779b7dcf4f5e7f58f0136cfe4cb63e30f84c5d49cf6a176ea7c44", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e1f99138-20de-4cdf-9778-e43fe46b6bb9", "node_type": "1", "metadata": {"Header_2": " The foundation: LlamaIndex and data ingestion"}, "hash": "84f7b4938f3796012b07e704c74d67f6af825ce1c8282a176f1ddd577734c74f", "class_name": "RelatedNodeInfo"}}, "text": "_This is a guest post from Team CLAB, the winners of \"Best Use of LlamaIndex\"\nat our recent hackathon with MongoDB._\n\nImagine this: you\u2019re deep in a coding project, and a critical question pops up\nabout a specific tool or library. You start the dreaded documentation shuffle\n\u2014 searching through wikis, FAQs, maybe even firing up a separate chatbot for\nspecific tools (like those from LlamaIndex, FireworksAI or anyone else). It\u2019s\nfrustrating! We wanted to change that.\n\nThat\u2019s why Team CLAB built [ LlamaWorksDB (try it out!) ](https://clab-\nui.vercel.app/) , your friendly AI-powered doc wizard . No more scattered\nsearches! It taps into the knowledge of multiple sponsors of our hackathon\nincluding LlamaIndex, Fireworks.ai, and MongoDB, all through a single chatbot\ninterface. Need something explained from MongoDB\u2019s docs? Got it! Want a code\nexample from Fireworks.ai? Easy!", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 878, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e1f99138-20de-4cdf-9778-e43fe46b6bb9": {"__data__": {"id_": "e1f99138-20de-4cdf-9778-e43fe46b6bb9", "embedding": null, "metadata": {"Header_2": " The foundation: LlamaIndex and data ingestion", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da", "node_type": "4", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "9499fc1f51d779b7dcf4f5e7f58f0136cfe4cb63e30f84c5d49cf6a176ea7c44", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2e2c896a-f56c-4fb3-b14f-4baf92cdf924", "node_type": "1", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "311377dbeae48e00ec669d196a91b5bc69cf3eecd1598dd167ef25f53eef4968", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "53ea01a9-dff2-4a9b-9732-a438a582bd70", "node_type": "1", "metadata": {"Header_2": " MongoDB Atlas for vector search"}, "hash": "9c71210ebd1af8f03235b41247a575b6f7ae3a44d56912e6cbd659bd182dccc0", "class_name": "RelatedNodeInfo"}}, "text": "The foundation: LlamaIndex and data ingestion\n\nLlamaIndex was the heart and soul of LlamaWorksDB. It\u2019s like a super versatile\ntoolbox for handling all kinds of documentation! We primarily used their open-\nsource readers to grab info straight from websites. A cool hack we did was\ncustomize the ` SimpleWebPageReader ` . We taught it to ignore website\nnavigation bars, saving us a ton of precious tokens. While this worked great\nfor the documentation sites, we used LlamaIndex\u2019s ` GithubRepositoryReader `\nto easily read through each repo.\n\n    \n    \n    from llama_index.readers.web import SimpleWebPageReader\n    import re\n    \n    class LlamaDocsPageReader(SimpleWebPageReader):\n       def load_data(self, urls):\n           documents = super().load_data(urls)\n           processed_documents = []\n           for doc in documents:\n               processed_doc = self.process_document(doc)\n               processed_documents.append(processed_doc)\n           return processed_documents\n    \n       def process_document(self, document):\n           # Split the document text by \"Table of Contents\"\n           pattern = r'(?i)\\n\\n*table\\s*of\\s*contents\\n\\n*'\n           parts = re.split(pattern, document.text, maxsplit=1)\n           # If there is a part after \"Table of Contents\", use it as the document text\n           if len(parts) > 1:\n               document.text = \"Table of contents\".join(parts[1:])\n           return document\n\nChoosing how to split up the docs was interesting. LlamaIndex has options\nranging from the basic ` SentenceSplitter ` to their ` SemanticNodeParser ` ,\nwhich uses AI to group similar ideas. We went with the latter for those\nperfectly sized, meaningful chunks.\n\nFinally, we embedded each \u2018node\u2019 and sent each as a document to MongoDB. Talk\nabout streamlined! MongoDB stored the text, metadata, _and_ our embeddings \u2014\nideal for the kind of search we wanted to build. We used Nomic\u2019s flexible\nembedding model via Fireworks, which let us fine-tune the dimensions for\nmaximum efficiency.\n\n    \n    \n    # FireworksEmbedding defaults to using model\n    embed_model = FireworksEmbedding(api_key=os.getenv('FIREWORKS_API_KEY'),\n                                    model=\"nomic-ai/nomic-embed-text-v1.5\",\n                                    embed_batch_size=10,\n                                    dimensions=768 # can range from 64 to 768\n                                    )\n    \n    # the tried and true sentence splitter\n    text_splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=200)\n    # the semantic splitter uses our embedding model to group semantically related sentences together\n    semantic_parser = SemanticSplitterNodeParser(embed_model=embed_model)\n    \n    # we set up MongoDB as our document and vector database\n    vector_store = MongoDBAtlasVectorSearch(\n       pymongo.MongoClient(os.getenv('MONGO_URI')),\n       db_name=\"fireParse\",\n       collection_name=\"llamaIndexDocs\",\n       index_name=\"llama_docs_index\"\n    )\n    \n    #finally we use LlamaIndex's pipeline to string this all together\n    pipeline = IngestionPipeline(\n       transformations=[\n           semantic_parser, #can replace with text_splitter\n           embed_model,\n       ],\n       vector_store=vector_store,\n    )\n\nOnce we have everything set up, we can create documents from URLs in MongoDB!\nBelow is an example of using three URLs but we used hundreds.\n\n    \n    \n    example_urls = [\n       \"https://docs.llamaindex.ai/en/stable/examples/cookbooks/llama3_cookbook\",\n       \"https://docs.llamaindex.ai/en/stable/examples/cookbooks/anthropic_haiku/\",\n      \"https://docs.llamaindex.ai/en/stable/examples/vector_stores/MongoDBAtlasVectorSearch/\"\n    ]\n    \n    # read in the documents and pass them through our pipeline\n    documents = LlamaDocsPageReader(html_to_text=True).load_data(example_urls)\n    pipeline.run(documents=documents, show_progress=True)\n\nYou can see in MongoDB how our documents have text, embedding (with 768\ndimensions), and metadata.\n\nExample document in MongoDB Atlas that resulted from the pipeline", "mimetype": "text/plain", "start_char_idx": 884, "end_char_idx": 4931, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "53ea01a9-dff2-4a9b-9732-a438a582bd70": {"__data__": {"id_": "53ea01a9-dff2-4a9b-9732-a438a582bd70", "embedding": null, "metadata": {"Header_2": " MongoDB Atlas for vector search", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da", "node_type": "4", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "9499fc1f51d779b7dcf4f5e7f58f0136cfe4cb63e30f84c5d49cf6a176ea7c44", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e1f99138-20de-4cdf-9778-e43fe46b6bb9", "node_type": "1", "metadata": {"Header_2": " The foundation: LlamaIndex and data ingestion", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "5038aab37986337c6b68e375876874ea362359ebea6a179858a64be5d3d797fe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3d611a16-f462-4e7d-a07f-023f7a77af9e", "node_type": "1", "metadata": {"Header_2": " ` create-llama ` : from idea to app in record time"}, "hash": "d80b54519d7653608953c9b293b04144f1ce6f7be8189e8fa3ed27141a29cf00", "class_name": "RelatedNodeInfo"}}, "text": "MongoDB Atlas for vector search\n\nMongoDB Atlas was our go-to for storing both the documentation text and the\nembeddings themselves. It\u2019s incredibly versatile! Setting up vector search\nwithin Atlas is a breeze, allowing us to quickly find the most relevant\ndocument chunks. Plus, LlamaIndex\u2019s metadata parsing played perfectly with\nAtlas \u2014 we could easily filter results based on things like document source or\ntopic.\n\n**Setting up Vector Search:** It was remarkably simple! We just specified\nthese few things:\n\n  * Path to the embedding field within our documents. \n  * Embedding dimension size. \n  * Similarity metric (e.g., cosine similarity). \n  * That it\u2019s a vector index. \n\n**Filtering Power (Optional):** For even finer control, we could add paths to\nfields we wanted to filter our searches by (like the company\u2019s name).\n\nWhether you\u2019re building a complex web app or a quick Streamlit prototype,\nLlamaIndex ChatEngines have you covered. They effortlessly manage conversation\nhistory, let you perform lightning-fast vector searches, and unlock a whole\nsuite of powerful tools.\n\nWe built our ChatEngine directly from our trusty MongoDB index. This\nintegration was surprisingly simple:\n\n    \n    \n    def get_index():\n       logger.info(\"Connecting to index from MongoDB...\")\n       store = MongoDBAtlasVectorSearch(\n           db_name=os.environ[\"MONGODB_DATABASE\"],\n           collection_name=os.environ[\"MONGODB_VECTORS\"],\n           index_name=os.environ[\"MONGODB_VECTOR_INDEX\"],\n       )\n       index = VectorStoreIndex.from_vector_store(store)\n       logger.info(\"Finished connecting to index from MongoDB.\")\n       return index\n    \n    index = get_index()\n    index.as_chat_engine(\n        llm = Fireworks(\n                 api_key=env_vars['FIREWORKS_API_KEY'],\n                 model=\"accounts/fireworks/models/mixtral-8x22b-instruct\" #Can be changed out for Llama3\n                 )\n        chat_mode=\"best\", \n        context_prompt=(\n               \"\"\" You are a software developer bot that is an expert at reading over documentation to answer questions.\n               Use the relevant documents for context:\n               {context_str}\n               \\nInstruction: Use the previous chat history, or the context above, to interact and help the user.\n               \"\"\"\n               ),\n        verbose=True\n        )", "mimetype": "text/plain", "start_char_idx": 4937, "end_char_idx": 7273, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3d611a16-f462-4e7d-a07f-023f7a77af9e": {"__data__": {"id_": "3d611a16-f462-4e7d-a07f-023f7a77af9e", "embedding": null, "metadata": {"Header_2": " ` create-llama ` : from idea to app in record time", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da", "node_type": "4", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "9499fc1f51d779b7dcf4f5e7f58f0136cfe4cb63e30f84c5d49cf6a176ea7c44", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "53ea01a9-dff2-4a9b-9732-a438a582bd70", "node_type": "1", "metadata": {"Header_2": " MongoDB Atlas for vector search", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "12ee0ae0248cf44111272c541e2020888edcc31b0addf07ebb8f09b4ebbb4234", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e4475e9e-1cf0-4420-979b-ff2633a618b3", "node_type": "1", "metadata": {"Header_2": " Deployment: Render and Vercel"}, "hash": "daea860dc11c37d648db14e30fa75d2a2d9c5009b8f217bf5fbe0f6cac1f77e2", "class_name": "RelatedNodeInfo"}}, "text": "` create-llama ` : from idea to app in record time\n\nWe were seriously impressed by Create-Llama. Usually, building a full-stack\napp takes time, but Create-Llama had us up and running in under 15 minutes!\nAll we did was point it towards our vector database and give a few basic\ndetails. Honestly, it made development a joy! [ This blog post goes into more\ndetail about how to use create-llama. ](https://www.llamaindex.ai/blog/create-\nllama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191)\n\nThe create-llama setup screen  The create-llama app, customized and ready to\ngo", "mimetype": "text/plain", "start_char_idx": 7279, "end_char_idx": 7861, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e4475e9e-1cf0-4420-979b-ff2633a618b3": {"__data__": {"id_": "e4475e9e-1cf0-4420-979b-ff2633a618b3", "embedding": null, "metadata": {"Header_2": " Deployment: Render and Vercel", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da", "node_type": "4", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "9499fc1f51d779b7dcf4f5e7f58f0136cfe4cb63e30f84c5d49cf6a176ea7c44", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3d611a16-f462-4e7d-a07f-023f7a77af9e", "node_type": "1", "metadata": {"Header_2": " ` create-llama ` : from idea to app in record time", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "3446f1bd621c29ffe6cf60145d1a20b13c471268372fad4802d354bd3ac8dfab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "30a938cc-03ed-4c47-b94e-1adef059bfa6", "node_type": "1", "metadata": {"Header_2": " Future directions"}, "hash": "90204e2f3cd84a72e45df3229424ddfa62fe1578933e6cac3c112788276ebb90", "class_name": "RelatedNodeInfo"}}, "text": "Deployment: Render and Vercel\n\nTo make LlamaWorksDB production-ready and easily accessible, we turned to [\nRender ](https://render.com/) and [ Vercel ](https://vercel.com/) . Render was\na perfect fit for our Python FastAPI backend, as it focuses on ease of\ndeployment and scalability. Vercel seamlessly handled our Next.js frontend \u2014\nwe loved its developer-centric approach and the effortless build process. Both\nplatforms made deployment a breeze, letting us focus on coding rather than\ncomplex infrastructure setup.", "mimetype": "text/plain", "start_char_idx": 7867, "end_char_idx": 8384, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "30a938cc-03ed-4c47-b94e-1adef059bfa6": {"__data__": {"id_": "30a938cc-03ed-4c47-b94e-1adef059bfa6", "embedding": null, "metadata": {"Header_2": " Future directions", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da", "node_type": "4", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "9499fc1f51d779b7dcf4f5e7f58f0136cfe4cb63e30f84c5d49cf6a176ea7c44", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e4475e9e-1cf0-4420-979b-ff2633a618b3", "node_type": "1", "metadata": {"Header_2": " Deployment: Render and Vercel", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "67537a08d9c06abe6e79210d5b92317fb60a7803e00b031116eab8888dc60e28", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "693b5457-0c7d-4393-b40f-f81661388c82", "node_type": "1", "metadata": {"Header_2": " Meet Team CLAB!"}, "hash": "6a2151b25c84ef09bd7a3e37fedaf8605256a32785b4182d2c27c04fe320f638", "class_name": "RelatedNodeInfo"}}, "text": "Future directions\n\nOur hackathon success is just the beginning. We envision LlamaWorksDB evolving\ninto a powerhouse for developers seeking answers within technical\ndocumentation. Here\u2019s how we see it growing:\n\n  * **Enhanced Retrieval:** We\u2019re excited to experiment with LlamaIndex\u2019s powerful capabilities like MultiVectorSearch to further refine our results. Integrating different LLMs will open up new possibilities for how LlamaWorksDB understands and interacts with technical content. \n  * **A Focus on Documentation:** We want to double down on making LlamaWorksDB the ultimate tool for navigating documentation. This means exploring specialized techniques and tools designed specifically for understanding complex technical information. \n\nLlamaWorksDB is an open-source project in Beta, and we believe in the power of\ncollaboration! If you\u2019re passionate about AI-powered documentation tools, we\ninvite you to:\n\n  * **Try it out:** Explore our [ GitHub repo ](https://github.com/clab2024/clab/tree/main) and give [ LlamaWorksDB a spin ](https://clab-ui.vercel.app/) ! \n  * **Contribute:** Help us build new features, test integrations, and refine our search capabilities. \n  * **Share your feedback:** Let us know how we can make LlamaWorksDB even better. \n\nTogether, let\u2019s revolutionize the way developers interact with documentation!\n\nExplore our project and join the innovation: [\nhttps://github.com/clab2024/clab/ ](https://github.com/clab2024/clab/)\n\n[ https://clab-ui.vercel.app/ ](https://clab-ui.vercel.app/) (front-end)\n(leverages free credits responds late)\n\n[ https://clab.onrender.com/docs ](https://clab.onrender.com/docs) (back-end)", "mimetype": "text/plain", "start_char_idx": 8390, "end_char_idx": 10041, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "693b5457-0c7d-4393-b40f-f81661388c82": {"__data__": {"id_": "693b5457-0c7d-4393-b40f-f81661388c82", "embedding": null, "metadata": {"Header_2": " Meet Team CLAB!", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da", "node_type": "4", "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "9499fc1f51d779b7dcf4f5e7f58f0136cfe4cb63e30f84c5d49cf6a176ea7c44", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "30a938cc-03ed-4c47-b94e-1adef059bfa6", "node_type": "1", "metadata": {"Header_2": " Future directions", "filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}, "hash": "1ec6923d651c97564c5a665f1191945669ca3b8afaf8f606820ad8516294b28e", "class_name": "RelatedNodeInfo"}}, "text": "Meet Team CLAB!\n\n  * [ **Chris Wood** ](https://www.linkedin.com/in/chris-wood-b9282a22a/) : Up-and-coming tech whiz, ready to graduate with valuable insights from his internship at Tutello. \n  * [ **Leo Walker** ](https://www.linkedin.com/in/leowalker/) : Data Scientist with the discipline and precision of a Military Veteran. \n  * [ **Andrew Townsend** ](https://www.linkedin.com/in/andrew-g-townsend/) : A Computer Science graduate from SJSU, bringing fresh academic perspectives. \n  * [ **Barath Subramaniam** ](https://www.linkedin.com/in/barathsubramaniam/) : The strategic mind behind Product Security AI and Data engineering at Adobe. Twitter: [ @baraths84 ](https://twitter.com/baraths84)\n\nTeam CLAB (plus Laurie)", "mimetype": "text/plain", "start_char_idx": 10047, "end_char_idx": 10770, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"2e2c896a-f56c-4fb3-b14f-4baf92cdf924": {"doc_hash": "311377dbeae48e00ec669d196a91b5bc69cf3eecd1598dd167ef25f53eef4968", "ref_doc_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da"}, "e1f99138-20de-4cdf-9778-e43fe46b6bb9": {"doc_hash": "5038aab37986337c6b68e375876874ea362359ebea6a179858a64be5d3d797fe", "ref_doc_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da"}, "53ea01a9-dff2-4a9b-9732-a438a582bd70": {"doc_hash": "12ee0ae0248cf44111272c541e2020888edcc31b0addf07ebb8f09b4ebbb4234", "ref_doc_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da"}, "3d611a16-f462-4e7d-a07f-023f7a77af9e": {"doc_hash": "3446f1bd621c29ffe6cf60145d1a20b13c471268372fad4802d354bd3ac8dfab", "ref_doc_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da"}, "e4475e9e-1cf0-4420-979b-ff2633a618b3": {"doc_hash": "67537a08d9c06abe6e79210d5b92317fb60a7803e00b031116eab8888dc60e28", "ref_doc_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da"}, "30a938cc-03ed-4c47-b94e-1adef059bfa6": {"doc_hash": "1ec6923d651c97564c5a665f1191945669ca3b8afaf8f606820ad8516294b28e", "ref_doc_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da"}, "693b5457-0c7d-4393-b40f-f81661388c82": {"doc_hash": "c700fb3487730921e91805e3aac43ed901be8afa4a4023130eeac34bf1a5b2d2", "ref_doc_id": "912d2621-ca2f-43ff-affc-3d5ecf2d68da"}}, "docstore/ref_doc_info": {"912d2621-ca2f-43ff-affc-3d5ecf2d68da": {"node_ids": ["2e2c896a-f56c-4fb3-b14f-4baf92cdf924", "e1f99138-20de-4cdf-9778-e43fe46b6bb9", "53ea01a9-dff2-4a9b-9732-a438a582bd70", "3d611a16-f462-4e7d-a07f-023f7a77af9e", "e4475e9e-1cf0-4420-979b-ff2633a618b3", "30a938cc-03ed-4c47-b94e-1adef059bfa6", "693b5457-0c7d-4393-b40f-f81661388c82"], "metadata": {"filename": "streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb.md", "extension": ".md", "title": "Streamlining knowledge work with LlamaIndex, Fireworks and MongoDB", "date": "Apr 29, 2024", "url": "https://www.llamaindex.ai/blog/streamlining-knowledge-work-with-llamaindex-fireworks-and-mongodb"}}}}