{"docstore/data": {"3f38cdb0-6be8-45cb-865e-df5c4fd40323": {"__data__": {"id_": "3f38cdb0-6be8-45cb-865e-df5c4fd40323", "embedding": null, "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f470e5f0-c181-437e-966c-de7f2a798566", "node_type": "1", "metadata": {"Header_2": " **About UpTrain**"}, "hash": "c54d6b6260b6ae55de31170287dbd806c02fafbdb002d20b75bde265f90b000d", "class_name": "RelatedNodeInfo"}}, "text": "_This is a guest post from Uptrain._\n\nWe are excited to announce the recent integration of LlamaIndex with UpTrain -\nan open-source LLM evaluation framework to evaluate your RAG pipelines and\nexperiment with different configurations. As an increasing number of companies\nare graduating their LLM prototypes to production-ready systems, robust\nevaluations provide a systematic framework to make decisions rather than going\nwith the \u2018vibes\u2019. By combining LlamaIndex's flexibility and UpTrain's\nevaluation framework, developers can experiment with different configurations,\nfine-tuning their LLM-based applications for optimal performance.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 636, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f470e5f0-c181-437e-966c-de7f2a798566": {"__data__": {"id_": "f470e5f0-c181-437e-966c-de7f2a798566", "embedding": null, "metadata": {"Header_2": " **About UpTrain**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3f38cdb0-6be8-45cb-865e-df5c4fd40323", "node_type": "1", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "276b84c9ea3f1179073bc936ce5179b0b3c145bb67423029c0d2a98f9149e2ef", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c30abf8a-2618-4bd1-899d-5932396e7f10", "node_type": "1", "metadata": {"Header_2": " **LlamaIndex x UpTrain Callback Handler**"}, "hash": "d891e84917d31310a72113a2c436d1deb8fc8ee698b959ccf88fcbec2f125c62", "class_name": "RelatedNodeInfo"}}, "text": "**About UpTrain**\n\n**UpTrain** [ [ github ](https://github.com/uptrain-ai/uptrain) || [ website\n](https://uptrain.ai/) || [ docs ](https://docs.uptrain.ai/getting-\nstarted/introduction) ] is an open-source platform to evaluate and improve LLM\napplications. It provides grades for 20+ preconfigured checks (covering\nlanguage, code, embedding use cases), performs root cause analyses on\ninstances of failure cases and provides guidance for resolving them.\n\n**Key Highlights:**\n\n  * **Data Security:** As an open-source solution, UpTrain conducts all evaluations and analyses locally, ensuring that your data remains within your secure environment (except for the LLM calls). \n  * **Custom Evaluator LLMs:** UpTrain allows for [ customisation of your evaluator LLM ](https://github.com/uptrain-ai/uptrain/blob/main/examples/open_source_evaluator_tutorial.ipynb) , offering options among several endpoints, including OpenAI, Anthropic, Llama, Mistral, or Azure. \n  * **Insights that help with model improvement:** Beyond mere evaluation, UpTrain performs [ root cause analysis ](https://github.com/uptrain-ai/uptrain/blob/main/examples/root_cause_analysis/rag_with_citation.ipynb) to pinpoint the specific components of your LLM pipeline, that are underperforming, as well as identifying common patterns among failure cases, thereby helping in their resolution. \n  * **Diverse Experimentations:** The platform enables [ experimentation ](https://github.com/uptrain-ai/uptrain/tree/main/examples/experiments) with different prompts, LLM models, RAG modules, embedding models, etc. and helps you find the best fit for your specific use case. \n  * **Compare open-source LLMs:** With UpTrain, you can compare your fine-tuned open-source LLMs against proprietary ones (such as GPT-4), helping you to find the most cost-effective model without compromising quality. \n\nIn the following sections, we will illustrate how you can use UpTrain to\nevaluate your LlamaIndex pipeline. The evaluations demonstrated here will help\nyou quickly find what\u2019s affecting the quality of your responses, allowing you\nto take appropriate corrective actions.", "mimetype": "text/plain", "start_char_idx": 642, "end_char_idx": 2769, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c30abf8a-2618-4bd1-899d-5932396e7f10": {"__data__": {"id_": "c30abf8a-2618-4bd1-899d-5932396e7f10", "embedding": null, "metadata": {"Header_2": " **LlamaIndex x UpTrain Callback Handler**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f470e5f0-c181-437e-966c-de7f2a798566", "node_type": "1", "metadata": {"Header_2": " **About UpTrain**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "70633a9a9473967aa53703e46d830492a06b86b0f09ea7b6e2f12b16af3453de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c97ef329-bfc9-4e77-9ef9-76f0822c5308", "node_type": "1", "metadata": {"Header_2": " **Evals across the board: From Vanilla to Advanced RAG**"}, "hash": "03e3433483002ad0a448d94ef94e2acc2664bc9843925f4af4a70ab6c978282d", "class_name": "RelatedNodeInfo"}}, "text": "**LlamaIndex x UpTrain Callback Handler**\n\nWe introduce an UpTrain Callback Handler which makes evaluating your existing\nLlamaIndex Pipeline seamless. By adding just a few lines of code, UpTrain will\nautomatically perform a series of checks - evaluating the quality of generated\nresponses, the quality of contextual data retrieved by the RAG pipeline as\nwell as the performance of all the interim steps.\n\nIf you wish to skip right ahead to the tutorial, check it out [ here.\n](https://colab.research.google.com/github/run-\nllama/llama_index/blob/main/docs/examples/callbacks/UpTrainCallback.ipynb)", "mimetype": "text/plain", "start_char_idx": 2775, "end_char_idx": 3372, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c97ef329-bfc9-4e77-9ef9-76f0822c5308": {"__data__": {"id_": "c97ef329-bfc9-4e77-9ef9-76f0822c5308", "embedding": null, "metadata": {"Header_2": " **Evals across the board: From Vanilla to Advanced RAG**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c30abf8a-2618-4bd1-899d-5932396e7f10", "node_type": "1", "metadata": {"Header_2": " **LlamaIndex x UpTrain Callback Handler**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "3489d1dfca377ed22abc5d37154bf9cd5691e80465cfc4681d8f021416fe3f76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9186e020-0b4f-4825-9f34-37a19de14d6b", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**"}, "hash": "a86b1e046021ecbe4d9649494e13170a852880d5dae2a8e8446b338bcc5d4c58", "class_name": "RelatedNodeInfo"}}, "text": "**Evals across the board: From Vanilla to Advanced RAG**\n\nVanilla RAG involves a few steps. You need to embed the documents and store\nthem in a vector database. When the user asks questions, the framework embeds\nthem and uses similarity search to find the most relevant documents. The\ncontent of these retrieved documents, and the original query, are then passed\non to the LLM to generate the final response.\n\nWhile the above is a great starting point, there have been a lot of\nimprovements to achieve better results. Advanced RAG applications have many\nadditional steps that improve the quality of the retrieved documents, which in\nturn improve the quality of your responses.\n\nBut as Uncle Ben famously said to Peter Parker in the GenAI universe:\n\n_\u201cWith increased complexity comes more points of failure.\u201d._\n\nMost of the LLM evaluation tools only evaluate the final context-response pair\nand fail to take into consideration the intermediary steps of an advanced RAG\npipeline. Let\u2019s look at all the evaluations provided by UpTrain.", "mimetype": "text/plain", "start_char_idx": 3378, "end_char_idx": 4410, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9186e020-0b4f-4825-9f34-37a19de14d6b": {"__data__": {"id_": "9186e020-0b4f-4825-9f34-37a19de14d6b", "embedding": null, "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c97ef329-bfc9-4e77-9ef9-76f0822c5308", "node_type": "1", "metadata": {"Header_2": " **Evals across the board: From Vanilla to Advanced RAG**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "fcee2b3a168fade7e2d4428b59797a954485ac6b534c2596bd4f5e9ec122bf99", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b07dfef7-baa6-4d83-8468-26934c70c213", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **1\\. RAG Query Engine Evaluation**"}, "hash": "059571114db84821737ee53b08bd2c106c83ae76f4b0723fdddbb2e90a624489", "class_name": "RelatedNodeInfo"}}, "text": "**Addressing Points of Failure in RAG Pipelines**", "mimetype": "text/plain", "start_char_idx": 4416, "end_char_idx": 4465, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b07dfef7-baa6-4d83-8468-26934c70c213": {"__data__": {"id_": "b07dfef7-baa6-4d83-8468-26934c70c213", "embedding": null, "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **1\\. RAG Query Engine Evaluation**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9186e020-0b4f-4825-9f34-37a19de14d6b", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f651ac30f04d656f7b09c1de6f3910a818072755add5949fde560f91351a65a1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff2104de-8b24-4892-a526-5ec9edbc2607", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **2\\. Sub-Question Query Engine Evaluation**"}, "hash": "335c20b475217c9136bee8c3612c81f11c21eac85e37b2c6e5fc7c0ede93998c", "class_name": "RelatedNodeInfo"}}, "text": "**1\\. RAG Query Engine Evaluation**\n\nLet's first take a Vanilla RAG Pipeline and see how you can test its\nperformance. UpTrain provides three operators curated for testing both the\nretrieved context as well as the LLM's response.\n\n  * [ **Context Relevance** ](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-relevance) : However informative the documents retrieved might be, if they are not relevant to your query, you will likely not get a response that answers your query. The Context Relevance operator determines if the documents fetched from the vector store contain information that can be used to answer your query. \n  * [ **Factual Accuracy** ](https://docs.uptrain.ai/predefined-evaluations/context-awareness/factual-accuracy) : Now that we have checked if the context contains information to answer our query, we will check if the response provided by the LLM is backed by the information present in the context. The Factual Accuracy operator assesses if the LLM is hallucinating or providing information that is not present in the context. \n  * [ **Response Completeness** ](https://docs.uptrain.ai/predefined-evaluations/response-quality/response-completeness) : Not all queries are straightforward. Some of them have multiple parts to them. A good response should be able to answer all the aspects of the query. The Response Completeness operator checks if the response contains all the information requested by the query.", "mimetype": "text/plain", "start_char_idx": 4472, "end_char_idx": 5933, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ff2104de-8b24-4892-a526-5ec9edbc2607": {"__data__": {"id_": "ff2104de-8b24-4892-a526-5ec9edbc2607", "embedding": null, "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **2\\. Sub-Question Query Engine Evaluation**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b07dfef7-baa6-4d83-8468-26934c70c213", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **1\\. RAG Query Engine Evaluation**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "299ef984947cd1dc9c450d5da880b0c3b80517f20e54f755a21f630556f1c936", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a248c8d4-1052-49e5-8e43-e8a82a277ccd", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **3\\. Reranking Evaluations**"}, "hash": "ccaf667d934fede7292450ddf12dc455bca1f072fca872514160b93835101780", "class_name": "RelatedNodeInfo"}}, "text": "**2\\. Sub-Question Query Engine Evaluation**\n\nLet's say you tried out a Vanilla RAG pipeline and got consistently low\nResponse Completeness scores. This means that the LLM is not answering all\naspects of your query. One of the ways to solve this is by splitting the query\ninto multiple smaller sub-queries that the LLM can answer more easily. To do\nthis, you can use the SubQuestionQueryGeneration operator provided by\nLlamaIndex. This operator decomposes a question into sub-questions, generating\nresponses for each using an RAG query engine.\n\nIf you include this SubQuery module in your RAG pipeline, it introduces\nanother point of failure, e.g. what if the sub-questions that we split our\noriginal question aren't good representations of it? UpTrain automatically\nadds new evaluations to check how well the module performs:\n\n  * [ **Sub Query Completeness** ](https://docs.uptrain.ai/predefined-evaluations/sub-query/sub-query-completeness) : It evaluates whether the sub-questions accurately and comprehensively cover the original query. \n  * Context Relevance, Factual Accuracy and Response Completeness for each of the sub-queries.", "mimetype": "text/plain", "start_char_idx": 5941, "end_char_idx": 7078, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a248c8d4-1052-49e5-8e43-e8a82a277ccd": {"__data__": {"id_": "a248c8d4-1052-49e5-8e43-e8a82a277ccd", "embedding": null, "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **3\\. Reranking Evaluations**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff2104de-8b24-4892-a526-5ec9edbc2607", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **2\\. Sub-Question Query Engine Evaluation**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "839cb33cb591c7cf7f0f8c2bf24e1be88e73d714236a249a72bffdd04ce8e5ed", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d9cf86c6-65bd-4641-bf8f-a468c8c32cd8", "node_type": "1", "metadata": {"Header_2": " **Key Takeaways: Enhancing RAG Pipelines Through Advanced Techniques and"}, "hash": "7d6e9a61f6130a11be9afe4e2ed48871c03da5741240aa01bee7485b1b0fca25", "class_name": "RelatedNodeInfo"}}, "text": "**3\\. Reranking Evaluations**\n\nWe looked at a way of dealing with low Response Completeness scores. Now,\nlet's look at a way of dealing with low Context Relevance scores.\n\nRAG pipelines retrieve documents based on semantic similarity. These documents\nare ordered based on how similar they are to the query asked. However, recent\nresearch [ [ Lost in the Middle: How Language Model Uses Long Contexts\n](https://arxiv.org/pdf/2307.03172.pdf) ] has shown that the LLMs are\nsensitive to the placement of the most critical information within the\nretrieved context. To solve this, you might want to add a reranking block.\n\nReranking involves using a semantic search model (specially tuned for the\nreranking task) that breaks down the retrieved context into smaller chunks,\nfinds the semantic similarity between them and the query and rewrites the\ncontext by ranking them in order of their similarity.\n\nWe observed that when using the reranking operators in LlamaIndex, two\nscenarios can occur. These scenarios differ based on the number of nodes\nbefore and after the reranking process:\n\n**a. Same Number of Nodes Before and After Reranking:**\n\nIf the number of nodes after the reranking remains the same, then we need to\ncheck if the new order is such that nodes higher in rank are more relevant to\nthe query as compared to the older order. To check for this, UpTrain provides\na Context Reranking operator.\n\n  * [ **Context Reranking** ](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-reranking) : Checks if the order of reranked nodes is more relevant to the query than the original order. \n\n**b. Fewer Number of Nodes After Reranking:**\n\nReducing the number of nodes can help the LLM give better responses. This is\nbecause the LLMs process smaller context lengths better. However, we need to\nmake sure that we don't lose information that would have been useful in\nanswering the question. Therefore, during the process of reranking, if the\nnumber of nodes in the output is reduced, we provide a Context Conciseness\noperator.\n\n  * [ **Context Conciseness** ](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-conciseness) : Examines whether the reduced number of nodes still provides all the required information.", "mimetype": "text/plain", "start_char_idx": 7086, "end_char_idx": 9342, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d9cf86c6-65bd-4641-bf8f-a468c8c32cd8": {"__data__": {"id_": "d9cf86c6-65bd-4641-bf8f-a468c8c32cd8", "embedding": null, "metadata": {"Header_2": " **Key Takeaways: Enhancing RAG Pipelines Through Advanced Techniques and", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a248c8d4-1052-49e5-8e43-e8a82a277ccd", "node_type": "1", "metadata": {"Header_2": " **Addressing Points of Failure in RAG Pipelines**", "Header_3": " **3\\. Reranking Evaluations**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "1e7f792dff750d96fcc25c8a062945bdacbf3f52e20c10956dfee117efa0fd10", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "64486899-c29f-493c-aca7-8356c8afd96d", "node_type": "1", "metadata": {"Header_2": " **References**"}, "hash": "a0e59884a492e56c7d9fca9e79f17a991aafb5ef7db53e2db825f3f7e1225a28", "class_name": "RelatedNodeInfo"}}, "text": "**Key Takeaways: Enhancing RAG Pipelines Through Advanced Techniques and\nEvaluation**\n\nLet's do a quick recap here. We started off with a Vanilla RAG pipeline and\nevaluated the quality of the generated response and retrieved context. Then,\nwe moved to advanced RAG concepts like the SubQuery technique (used to combat\ncases with low Response Completeness scores) and the Reranking technique (used\nto improve the quality of retrieved context) and looked at advanced\nevaluations to quantify their performance.\n\nThis essentially provides a framework to systematically test the performance\nof different modules as well as evaluate if they actually lead to better\nquality responses by making data-driven decisions.\n\nMuch of the success in the field of Artificial intelligence can be attributed\nto experimentation with different architectures, hyperparameters, datasets,\netc., and our integration with UpTrain allows you to import those best\npractices while building RAG pipelines. Get started with uptrain with this [\nquickstart tutorial ](https://docs.uptrain.ai/getting-started/quickstart) .", "mimetype": "text/plain", "start_char_idx": 9349, "end_char_idx": 10437, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "64486899-c29f-493c-aca7-8356c8afd96d": {"__data__": {"id_": "64486899-c29f-493c-aca7-8356c8afd96d", "embedding": null, "metadata": {"Header_2": " **References**", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5034ac69-04b7-477e-89fc-4742a035a297", "node_type": "4", "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "f8100da6206ccae117431f581f3298b2dd95bb453c0f28929d830d1e83b389bb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d9cf86c6-65bd-4641-bf8f-a468c8c32cd8", "node_type": "1", "metadata": {"Header_2": " **Key Takeaways: Enhancing RAG Pipelines Through Advanced Techniques and", "filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}, "hash": "709572c17510260fe6d0b61201c991a34bb7f57524dba34c83d273753e9c2264", "class_name": "RelatedNodeInfo"}}, "text": "**References**\n\n  1. [ UpTrain Callback Handler Tutorial ](https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/callbacks/UpTrainCallback.ipynb)\n  2. [ UpTrain GitHub Repository ](https://github.com/uptrain-ai/uptrain)\n  3. [ Advanced RAG Techniques: an Illustrated Overview ](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6)\n  4. [ Lost in the Middle: How Language Models Use Long Contexts ](https://arxiv.org/pdf/2307.03172.pdf)\n  5. [ UpTrainCallbackHandler documentation ](https://docs.llamaindex.ai/en/stable/community/integrations/uptrain.html)\n  6. [ UpTrain Website ](https://uptrain.ai/)", "mimetype": "text/plain", "start_char_idx": 10443, "end_char_idx": 11112, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"3f38cdb0-6be8-45cb-865e-df5c4fd40323": {"doc_hash": "276b84c9ea3f1179073bc936ce5179b0b3c145bb67423029c0d2a98f9149e2ef", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "f470e5f0-c181-437e-966c-de7f2a798566": {"doc_hash": "70633a9a9473967aa53703e46d830492a06b86b0f09ea7b6e2f12b16af3453de", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "c30abf8a-2618-4bd1-899d-5932396e7f10": {"doc_hash": "3489d1dfca377ed22abc5d37154bf9cd5691e80465cfc4681d8f021416fe3f76", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "c97ef329-bfc9-4e77-9ef9-76f0822c5308": {"doc_hash": "fcee2b3a168fade7e2d4428b59797a954485ac6b534c2596bd4f5e9ec122bf99", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "9186e020-0b4f-4825-9f34-37a19de14d6b": {"doc_hash": "f651ac30f04d656f7b09c1de6f3910a818072755add5949fde560f91351a65a1", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "b07dfef7-baa6-4d83-8468-26934c70c213": {"doc_hash": "299ef984947cd1dc9c450d5da880b0c3b80517f20e54f755a21f630556f1c936", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "ff2104de-8b24-4892-a526-5ec9edbc2607": {"doc_hash": "839cb33cb591c7cf7f0f8c2bf24e1be88e73d714236a249a72bffdd04ce8e5ed", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "a248c8d4-1052-49e5-8e43-e8a82a277ccd": {"doc_hash": "1e7f792dff750d96fcc25c8a062945bdacbf3f52e20c10956dfee117efa0fd10", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "d9cf86c6-65bd-4641-bf8f-a468c8c32cd8": {"doc_hash": "709572c17510260fe6d0b61201c991a34bb7f57524dba34c83d273753e9c2264", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}, "64486899-c29f-493c-aca7-8356c8afd96d": {"doc_hash": "416b867b5cbc9fdd83cc497e7ce492c12d84cf1f99627c80a2fc1fddff2a381d", "ref_doc_id": "5034ac69-04b7-477e-89fc-4742a035a297"}}, "docstore/ref_doc_info": {"5034ac69-04b7-477e-89fc-4742a035a297": {"node_ids": ["3f38cdb0-6be8-45cb-865e-df5c4fd40323", "f470e5f0-c181-437e-966c-de7f2a798566", "c30abf8a-2618-4bd1-899d-5932396e7f10", "c97ef329-bfc9-4e77-9ef9-76f0822c5308", "9186e020-0b4f-4825-9f34-37a19de14d6b", "b07dfef7-baa6-4d83-8468-26934c70c213", "ff2104de-8b24-4892-a526-5ec9edbc2607", "a248c8d4-1052-49e5-8e43-e8a82a277ccd", "d9cf86c6-65bd-4641-bf8f-a468c8c32cd8", "64486899-c29f-493c-aca7-8356c8afd96d"], "metadata": {"filename": "supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations.md", "extension": ".md", "title": "Supercharge your LlamaIndex RAG Pipeline with UpTrain Evaluations", "date": "Mar 19, 2024", "url": "https://www.llamaindex.ai/blog/supercharge-your-llamaindex-rag-pipeline-with-uptrain-evaluations"}}}}