{"docstore/data": {"e2176012-b837-44b0-898f-ad7dc0843c4c": {"__data__": {"id_": "e2176012-b837-44b0-898f-ad7dc0843c4c", "embedding": null, "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b01fd65c-ccf4-4774-9d0b-04502251db23", "node_type": "1", "metadata": {"Header_1": " High-Level Findings"}, "hash": "66fb8575b1db9a111792ad5350dcca0e7f91f176c23e14117a862ab4016ce9b1", "class_name": "RelatedNodeInfo"}}, "text": "Anthropic\u2019s [ 100K Context Window\n](https://www.anthropic.com/index/100k-context-windows) expansion, just\nreleased yesterday, has taken the AI community by storm. A 100k token limit is\napproximately 75k words (~3x GPT4\u201332k\u2019s context window, ~25x that of\nGPT-3.5/ChatGPT); this means that you can now fit 300 pages of text in a\n_single_ inference call _._\n\nOne of the core use cases highlighted in the Anthropic blog is [ analyzing an\nSEC 10-K filing ](https://vimeo.com/825669443) ; the model is capable of\ningesting the entire report, and producing answers to different questions.\n\nCoincidentally, we [ published a tutorial\n](https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-\nbring-the-power-of-llms-to-your-own-data-3657d063e30d) a few months ago\nshowing how LlamaIndex + Unstructured + GPT3 could help you perform different\nqueries over UBER SEC 10-k filings. LlamaIndex provides a comprehensive\ntoolkit to help manage external data on top of any LLM with limited context\nwindows, and we show that we can execute a diverse range of queries, from\nquestions over a single document to comparing sections across documents.\n\nHow well does Anthropic\u2019s 100k model do over UBER SEC 10-k filings? Moreover,\nhow well does it do _without_ the help of any of LlamaIndex\u2019s more advanced\ndata structures? In this blog we show the performance of Anthropic\u2019s model on\ndifferent queries, using the simplest data structure available: the list\nindex.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1458, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b01fd65c-ccf4-4774-9d0b-04502251db23": {"__data__": {"id_": "b01fd65c-ccf4-4774-9d0b-04502251db23", "embedding": null, "metadata": {"Header_1": " High-Level Findings", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e2176012-b837-44b0-898f-ad7dc0843c4c", "node_type": "1", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "cd8675edd0bdf8e43f820726f04173b1ee5e550271204862f0778f1c87b7cfd5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f306ad85-8799-4b87-b21d-da529c9abd0d", "node_type": "1", "metadata": {"Header_1": " Overview of Methodology"}, "hash": "87800b39612fb1ed1ec1dc67c80617687f85c8b86be91ff833911bccc0c325d0", "class_name": "RelatedNodeInfo"}}, "text": "High-Level Findings\n\nWhere Anthropic\u2019s 100k model does well:\n\n  * **Holistic understanding of the data (kind of, after some prompt tuning):** Anthropic\u2019s model does demonstrate an impressive capability to synthesize insights across the entire context window to answer the question at hand (assuming we set ` response_mode=\"tree_summarize\" ` , see below). It can miss details though; see below! \n  * **Latency:** This one was surprising to us. Anthropic\u2019s model is able to crunch an entire UBER 10-k filing in ~60\u201390 seconds, which seems long but is much faster than repeated API calls to GPT-3 (which when added up can take minutes). \n\nWhere Anthropic\u2019s 100k model doesn\u2019t do well:\n\n  * **Cost:** This one is obvious. Every query we ran processed hundreds of thousands of tokens. At [ $11 per million tokens for Claude-v1 ](https://console.anthropic.com/account/pricing) , this equates to $1 per query, which can quickly add up. \n  * **Reasoning over more complicated prompts:** Anthropic\u2019s model demonstrated a surprising lack of ability to understand our refine prompt for [ \u201ccreate-and-refine\u201d response synthesis ](https://gpt-index.readthedocs.io/en/latest/how_to/query/response_synthesis.html#refine) , returning incorrect/irrelevant results. We ended up switching to [ \u201ctree summarization\u201d instead ](https://gpt-index.readthedocs.io/en/latest/how_to/query/response_synthesis.html#tree-summarize) . See below for results.", "mimetype": "text/plain", "start_char_idx": 1463, "end_char_idx": 2889, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f306ad85-8799-4b87-b21d-da529c9abd0d": {"__data__": {"id_": "f306ad85-8799-4b87-b21d-da529c9abd0d", "embedding": null, "metadata": {"Header_1": " Overview of Methodology", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b01fd65c-ccf4-4774-9d0b-04502251db23", "node_type": "1", "metadata": {"Header_1": " High-Level Findings", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "8e6af32e3917932b18ab9518cbec397e263dcae1d82c658285833ded52f60ff1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45e90650-32e5-410a-8665-39f6d6e63256", "node_type": "1", "metadata": {"Header_1": " Tutorial Setup"}, "hash": "67e47723c52c193d0f3f8965968a7b82cfc5c2310711a5de4f190433776726ff", "class_name": "RelatedNodeInfo"}}, "text": "Overview of Methodology\n\nWe want to test the capabilities of Anthropic\u2019s 100K model on top of UBER 10-k\nfilings from 2019\u20132022. We also want to do this while using as little\nretrieval/synthesis constructs as possible. This means no embeddings, and no\nfancy retrieval mechanisms.\n\nIdeally, we can directly insert an entire 10-k filing (or even all four 10-k\nfilings) into the prompt. However, we found that a single UBER 10-k filing\nactually consists of ~ **160k tokens, which is greater than the 100k context\nwindow.** This means that we still have to chunk up each filing!\n\nWe end up using our [ list index data structure ](https://gpt-\nindex.readthedocs.io/en/latest/guides/primer/index_guide.html#querying) \u2014 we\nsplit each text up into massive ~100k token chunks, and use our **response\nsynthesis strategies** to synthesize an answer across multiple chunks.\n\nWe run some queries over each filing as well as over multiple filings, similar\nto our original blog post. We report the results below.", "mimetype": "text/plain", "start_char_idx": 2895, "end_char_idx": 3891, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "45e90650-32e5-410a-8665-39f6d6e63256": {"__data__": {"id_": "45e90650-32e5-410a-8665-39f6d6e63256", "embedding": null, "metadata": {"Header_1": " Tutorial Setup", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f306ad85-8799-4b87-b21d-da529c9abd0d", "node_type": "1", "metadata": {"Header_1": " Overview of Methodology", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "bb70c927678030e8b029f360289aaed71c0a2c431872dc9273a3b70d75a670eb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1dc1f9b-8c0b-44da-91cf-a1c870086a72", "node_type": "1", "metadata": {"Header_1": " Analyzing a Single Document"}, "hash": "8d74b1232195ccf3da0d75749d00a93846ae0227d3263da181045e0f017d7378", "class_name": "RelatedNodeInfo"}}, "text": "Tutorial Setup\n\nOur data ingestion is the same as the LlamaIndex + Unstructured blog post. We\nuse Unstructured\u2019s HTML parser to parse the HTML DOM into nicely formatted\ntext. We then create a Document object for each SEC filing.\n\nYou can access Unstructured data loaders on [ LlamaHub\n](https://llamahub.ai/l/file-unstructured) .\n\n    \n    \n    from llama_index import download_loader\n    from pathlib import Path\n    \n    UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)\n    \n    loader = UnstructuredReader()\n    doc_set = {}\n    all_docs = []\n    years = [2022, 2021, 2020, 2019]\n    for year in years:\n        year_doc = loader.load_data(file=Path(f'./data/UBER/UBER_{year}.html'), split_documents=False)[0]\n        # insert year metadata into each year\n        year_doc.extra_info = {\"year\": year}\n        doc_set[year] = year_doc\n        all_docs.append(year_doc)\n\nNext, we want to setup the Anthropic LLM. We\u2019re using claude-v1 by default. We\nalso want to manually define the new 100k-token input size within our `\nPromptHelper ` object; this will help us figure out how to \u201ccompact\u201d context\ninto the input prompt space during response synthesis.\n\nWe set the ` max_input_size ` to 100k and the output length to 2048. We also\nset the context chunk size to a high value (95k, leaving some buffer room for\nrest of the prompt). Context will only be chunked if the number of tokens\nexceeds this limit.\n\n    \n    \n    from llama_index import PromptHelper, LLMPredictor, ServiceContext\n    from langchain.llms import Anthropic\n    \n    # define prompt helper\n    # set maximum input size\n    max_input_size = 100000\n    # set number of output tokens\n    num_output = 2048\n    # set maximum chunk overlap\n    max_chunk_overlap = 20\n    prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n    \n    llm_predictor = LLMPredictor(llm=Anthropic(model=\"claude-v1.3-100k\", temperature=0, max_tokens_to_sample=num_output))\n    service_context = ServiceContext.from_defaults(\n        llm_predictor=llm_predictor, prompt_helper=prompt_helper,\n        chunk_size_limit=95000\n    )", "mimetype": "text/plain", "start_char_idx": 3896, "end_char_idx": 6018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c1dc1f9b-8c0b-44da-91cf-a1c870086a72": {"__data__": {"id_": "c1dc1f9b-8c0b-44da-91cf-a1c870086a72", "embedding": null, "metadata": {"Header_1": " Analyzing a Single Document", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45e90650-32e5-410a-8665-39f6d6e63256", "node_type": "1", "metadata": {"Header_1": " Tutorial Setup", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "b4094b72ae7956ac0b55c314e2a116c5db6f324b1baf6c9191993544ee3c40bf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "03d66a53-16f0-4eb3-88b6-089fc03eeb10", "node_type": "1", "metadata": {"Header_1": " Analyzing a Single Document", "Header_2": " Token Usage and Latency"}, "hash": "86419ddf129053b9b8ea23b5889e90ebbd684c38fb5fe70c65affab936f316ce", "class_name": "RelatedNodeInfo"}}, "text": "Analyzing a Single Document\n\nLet\u2019s first analyze queries over a single document. We build a list index over\nthe 2019 UBER 10-K:\n\n    \n    \n    list_index = GPTListIndex.from_documents([doc_set[2019]], service_context=service_context)\n    print(len(list_index.index_struct.nodes))\n\nAs mentioned, the 10-K exceeds the 100k token limit, and so there are two\nnodes within the list index.\n\nWe then ask a query: \u201cWhat were some of the biggest risk factors in 2019?\u201d\n\nRecall that there are two approaches within LlamaIndex for response synthesis\nacross multiple nodes (where the total context exceeds the context window): a\n\u201ccreate-and-refine\u201d strategy, and a \u201ctree summarize\u201d strategy.\n\n  * **Create-and-Refine:** sequentially go through each retrieved ` Node ` . Use a Question-Answer Prompt for the first Node, and use a Refine Prompt for subsequent Nodes. Make a separate LLM call per Node. \n  * **Tree Summarize:** Given a set of ` Node ` objects and the query, recursively construct a tree using the Question Answer Prompt and return the root node as the response. Good for summarization purposes. \n\nClaude-v1 100K does not do well with the \u201ccreate-and-refine\u201d strategy (which\nis the default).\n\n    \n    \n    # NOTE: the default create/refine approach does not give good answers\n    query = \"What were some of the biggest risk factors in 2019?\"\n    query_engine = list_index.as_query_engine(service_context=service_context)\n    response = query_engine.query(query)\n\nHere is the retrieved answer:\n\n    \n    \n    Original answer:\n    \n    Some of the biggest risk factors for Uber in 2019 included:\n    \n    \u2022 Regulatory challenges and uncertainty. Uber faced regulatory challenges and uncertainty in many markets, including restrictions on its products and services, caps on pricing, and licensing requirements. For example, California's AB5 law and other similar laws increased the risk of Drivers being classified as employees. Uber also faced regulatory scrutiny and bans in London, Barcelona, and other markets.\n    \n    \u2022 Competition. The markets in which Uber operates are highly competitive, and Uber faced significant competition from well-established and low-cost alternatives in 2019. Competitors also aggressively competed for Drivers and consumers by offering significant incentives and discounts. \n    \n    \u2022 Safety and security. There were risks related to the safety and security of Uber's platform, including risks from vehicle or scooter accidents, assaults, and other incidents. Uber released a safety report in 2019 detailing reports of sexual assaults on its platform which brought additional scrutiny.\n    \n    \u2022 Financial performance and profitability. Uber continued to experience significant losses in 2019 as it invested in growth. There was no guarantee that Uber would achieve or sustain profitability in the future.  \n    \n    \u2022 Reliance on third parties. Uber relied on third parties for key elements of its business like cloud computing services, payment processing, and background checks. If these third parties failed to provide services or increased costs, it could adversely impact Uber's business.\n    \n    \u2022 Macroeconomic conditions. Uber's business was sensitive to economic conditions and changes that impacted discretionary consumer spending. A decline in the economy could reduce demand for Uber's products and services.  \n    \n    \u2022 Reliance on Drivers and Restaurants. Uber's success depended on attracting and retaining enough Drivers and Restaurants to its platform. If Uber was unable to attract or retain enough Drivers and Restaurants, it could negatively impact its operations.\n    \n    \u2022 Intellectual property. If Uber was unable to protect its intellectual property, or if third parties claimed Uber was infringing on their intellectual property, it could harm Uber's business. Uber relied on a combination of copyright, trademark, patent, and trade secret laws to establish its intellectual property rights.\n    \n    Refined answer:\n    \n    Some of the biggest risk factors for Uber in 2019 included:\n    \n    \u2022 Regulatory challenges and uncertainty. Uber faced significant regulatory challenges in 2019, including AB5 in California which increased the risk of Drivers being classified as employees and regulatory scrutiny and temporary bans in London and other markets. These regulatory issues created uncertainty and posed risks to Uber's business model and financial results.\n    \n    \u2022 Competition. The ridesharing and meal delivery markets are highly competitive, and competitors offered significant incentives and discounts to take market share from Uber in 2019. This competition could negatively impact Uber's growth and profitability.\n    \n    \u2022 Safety and security. There were risks related to the safety and security of Uber's platform, including risks from vehicle or scooter accidents, assaults, and other incidents. Uber's safety report detailing sexual assault reports brought additional scrutiny and risks. Any failure to ensure safety could significantly damage Uber's reputation and business.\n    \n    \u2022 Financial performance and profitability. Uber continued to experience substantial losses in 2019 due to investments in growth, and there was no guarantee of future profitability. Uber's path to profitability was uncertain, and failure to become profitable could threaten its business model and access to capital.  \n    \n    \u2022 Reliance on third parties. Uber relied on third parties for services like cloud computing, payment processing, and background checks. If these third parties failed to provide services or increased costs, it could negatively impact Uber's offerings, growth, and profitability.  \n    \n    \u2022 Macroeconomic conditions. Uber's business was sensitive to the economy and consumer discretionary spending. An economic downturn could reduce demand for Uber's offerings and threaten its growth and financial performance.\n    \n    \u2022 Reliance on Drivers and Restaurants. Uber's success depended on attracting and retaining enough Drivers and Restaurants to support growth and meet consumer demand. Failure to attract or retain Drivers and Restaurants could significantly impact Uber's business.  \n    \n    \u2022 Intellectual property. Failure to protect intellectual property or infringement of others' intellectual property could damage Uber's competitive position and business. Uber relied on laws and policies to protect intellectual property, but monitoring infringement and unauthorized use was difficult.\n\nAs shown, the answer contains the prompt within it; the point of the refine\nprompt was to produce just the refined answer, not produce both the original\nand refined answers.\n\nFor some reason, using the Tree Summarize strategy works much better.\n\n    \n    \n    # NOTE: tree_summarize gives better answers\n    query = \"What were some of the biggest risk factors in 2019?\"\n    query_engine = list_index.as_query_engine(service_context=service_context, response_mode=\"tree_summarize\")\n    response = query_engine.query(query)\n\nReturned response:\n\n    \n    \n    \u2022 Regulatory challenges and uncertainty: Uber faced significant regulatory challenges and uncertainty in 2019, including AB5 in California which codified a new test for determining whether workers should be classified as employees or independent contractors. Uber also faced regulatory scrutiny and bans in other markets like London, UK. These regulatory issues created uncertainty and risk around Uber's business model and operations.\n    \n    \u2022 Safety and security: Uber received negative publicity around safety incidents on its platform which could damage its brand and reputation. Uber released a safety report in 2019 on sexual assaults and other incidents which led to additional scrutiny. Safety and security risks remain an ongoing issue for Uber's business.\n    \n    \u2022 Competition: The markets in which Uber competes are intensely competitive, and Uber faces competition from new and existing companies in the various segments it operates in like ridesharing, food delivery, and logistics. Increased competition could make it difficult for Uber to attract and retain platform users.\n    \n    \u2022 Financial losses: Uber continued to experience significant losses from operations in 2019 as it invested in growth. Uber may not achieve or sustain profitability in the future which could negatively impact its business and stock price.\n    \n    \u2022 Reliance on third-parties: Uber relies on third-party data centers, cloud computing services, and software which exposes it to risks if these third-parties experience any disruptions or interference. Any disruption of third-party services could negatively impact Uber's business.\n    \n    \u2022 Macroeconomic conditions: Uber's business is sensitive to macroeconomic conditions, and any downturn could reduce discretionary consumer spending which would harm Uber's business. Issues like a recession, increased unemployment, or reduced consumer confidence could all potentially impact Uber's business.\n    \n    \u2022 Reliance on Drivers and Restaurants: Uber's business depends on attracting and retaining Drivers and Restaurants to its platform. If Uber is unable to attract or maintain a critical mass of Drivers and Restaurants, its platform will become less appealing to platform users and its financial results would be adversely impacted.\n\nThe answer is much better. It goes into details about the US-China trade war,\nslowing economic growth, Brexit, and more (keep in mind 2019 is pre-COVID).", "mimetype": "text/plain", "start_char_idx": 6023, "end_char_idx": 15514, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03d66a53-16f0-4eb3-88b6-089fc03eeb10": {"__data__": {"id_": "03d66a53-16f0-4eb3-88b6-089fc03eeb10", "embedding": null, "metadata": {"Header_1": " Analyzing a Single Document", "Header_2": " Token Usage and Latency", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1dc1f9b-8c0b-44da-91cf-a1c870086a72", "node_type": "1", "metadata": {"Header_1": " Analyzing a Single Document", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "417a4efed1e283ca5884613d71904a9f3c89e7074ac043ecc1e61cabfe81f25d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "709340a6-3088-4b8a-95ab-56eac629053a", "node_type": "1", "metadata": {"Header_1": " Analyzing Multiple Documents"}, "hash": "3899253680872ebfd80e21ff5f0daee2fe0efe6c35210d26a0fe4e40a08a7207", "class_name": "RelatedNodeInfo"}}, "text": "Token Usage and Latency\n\nThe document contains around ~170K tokens. For some reason, this number is not\nreflected on the Anthropic usage logs (the \u201cPrompt Tokens\u201d section seems\ncapped at 10240). But the Prompt Length (in characters) is logged, as well as\nthe model latency.\n\nGiven the pricing, ~170K tokens would be equivalent to $1.5\u20132 USD.\n\nA query through one Uber SEC-10K takes around **150** **seconds** , including\nall LLM calls. This is actually a bit faster than repeated calls to\nChatGPT/davinci. Each ChatGPT/davinci call (with the 4K token window\nmaximized), empirically can take 6\u201310 seconds to complete \u2192 **125\u2013250 seconds\n(** or more).", "mimetype": "text/plain", "start_char_idx": 15520, "end_char_idx": 16169, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "709340a6-3088-4b8a-95ab-56eac629053a": {"__data__": {"id_": "709340a6-3088-4b8a-95ab-56eac629053a", "embedding": null, "metadata": {"Header_1": " Analyzing Multiple Documents", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "03d66a53-16f0-4eb3-88b6-089fc03eeb10", "node_type": "1", "metadata": {"Header_1": " Analyzing a Single Document", "Header_2": " Token Usage and Latency", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "adf87aafb4f24b92b1c6d6164228b94df74a9dd8f1bcb9da30accdb90c9db969", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e2947ecc-fc1c-4a3f-9551-428108b3a0d6", "node_type": "1", "metadata": {"Header_1": " Analyzing Multiple Documents", "Header_2": " **Token Usage and Latency**"}, "hash": "b60671e2b27489b818679cdd960389d6b51b42f7d3a4ff763af6d91006e6f2b3", "class_name": "RelatedNodeInfo"}}, "text": "Analyzing Multiple Documents\n\nA popular example in our [ previous blog post\n](https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-\nbring-the-power-of-llms-to-your-own-data-3657d063e30d) was showcasing that you\ncould compare/contrast different documents with LlamaIndex graph structures.\n\nWe test whether we can do that here as well, by feeding in multiple SEC\nreports into Claude-v1 100k.\n\n**Caveat:** Considering that one UBER SEC-10K filing doesn\u2019t even fit in the\ncontext window, we\u2019ll of course also need to implement response synthesis\nstrategies in order to handle ingesting multiple 10K filings.\n\nWe build a list index over all 4 10K filings: 2019, 2020, 2021, and 2022.\n\n    \n    \n    list_index = GPTListIndex.from_documents(all_docs, service_context=service_context)\n    print(len(list_index.index_struct.nodes))\n\nWe then ask our question using our Tree Summarize response mode.\n\n    \n    \n    query = \"How are the risk factors changing across years? Compare/contrast the risk factors across the SEC filings.\"\n    query_engine = list_index.as_query_engine(response_mode=\"tree_summarize\")\n    response = query_engine.query(query)\n\nThe full answer is given below:\n\n    \n    \n    The risk factors disclosed in Uber's SEC filings have evolved over time based on Uber's business and industry changes. Some of the key differences in risk factors across the filings are:\n    \n    2017 10-K:\n    - Focused heavily on risks related to negative publicity, competition, dependence on independent contractors, and regulatory challenges as Uber was still facing backlash from various PR crises and regulatory pushback. \n    - Also highlighted risks from intellectual property litigation given various IP disputes at the time.\n    \n    2018 10-K:\n    - Added more risks related to autonomous vehicles as Uber ramped up its self-driving car efforts. Specifically called out risks from accidents, technical challenges, and competition in the AV space.\n    - Removed some risks related to negative publicity and PR crises as those issues had subsided. But added risks related to corporate culture and workplace environment given the Fowler scandal.\n    \n    2019 10-K: \n    - Further expanded AV risks to include risks from partnerships and third party relationships as Uber relied more on partnerships with other companies like Toyota and Volvo. \n    - Added risks related to environmental regulations and climate change as those issues received more mainstream attention. \n    - Removed risks related to initial scaling challenges as Uber had matured as a company. But added risks related to growth into new offerings and markets as Uber expanded into freight shipping, scooters, etc.\n    \n    In summary, Uber's risk factors have evolved to reflect the key issues and challenges facing the company at any point in time. The risks highlight both external factors like regulations as well as internal factors related to Uber's business, technology, and operations. The changes over time show how an innovative company's risks can shift quite quickly.\n    \n    Some of the key trends in how the risk factors are changing include:\n    \n    1. Risks related to negative publicity and PR crises decreased over time as those issues subsided, while risks related to other issues like AV technology, workplace culture, and new initiatives increased. This shows how Uber's risks evolved as the company matured.\n    \n    2. Risks tend to increase in areas where Uber is actively investing or expanding into. For example, risks related to AVs, partnerships, and new mobility offerings increased as Uber ramped up efforts in those areas. This highlights how risk profiles change with a company's strategic priorities.\n    \n    3. External risks like regulations and climate change were added as those issues gained more mainstream attention and importance. This shows how companies have to adapt their risk factors to account for changes in the overall business environment. \n    \n    4. Certain foundational risks around competition, growth, and reliance on independent contractors persisted over time. But the specifics and details provided for those risks evolved based on Uber's current challenges and priorities. So while the themes remained, the risks were actively updated.\n    \n    In summary, Uber's risk factors changed over time to provide more details on the company's priorities, challenges, partnerships, and external environment at any given point. But certain core risks inherent to Uber's business model have also remained consistently highlighted, demonstrating how those foundational risks are long-term in nature. The changes in risks over time provide a glimpse into how an innovative company's risk profile is constantly evolving.\n\nThis response only contains risk refactor analysis over the 2019 10-K (which\nin turn contains risk refactors for 2017 and 2018). It does not contain the\nyears from 2020 onwards. Part of this is potentially due to our tree summarize\nresponse synthesis strategy. Nevertheless, it shows that trying to naively\n\u201cstuff\u201d documents into big 100K token chunks with simple response synthesis\nstrategies still does not produce the optimal answers.", "mimetype": "text/plain", "start_char_idx": 16174, "end_char_idx": 21369, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e2947ecc-fc1c-4a3f-9551-428108b3a0d6": {"__data__": {"id_": "e2947ecc-fc1c-4a3f-9551-428108b3a0d6", "embedding": null, "metadata": {"Header_1": " Analyzing Multiple Documents", "Header_2": " **Token Usage and Latency**", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "709340a6-3088-4b8a-95ab-56eac629053a", "node_type": "1", "metadata": {"Header_1": " Analyzing Multiple Documents", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "b3a05877ac200ae91c4fcdda64b915dd2e695e0e97f1bfd4c5abf1dd4d25d394", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58d5e5cb-6ecb-4952-a147-47d2151b13d8", "node_type": "1", "metadata": {"Header_1": " Conclusion"}, "hash": "32b09782a9c518b48b2f4f429233d71cb5ec95db6c18c27c4d2272f5d27e4c84", "class_name": "RelatedNodeInfo"}}, "text": "**Token Usage and Latency**\n\nAs expected, feeding all four documents into Anthropic necessitates many more\nchained LLM calls, which consumes way more tokens and takes a lot longer (on\nthe order of 9\u201310 minutes).", "mimetype": "text/plain", "start_char_idx": 21375, "end_char_idx": 21586, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "58d5e5cb-6ecb-4952-a147-47d2151b13d8": {"__data__": {"id_": "58d5e5cb-6ecb-4952-a147-47d2151b13d8", "embedding": null, "metadata": {"Header_1": " Conclusion", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e2947ecc-fc1c-4a3f-9551-428108b3a0d6", "node_type": "1", "metadata": {"Header_1": " Analyzing Multiple Documents", "Header_2": " **Token Usage and Latency**", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "671e60031fded9f21c9d056e4b1ae1b0b3278e980d8c38d62a33c888dc380eb2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "564c61e9-6a45-4545-bf43-afe47f8fa9c3", "node_type": "1", "metadata": {"Header_1": " Conclusion", "Header_2": " Resources"}, "hash": "fe91dddee915d02d456b2df899699d62a32fe2375965e60c701e0ee31db66291", "class_name": "RelatedNodeInfo"}}, "text": "Conclusion\n\nIn general, the new 100K context window is incredibly exciting and offers\ndevelopers a new mode of feeding in data into the LLM for different\ntasks/queries. It offers coherent analysis with a marginal token cost that is\nmuch cheaper than that of GPT-4.\n\nThat said, trying to maximize this context window with each inference call\ndoes come with tradeoffs in terms of latency and cost.\n\nWe look forward to doing more experiments/comparisons/thought pieces on top of\nClaude! Let us know your feedback.", "mimetype": "text/plain", "start_char_idx": 21591, "end_char_idx": 22101, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "564c61e9-6a45-4545-bf43-afe47f8fa9c3": {"__data__": {"id_": "564c61e9-6a45-4545-bf43-afe47f8fa9c3", "embedding": null, "metadata": {"Header_1": " Conclusion", "Header_2": " Resources", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36", "node_type": "4", "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "d23518db6ea14b22a2bcfeed1a8db3a97e45ad3edbbb75c07d3f4f421ba4c37a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58d5e5cb-6ecb-4952-a147-47d2151b13d8", "node_type": "1", "metadata": {"Header_1": " Conclusion", "filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}, "hash": "0618fbf90bbe6a982a8f5a33385c58c649cd0c1d1a3690b3e4125089b1b27e2a", "class_name": "RelatedNodeInfo"}}, "text": "Resources\n\nYou can check out our [ full Colab notebook here\n](https://colab.research.google.com/drive/1uuqvPI2_WNFMd7g-ahFoioSHV7ExB2GR?usp=sharing)\n.", "mimetype": "text/plain", "start_char_idx": 22107, "end_char_idx": 22257, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"e2176012-b837-44b0-898f-ad7dc0843c4c": {"doc_hash": "cd8675edd0bdf8e43f820726f04173b1ee5e550271204862f0778f1c87b7cfd5", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "b01fd65c-ccf4-4774-9d0b-04502251db23": {"doc_hash": "8e6af32e3917932b18ab9518cbec397e263dcae1d82c658285833ded52f60ff1", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "f306ad85-8799-4b87-b21d-da529c9abd0d": {"doc_hash": "bb70c927678030e8b029f360289aaed71c0a2c431872dc9273a3b70d75a670eb", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "45e90650-32e5-410a-8665-39f6d6e63256": {"doc_hash": "b4094b72ae7956ac0b55c314e2a116c5db6f324b1baf6c9191993544ee3c40bf", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "c1dc1f9b-8c0b-44da-91cf-a1c870086a72": {"doc_hash": "417a4efed1e283ca5884613d71904a9f3c89e7074ac043ecc1e61cabfe81f25d", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "03d66a53-16f0-4eb3-88b6-089fc03eeb10": {"doc_hash": "adf87aafb4f24b92b1c6d6164228b94df74a9dd8f1bcb9da30accdb90c9db969", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "709340a6-3088-4b8a-95ab-56eac629053a": {"doc_hash": "b3a05877ac200ae91c4fcdda64b915dd2e695e0e97f1bfd4c5abf1dd4d25d394", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "e2947ecc-fc1c-4a3f-9551-428108b3a0d6": {"doc_hash": "671e60031fded9f21c9d056e4b1ae1b0b3278e980d8c38d62a33c888dc380eb2", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "58d5e5cb-6ecb-4952-a147-47d2151b13d8": {"doc_hash": "0618fbf90bbe6a982a8f5a33385c58c649cd0c1d1a3690b3e4125089b1b27e2a", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}, "564c61e9-6a45-4545-bf43-afe47f8fa9c3": {"doc_hash": "0787bd79f065bb00e19162ba43a288a185d0933f2f0989a9ad7cb74a86503e3d", "ref_doc_id": "18110991-f15d-4396-a81a-5ffe5c6c3b36"}}, "docstore/ref_doc_info": {"18110991-f15d-4396-a81a-5ffe5c6c3b36": {"node_ids": ["e2176012-b837-44b0-898f-ad7dc0843c4c", "b01fd65c-ccf4-4774-9d0b-04502251db23", "f306ad85-8799-4b87-b21d-da529c9abd0d", "45e90650-32e5-410a-8665-39f6d6e63256", "c1dc1f9b-8c0b-44da-91cf-a1c870086a72", "03d66a53-16f0-4eb3-88b6-089fc03eeb10", "709340a6-3088-4b8a-95ab-56eac629053a", "e2947ecc-fc1c-4a3f-9551-428108b3a0d6", "58d5e5cb-6ecb-4952-a147-47d2151b13d8", "564c61e9-6a45-4545-bf43-afe47f8fa9c3"], "metadata": {"filename": "testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba.md", "extension": ".md", "title": "Testing Anthropic Claude\u2019s 100k-token window on SEC 10-K Filings", "date": "May 12, 2023", "url": "https://www.llamaindex.ai/blog/testing-anthropic-claudes-100k-token-window-on-sec-10-k-filings-473310c20dba"}}}}