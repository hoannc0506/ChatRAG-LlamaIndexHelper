{"docstore/data": {"300e3744-518b-43cd-be30-fc67c409109c": {"__data__": {"id_": "300e3744-518b-43cd-be30-fc67c409109c", "embedding": null, "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18", "node_type": "4", "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "833bde702cdf6187927ff5bebb67291677f77dc2e3e2adf4665d7c7ccc8d6713", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a8343567-ef22-4060-9b9e-b745e8220f46", "node_type": "1", "metadata": {"Header_1": " Introduction"}, "hash": "fcf5dd1be80201f620c8c014142141c18439d6e94d555fe90122a1a8d1b02fc5", "class_name": "RelatedNodeInfo"}}, "text": "_In this technical walkthrough, we\u2019ll highlight the functionality of Tonic\nValidate and its integration with LlamaIndex. Sign up for a free account_ [\n_here_ ](https://www.tonic.ai/validate) _before you start._", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 210, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a8343567-ef22-4060-9b9e-b745e8220f46": {"__data__": {"id_": "a8343567-ef22-4060-9b9e-b745e8220f46", "embedding": null, "metadata": {"Header_1": " Introduction", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18", "node_type": "4", "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "833bde702cdf6187927ff5bebb67291677f77dc2e3e2adf4665d7c7ccc8d6713", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "300e3744-518b-43cd-be30-fc67c409109c", "node_type": "1", "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "673e3ccdf19d293c12ca6fc980e71eddbb1b3754ea44391d78ad2e9659c3f316", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "938ac513-cf61-4871-bd09-8689b106d943", "node_type": "1", "metadata": {"Header_1": " What is Tonic Validate?"}, "hash": "6f6212d44c420ce72ab4c586a62b8a3477fbd53c436edd9e518b8ffaa8a1a92e", "class_name": "RelatedNodeInfo"}}, "text": "Introduction\n\nAs enterprise adoption of generative AI technologies continues, companies are\nturning to Retrieval Augmented Generation (RAG) systems to extend the\napplication of large-language models (LLMs) to their private data (e.g., a\nchatbot that can answer questions based on internal technical documentation).\nTraditionally in software engineering, companies have placed a high emphasis\non implementing continuous integration tests to ensure systems remain\nperformant when updates are made. More recently, these same principles have\nbeen applied to machine learning models in production.\n\nHowever, as a young technology, RAG currently lacks best practices for\nintegration tests to ensure breaking changes aren\u2019t introduced to the\nproduction system. In this article, we will demonstrate how you can use Tonic\nValidate\u2019s RAG performance monitoring capabilities, LlamaIndex, and GitHub\nActions to create novel integration tests that alert you to changes in RAG\nsystem performance. To make things easy, Tonic Validate is available natively\nwithin LlamaIndex\u2019s core library \u2014 you can read more about that [ here\n](https://www.tonic.ai/blog/tonic-ai-and-llamaindex-join-forces-to-help-\ndevelopers-build-more-performant-rag-systems) .", "mimetype": "text/plain", "start_char_idx": 215, "end_char_idx": 1447, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "938ac513-cf61-4871-bd09-8689b106d943": {"__data__": {"id_": "938ac513-cf61-4871-bd09-8689b106d943", "embedding": null, "metadata": {"Header_1": " What is Tonic Validate?", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18", "node_type": "4", "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "833bde702cdf6187927ff5bebb67291677f77dc2e3e2adf4665d7c7ccc8d6713", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8343567-ef22-4060-9b9e-b745e8220f46", "node_type": "1", "metadata": {"Header_1": " Introduction", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "120a7e62d0e27c0c942ef18dc4f78f57b82faebb5a9101c266006a51748142af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7a437738-90e1-4457-bc7d-add2680b07bf", "node_type": "1", "metadata": {"Header_1": " Setting up LlamaIndex"}, "hash": "8bf244d9e191bcfe08210103f7ea8017172372de5428557ad6ac9c383c22ac2e", "class_name": "RelatedNodeInfo"}}, "text": "What is Tonic Validate?\n\nTonic Validate is a RAG benchmarking and evaluation platform that monitors\nperformance of RAG systems in production. It provides comprehensive metrics\nfor measuring the performance of each component in your RAG system,\nvisualizations for comparing performance across time as the system changes,\nand workflows for creating benchmark question-answer sets and reviewing LLM\nresponses. Tonic Validate shines a light on how your RAG system is truly\nperforming, enabling continuous performance monitoring of your production RAG\nsystems. You can [ learn more ](https://www.tonic.ai/validate) and [ sign up\nfor a free account ](https://validate.tonic.ai/) .", "mimetype": "text/plain", "start_char_idx": 1452, "end_char_idx": 2126, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7a437738-90e1-4457-bc7d-add2680b07bf": {"__data__": {"id_": "7a437738-90e1-4457-bc7d-add2680b07bf", "embedding": null, "metadata": {"Header_1": " Setting up LlamaIndex", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18", "node_type": "4", "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "833bde702cdf6187927ff5bebb67291677f77dc2e3e2adf4665d7c7ccc8d6713", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "938ac513-cf61-4871-bd09-8689b106d943", "node_type": "1", "metadata": {"Header_1": " What is Tonic Validate?", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "6d8efc9a3e67a4a42644a3edef1895664e3619b0fa6983349e4e340ee9e8a57a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "df7eafcc-1372-4b44-839a-cd102e30a46a", "node_type": "1", "metadata": {"Header_1": " Setting up Tonic Validate"}, "hash": "620e9a3becf3e84aeccbc2a91aa9c6ffabf83c7af7fd9f656c17224d8b9eaa88", "class_name": "RelatedNodeInfo"}}, "text": "Setting up LlamaIndex\n\nTo get started, let\u2019s create an example RAG system for us to test. In this\ncase, LlamaIndex provides a tool called ` create-llama ` which can generate a\nfull-stack RAG application for us. To install it, we need to make sure we have\nNode.JS installed and run the following command:\n\n    \n    \n    npx create-llama@latest\n\nThis command will take you through a series of prompts. Here are the options\nto select for each prompt:\n\n    \n    \n    What is your project named? \u00bb llama-validate-demo\n    Which template would you like to use? \u00bb Chat without streaming\n    Which framework would you like to use? \u00bb FastAPI (Python)\n    Would you like to install dependencies automatically? \u00bb No\n    Which model would you like to use? \u00bb gpt-4\u20131106-preview\n    Which data source would you like to use? \u00bb Use an example PDF\n    Would you like to use a vector database? \u00bb No, just store the data in the file system\n\nOnce these options are selected, your project should be created in a folder\ncalled ` llama-validate-demo ` . For this demo, we are going to replace the\nexample PDF ` create-llama ` provides with our own larger dataset. The dataset\nconsists of a collection of essays from Paul Graham\u2019s blog. This should more\nclosely replicate a real world scenario where a company runs RAG on a larger\ninternal dataset. To add the essays, download them from [ our Github\n](https://github.com/TonicAI/llama-validate-demo/blob/main/data.zip) and unzip\nthem inside the root folder of your created project. Make sure the unzipped\nfolder is named ` data ` . Be sure to delete any existing files in the folder\nbefore copying the new dataset.\n\nAfter you have the essays in the right directory, you can set up your OpenAI\nAPI key by setting it as an environment variable called ` OPENAI_API_KEY ` .\nYou can do this either via setting the environment variable system wide or by\ncreating a ` .env ` file in the root folder of your ` create-llama ` project.\nThen you can run the following commands in the root folder for your ` create-\nllama ` project:\n\n    \n    \n    poetry install\n    poetry shell\n    python app/engine/generate.py\n\nThis will install the dependencies and generate the RAG embeddings for the\nPaul Graham essays. After this, you can run the chatbot with:\n\n    \n    \n    python main.py\n\nTo test the chatbot, you can send a request via curl:\n\n    \n    \n    curl - location 'localhost:8000/api/chat' \\\n     - header 'Content-Type: application/json' \\\n     - data '{ \"messages\": [{ \"role\": \"user\", \"content\": \"In the early days, how were the Airbnb founders financing their startup?\" }] }'\n\nLlamaIndex will then return a response:\n\n    \n    \n    {\n        \"result\": {\n            \"role\": \"assistant\",\n            \"content\": \"In the early days, the Airbnb founders financed their startup by creating and selling themed breakfast cereals. They created limited-edition cereal boxes, such as \\\"Obama O's\\\" and \\\"Cap'n McCain's,\\\" during the 2008 U.S. presidential election, which became a collectible and helped them raise funds for their company. This creative approach to funding allowed them to sustain the business in its initial phase before securing more traditional forms of investment.\"\n        }\n    }\n\nFinally, in ` llama-validate-demo/app/api/routers/chat.py ` we want to replace\nthe ` return _Result ` line at the end of the chat function with the\nfollowing.\n\n    \n    \n    return _Result(\n        result=_Message(\n            role=MessageRole.ASSISTANT,\n            content=response.response,\n            context=[x.text for x in response.source_nodes]\n        )\n    )\n\nThis allows the LlamaIndex API to return the RAG context that was used to\nanswer the question asked. Now, we can move on to setting up Tonic Validate!", "mimetype": "text/plain", "start_char_idx": 2131, "end_char_idx": 5867, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "df7eafcc-1372-4b44-839a-cd102e30a46a": {"__data__": {"id_": "df7eafcc-1372-4b44-839a-cd102e30a46a", "embedding": null, "metadata": {"Header_1": " Setting up Tonic Validate", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18", "node_type": "4", "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "833bde702cdf6187927ff5bebb67291677f77dc2e3e2adf4665d7c7ccc8d6713", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7a437738-90e1-4457-bc7d-add2680b07bf", "node_type": "1", "metadata": {"Header_1": " Setting up LlamaIndex", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "1046464a983d84fc07493cb6ed75f0016a3bbfbefa8454a616a94e5acffb2ef5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67f9bd3b-6843-4327-96b1-f2cceb6bfb2a", "node_type": "1", "metadata": {"Header_1": " Setting up GitHub Actions"}, "hash": "ca61f31bc02ff98a5ff0b374a9eaf7781713965bc403aa744a98a83c6936dd8b", "class_name": "RelatedNodeInfo"}}, "text": "Setting up Tonic Validate\n\nTo set up Tonic Validate, first install it via poetry:\n\n    \n    \n    poetry add tonic-validate\n\nNow, we can create our tests for Tonic Validate. To get started, create a file\ninside ` llama-validate-demo/tests ` called ` validate_test.py ` . We will\nalso need to create a list of test questions and answers which you can find [\nhere ](https://github.com/TonicAI/llama-validate-\ndemo/blob/main/tests/qa_pairs.json) . Alternatively, you can also use the\nTonic Validate UI to create the test set and call it via the SDK \u2014 we\u2019ll be\nadding a feature to help generate these benchmarks using synthetic data to\nmake this process even easier. Download the ` qa_pairs.json ` file from the\nlink and paste it into ` llama-validate-demo/tests ` . Once we have both of\nthese files, we can add the following code into ` validate_test.py ` .\n\n    \n    \n    import json\n    import os\n    from tonic_validate import ValidateApi\n    from tonic_validate.metrics import AnswerSimilarityMetric, RetrievalPrecisionMetric, AugmentationPrecisionMetric, AnswerConsistencyMetric\n    from llama_index.evaluation import TonicValidateEvaluator\n    import requests\n    \n    from dotenv import load_dotenv\n    \n    load_dotenv()\n    \n    def get_llm_response(prompt):\n        url = \"http://localhost:8000/api/chat\"\n    \n        payload = json.dumps({\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": prompt\n                }\n            ]\n        })\n        headers = { 'Content-Type': 'application/json' }\n        response = requests.request(\"POST\", url, headers=headers, data=payload).json()\n        result = response['result']\n        return result['content'], result['context']\n\nThis code sets up the dependency imports and also specifies a `\nget_llm_response ` function which sends a request to the LlamaIndex API server\nwe set up earlier to get a response. Now, let\u2019s create a function that gets\nthe list of questions to ask LlamaIndex for our testing.\n\n    \n    \n    def get_q_and_a():\n        # Load qa_pairs.json\n        qa_pairs = json.load(open('./tests/qa_pairs.json'))\n        return ([x['question'] for x in qa_pairs], [x['answer'] for x in qa_pairs])\n\nThis function gets the question-answer pairs from our json file. The questions\nare what we will ask the RAG system and the answers are the correct answers\nfor those questions. For instance, if the question was \u201cWhat is the capital of\nFrance?\u201d then the answer would be \u201cParis\u201d.\n\nNext, we can add the code that queries LlamaIndex:\n\n    \n    \n    def get_responses(questions):\n        llm_answers = []\n        context_lists = []\n        for item in questions:\n            llm_answer, llm_context_list = get_llm_response(item)\n            llm_answers.append(llm_answer)\n            context_lists.append(llm_context_list)\n        return (llm_answers, context_lists)\n\nThis code iterates over the questions, queries LlamaIndex, and logs each\nresponse into an array. We have two arrays. One is the actual answer from\nLlamaIndex. The other is a list of the snippets of text (called the context\nlist) that LlamaIndex provided to help the LLM answer the question.\n\nNow we have a list of LLM responses generated from a list of test questions.\nLet\u2019s score them:\n\n    \n    \n    def score_run(questions, context_lists, reference_answers, llm_answers):\n        metrics = [\n            AnswerSimilarityMetric(),\n            RetrievalPrecisionMetric(),\n            AugmentationPrecisionMetric(),\n            AnswerConsistencyMetric()\n        ]\n        scorer = TonicValidateEvaluator(metrics, model_evaluator=\"gpt-4-1106-preview\")\n        run = scorer.evaluate_run(\n            questions, llm_answers, context_lists, reference_answers\n        )\n        return run, metrics\n\nWe first need to define the metrics in Tonic Validate that we want to use. You\ncan find a list of available metrics and their definitions [ here\n](https://github.com/TonicAI/tonic_validate?tab=readme-ov-file#tonic-validate-\nmetrics) . After we create the metrics, we can take advantage of Tonic\nValidate\u2019s integration with LlamaIndex. Since Tonic Validate is built into\nLlamaIndex\u2019s evaluation framework as an evaluator, all we need to do is create\na ` TonicValidateEvaluator ` , which scores the LlamaIndex responses across\nthe chosen metrics. Then we return the results along with the metrics.\n\nFinally, we can create our test function for pytest which evaluates\nLlamaIndex.\n\n    \n    \n    def test_llama_index():\n        questions, reference_answers = get_q_and_a()\n        llm_answers, context_lists = get_responses(questions)\n        run, metrics = score_run(questions, context_lists, reference_answers, llm_answers)\n        # Upload results to web ui\n        validate_api = ValidateApi()\n        # Get project id from env\n        project_id = os.getenv(\"PROJECT_ID\")\n        validate_api.upload_run(project_id, run)\n\nThis runs all the code we\u2019ve written to get the scores and then sends them to\nTonic Validate\u2019s API to visualize in the UI. In order to send the metrics for\neach run to the UI, you need to sign up for a free account, which you can do [\nhere ](https://validate.tonic.ai/) . I highly recommend utilizing the UI to\nmake visualizing and monitoring performance changes a breeze. Once you sign\nup, you will be taken through a short onboarding process where you create an\nAPI key and a project. The API key should be stored in an environment variable\ncalled ` TONIC_VALIDATE_API_KEY ` and the project ID in an environment\nvariable called ` PROJECT_ID ` .\n\nOnce you have set up your account and configured your environment variables,\nyou can run the test via the following commands:\n\n    \n    \n    poetry shell\n    pytest\n\nYou can also make the test fail if the metrics score too low. This would be a\npertinent step to add in if you want to avoid introducing breaking changes to\na production RAG system; for example, if you update the model version and the\nanswer similarity score suddenly drop below a certain threshold, you could\nhave the test fail and issue a warning to debug the issue.\n\n    \n    \n    # Check none of the metrics scored too low    \n    for metric in metrics:\n        if metric.name == AnswerSimilarityMetric.name:\n            assert run.overall_scores[metric.name] &gt;= 3.5\n        else:\n            assert run.overall_scores[metric.name] &gt;= 0.7", "mimetype": "text/plain", "start_char_idx": 5872, "end_char_idx": 12237, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67f9bd3b-6843-4327-96b1-f2cceb6bfb2a": {"__data__": {"id_": "67f9bd3b-6843-4327-96b1-f2cceb6bfb2a", "embedding": null, "metadata": {"Header_1": " Setting up GitHub Actions", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18", "node_type": "4", "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "833bde702cdf6187927ff5bebb67291677f77dc2e3e2adf4665d7c7ccc8d6713", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "df7eafcc-1372-4b44-839a-cd102e30a46a", "node_type": "1", "metadata": {"Header_1": " Setting up Tonic Validate", "filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}, "hash": "b6e3614d87dd12efd3c9ffb155d9b9c9a87db8b0d4b541f069eb1c5fe2dc2f45", "class_name": "RelatedNodeInfo"}}, "text": "Setting up GitHub Actions\n\nWith LlamaIndex and Tonic Validate configured, we have the ability to connect\ndata to an LLM and measure the accuracy of LLM responses. You can push this\nsetup into production and have a functional chatbot. As is common in modern\nsoftware development practices, you will likely continue to fix bugs, make\nimprovements, and add new data or features to your RAG system. Before pushing\nto production, QA testing is in place to catch any changes to your code that\nmay introduce unintended effects. For example, adding a new dataset or\nupdating an LLM to a new version could lead to changes in the quality of\nresponses. One approach, the one that we recommend, for adding QA testing for\nyour RAG system is to use GitHub Actions to establish an integration test\nusing Tonic Validate that checks the LLM response quality of your RAG system,\nallowing you to catch and rectify any performance degradation before it is\npushed into production.\n\nTo set up Tonic Validate to run in GitHub Actions, we can create a folder `\nllama-validate-demo/.github/workflows ` with a file called ` python-app.yml `\n. In this file, we will include the following code configuration that defines\nthe integration test workflow:\n\n    \n    \n    # This workflow will install Python dependencies and run tests with LlamaIndex\n    \n    name: Python application\n    \n    on:\n      push:\n        branches: [ \"main\" ]\n      pull_request:\n        branches: [ \"main\" ]\n    \n    permissions:\n      contents: read\n    \n    jobs:\n      build:\n    \n        runs-on: ubuntu-latest\n        environment: Actions\n    \n        steps:\n        - uses: actions/checkout@v3\n        - name: Set up Python 3.11\n          uses: actions/setup-python@v3\n          with:\n            python-version: \"3.11\"\n        - name: Install dependencies\n          run: |\n            python -m pip install --upgrade pip\n            pip install poetry\n            poetry config virtualenvs.create false\n            poetry install --no-root --no-dev --no-directory\n        - name: Set PYTHONPATH\n          run: echo \"PYTHONPATH=$GITHUB_WORKSPACE\" &gt;&gt; $GITHUB_ENV\n        - name: Set up vector index\n          env:\n            OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n          run: |\n            python app/engine/generate.py\n        - name: Start up test server\n          env:\n            OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n            MODEL: gpt-4-1106-preview\n          run: |\n            python main.py &amp;\n            sleep 10\n        - name: Test with pytest\n          env:\n            OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n            TONIC_VALIDATE_API_KEY: ${{ secrets.TONIC_VALIDATE_API_KEY }}\n            PROJECT_ID: ${{ secrets.PROJECT_ID }}\n          run: |\n            pytest\n\nThis configures GitHub to run the tests defined with Tonic Validate upon every\ncommit. The GitHub Actions configuration downloads the repo, sets up the\ndependencies, generates the embeddings, and then starts up the test server and\nruns the test.\n\nAfter this file is set up, we just need to set our secrets in GitHub. In\nGitHub, go to ` Settings > Secrets and variables > Actions ` for your repo and\ncreate a secret called ` OPENAI_API_KEY ` , ` TONIC_VALIDATE_API_KEY ` , and `\nPROJECT_ID ` . These values will all be the same as the values you set\nearlier. Now your GitHub actions set up is complete and you can proactively\nmonitor changes to your RAG system during development and before going into\nproduction.\n\nTry pushing some commits to it and watch it run! To view the results, go to [\nTonic Validate\u2019s web app ](https://validate.tonic.ai/) and navigate to your\nproject. You should see a view like this that shows recent metrics and their\nevolution over time:\n\nNow you and your team can track your RAG system\u2019s performance over time to\nmake sure there aren\u2019t any dips in performance! Thank you for reading and make\nsure to check out Tonic Validate!\n\n_For more information on Tonic Validate, visit our_ [ _website_\n](https://www.tonic.ai/validate) _and sign up for a_ [ _free account_\n](https://validate.tonic.ai/signup) _today. You can also visit our GitHub_ [\n_page_ ](https://github.com/TonicAI/llama-validate-demo) _to view all of the\ncode used in this post and the rest of our SDK. Our LlamaIndex integration is\navailable_ [ _here_ ](https://github.com/run-\nllama/llama_index/blob/main/docs/examples/evaluation/TonicValidateEvaluators.ipynb)\n_._", "mimetype": "text/plain", "start_char_idx": 12242, "end_char_idx": 16672, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"300e3744-518b-43cd-be30-fc67c409109c": {"doc_hash": "673e3ccdf19d293c12ca6fc980e71eddbb1b3754ea44391d78ad2e9659c3f316", "ref_doc_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18"}, "a8343567-ef22-4060-9b9e-b745e8220f46": {"doc_hash": "120a7e62d0e27c0c942ef18dc4f78f57b82faebb5a9101c266006a51748142af", "ref_doc_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18"}, "938ac513-cf61-4871-bd09-8689b106d943": {"doc_hash": "6d8efc9a3e67a4a42644a3edef1895664e3619b0fa6983349e4e340ee9e8a57a", "ref_doc_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18"}, "7a437738-90e1-4457-bc7d-add2680b07bf": {"doc_hash": "1046464a983d84fc07493cb6ed75f0016a3bbfbefa8454a616a94e5acffb2ef5", "ref_doc_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18"}, "df7eafcc-1372-4b44-839a-cd102e30a46a": {"doc_hash": "b6e3614d87dd12efd3c9ffb155d9b9c9a87db8b0d4b541f069eb1c5fe2dc2f45", "ref_doc_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18"}, "67f9bd3b-6843-4327-96b1-f2cceb6bfb2a": {"doc_hash": "c7fa6b8f8d41594cc31b7eee5fbb23f6a3b76904453ee04290ef48bf75ae91d2", "ref_doc_id": "f64c4bd0-ea00-46cc-a1fe-7994ba591c18"}}, "docstore/ref_doc_info": {"f64c4bd0-ea00-46cc-a1fe-7994ba591c18": {"node_ids": ["300e3744-518b-43cd-be30-fc67c409109c", "a8343567-ef22-4060-9b9e-b745e8220f46", "938ac513-cf61-4871-bd09-8689b106d943", "7a437738-90e1-4457-bc7d-add2680b07bf", "df7eafcc-1372-4b44-839a-cd102e30a46a", "67f9bd3b-6843-4327-96b1-f2cceb6bfb2a"], "metadata": {"filename": "tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9.md", "extension": ".md", "title": "Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex", "date": "Jan 26, 2024", "url": "https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9"}}}}